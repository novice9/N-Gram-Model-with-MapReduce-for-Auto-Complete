thread-5: Start crawling
WebPage index: 00000
English language
English i / ˈ ɪ ŋ ɡ l ɪ ʃ / is a West Germanic language that was first spoken in early medieval England and is now the global lingua franca . [4] [5] Named after the Angles , one of the Germanic tribes that migrated to England , it ultimately derives its name from the Anglia (Angeln) peninsula in the Baltic Sea . It is closely related to the Frisian languages , but its vocabulary has been significantly influenced by other Germanic languages , as well as by Latin and Romance languages , [6] particularly French .
English is either the official language or one of the official languages in almost 60 sovereign states . It is the most commonly spoken language in the United Kingdom, the United States, Canada, Australia, Ireland, and New Zealand, and is widely spoken in some areas of the Caribbean , Africa, and South Asia. [7] It is the third most common native language in the world, after Mandarin and Spanish . [8] It is the most widely learned second language and an official language of the United Nations , of the European Union , and of many other world and regional international organisations. It is the most widely spoken Germanic language, accounting for at least 70% of speakers of this Indo-European branch.
English has developed over the course of more than 1,400 years. The earliest forms of English, a set of Anglo-Frisian dialects brought to Great Britain by Anglo-Saxon settlers in the fifth century, are called Old English . Middle English began in the late 11th century with the Norman conquest of England , and was a period in which the language was influenced by French. [9] Early Modern English began in the late 15th century with the introduction of the printing press to London and the King James Bible , and the start of the Great Vowel Shift . [10] Through the worldwide influence of the British Empire , modern English spread around the world from the 17th to mid-20th centuries. Through all types of printed and electronic media, as well as the emergence of the United States as a global superpower , English has become the leading language of international discourse and the lingua franca in many regions and in professional contexts such as science, navigation, and law. [11]
Modern English grammar is the result of a gradual change from a typical Indo-European dependent marking pattern with a rich inflectional morphology and relatively free word order , to a mostly analytic pattern with little inflection , a fairly fixed SVO word order and a complex syntax . [12] Modern English relies more on auxiliary verbs and word order for the expression of complex tenses , aspect and mood , as well as passive constructions , interrogatives and some negation . Despite noticeable variation among the accents and dialects of English used in different countries and regions – in terms of phonetics and phonology , and sometimes also vocabulary , grammar and spelling – English-speakers from around the world are able to communicate with one another with relative ease .

Classification
English is an Indo-European language , and belongs to the West Germanic group of the Germanic languages . [13] Most closely related to English are the Frisian languages , and English and Frisian form the Anglo-Frisian subgroup within West Germanic. Old Saxon and its descendent Low German (Low Saxon) languages are also closely related, and sometimes Low German, English, and Frisian are grouped together as the Ingvaeonic or North Sea Germanic languages. [14] Modern English descends from Middle English , which in turn descends from Old English . [15] Particular dialects of Old and Middle English also developed into a number of other English (Anglic) languages , including Scots [16] and the extinct Fingallian and Forth and Bargy (Yola) dialects of Ireland. [17]
English is classified as a Germanic language because it shares innovations with other Germanic languages such as Dutch , German , and Swedish . [18] These shared innovations show that the languages have descended from a single common ancestor, which linguists call Proto-Germanic . Some shared features of Germanic languages are the use of modal verbs , the division of verbs into strong and weak classes, and the sound changes affecting Proto-Indo-European consonants, known as Grimm's and Verner's laws . Through Grimm's law, the word for foot begins with /f/ in Germanic languages, but its cognates in other Indo-European languages begin with /p/ . English is classified as an Anglo-Frisian language because Frisian and English share other features, such as the palatalisation of consonants that were velar consonants in Proto-Germanic (see Phonological history of Old English § Palatalization ). [19]
English, like the other insular Germanic languages, Icelandic and Faroese , developed independently of the continental Germanic languages and their influences. English is thus not mutually intelligible with any continental Germanic language, differing in vocabulary , syntax , and phonology , although some, such as Dutch, do show strong affinities with English, especially with its earlier stages. [20]
Because English through its history has changed considerably in response to contact with other languages, particularly Old Norse and Norman French , some scholars have argued that English can be considered a mixed language or a creole – a theory called the Middle English creole hypothesis . Although the high degree of influence from these languages on the vocabulary and grammar of Modern English is widely acknowledged, most specialists in language contact do not consider English to be a true mixed language. [21] [22]

History

Proto-Germanic to Old English
The earliest form of English is called Old English or Anglo-Saxon (c. 550–1066 CE). Old English developed from a set of North Sea Germanic dialects originally spoken along the coasts of Frisia , Lower Saxony , Jutland , and Southern Sweden by Germanic tribes known as the Angles , Saxons , and Jutes . In the fifth century, the Anglo-Saxons settled Britain and the Romans withdrew from Britain . By the seventh century, the Germanic language of the Anglo-Saxons became dominant in Britain, replacing the languages of Roman Britain (43–409 CE): Common Brittonic , a Celtic language , and Latin , brought to Britain by the Roman occupation . [23] [24] [25] England and English (originally Ænglaland and Ænglisc ) are named after the Angles. [26]
Old English was divided into four dialects: the Anglian dialects, Mercian and Northumbrian , and the Saxon dialects, Kentish and West Saxon . [27] Through the educational reforms of King Alfred in the ninth century and the influence of the kingdom of Wessex , the West Saxon dialect became the standard written variety . [28] The epic poem Beowulf is written in West Saxon, and the earliest English poem, Cædmon's Hymn , is written in Northumbrian. [29] Modern English developed mainly from Mercian, but the Scots language developed from Northumbrian. A few short inscriptions from the early period of Old English were written using a runic script . [30] By the sixth century, a Latin alphabet was adopted, written with half-uncial letterforms . It included the runic letters wynn ⟨ ƿ ⟩ and thorn ⟨ þ ⟩, and the modified Latin letters eth ⟨ ð ⟩, and ash ⟨ æ ⟩. [30] [31]
Old English is very different from Modern English and difficult for 21st-century English speakers to understand. Its grammar was similar to that of modern German , and its closest relative is Old Frisian . Nouns, adjectives, pronouns, and verbs had many more inflectional endings and forms , and word order was much freer than in Modern English. Modern English has case forms in pronouns ( he , him , his ) and a few verb endings ( I have , he has ), but Old English had case endings in nouns as well, and verbs had more person and number endings. [32] [33] [34]
The translation of Matthew 8:20 from 1000 CE shows examples of case endings ( nominative plural, accusative plural, genitive singular) and a verb ending ( present plural):

Middle English
In the period from the 8th to the 12th century, Old English gradually transformed through language contact into Middle English . Middle English is often arbitrarily defined as beginning with the conquest of England by William the Conqueror in 1066, but it developed further in the period from 1200–1450.
First, the waves of Norse colonisation of northern parts of the British Isles in the 8th and 9th centuries put Old English into intense contact with Old Norse , a North Germanic language. Norse influence was strongest in the Northeastern varieties of Old English spoken in the Danelaw area around York, which was the centre of Norse colonisation; today these features are still particularly present in Scots and Northern English . However the centre of norsified English seems to have been in the Midlands around Lindsey , and after 920 CE when Lindsey was reincorporated into the Anglo-Saxon polity, Norse features spread from there into English varieties that had not been in intense contact with Norse speakers. Some elements of Norse influence that persist in all English varieties today are the pronouns beginning with th- ( they, them, their ) which replaced the Anglo-Saxon pronouns with h- ( hie, him, hera ). [37]
With the Norman conquest of England in 1066, the now norsified Old English language was subject to contact with the Old Norman language, a Romance language closely related to Modern French . The Norman language in England eventually developed into Anglo-Norman . Because Norman was spoken primarily by the elites and nobles, while the lower classes continued speaking Anglo-Saxon, the influence of Norman consisted of introducing a wide range of loanwords related to politics, legislation and prestigious social domains. [38] Middle English also greatly simplified the inflectional system, probably in order to reconcile Old Norse and Old English, which were inflectionally different but morphologically similar. The distinction between nominative and accusative case was lost except in personal pronouns, the instrumental case was dropped, and the use of the genitive case was limited to describing possession . The inflectional system regularised many irregular inflectional forms, [39] and gradually simplified the system of agreement, making word order less flexible. [40] By the Wycliffe Bible of the 1380s, the passage Matthew 8:20 was written
Here the plural suffix -n on the verb have is still retained, but none of the case endings on the nouns are present.
By the 12th century Middle English was fully developed, integrating both Norse and Norman features; it continued to be spoken until the transition to early Modern English around 1500. Middle English literature includes Geoffrey Chaucer 's The Canterbury Tales , and Malory's Le Morte d'Arthur . In the Middle English period the use of regional dialects in writing proliferated, and dialect traits were even used for effect by authors such as Chaucer.

Early Modern English
The next period in the history of English was Early Modern English (1500–1700). Early Modern English was characterised by the Great Vowel Shift (1350–1700), inflectional simplification, and linguistic standardisation.
The Great Vowel Shift affected the stressed long vowels of Middle English. It was a chain shift , meaning that each shift triggered a subsequent shift in the vowel system. Mid and open vowels were raised , and close vowels were broken into diphthongs . For example, the word bite was originally pronounced as the word beet is today, and the second vowel in the word about was pronounced as the word boot is today. The Great Vowel Shift explains many irregularities in spelling, since English retains many spellings from Middle English, and it also explains why English vowel letters have very different pronunciations from the same letters in other languages. [42] [43]
English began to rise in prestige during the reign of Henry V . Around 1430, the Court of Chancery in Westminster began using English in its official documents , and a new standard form of Middle English, known as Chancery Standard , developed from the dialects of London and the East Midlands . In 1476, William Caxton introduced the printing press to England and began publishing the first printed books in London, expanding the influence of this form of English. [44] Literature from the Early Modern period includes the works of William Shakespeare and the translation of the Bible commissioned by King James I . Even after the vowel shift the language still sounded different from Modern English: for example, the consonant clusters /kn ɡn sw/ in knight , gnat , and sword were still pronounced. Many of the grammatical features that a modern reader of Shakespeare might find quaint or archaic represent the distinct characteristics of Early Modern English. [45]
In the 1611 King James Version of the Bible, written in Early Modern English, Matthew 8:20 says:
This exemplifies the loss of case and its effects on sentence structure (replacement with Subject-Verb-Object word order, and the use of of instead of the non-possessive genitive), and the introduction of loanwords from French ( ayre ) and word replacements ( bird originally meaning "nestling" had replaced OE fugol ).

Spread of Modern English
By the late 18th century, the British Empire had facilitated the spread of English through its colonies and geopolitical dominance. Commerce, science and technology, diplomacy, art, and formal education all contributed to English becoming the first truly global language. English also facilitated worldwide international communication. [46] [47] As England continued to form new colonies, these in turn became independent and developed their own norms for how to speak and write the language. English was adopted in North America, India, parts of Africa, Australasia, and many other regions. In the post-colonial period, some of the newly created nations that had multiple indigenous languages opted to continue using English as the official language to avoid the political difficulties inherent in promoting any one indigenous language above the others. [48] [49] [50] In the 20th century the growing economic and cultural influence of the United States and its status as a superpower following the Second World War has, along with worldwide broadcasting in English by the BBC [51] and other broadcasters, significantly accelerated the spread of the language across the planet. [52] [53] By the 21st century, English was more widely spoken and written than any language has ever been. [54]
A major feature in the early development of Modern English was the codification of explicit norms for standard usage, and their dissemination through official media such as public education and state sponsored publications. In 1755 Samuel Johnson published his A Dictionary of the English Language which introduced a standard set of spelling conventions and usage norms. In 1828, Noah Webster published the American Dictionary of the English language in an effort to establish a norm for speaking and writing American English that was independent from the British standard. Within Britain, non-standard or lower class dialect features were increasingly stigmatised, leading to the quick spread of the prestige varieties among the middle classes. [55]
In terms of grammatical evolution, Modern English has now reached a stage where the loss of case is almost complete (case is now only found in pronouns, such as he and him , she and her , who and whom ), and where SVO word-order is mostly fixed. [55] Some changes, such as the use of do-support have become universalised. (Earlier English did not use the word "do" as a general auxiliary as Modern English does; at first it was only used in question constructions where it was not obligatory. [56] Now, do-support with the verb have is becoming increasingly standardised.) The use of progressive forms in -ing , appears to be spreading to new constructions, and forms such as had been being built are becoming more common. Regularisation of irregular forms also slowly continues (e.g. dreamed instead of dreamt ), and analytical alternatives to inflectional forms are becoming more common (e.g. more polite instead of politer ). British English is also undergoing change under the influence of American English, fuelled by the strong presence of American English in the media and the prestige associated with the US as a world power. [57] [58] [59]

Geographical distribution
As of 2016, 400 million people spoke English as their first language , and 1.1 billion spoke it as a secondary language. [60] English is probably the third largest language by number of native speakers, after Mandarin and Spanish . [8] However, when combining native and non-native speakers it may, depending on the estimate used, be the most commonly spoken language in the world. [54] [61] [62] [63] English is spoken by communities on every continent and on oceanic islands in all the major oceans. [64] The countries in which English is spoken can be grouped into different categories by how English is used in each country. The "inner circle" [65] countries with many native speakers of English share an international standard of written English and jointly influence speech norms of English around the world. English does not belong to just one country, and it does not belong solely to descendants of English settlers. English is an official language of countries populated by few descendants of native speakers of English. It has also become by far the most important language of international communication when people who share no native language meet anywhere in the world.

Three circles of English-speaking countries
Braj Kachru distinguishes countries where English is spoken with a three circles model . [65] In his model, the "inner circle" countries are countries with large communities of native speakers of English, "outer circle" countries have small communities of native speakers of English but widespread use of English as a second language in education or broadcasting or for local official purposes, and "expanding circle" countries are countries where many learners learn English as a foreign language. Kachru bases his model on the history of how English spread in different countries, how users acquire English, and the range of uses English has in each country. The three circles change membership over time. [66]
Countries with large communities of native speakers of English (the inner circle) include Britain, the United States, Australia, Canada, Ireland, and New Zealand, where the majority speaks English, and South Africa, where a significant minority speaks English. The countries with the most native English speakers are, in descending order, the United States (at least 231 million), [67] the United Kingdom (60 million), [68] [69] [70] Canada (19 million), [71] Australia (at least 17 million), [72] South Africa (4.8 million), [73] Ireland (4.2 million), and New Zealand (3.7 million). [74] In these countries, children of native speakers learn English from their parents, and local people who speak other languages or new immigrants learn English to communicate in their neighbourhoods and workplaces. [75] The inner-circle countries provide the base from which English spreads to other countries in the world. [66]
Estimates of the number of English speakers who are second language and foreign-language speakers vary greatly from 470 million to more than 1,000 million depending on how proficiency is defined. [7] Linguist David Crystal estimates that non-native speakers now outnumber native speakers by a ratio of 3 to 1. [61] In Kachru's three-circles model, the "outer circle" countries are countries such as the Philippines , [76] Jamaica , [77] India, Pakistan [ citation needed ] , Singapore, [78] and Nigeria [79] [80] with a much smaller proportion of native speakers of English but much use of English as a second language for education, government, or domestic business, and where English is routinely used for school instruction and official interactions with the government. [81] Those countries have millions of native speakers of dialect continua ranging from an English-based creole to a more standard version of English. They have many more speakers of English who acquire English in the process of growing up through day by day use and listening to broadcasting, especially if they attend schools where English is the medium of instruction. Varieties of English learned by speakers who are not native speakers born to English-speaking parents may be influenced, especially in their grammar, by the other languages spoken by those learners. [75] Most of those varieties of English include words little used by native speakers of English in the inner-circle countries, [75] and they may have grammatical and phonological differences from inner-circle varieties as well. The standard English of the inner-circle countries is often taken as a norm for use of English in the outer-circle countries. [75]
In the three-circles model, countries such as Poland, China, Brazil, Germany, Japan, Indonesia, Egypt, and other countries where English is taught as a foreign language make up the "expanding circle". [82] The distinctions between English as a first language, as a second language, and as a foreign language are often debatable and may change in particular countries over time. [81] For example, in the Netherlands and some other countries of Europe, knowledge of English as a second language is nearly universal, with over 80 percent of the population able to use it, [83] and thus English is routinely used to communicate with foreigners and often in higher education. In these countries, although English is not used for government business, the widespread use of English in these countries puts them at the boundary between the "outer circle" and "expanding circle". English is unusual among world languages in how many of its users are not native speakers but speakers of English as a second or foreign language. [84] Many users of English in the expanding circle use it to communicate with other people from the expanding circle, so that interaction with native speakers of English plays no part in their decision to use English. [85] Non-native varieties of English are widely used for international communication, and speakers of one such variety often encounter features of other varieties. [86] Very often today a conversation in English anywhere in the world may include no native speakers of English at all, even while including speakers from several different countries. [87]

Pluricentric English
English is a pluricentric language , which means that no one national authority sets the standard for use of the language. [88] [89] [90] [91] But English is not a divided language, [92] despite a long-standing joke originally attributed to George Bernard Shaw that the United Kingdom and the United States are "two countries separated by a common language". [93] Spoken English, for example English used in broadcasting, generally follows national pronunciation standards that are also established by custom rather than by regulation. International broadcasters are usually identifiable as coming from one country rather than another through their accents , [94] but newsreader scripts are also composed largely in international standard written English . The norms of standard written English are maintained purely by the consensus of educated English-speakers around the world, without any oversight by any government or international organisation. [95] American listeners generally readily understand most British broadcasting, and British listeners readily understand most American broadcasting. Most English speakers around the world can understand radio programmes, television programmes, and films from many parts of the English-speaking world. [96] Both standard and nonstandard varieties of English can include both formal or informal styles, distinguished by word choice and syntax and use both technical and non-technical registers. [97]
The settlement history of the English-speaking inner circle countries outside Britain helped level dialect distinctions and produce koineised forms of English in South Africa, Australia, and New Zealand. [98] The majority of immigrants to the United States without British ancestry rapidly adopted English after arrival. Now the majority of the United States population are monolingual English speakers, [99] [67] although English has been given official status by only 30 of the 50 state governments of the US. [100] [101]

English as a global language
English has ceased to be an "English language" in the sense of belonging only to people who are ethnically English. [102] [103] Use of English is growing country-by-country internally and for international communication. Most people learn English for practical rather than ideological reasons. [104] Many speakers of English in Africa have become part of an "Afro-Saxon" language community that unites Africans from different countries. [105]
As decolonisation proceeded throughout the British Empire in the 1950s and 1960s, former colonies often did not reject English but rather continued to use it as independent countries setting their own language policies. [49] [50] [106] For example, the view of the English language among many Indians has gone from associating it with colonialism to associating it with economic progress, and English continues to be an official language of India. [107] English is also widely used in media and literature, and the number of English language books published annually in India is the third largest in the world after the US and UK. [108] However English is rarely spoken as a first language, numbering only around a couple hundred-thousand people, and less than 5% of the population speak fluent English in India. [109] [110] David Crystal claimed in 2004 that, combining native and non-native speakers, India now has more people who speak or understand English than any other country in the world, [111] but the number of English speakers in India is very uncertain, with most scholars concluding that the United States still has more speakers of English than India. [112]
Modern English, sometimes described as the first global lingua franca , [52] [113] is also regarded as the first world language . [114] [115] English is the world's most widely used language in newspaper publishing, book publishing, international telecommunications, scientific publishing, international trade, mass entertainment, and diplomacy. [115] English is, by international treaty, the basis for the required controlled natural languages [116] Seaspeak and Airspeak, used as international languages of seafaring [117] and aviation. [118] English used to have parity with French & German in scientific research, but now it dominates that field. [119] It achieved parity with French as a language of diplomacy at the Treaty of Versailles negotiations in 1919. [120] By the time of the foundation of the United Nations at the end of World War II , English had become pre-eminent [121] and is now the main worldwide language of diplomacy and international relations. [122] It is one of six official languages of the United Nations. [123] Many other worldwide international organisations, including the International Olympic Committee , specify English as a working language or official language of the organisation.
Many regional international organisations such as the European Free Trade Association , Association of Southeast Asian Nations (ASEAN), [53] and Asia-Pacific Economic Cooperation (APEC) set English as their organisation's sole working language even though most members are not countries with a majority of native English speakers. While the European Union (EU) allows member states to designate any of the national languages as an official language of the Union, in practice English is the main working language of EU organisations. [124]
Although in most countries English is not an official language, it is currently the language most often taught as a foreign language . [52] [53] In the countries of the EU, English is the most widely spoken foreign language in nineteen of the twenty-five member states where it is not an official language (that is, the countries other than the UK, Ireland and Malta ). In a 2012 official Eurobarometer poll, 38 percent of the EU respondents outside the countries where English is an official language said they could speak English well enough to have a conversation in that language. The next most commonly mentioned foreign language, French (which is the most widely known foreign language in the UK and Ireland), could be used in conversation by 12 percent of respondents. [125]
A working knowledge of English has become a requirement in a number of occupations and professions such as medicine [126] and computing. English has become so important in scientific publishing that more than 80 percent of all scientific journal articles indexed by Chemical Abstracts in 1998 were written in English, as were 90 percent of all articles in natural science publications by 1996 and 82 percent of articles in humanities publications by 1995. [127]
Specialised subsets of English arise spontaneously in international communities, for example, among international business people, as an auxiliary language . This has led some scholars to develop the study of English as an auxiliary languages. Globish uses a relatively small subset of English vocabulary (about 1500 words with highest use in international business English) in combination with the standard English grammar. Other examples include Simple English .
The increased use of the English language globally has had an effect on other languages, leading to some English words being assimilated into the vocabularies of other languages. This influence of English has led to concerns about language death , [128] and to claims of linguistic imperialism , [129] and has provoked resistance to the spread of English; however the number of speakers continues to increase because many people around the world think that English provides them with opportunities for better employment and improved lives. [130]
Although some scholars mention a possibility of future divergence of English dialects into mutually unintelligible languages, most think a more likely outcome is that English will continue to function as a koineised language in which the standard form unifies speakers from around the world. [131] English is used as the language for wider communication in countries around the world. [132] Thus English has grown in worldwide use much more than any constructed language proposed as an international auxiliary language , including Esperanto . [133] [134]

Phonology
The phonetics and phonology of English differ between dialects, usually without interfering with mutual communication. Phonological variation affects the inventory of phonemes (speech sounds that distinguish meaning), and phonetic variation is differences in pronunciation of the phonemes. [135] This overview mainly describes the standard pronunciations of the United Kingdom and the United States : Received Pronunciation (RP) and General American (GA) (See Section below on "Dialects, accents and varieties" ). The phonetic symbols used below are from the International Phonetic Alphabet (IPA). [136] [137] [138]

Consonants
Most English dialects share the same 24 consonant phonemes. The consonant inventory shown below is valid for Californian American English, [139] and for RP. [140]
* Conventionally transcribed /r/ .
In the table, when obstruents (stops, affricates, and fricatives) appear in pairs, such as /p b/ , /tʃ dʒ/ , and /s z/ , the first is fortis (strong) and the second is lenis (weak). Fortis obstruents, such as /p tʃ s/ are pronounced with more muscular tension and breath force than lenis consonants, such as /b dʒ z/ , and are always voiceless . Lenis consonants are partly voiced at the beginning and end of utterances, and fully voiced between vowels. Fortis stops such as /p/ have additional articulatory or acoustic features in most dialects: they are aspirated [pʰ] when they occur alone at the beginning of a stressed syllable, often unaspirated in other cases, and often unreleased [p̚ ] or pre-glottalised [ˀp] at the end of a syllable. In a single-syllable word, a vowel before a fortis stop is shortened: thus nip has a noticeably shorter vowel (phonetically, but not phonemically) than nib [nɪˑp̬] ( see below ). [141]
In RP, the lateral approximant /l/ , has two main allophones (pronunciation variants): the clear or plain [l] , as in light , and the dark or velarised [ɫ] , as in full . [142] GA has dark l in most cases. [143]
All sonorants (liquids /l, r/ and nasals /m, n, ŋ/ ) devoice when following a voiceless obstruent, and they are syllabic when following a consonant at the end of a word. [144]

Vowels
The pronunciation of vowels varies a great deal between dialects and is one of the most detectable aspects of a speaker's accent. The table below lists the vowel phonemes in Received Pronunciation (RP) and General American (GA), with examples of words in which they occur from lexical sets compiled by linguists. The vowels are represented with symbols from the International Phonetic Alphabet; those given for RP are standard in British dictionaries and other publications.
In RP, vowel length is phonemic; long vowels are marked with a triangular colon ⟨ ː ⟩ in the table above, such as the vowel of need [niːd] as opposed to bid [bɪd] . GA does not have long vowels.
In both RP and GA, vowels are phonetically shortened before fortis consonants in the same syllable , like /t tʃ f/ , but not before lenis consonants like /d dʒ v/ or in open syllables: thus, the vowels of rich [rɪ̆tʃ] , neat [niˑt] , and safe [sĕɪ̆f] are noticeably shorter than the vowels of ridge [rɪdʒ] , need [niːd] , and save [seɪv] , and the vowel of light [lăɪ̆t] is shorter than that of lie [laɪ] . Because lenis consonants are frequently voiceless at the end of a syllable, vowel length is an important cue as to whether the following consonant is lenis or fortis. [145]
The vowels /ɨ ə/ only occur in unstressed syllables and are a result of vowel reduction . Some dialects do not distinguish them, so that roses and comma end in the same vowel, a dialect feature called weak-vowel merger . GA has an unstressed r -coloured schwa /ɚ/ , as in butter [ˈbʌtɚ] , which in RP has the same vowel as the word-final vowel in comma .

Phonotactics
An English syllable includes a syllable nucleus consisting of a vowel sound. Syllable onset and coda (start and end) are optional. A syllable can start with up to three consonant sounds, as in sprint /sprɪnt/ , and end with up to four, as in texts /teksts/ . This gives an English syllable the following structure, (CCC)V(CCCC) where C represents a consonant and V a vowel. The consonants that may appear together in onsets or codas are restricted, as is the order in which they may appear. Onsets can only have four types of consonant clusters: a stop and approximant, as in play ; a voiceless fricative and approximant, as in fly or sly ; s and a voiceless stop, as in stay ; and s , a voiceless stop, and an approximant, as in string . [146] Clusters of nasal and stop are only allowed in codas. Clusters of obstruents always agree in voicing, and clusters of sibilants and of plosives with the same point of articulation are prohibited. Furthermore, several consonants have limited distributions: /h/ can only occur in syllable initial position, and /ŋ/ only in syllable final position. [147]

Stress, rhythm and intonation
Stress plays an important role in English. Certain syllables are stressed, while others are unstressed. Stress is a combination of duration, intensity, vowel quality, and sometimes changes in pitch. Stressed syllables are pronounced longer and louder than unstressed syllables, and vowels in unstressed syllables are frequently reduced while vowels in stressed syllables are not. [148] Some words, primarily short function words but also some modal verbs such as can , have weak and strong forms depending on whether they occur in stressed or non-stressed position within a sentence.
Stress in English is phonemic , and some pairs of words are distinguished by stress. For instance, the word contract is stressed on the first syllable ( / ˈ k ɒ n t r æ k t / KON -trakt ) when used as a noun, but on the last syllable ( / k ə n ˈ t r æ k t / kən- TRAKT ) for most meanings (for example, "reduce in size") when used as a verb. [149] [150] [151] Here stress is connected to vowel reduction : in the noun "contract" the first syllable is stressed and has the unreduced vowel /ɒ/ , but in the verb "contract" the first syllable is unstressed and its vowel is reduced to /ə/ . Stress is also used to distinguish between words and phrases, so that a compound word receives a single stress unit, but the corresponding phrase has two: e.g. to búrn óut versus a búrnout , and a hótdog versus a hót dóg . [152]
In terms of rhythm , English is generally described as a stress-timed language, meaning that the amount of time between stressed syllables tends to be equal. Stressed syllables are pronounced longer, but unstressed syllables (syllables between stresses) are shortened. Vowels in unstressed syllables are shortened as well, and vowel shortening causes changes in vowel quality : vowel reduction .

Regional variation
Varieties of English vary the most in pronunciation of vowels. The best known national varieties used as standards for education in non English-speaking countries are British (BrE) and American (AmE). Countries such as Canada , Australia , Ireland , New Zealand and South Africa have their own standard varieties which are less often used as standards for education internationally. Some differences between the various dialects are shown in the table "Varieties of Standard English and their features". [153]
English has undergone many historical sound changes , some of them affecting all varieties, and others affecting only a few. Most standard varieties are affected by the Great Vowel Shift , which changed the pronunciation of long vowels, but a few dialects have slightly different results. In North America, a number of chain shifts such as the Northern Cities Vowel Shift and Canadian Shift have produced very different vowel landscapes in some regional accents.
Some dialects have fewer or more consonant phonemes and phones than the standard varieties. Some conservative varieties like Scottish English have a voiceless [ ʍ ] sound in whine that contrasts with the voiced [w] in wine , but most other dialects pronounce both words with voiced [w] , a dialect feature called wine – whine merger . The unvoiced velar fricative sound /x/ is found in Scottish English, which distinguishes loch /lɔx/ from lock /lɔk/ . Accents like Cockney with " h -dropping" lack the glottal fricative /h/ , and dialects with th -stopping and th -fronting like African American Vernacular and Estuary English do not have the dental fricatives /θ, ð/ , but replace them with dental or alveolar stops /t, d/ or labiodental fricatives /f, v/ . [154] [155] Other changes affecting the phonology of local varieties are processes such as yod -dropping , yod -coalescence , and reduction of consonant clusters.
General American and Received Pronunciation vary in their pronunciation of historical /r/ after a vowel at the end of a syllable (in the syllable coda ). GA is a rhotic dialect , meaning that it pronounces /r/ at the end of a syllable, but RP is non-rhotic, meaning that it loses /r/ in that position. English dialects are classified as rhotic or non-rhotic depending on whether they elide /r/ like RP or keep it like GA. [156]
There is complex dialectal variation in words with the open front and open back vowels /æ ɑː ɒ ɔː/ . These four vowels are only distinguished in RP, Australia, New Zealand and South Africa. In GA, these vowels merge to three /æ ɑ ɔ/ , [157] and in Canadian English they merge to two /æ ɑ/ . [158] In addition, the words that have each vowel vary by dialect. The table "Dialects and open vowels" shows this variation with lexical sets in which these sounds occur.

Grammar
As is typical of an Indo-European language, English follows accusative morphosyntactic alignment . English distinguishes at least seven major word classes: verbs, nouns, adjectives, adverbs, determiners (i.e. articles), prepositions, and conjunctions. Some analyses add pronouns as a class separate from nouns, and subdivide conjunctions into subordinators and coordinators, and add the class of interjections. [159] English also has a rich set of auxiliary verbs, such as have and do , expressing the categories of mood and aspect. Questions are marked by do-support , wh-movement (fronting of question words beginning with wh -) and word order inversion with some verbs.
Some traits typical of Germanic languages persist in English, such as the distinction between irregularly inflected strong stems inflected through ablaut (i.e. changing the vowel of the stem, as in the pairs speak/spoke and foot/feet ) and weak stems inflected through affixation (such as love/loved , hand/hands ). Vestiges of the case and gender system are found in the pronoun system ( he/him, who/whom ) and in the inflection of the copula verb to be .
The seven word classes are exemplified in this sample sentence: [160]

Nouns and noun phrases
English nouns are only inflected for number and possession. New nouns can be formed through derivation or compounding. They are semantically divided into proper nouns (names) and common nouns. Common nouns are in turn divided into concrete and abstract nouns, and grammatically into count nouns and mass nouns . [161]
Most count nouns are inflected for plural number through the use of the plural suffix - s , but a few nouns have irregular plural forms. Mass nouns can only be pluralised through the use of a count noun classifier, e.g. one loaf of bread , two loaves of bread . [162]
Regular plural formation:
Irregular plural formation:
Possession can be expressed either by the possessive enclitic - s (also traditionally called a genitive suffix), or by the preposition of . Historically the -s possessive has been used for animate nouns, whereas the of possessive has been reserved for inanimate nouns. Today this distinction is less clear, and many speakers use - s also with inanimates. Orthographically the possessive -s is separated from the noun root with an apostrophe.
Possessive constructions:
Nouns can form noun phrases (NPs) where they are the syntactic head of the words that depend on them such as determiners, quantifiers, conjunctions or adjectives. [163] Noun phrases can be short, such as the man , composed only of a determiner and a noun. They can also include modifiers such as adjectives (e.g. red , tall , all ) and specifiers such as determiners (e.g. the , that ). But they can also tie together several nouns into a single long NP, using conjunctions such as and , or prepositions such as with , e.g. the tall man with the long red trousers and his skinny wife with the spectacles (this NP uses conjunctions, prepositions, specifiers and modifiers). Regardless of length, an NP functions as a syntactic unit. For example, the possessive enclitic can, in cases which do not lead to ambiguity, follow the entire noun phrase, as in The President of India's wife , where the enclitic follows India and not President .
The class of determiners is used to specify the noun they precede in terms of definiteness , where the marks a definite noun and a or an an indefinite one. A definite noun is assumed by the speaker to be already known by the interlocutor, whereas an indefinite noun is not specified as being previously known. Quantifiers, which include one , many , some and all , are used to specify the noun in terms of quantity or number. The noun must agree with the number of the determiner, e.g. one man (sg.) but all men (pl.). Determiners are the first constituents in a noun phrase. [164]

Adjectives
Adjectives modify a noun by providing additional information about their referents. In English, adjectives come before the nouns they modify and after determiners. [165] In Modern English, adjectives are not inflected, and they do not agree in form with the noun they modify, as adjectives in most other Indo-European languages do. For example, in the phrases the slender boy , and many slender girls , the adjective slender does not change form to agree with either the number or gender of the noun.
Some adjectives are inflected for degree of comparison , with the positive degree unmarked, the suffix -er marking the comparative, and -est marking the superlative: a small boy , the boy is smaller than the girl , that boy is the smallest . Some adjectives have irregular comparative and superlative forms, such as good , better , and best . Other adjectives have comparatives formed by periphrastic constructions , with the adverb more marking the comparative, and most marking the superlative: happier or more happy , the happiest or most happy . [166] There is some variation among speakers regarding which adjectives use inflected or periphrastic comparison, and some studies have shown a tendency for the periphrastic forms to become more common at the expense of the inflected form. [167]

Pronouns, case and person
English pronouns conserve many traits of case and gender inflection. The personal pronouns retain a difference between subjective and objective case in most persons ( I/me, he/him, she/her, we/us, they/them ) as well as a gender and animateness distinction in the third person singular (distinguishing he/she/it ). The subjective case corresponds to the Old English nominative case , and the objective case is used both in the sense of the previous accusative case (in the role of patient, or direct object of a transitive verb), and in the sense of the Old English dative case (in the role of a recipient or indirect object of a transitive verb). [168] [169] Subjective case is used when the pronoun is the subject of a finite clause, and otherwise the objective case is used. [170] While grammarians such as Henry Sweet [171] and Otto Jespersen [172] noted that the English cases did not correspond to the traditional Latin based system, some contemporary grammars, for example Huddleston & Pullum (2002) , retain traditional labels for the cases, calling them nominative and accusative cases respectively.
Possessive pronouns exist in dependent and independent forms; the dependent form functions as a determiner specifying a noun (as in my chair ), while the independent form can stand alone as if it were a noun (e.g. the chair is mine ). [173] The English system of grammatical person no longer has a distinction between formal and informal pronouns of address, and the forms for 2nd person plural and singular are identical except in the reflexive form. Some dialects have introduced innovative 2nd person plural pronouns such as y'all found in Southern American English and African American (Vernacular) English or youse and ye found in Irish English.
Pronouns are used to refer to entities deictically or anaphorically . A deictic pronoun points to some person or object by identifying it relative to the speech situation — for example the pronoun I identifies the speaker, and the pronoun you , the addressee. Anaphorical pronouns such as that refer back to an entity already mentioned or assumed by the speaker to be known by the audience, for example in the sentence I already told you that . The reflexive pronouns are used when the oblique argument is identical to the subject of a phrase (e.g. "he sent it to himself" or "she braced herself for impact"). [174]

Prepositions
Prepositional phrases (PP) are phrases composed of a preposition and one or more nouns, e.g. with the dog , for my friend , to school , in England . Prepositions have a wide range of uses in English. They are used to describe movement, place, and other relations between different entities, but they also have many syntactic uses such as introducing complement clauses and oblique arguments of verbs. For example, in the phrase I gave it to him , the preposition to marks the recipient, or Indirect Object of the verb to give . Traditionally words were only considered prepositions if they governed the case of the noun they preceded, for example causing the pronouns to use the objective rather than subjective form, "with her", "to me", "for us". But some contemporary grammars such as that of Huddleston & Pullum (2002 :598–600) no longer consider government of case to be the defining feature of the class of prepositions, rather defining prepositions as words that can function as the heads of prepositional phrases.

Verbs and verb phrases
English verbs are inflected for tense and aspect, and marked for agreement with third person singular subject. Only the copula verb to be is still inflected for agreement with the plural and first and second person subjects. [166] Auxiliary verbs such as have and be are paired with verbs in the infinitive, past, or progressive forms. They form complex tenses, aspects, and moods. Auxiliary verbs differ from other verbs in that they can be followed by the negation, and in that they can occur as the first constituent in a question sentence. [175] [176]
Most verbs have six inflectional forms. The primary forms are a plain present, a third person singular present, and a preterite (past) form. The secondary forms are a plain form used for the infinitive, a gerund–participle and a past participle. [177] The copula verb to be is the only verb to retain some of its original conjugation, and takes different inflectional forms depending on the subject. The first person present tense form is am , the third person singular form is and the form are is used second person singular and all three plurals. The only verb past participle is been and its gerund-participle is being .

Tense, aspect and mood
English has two primary tenses, past (preterit) and non-past. The preterit is inflected by using the preterit form of the verb, which for the regular verbs includes the suffix -ed , and for the strong verbs either the suffix -t or a change in the stem vowel. The non-past form is unmarked except in the third person singular, which takes the suffix -s . [175]
English does not have a morphologised future tense. [178] Futurity of action is expressed periphrastically with one of the auxiliary verbs will or shall . [179] Many varieties also use a near future constructed with the phrasal verb be going to . [180]
Further aspectual distinctions are encoded by the use of auxiliary verbs, primarily have and be , which encode the contrast between a perfect and non-perfect past tense ( I have run vs. I was running ), and compound tenses such as preterite perfect ( I had been running ) and present perfect ( I have been running ). [181]
For the expression of mood, English uses a number of modal auxiliaries, such as can , may , will , shall and the past tense forms could , might , would , should . There is also a subjunctive and an imperative mood, both based on the plain form of the verb (i.e. without the third person singular -s ), and which is used in subordinate clauses (e.g. subjunctive: It is important that he run every day ; imperative Run! ). [179]
An infinitive form, that uses the plain form of the verb and the preposition to , is used for verbal clauses that are syntactically subordinate to a finite verbal clause. Finite verbal clauses are those that are formed around a verb in the present or preterit form. In clauses with auxiliary verbs they are the finite verbs and the main verb is treated as a subordinate clause. For example, he has to go where only the auxiliary verb have is inflected for time and the main verb to go is in the infinitive, or in a complement clause such as I saw him leave , where the main verb is to see which is in a preterite form, and leave is in the infinitive.

Phrasal verbs
English also makes frequent use of constructions traditionally called phrasal verbs , verb phrases that are made up of a verb root and a preposition or particle which follows the verb. The phrase then functions as a single predicate. In terms of intonation the preposition is fused to the verb, but in writing it is written as a separate word. Examples of phrasal verbs are to get up , to ask out , to back up , to give up , to get together , to hang out , to put up with , etc. The phrasal verb frequently has a highly idiomatic meaning that is more specialised and restricted than what can be simply extrapolated from the combination of verb and preposition complement (e.g. lay off meaning terminate someone's employment ). [182] In spite of the idiomatic meaning, some grammarians, including Huddleston & Pullum (2002) :274, do not consider this type of construction to form a syntactic constituent and hence refrain from using the term "phrasal verb". Instead they consider the construction simply to be a verb with a prepositional phrase as its syntactic complement, i.e. he woke up in the morning and he ran up in the mountains are syntactically equivalent.

Adverbs
The function of adverbs is to modify the action or event described by the verb by providing additional information about the manner in which it occurs. Many adverbs are derived from adjectives with the suffix -ly , but not all, and many speakers tend to omit the suffix in the most commonly used adverbs. For example, in the phrase the woman walked quickly the adverb quickly derived from the adjective quick describes the woman's way of walking. Some commonly used adjectives have irregular adverbial forms, such as good which has the adverbial form well .

Syntax
Modern English syntax language is moderately analytic . [183] It has developed features such as modal verbs and word order as resources for conveying meaning. Auxiliary verbs mark constructions such as questions, negative polarity, the passive voice and progressive aspect .

Basic constituent order
English word order has moved from the Germanic verb-second (V2) word order to being almost exclusively subject–verb–object (SVO). [184] The combination of SVO order and use of auxiliary verbs often creates clusters of two or more verbs at the centre of the sentence, such as he had hoped to try to open it .
In most sentences English only marks grammatical relations through word order. [185] The subject constituent precedes the verb and the object constituent follows it. The example below demonstrates how the grammatical roles of each constituent is marked only by the position relative to the verb:
An exception is found in sentences where one of the constituents is a pronoun, in which case it is doubly marked, both by word order and by case inflection, where the subject pronoun precedes the verb and takes the subjective case form, and the object pronoun follows the verb and takes the objective case form. The example below demonstrates this double marking in a sentence where both object and subject is represented with a third person singular masculine pronoun:
Indirect objects (IO) of ditransitive verbs can be placed either as the first object in a double object construction (S V IO O), such as I gave Jane the book or in a prepositional phrase, such as I gave the book to Jane [186]

Clause syntax
In English a sentence may be composed of one or more clauses, that may in turn be composed of one or more phrases (e.g. Noun Phrases, Verb Phrases, and Prepositional Phrases). A clause is built around a verb, and includes its constituents, such as any NPs and PPs. Within a sentence one clause is always the main clause (or matrix clause) whereas other clauses are subordinate to it. Subordinate clauses may function as arguments of the verb in the main clause. For example, in the phrase I think (that) you are lying , the main clause is headed by the verb think , the subject is I , but the object of the phrase is the subordinate clause (that) you are lying . The subordinating conjunction that shows that the clause that follows is a subordinate clause, but it is often omitted. [187] Relative clauses are clauses that function as a modifier or specifier to some constituent in the main clause: For example, in the sentence I saw the letter that you received today , the relative clause that you received today specifies the meaning of the word letter , the object of the main clause. Relative clauses can be introduced by the pronouns who , whose , whom and which as well as by that (which can also be omitted.) [188] In contrast to many other Germanic languages there is no major differences between word order in main and subordinate clauses. [189]

Auxiliary verb constructions
English syntax relies on auxiliary verbs for many functions including the expression of tense, aspect and mood. Auxiliary verbs form main clauses, and the main verbs function as heads of a subordinate clause of the auxiliary verb. For example, in the sentence the dog did not find its bone , the clause find its bone is the complement of the negated verb did not . Subject–auxiliary inversion is used in many constructions, including focus, negation, and interrogative constructions.
The verb do can be used as an auxiliary even in simple declarative sentences, where it usually serves to add emphasis, as in "I did shut the fridge." However, in the negated and inverted clauses referred to above, it is used because the rules of English syntax permit these constructions only when an auxiliary is present. Modern English does not allow the addition of the negating adverb not to an ordinary finite lexical verb, as in *I know not —it can only be added to an auxiliary (or copular ) verb, hence if there is no other auxiliary present when negation is required, the auxiliary do is used, to produce a form like I do not (don't) know. The same applies in clauses requiring inversion, including most questions—inversion must involve the subject and an auxiliary verb, so it is not possible to say *Know you him? ; grammatical rules require Do you know him? [190]
Negation is done with the adverb not , which precedes the main verb and follows an auxiliary verb. A contracted form of not -n't can be used as an enclitic attaching to auxiliary verbs and to the copula verb to be . Just as with questions, many negative constructions require the negation to occur with do-support, thus in Modern English I don't know him is the correct answer to the question Do you know him? , but not *I know him not , although this construction may be found in older English. [191]
Passive constructions also use auxiliary verbs. A passive construction rephrases an active construction in such a way that the object of the active phrase becomes the subject of the passive phrase, and the subject of the active phrase is either omitted or demoted to a role as an oblique argument introduced in a prepositional phrase. They are formed by using the past participle either with the auxiliary verb to be or to get , although not all varieties of English allow the use of passives with get . For example, putting the sentence she sees him into the passive becomes he is seen (by her) , or he gets seen (by her) . [192]

Questions
Both yes–no questions and wh -questions in English are mostly formed using subject–auxiliary inversion ( Am I going tomorrow? , Where can we eat? ), which may require do -support ( Do you like her? , Where did he go? ). In most cases, interrogative words ( wh -words; e.g. what , who , where , when , why , how ) appear in a fronted position . For example, in the question What did you see? , the word what appears as the first constituent despite being the grammatical object of the sentence. (When the wh -word is the subject or forms part of the subject, no inversion occurs: Who saw the cat? .) Prepositional phrases can also be fronted when they are the question's theme, e.g. To whose house did you go last night? . The personal interrogative pronoun who is the only interrogative pronoun to still show inflection for case, with the variant whom serving as the objective case form, although this form may be going out of use in many contexts. [193]

Discourse level syntax
At the discourse level English tends to use a topic-comment structure, where the known information (topic) precedes the new information (comment). Because of the strict SVO syntax, the topic of a sentence generally has to be the grammatical subject of the sentence. In cases where the topic is not the grammatical subject of the sentence, frequently the topic is promoted to subject position through syntactic means. One way of doing this is through a passive construction, the girl was stung by the bee . Another way is through a cleft sentence where the main clause is demoted to be a complement clause of a copula sentence with a dummy subject such as it or there , e.g. it was the girl that the bee stung , there was a girl who was stung by a bee . [194] Dummy subjects are also used in constructions where there is no grammatical subject such as with impersonal verbs (e.g., it is raining ) or in existential clauses ( there are many cars on the street ). Through the use of these complex sentence constructions with informationally vacuous subjects, English is able to maintain both a topic comment sentence structure and a SVO syntax.
Focus constructions emphasise a particular piece of new or salient information within a sentence, generally through allocating the main sentence level stress on the focal constituent. For example, the girl was stung by a bee (emphasising it was a bee and not for example a wasp that stung her), or The girl was stung by a bee (contrasting with another possibility, for example that it was the boy). [195] Topic and focus can also be established through syntactic dislocation, either preposing or postposing the item to be focused on relative to the main clause. For example, That girl over there, she was stung by a bee , emphasises the girl by preposition, but a similar effect could be achieved by postposition, she was stung by a bee, that girl over there , where reference to the girl is established as an "afterthought". [196]
Cohesion between sentences is achieved through the use of deictic pronouns as anaphora (e.g. that is exactly what I mean where that refers to some fact known to both interlocutors, or then used to locate the time of a narrated event relative to the time of a previously narrated event). [197] Discourse markers such as oh , so or well , also signal the progression of ideas between sentences and help to create cohesion. Discourse markers are often the first constituents in sentences. Discourse markers are also used for stance taking in which speakers position themselves in a specific attitude towards what is being said, for example, no way is that true! (the idiomatic marker no way! expressing disbelief), or boy! I'm hungry (the marker boy expressing emphasis). While discourse markers are particularly characteristic of informal and spoken registers of English, they are also used in written and formal registers. [198]

Vocabulary
The vocabulary of English is vast, and counting exactly how many words English (or any language) has is impossible. [199] [200] [201] The Oxford Dictionaries suggest that there are at least a quarter of a million distinct English words. [199] Early studies of English vocabulary by lexicographers , the scholars who formally study vocabulary, compile dictionaries, or both, were impeded by a lack of comprehensive data on actual vocabulary in use from good-quality linguistic corpora , [202] collections of actual written texts and spoken passages. Many statements published before the end of the 20th century about the growth of English vocabulary over time, the dates of first use of various words in English, and the sources of English vocabulary will have to be corrected as new computerised analysis of linguistic corpus data becomes available. [201] [203]

Word formation processes
English forms new words from existing words or roots in its vocabulary through a variety of processes. One of the most productive processes in English is conversion, [204] using a word with a different grammatical role, for example using a noun as a verb or a verb as a noun. Another productive word-formation process is nominal compounding, [201] [203] producing compound words such as babysitter or ice cream or homesick . [204] A process more common in Old English than in Modern English, but still productive in Modern English, is the use of derivational suffixes ( -hood , -ness , -ing , -ility ) to derive new words from existing words (especially those of Germanic origin) or stems (especially for words of Latin or Greek origin). Formation of new words, called neologisms , based on Greek or Latin roots (for example television or optometry ) is a highly productive process in English and in most modern European languages, so much so that it is often difficult to determine in which language a neologism originated. For this reason, lexicographer Philip Gove attributed many such words to the " international scientific vocabulary " (ISV) when compiling Webster's Third New International Dictionary (1961). Another active word-formation process in English is acronyms , [205] words formed by pronouncing as a single word abbreviations of longer phrases (e.g. NATO , laser ).

Word origins
English, besides forming new words from existing words and their roots, also borrows words from other languages. This process of adding words from other languages is commonplace in many world languages, but English is characterised as being especially open to borrowing of foreign words throughout the last 1,000 years. [207] The most commonly used words in English are West Germanic. [208] The words in English learned first by children as they learn to speak, particularly the grammatical words that dominate the word count of both spoken and written texts, are the Germanic words inherited from the earliest periods of the development of Old English. [201] But one of the consequences of long language contact between French and English in all stages of their development is that the vocabulary of English has a very high percentage of "Latinate" words (derived from French, especially, and also from Latin or from other Romance languages). [209] French words from various periods of the development of French now make up one-third of the vocabulary of English. [210]
English has also borrowed many words directly from Latin, the ancestor of the Romance languages, during all stages of its development. [203] [201] Many of these words were earlier borrowed into Latin from Greek. Latin or Greek are still highly productive sources of stems used to form vocabulary of subjects learned in higher education such as the sciences, philosophy, and mathematics. [211] English continues to gain new loanwords and calques ("loan translations") from languages all over the world, and words from languages other than the ancestral Anglo-Saxon language make up about 60 percent of the vocabulary of English. [212] English has formal and informal speech registers , and informal registers, including child directed speech, tend to be made up predominantly of words of Anglo-Saxon origin, while the percentage of vocabulary that is of Latinate origin is higher in legal, scientific, and academic texts. [213] [214]

English loanwords and calques in other languages
English has a strong influence on the vocabulary of other languages. [210] [215] The influence of English comes from such factors as opinion leaders in other countries knowing the English language, the role of English as a world lingua franca, and the large number of books and films that are translated from English into other languages. [216] That pervasive use of English leads to a conclusion in many places that English is an especially suitable language for expressing new ideas or describing new technologies. Among varieties of English, it is especially American English that influences other languages. [217] Some languages, such as Chinese, write words borrowed from English mostly as calques , while others, such as Japanese, readily take in English loanwords written in sound-indicating script. [218] Dubbed films and television programmes are an especially fruitful source of English influence on languages in Europe. [218]

Writing system
Since the ninth century, English has been written in a Latin alphabet (also called Roman alphabet). Earlier Old English texts in Anglo-Saxon runes are only short inscriptions. The great majority of literary works in Old English that survive to today are written in the Roman alphabet. [30] The modern English alphabet contains 26 letters of the Latin script : a , b , c , d , e , f , g , h , i , j , k , l , m , n , o , p , q , r , s , t , u , v , w , x , y , z (which also have capital forms: A, B, C, D, E, F, G, H, I, J, K, L, M, N, O, P, Q, R, S, T, U, V, W, X, Y, Z).
The spelling system, or orthography , of English is multi-layered, with elements of French, Latin, and Greek spelling on top of the native Germanic system. [219] Further complications have arisen through sound changes with which the orthography has not kept pace. [42] Compared to European languages for which official organisations have promoted spelling reforms, English has spelling that is a less consistent indicator of pronunciation and standard spellings of words that are more difficult to guess from knowing how a word is pronounced. [220] There are also systematic spelling differences between British and American English . These situations have prompted proposals for spelling reform in English. [221]
Although letters and speech sounds do not have a one-to-one correspondence in standard English spelling, spelling rules that take into account syllable structure, phonetic changes in derived words, and word accent are reliable for most English words. [222] Moreover, standard English spelling shows etymological relationships between related words that would be obscured by a closer correspondence between pronunciation and spelling, for example the words photograph , photography , and photographic , [222] or the words electricity and electrical . While few scholars agree with Chomsky and Halle (1968) that conventional English orthography is "near-optimal", [219] there is a rationale for current English spelling patterns. [223] The standard orthography of English is the most widely used writing system in the world. [224] Standard English spelling is based on a graphomorphemic segmentation of words into written clues of what meaningful units make up each word. [225]
Readers of English can generally rely on the correspondence between spelling and pronunciation to be fairly regular for letters or digraphs used to spell consonant sounds. The letters b, d, f, h, j, k, l, m, n, p, r, s, t, v, w, y, z represent, respectively, the phonemes /b, d, f, h, dʒ, k, l, m, n, p, r, s, t, v, w, j, z/ . The letters c and g normally represent /k/ and /ɡ/ , but there is also a soft c pronounced /s/ , and a soft g pronounced /dʒ/ . The differences in the pronunciations of the letters c and g are often signalled by the following letters in standard English spelling. Digraphs used to represent phonemes and phoneme sequences include ch for /tʃ/ , sh for /ʃ/ , th for /θ/ or /ð/ , ng for /ŋ/ , qu for /kw/ , and ph for /f/ in Greek-derived words. The single letter x is generally pronounced as /z/ in word-initial position and as /ks/ otherwise. There are exceptions to these generalisations, often the result of loanwords being spelled according to the spelling patterns of their languages of origin [222] or proposals by pedantic scholars in the early period of Modern English to mistakenly follow the spelling patterns of Latin for English words of Germanic origin. [226]
For the vowel sounds of the English language, however, correspondences between spelling and pronunciation are more irregular. There are many more vowel phonemes in English than there are vowel letters ( a , e , i , o , u , w , y ). As a result of a smaller set of single letter symbols than the set of vowel phonemes, some " long vowels " are often indicated by combinations of letters (like the oa in boat , the ow in how , and the ay in stay ), or the historically based silent e (as in note and cake ). [223]
The consequence of this complex orthographic history is that learning to read can be challenging in English. It can take longer for school pupils to become independently fluent readers of English than of many other languages, including Italian, Spanish, or German. [227] Nonetheless, there is an advantage for learners of English reading in learning the specific sound-symbol regularities that occur in the standard English spellings of commonly used words. [222] Such instruction greatly reduces the risk of children experiencing reading difficulties in English. [228] [229] Making primary school teachers more aware of the primacy of morpheme representation in English may help learners learn more efficiently to read and write English. [230]
English writing also includes a system of punctuation that is similar to the system of punctuation marks used in most alphabetic languages around the world. The purpose of punctuation is to mark meaningful grammatical relationships in sentences to aid readers in understanding a text and to indicate features important for reading a text aloud. [231]

Dialects, accents, and varieties
Dialectologists distinguish between English dialects , regional varieties that differ from each other in terms of grammar and vocabulary, and regional accents , distinguished by different patterns of pronunciation. The major native dialects of English are often divided by linguists into the two general categories of the British dialects (BrE) and those of North America (AmE). [232] There also exists a grouping of major native varieties of English in the southern hemisphere, the most prominent being Australian and New Zealand English .

UK and Ireland
As the place where English first evolved, the British Isles, and particularly England, are home to the most variegated pattern of dialects. Within the United Kingdom, the Received Pronunciation (RP), an educated dialect of South East England , is traditionally used as the broadcast standard, and is considered the most prestigious of the British dialects. The spread of RP (also known as BBC English) through the media has caused many traditional dialects of rural England to recede, as youths adopt the traits of the prestige variety instead of traits from local dialects. At the time of the Survey of English Dialects , grammar and vocabulary differed across the country, but a process of lexical attrition has led most of this variation to disappear. [233] Nonetheless this attrition has mostly affected dialectal variation in grammar and vocabulary, and in fact only 3 percent of the English population actually speak RP, the remainder speaking regional accents and dialects with varying degrees of RP influence. [234] There is also variability within RP, particularly along class lines between Upper and Middle class RP speakers and between native RP speakers and speakers who adopt RP later in life. [235] Within Britain there is also considerable variation along lines of social class, and some traits though exceedingly common are considered "non-standard" and are associated with lower class speakers and identities. An example of this is H-dropping , which was historically a feature of lower class London English, particularly Cockney, but which today is the standard in all major English cities—yet it remains largely absent in broadcasting and among the upper crust of British society. [236]
English in England can be divided into four major dialect regions, Southwest English , South East English, Midlands English, and Northern English . Within each of these regions several local subdialects exist: Within the Northern region, there is a division between the Yorkshire dialects, and the Geordie dialect spoken in Northumbria around Newcastle, and the Lancashire dialects with local urban dialects in Liverpool ( Scouse ) and Manchester ( Mancunian ). Having been the centre of Danish occupation during the Viking Invasions, Northern English dialects, particularly the Yorkshire dialect, retain Norse features not found in other English varieties. [237]
Since the 15th century, Southeastern varieties centred around London, which has been the centre from which dialectal innovations have spread to other dialects. In London, the Cockney dialect was traditionally used by the lower classes, and it was long a socially stigmatised variety. Today a large area of Southeastern England has adopted traits from Cockney, resulting in the so-called Estuary English which spread in areas south and East of London beginning in the 1980s. Estuary English is distinguished by traits such as the use of intrusive R ( drawing is pronounced drawring /ˈdrɔːrɪŋ/ ), t -glottalisation ( Potter is pronounced with a glottal stop as Po'er /poʔʌ/ ), and the pronunciation of th- as /f/ ( thanks pronounced fanks ) or /v/ ( bother pronounced bover ). [238]
Scots is today considered a separate language from English, but it has its origins in early Northern Middle English [239] and developed and changed during its history with influence from other sources, particularly Scots Gaelic and Old Norse. Scots itself has a number of regional dialects. And in addition to Scots, Scottish English are the varieties of Standard English spoken in Scotland, most varieties are Northern English accents, with some influence from Scots. [240]
In Ireland , various forms of English have been spoken since the Norman invasions of the 11th century. In County Wexford , in the area surrounding Dublin , two highly conservative dialects known as Forth and Bargy and Fingallian developed as offshoots from Early Middle English, and were spoken until the 19th century. Modern Hiberno-English however has its roots in English colonisation in the 17th century. Today Irish English is divided into Ulster English, a dialect with strong influence from Scots, and southern Hiberno-English. Like Scots and Northern English, the Irish accents preserve the rhoticity which has been lost in most dialects influenced by RP. [17] [241]

North America
American English is fairly homogeneous compared to British English. Today, American accent variation is often increasing at the regional level and decreasing at the very local level, [242] though most Americans still speak within a phonological continuum of similar accents, [243] known collectively as General American (GA), with differences hardly noticed even among Americans themselves (such as Midland and Western American English ). [244] [245] [246] In most American and Canadian English, rhoticity (or r -fulness) is dominant, with non-rhoticity ( r -dropping) becoming associated with lower prestige and social class especially after World War II; this contrasts with the situation in England, where non-rhoticity has become the standard. [247] Separate from GA are American dialects with clearly distinct sound systems, historically including Southern American English , English of the coastal Northeast (famously including Eastern New England English and New York City English ), and African American Vernacular English , all of which are historically non-rhotic. Canadian English , except for the Atlantic provinces and perhaps Quebec , may be classified under GA as well, but it often shows raising of certain vowels , / aɪ / and / aʊ / , before voiceless consonants , as well as distinct norms for written and pronunciation standards. [248]
In Southern American English , the largest American "accent group" outside of GA, [249] rhoticity now strongly prevails, replacing the region's historical non-rhotic prestige. [250] [251] [252] Southern accents are colloquially described as a "drawl" or "twang," [253] being recognised most readily by the Southern Vowel Shift that begins with glide-deleting in the /aɪ/ vowel (e.g. pronouncing spy almost like spa ), the "Southern breaking" of several front pure vowels into a gliding vowel or even two syllables (e.g. pronouncing the word "press" almost like "pray-us"), [254] the pin–pen merger , and other distinctive phonological, grammatical, and lexical features, many of which are actually recent developments of the 19th century or later. [255]
Today spoken primarily by working- and middle-class African Americans , African American Vernacular English (AAVE) is also largely non-rhotic and likely originated among enslaved Africans and African Americans influenced primarily by the non-rhotic, non-standard English dialects of the Old South . A minority of linguists, [256] contrarily, propose that AAVE mostly traces back to African languages spoken by the slaves who had to develop a pidgin or Creole English to communicate with slaves of other ethnic and linguistic origins. [257] AAVE shares important commonalities with older Southern American English and so probably developed to a highly coherent and homogeneous variety in the 19th or early 20th century. AAVE is commonly stigmatised in North America as a form of "broken" or "uneducated" English, also common of modern Southern American English, but linguists today recognise both as fully developed varieties of English with their own norms shared by a large speech community. [258] [259]

Australia and New Zealand
Since 1788, English has been spoken in Oceania , and Australian English has developed as a first language of the vast majority of the inhabitants of the Australian continent, its standard accent being General Australian . The English of neighbouring New Zealand has to a lesser degree become an influential standard variety of the language. [260] Australian and New Zealand English are most closely related to each other with few differentiating characteristics, followed by South African English and the English of southeastern England, all of which have similarly non-rhotic accents, aside from some accents in the South Island of New Zealand. Australian and New Zealand English stand out for their innovative vowels: many short vowels are fronted or raised, whereas many long vowels have diphthongised. Australian English also has a contrast between long and short vowels, not found in most other varieties. Australian English grammar aligns closely to British and American English; like American English, collective plural subjects take on a singular verb (as in the government is rather than are ). [261] [262] New Zealand English uses [ʍ] for ⟨wh-⟩ and its front vowels are often even higher than in Australian English. [263] [264] [265]

Africa, the Caribbean, and South Asia
English is spoken widely in South Africa and is an official or co-official language in several countries. In South Africa , English has been spoken since 1820, co-existing with Afrikaans and various African languages such as the Khoe and Bantu languages . Today about 9 percent of the South African population speak South African English (SAE) as a first language. SAE is a non-rhotic variety, which tends to follow RP as a norm. It is alone among non-rhotic varieties in lacking intrusive r. There are different L2 varieties that differ based on the native language of the speakers. [266] Most phonological differences from RP are in the vowels. [267] Consonant differences include the tendency to pronounce /p, t, t͡ʃ, k/ without aspiration (e.g. pin pronounced [pɪn] rather than as [pʰɪn] as in most other varieties), while r is often pronounced as a flap [ɾ] instead of as the more common fricative. [268]
Several varieties of English are also spoken in the Caribbean Islands that were colonial possessions of Britain, including Jamaica, and the Leeward and Windward Islands and Trinidad and Tobago , Barbados , the Cayman Islands , and Belize . Each of these areas are home both to a local variety of English and a local English based creole, combining English and African languages. The most prominent varieties are Jamaican English and Jamaican Creole . In Central America, English based creoles are spoken in on the Caribbean coasts of Nicaragua and Panama. [269] Locals are often fluent both in the local English variety and the local creole languages and code-switching between them is frequent, indeed another way to conceptualise the relationship between Creole and Standard varieties is to see a spectrum of social registers with the Creole forms serving as "basilect" and the more RP-like forms serving as the "acrolect", the most formal register. [270]
Most Caribbean varieties are based on British English and consequently most are non-rhotic, except for formal styles of Jamaican English which are often rhotic. Jamaican English differs from RP in its vowel inventory, which has a distinction between long and short vowels rather than tense and lax vowels as in Standard English. The diphthongs /ei/ and /ou/ are monophthongs [eː] and [oː] or even the reverse diphthongs [ie] and [uo] (e.g. bay and boat pronounced [bʲeː] and [bʷoːt] ). Often word final consonant clusters are simplified so that "child" is pronounced [t͡ʃail] and "wind" [win] . [271] [272] [273]
As a historical legacy, Indian English tends to take RP as its ideal, and how well this ideal is realised in an individual's speech reflects class distinctions among Indian English speakers. Indian English accents are marked by the pronunciation of phonemes such as /t/ and /d/ (often pronounced with retroflex articulation as [ʈ] and [ɖ] ) and the replacement of /θ/ and /ð/ with dentals [t̪] and [d̪] . Sometimes Indian English speakers may also use spelling based pronunciations where the silent ⟨h⟩ found in words such as ghost is pronounced as an Indian voiced aspirated stop [ɡʱ] . [274]
WebPage index: 00001
Species complex
In biology, a species complex is a group of closely related species that are very similar in appearance to the point that the boundaries between them are often unclear. Terms sometimes used synonymously but with more precise meanings are: cryptic species for two or more species hidden under one species name, sibling species for two cryptic species that are each other's closest relative, and species flock for a group of closely related species living in the same habitat. As informal taxonomic ranks , species group , species aggregate , and superspecies are also in use.
Two or more taxa once considered conspecific (of the same species) may later be subdivided into infraspecific taxa (taxa within a species, such as bacterial strains or plant varieties ), but this is not a species complex.
A species complex is in most cases a monophyletic group with a common ancestor, although there are exceptions. It may represent an early stage after speciation , but may also have been separated for a long time period without evolving morphological differences. Hybrid speciation can be a component in the evolution of a species complex.
Species complexes exist in all groups of organisms. They are identified by the rigorous study of differences between individual species, making use of minute morphological details, tests of reproductive isolation , or DNA -based methods such as molecular phylogenetics or DNA barcoding . The existence of extremely similar species may cause local and global species diversity to be underestimated. Recognizing similar but distinct species is important for disease and pest control , and in conservation biology , although drawing dividing lines between species can be inherently difficult .

Definition
A species complex is typically considered as a group of close, but distinct species. [5] Obviously, the concept is closely tied to the definition of a species. Modern biology understands a species as "separately evolving metapopulation lineage " but acknowledges that the criteria to delimit species may depend on the group studied. [6] Thus, many species defined traditionally, based only on morphological similarity, have been found to comprise several distinct species when other criteria, such as genetic differentiation or reproductive isolation were applied. [7]
A more restricted use applies the term to close species between which hybridisation occurred or is occurring, leading to intermediate forms and blurred species boundaries. [8]
Some authors apply the term also to a species with intraspecific variability , which might be a sign of ongoing or incipient speciation . Examples are ring species [9] [10] or species with subspecies , where it is often unclear if these should be considered separate species. [11]

Included concepts
Several terms are used synonymously for a species complex, but some of them may also have slightly different, or more narrow meanings. In the nomenclature codes of zoology and bacteriology, no taxonomic ranks are defined at the level between subgenera and species, [12] [13] while the botanical code defines four ranks below genera (section, subsections, series and subseries). [14] Different informal taxonomic solutions have been used to indicate a species complex.

Identification
Distinguishing close species within a complex requires the study of often very small differences. Morphological differences may be minute and only visible using adapted methods, such as microscopy . However, distinct species may sometimes have no morphological differences. [16] In these cases, other characters, e.g. in the species' life history , behavior , physiology , or karyology can be explored. As an example, territorial songs are indicative of species in the treecreepers , a bird genus with little morphological differences. [28] Mating tests are common in some groups such as fungi to confirm the reproductive isolation of two species. [26]
Analysis of DNA sequences is becoming increasingly standard for species recognition and may in many cases be the only useful method. [16] Different methods are used to analyse such genetic data, for example molecular phylogenetics or DNA barcoding . Such methods have greatly contributed to the discovery of cryptic species, [16] including such emblematic species as the fly agaric [2] or the African elephants . [3]

Evolution and ecology

Speciation process
Species forming a complex have typically diverged very recently from each other, allowing in some cases to retrace the process of speciation . Species with differentiated populations such as ring species are sometimes seen as an example of early, ongoing speciation, i.e. a species complex in formation. Nevertheless, similar but distinct species have sometimes been isolated for a long time without evolving differences, a phenomenon called "morphological stasis". [16] As an examples, the Amazonian frog Pristimantis ockendeni is actually at least three different species that diverged over 5 million years ago. [30]
Stabilizing selection has been invoked as a force maintaining similarity in species complexes, especially when adaptation to special environments, such as a host in the case of symbionts, or extreme environments, constrains possible directions of evolution: In such cases, strongly divergent selection is not to be expected. [16] Also, asexual reproduction, such as through apomixis in plants, may separate lineages without producing a great degree of morphological differentiation.
A species complex is usually a group that has one common ancestor (a monophyletic group), although closer examination can sometimes disprove this. As an example, the yellow-spotted "fire salamanders" in the genus Salamandra , formerly all classified as one species S. salamandra , are not monophyletic: the Corsican fire salamander 's closest relative was shown to be the entirely black Alpine salamander . [29] In such cases, similarity has arisen from convergent evolution .
Hybrid speciation can lead to unclear species boundaries through a process of reticulate evolution , where species have two parent species as their most recent common ancestors . In such cases, the hybrid species may have intermediate characters, as demonstrated e.g. in Heliconius butterflies. [31] Hybrid speciation has been observed in various species complexes, such as insects, fungi, and plants. In plants, hybridization often takes place through polyploidization , and hybrid plant species are called nothospecies .

Range
In regards to whether or not members of a species group share a range , sources differ. A source from Iowa State University Department of Agronomy says that members of a species group usually have partially overlapping ranges but do not interbreed with each other. [32] A Dictionary of Zoology ( Oxford University Press 1999) describes a species group as complex of related species that exist allopatrically and explains that this "grouping can often be supported by experimental crosses in which only certain pairs of species will produce hybrids ." [33] The examples given below may support both uses of the term "species group."
Often such complexes only become evident when a new species is introduced into the system, breaking down existing species barriers. An example is the introduction of the Spanish slug in Northern Europe , where interbreeding with the local black slug and red slug , traditionally considered clearly separate species that did not interbreed, shows they may be actually just subspecies of the same species. [34]
Where closely related species coexist in sympatry , it is often a particular challenge to understand how these similar species persist without outcompeting each other. Niche partitioning is one mechanism invoked to explain this. Studies in some species complexes indeed suggest that species divergence went in par with ecological differentiation, with species now preferring different microhabitats. [ citation needed ] Similar methods also found that the Amazonian frog Eleutherodactylus ockendeni is actually at least 3 different species that diverged over 5 million years ago. [30] A species flock may arise when a species penetrates a new geographical area and diversifies to occupy a variety of ecological niches ; this process is known as adaptive radiation . The first species flock to be recognized as such was the 13 species of Darwin's finches on the Galápagos Islands described by Charles Darwin .

Practical implications

Biodiversity estimates
It has been suggested that cryptic species complexes are very common in the marine environment. [35] Although this suggestion came before the detailed analysis of many systems using DNA sequence data, it has been proven correct. [36] The increased use of DNA sequence in the investigation of organismal diversity (also called Phylogeography and DNA barcoding ) has led to the discovery of a great many cryptic species complexes in all habitats. In the marine bryozoan Celleporella hyalina , [37] detailed morphological analyses and mating compatibility tests between the isolates identified by DNA sequence analysis were used to confirm that these groups consisted of more than 10 ecologically distinct species that had been diverging for many million years.
Evidence from the identification of cryptic species has led some [ who? ] to conclude that current estimates of global species richness are too low.

Disease and pathogen control
Pests, species causing diseases, and their vectors, have direct importance for humans. When they are found to be cryptic species complexes, the ecology and virulence of each of these species needs to be reevaluated to devise appropriate control strategies. [ citation needed ] An example are cryptic species in the malaria vector Anopheles , or the fungi causing cryptococcosis .

Conservation biology
When a species is found to comprise in fact several phylogenetically distinct species, each of these typically have smaller distribution ranges and population sizes than reckoned before. These different species can also differ in their ecology, e.g. having different breeding strategies or habitat requirements, which has to be taken into account for appropriate management. [ citation needed ] For example, giraffe populations and subspecies differ genetically to such an extent that they may be considered species; while the giraffe as a whole is not considered threatened, considering each cryptic species separately would mean a much higher level of threat. [39]

See also
WebPage index: 00002
Zenobia
Septimia Zenobia ( Palmyrene : ( Btzby ), pronounced Bat-Zabbai ; AD c. 240–c.274) was a third-century queen of the Syria -based Palmyrene Empire . Many legends surround her ancestry; she was certainly born to a noble Palmyrene family and married the ruler of the city, Odaenathus . Her husband became king in 260, elevating Palmyra to supreme power in the Near East by defeating the Sassanians and stabilizing the Roman East. After Odaenathus' assassination, Zenobia became the regent of her son Vaballathus and held de facto power throughout his reign.
In 270, Zenobia launched an invasion which brought most of the Roman East under her sway and culminated with the annexation of Egypt . By mid-271 her realm extended from Ancyra in the north to southern Egypt, although she remained nominally subordinate to Rome. However, in reaction to Roman emperor Aurelian 's campaign in 272, Zenobia declared her son emperor and assumed the title of empress (declaring Palmyra's secession from Rome). The Romans were victorious after heavy fighting; the queen was besieged in her capital and captured by Aurelian, who exiled her to Rome where she spent the remainder of her life.
Zenobia was a cultured monarch and fostered an intellectual environment in her court, which was open to scholars and philosophers. She was tolerant toward her subjects, and protected religious minorities. The queen maintained a stable administration which governed a multicultural, multiethnic empire. Zenobia died after 274, and many tales have been recorded about her fate. Her rise and fall have inspired historians, artists and novelists, and she is a national hero in Syria.

Name and appearance
Zenobia was born c. 240–241. [2] She bore the gentilicium (surname) Septimia, [note 1] [5] and her native Palmyrene name was Bat-Zabbai (written "Btzby" in the Palmyrene alphabet , [6] an Aramaic name meaning "daughter of Zabbai"). [7] In Greek —Palmyra's diplomatic and second language, used in many Palmyrene inscriptions—she used the name Zenobia ("one whose life derives from Zeus "). [8] The ninth-century historian al-Tabari , in his highly fictionalized account, [9] wrote that the queen's name was Na'ila al-Zabba'. [10] Manichaean sources called her "Tadi". [note 2] [12]
In Palmyra, names such as Zabeida, Zabdila, Zabbai or Zabda were often transformed into "Zenobios" (masculine) and "Zenobia" (feminine) when written in Greek . [13] Historian Victor Duruy believed that the queen used the Greek name as a translation of her native name in deference to her Greek subjects. [14] No contemporary statues of Zenobia have been found in Palmyra or elsewhere, only inscriptions on statue bases; most known representations of Zenobia are the idealized portraits of her found on her coins. [15] Palmyrene sculptures were normally impersonal, unlike Greek and Roman ones: a statue of Zenobia would have given an idea of her general style in dress and jewelry but would not have revealed her true appearance. [15] British scholar William Wright visited Palmyra toward the end of the nineteenth century in a vain search for a sculpture of the queen. [16]
In addition to archaeological evidence, Zenobia's life was recorded in different ancient sources but many are flawed or fabricated; the Augustan History , a late-Roman collection of biographies, is the most notable (albeit unreliable) source for the era. [17] The author (or authors) of the Augustan History invented many events and letters attributed to Zenobia in the absence of contemporary sources. [17] Some Augustan History accounts are corroborated from other sources, and are more credible. [17] Byzantine chronicler Joannes Zonaras is considered an important source for the life of Zenobia. [17]

Early life and family
The Augustan History contains details of Zenobia's early life, although their credibility is doubtful. [18] According to Augustan History , the queen's hobby as a child was hunting. [18] Apparently not a commoner, [18] she would have received an education appropriate for a noble Palmyrene girl. [19] According to the Augustan History , in addition to her Palmyrene Aramaic mother tongue, Zenobia was reportedly fluent in Egyptian and Greek and spoke Latin . [20] [21] Around age 14 (c. 255) she became the second wife of Odaenathus , the ras (lord) of Palmyra. [18] [22]
Palmyrene society was an amalgam of Semitic tribes (mostly Aramean and Arab ), and Zenobia cannot be identified with any one group; as a Palmyrene, she would have had Aramean and Arab blood. [23] Information about Zenobia's ancestry and immediate family connections is scarce and contradictory. [24] Nothing is known about her mother, and her father's identity is debated. [22] Manichaean sources mention a "Nafsha", sister of the "queen of Palmyra", [22] but those sources are confused and "Nafsha" may refer to Zenobia herself: [25] it is doubtful that Zenobia had a sister. [12]

Contemporary epigraphical evidence
Based on archaeological evidence, several men have been suggested by historians as Zenobia's father: Julius Aurelius Zenobius appears on a Palmyrene inscription as a strategos of Palmyra in 231–232; based on the similarity of the names, [22] Zenobius was suggested as Zenobia's father by the numismatist Alfred von Sallet and others. [26] Another argument in favor of Zenobius' identification as the father is that his statue was opposite that of the queen on the Great Colonnade . [5] However, the only gentilicium appearing on Zenobia's inscriptions was "Septimia" (not "Julia Aurelia", which she would have borne if her father's gentilicium was Aurelius), [5] and it cannot be proven that the queen changed her gentilicium to Septimia after her marriage. [22] [26]
On the basis of Zenobia's Palmyrene name, Bat Zabbai, her father may have been called Zabbai; alternatively, Zabbai may have been the name of a more distant ancestor. [24] Historian Trevor Bryce suggests that she was related to Septimius Zabbai , Palmyra's garrison leader, and he may even have been her father. [24]
One of Zenobia's inscriptions recorded her as "Septimia Bat-Zabbai, daughter of Antiochus". [27] [28] Antiochus' identity is not definitively known: [24] his ancestry is not recorded in Palmyrene inscriptions, and the name was not common in Palmyra. [29] This, combined with the meaning of Zenobia's Palmyrene name (daughter of Zabbai), led scholars such as Harald Ingholt to speculate that Antiochus might have been a distant ancestor: the Seleucid king Antiochus IV Epiphanes or Antiochus VII Sidetes , whose wife was the Ptolemaic Cleopatra Thea . [27] [29]
In historian Richard Stoneman 's view, Zenobia would not have created an obscure ancestry to connect herself with the ancient Macedonian rulers: if a fabricated ancestry were needed, a more direct connection would have been invented. [18] According to Stoneman, Zenobia "had reason to believe [her Seleucid ancestry] to be true". [18] Historian Patricia Southern , noting that Antiochus was mentioned without a royal title or a hint of great lineage, believes that he was a direct ancestor or a relative rather than a Seleucid king who lived three centuries before Zenobia. [29]

Ancient sources
In the Augustan History , Zenobia is said to have been a descendant of Cleopatra and claimed descent from the Ptolemies. [note 3] [13] According to the Souda , a 10th-century Byzantine encyclopedia, [30] after the Palmyrene conquest of Egypt, [31] the Greek sophist Callinicus of Petra wrote a ten-volume history of Alexandria dedicated to Cleopatra. [32] According to modern scholars, by Cleopatra Callinicus meant Zenobia. [note 4] [32] [34] Apart from legend, there is no evidence in Egyptian coinage or papyri of a contemporary conflation of Zenobia with Cleopatra; [35] it may have been invented by Zenobia's enemies to discredit her. [note 5] [37] Zenobia's alleged claim of a connection to Cleopatra seems to have been politically motivated, [23] since it would have given her a connection with Egypt and made her a legitimate successor to the Ptolemies' throne. [38] A relationship between Zenobia and the Ptolemies is unlikely, [39] and attempts by classical sources to trace the queen's ancestry to the Ptolemies through the Seleucids are apocryphal . [40]

Arabic traditions and al-Zabba'
Although some Arab historians linked Zenobia to the Queen of Sheba , their accounts are apocryphal. [40] Medieval Arabic traditions identify a queen of Palmyra named al-Zabba', [41] and her most romantic account comes from al-Tabari. [42] According to al-Tabari, she was an Amalekite ; her father was 'Amr ibn Zarib, an 'Amālīq sheikh who was killed by the Tanukhids . [40] Al-Tabari identifies a sister of al-Zabba' as "Zabibah". [40] Jadhimah ibn Malik, the Tanukhid king who killed the queen's father, was killed by al-Zabba'. [42] According to al-Tabari, al-Zabba' had a fortress along the Euphrates and ruled Palmyra. [9]
Al-Tabari's account does not mention the Romans, Odaenathus, Vaballathus or the Sassanians; [9] focusing on the tribes and their relations, it is immersed in legends. [43] Although the account is certainly based on the story of Zenobia, [9] it is probably conflated with the story of a semi-legendary nomadic Arab queen (or queens). [44] [43] Al-Zabba' 's fortress was probably Halabiye , which was restored by the historic Palmyrene queen and named Zenobia. [9]

Queen of Palmyra

Consort
During the early centuries AD, Palmyra was a city subordinate to Rome and part of the province of Syria Phoenice . [45] In 260 the Roman emperor Valerian marched against the Sassanid Persian monarch Shapur I , who had invaded the empire's eastern regions; Valerian was defeated and captured near Edessa . [46] Odaenathus, formally loyal to Rome and its emperor Gallienus (Valerian's son), [47] was declared king of Palmyra. [48] Launching successful campaigns against Persia, he was crowned King of Kings of the East in 263. [49] Odaenathus crowned his eldest son, Herodianus , as co-ruler. [50] In addition to the royal titles, Odaenathus received many Roman titles , most importantly corrector totius orientis (governor of the entire East), and ruled the Roman territories from the Black Sea to Palestine . [51] In 267, when Zenobia was in her late twenties or early thirties, Odaenathus and his eldest son were assassinated while returning from a campaign. [50]
The first inscription mentioning Zenobia as queen is dated two or three years after Odaenathus' death, so exactly when Zenobia assumed the title "queen of Palmyra" is uncertain. [52] However, she was probably designated as queen when her husband became king. [52] As queen consort , Zenobia remained in the background and was not mentioned in the historical record. [53] According to later accounts, including one by Giovanni Boccaccio , she accompanied her husband on his campaigns. [54] If the accounts of her accompanying her husband are true, according to Southern, Zenobia would have boosted the morale of the soldiers and gained political influence, which she needed in her later career. [53]

Possible role in Odaenathus' assassination
According to the Augustan History , Odaenathus was assassinated by a cousin named Maeonius . [55] In Augustan History , Odaenathus' son from his first wife was named Herodes and was crowned co-ruler by his father. [56] The Augustan History claims that Zenobia conspired with Maeonius for a time because she did not accept her stepson as his father's heir (ahead of her own children). [55] The Augustan History does not suggest that Zenobia was involved in the events leading to her husband's murder, [57] and the crime is attributed to Maeonius' moral degeneration and jealousy. [55] This account, according to historian Alaric Watson , can be dismissed as fictional. [58] Although some modern scholarship suggests that Zenobia was involved in the assassination due to political ambition and opposition to her husband's pro-Roman policy, she continued Odaenathus' policies during her first years on the throne. [59]

Regent
In the Augustan History , Maeonius was emperor briefly before he was killed by his soldiers, [57] however, no inscriptions or evidence exist for his reign. [60] At the time of Odaenathus' assassination, Zenobia might have been with her husband; according to chronicler George Syncellus , he was killed near Heraclea Pontica in Bithynia . [61] The transfer of power seems to have been smooth, since Syncellus reports that the time from the assassination to the army handing the crown to Zenobia was one day. [61] Zenobia may have been in Palmyra, but this would have reduced the likelihood of a smooth transition; the soldiers might have chosen one of their officers, so the first scenario of her being with her husband is more likely. [61] The historical records are unanimous that Zenobia did not fight for supremacy and there is no evidence of delay in the transfer of the throne to Odaenathus and Zenobia's son, the ten-year-old Vaballathus . [62] Although she never claimed to rule in her own right and acted as a regent for her son, [63] Zenobia held the reins of power in the kingdom, [64] and Vaballathus was kept in his mother's shadow, never exercising real power. [65]

Consolidation of power
The Palmyrene monarchy was new; allegiance was based on loyalty to Odaenathus, making the transfer of power to a successor more difficult than it would have been in an established monarchy. [66] Odaenathus tried to ensure the dynasty's future by crowning his eldest son co-king, but both were assassinated. [67] Zenobia, left to secure the Palmyrene succession and retain the loyalty of its subjects, emphasized the continuity between her late husband and his successor (her son). [67] Vaballathus (with Zenobia orchestrating the process) assumed his father's royal titles immediately, and his earliest known inscription records him as King of Kings. [67] [62]
Odaenathus controlled a large area of the Roman East and held the highest political and military authority in the region, superseding that of the Roman provincial governors. [68] [50] His self-created status was formalized by Emperor Gallienus, [69] who had little choice but to acquiesce. [70] Odaenathus's power relative to that of the emperor and the central authority was unprecedented and elastic, but relations remained smooth until his death. [71] His assassination meant that the Palmyrene rulers' authority and position had to be clarified, which led to a conflict over their interpretation. [71] The Roman court viewed Odaenathus as an appointed Roman official who derived his power from the emperor, but the Palmyrene court saw his position as hereditary. [71] This conflict was the first step on the road to war between Rome and Palmyra. [71]
Odaenathus' Roman titles, such as dux Romanorum , corrector totius orientis and imperator totius orientis differed from his royal eastern ones because the Roman ranks were not hereditary. [72] Vaballathus had a legitimate claim to his royal titles, but had no right to the Roman ones—especially corrector (denoting a senior military and provincial commander in the Roman system), which Zenobia used for her son in his earliest known inscriptions with "King of Kings". [67] Although the Roman emperors accepted the royal succession, the assumption of Roman military rank antagonized the empire. [73] Emperor Gallienus may have decided to intervene in an attempt to regain central authority; [28] according to the Augustan History , praetorian prefect Aurelius Heraclianus was dispatched to assert imperial authority over the east and was repelled by the Palmyrene army . [74] The account is doubtful, however, since Heraclianus participated in Gallienus' assassination in 268. [75] Odaenathus was assassinated shortly before the emperor, and Heraclianus would have been unable to be sent to the East, fight the Palmyrenes and return to the West in time to become involved in the conspiracy against the emperor. [note 6] [75]

Early reign
The extent of Zenobia's territorial control during her early reign is debated; according to historian Fergus Millar , her authority was confined to Palmyra and Emesa until 270. [note 7] [77] If this was the case, the events of 270 (which saw Zenobia's conquest of the Levant and Egypt ) are extraordinary. [76] It is more likely that the queen ruled the territories controlled by her late husband, [76] a view supported by Southern and historian Udo Hartmann , [78] and backed by ancient sources (such as the Roman historian Eutropius , who wrote that the queen inherited her husband's power). [76] The Augustan History also mentioned that Zenobia took control of the East during Gallienus' reign. [76] [78] Further evidence of extended territorial control was a statement by the Byzantine historian Zosimus , who wrote that the queen had a residence in Antioch . [note 8] [76]
There is no recorded unrest against the queen accompanying her ascendance in ancient sources hostile to her, indicating no serious opposition to the new regime. [note 9] [80] The most obvious candidates for opposition were the Roman provincial governors, but the sources do not say that Zenobia marched on any of them or that they tried to remove her from the throne. [81] According to Hartmann, the governors and military leaders of the eastern provinces apparently acknowledged and supported Vaballathus as the successor of Odaenathus. [81] During Zenobia's early regency, she focused on safegarding the borders with Persia and pacifying the Tanukhids in Hauran . [82] To protect the Persian borders, the queen fortified many settlements on the Euphrates (including the citadels of Halabiye —later called Zenobia—and Zalabiye ). [83] Circumstantial evidence exists for confrontations with the Sassanid Persians; probably in 269, Vaballathus assumed the victory title of Persicus Maximus (the great victor in Persia); this may be connected to an unrecorded battle against a Persian army trying to control northern Mesopotamia. [note 10] [84] [85]

Expansion
In 269, while Claudius Gothicus (Gallienus' successor) was defending the borders of Italy and the Balkans against Germanic invasions, Zenobia was cementing her authority; Roman officials in the East were caught between loyalty to the emperor and Zenobia's increasing demands for allegiance. [86] The timing and rationale of the queen's decision to use military force to strengthen her authority in the East is unclear; [86] scholar Gary K. Young suggested that Roman officials refused to recognize Palmyrene authority, and Zenobia's expeditions were intended to maintain Palmyrene dominance. [87] Another factor may have been the weakness of Roman central authority and its corresponding inability to protect the provinces, which probably convinced Zenobia that the only way to maintain stability in the East was to control the region directly. [87] Historian Jacques Schwartz tied Zenobia's actions to her desire to protect Palmyra's economic interests, which were threatened by Rome's failure to protect the provinces. [88] Also, according to Schwartz, the economic interests conflicted; Bostra and Egypt received trade which would have otherwise passed through Palmyra. [89] The Tanukhids near Bostra and the merchants of Alexandria probably attempted to rid themselves of Palmyrene domination, triggering a military response from Zenobia. [89]

Syria and the invasion of Arabia Petraea
In the spring of 270, while Claudius was fighting the Goths in the mountains of Thrace , Zenobia sent her general Septemius Zabdas to Bostra (capital of the province of Arabia Petraea ); [86] the queen's timing seems intentional. [90] In Arabia the Roman governor ( dux ), Trassus (commanding the Legio III Cyrenaica ), [note 11] confronted the Palmyrenes and was routed and killed. [86] Zabdas destroyed the temple of Zeus Hammon , the legion's revered shrine. [86] A Latin inscription after the fall of Zenobia attests to its destruction: [92] "The temple of Iuppiter Hammon, destroyed by the Palmyrene enemies, which ... rebuilt, with a silver statue and iron doors (?)". [93] The city of Umm el-Jimal may have also been destroyed by the Palmyrenes in connection with their efforts to subjugate the Tanukhids. [92]
After his victory, Zabdas marched south along the Jordan Valley and apparently met little opposition. [86] There is evidence that Petra was attacked by a small contingent which penetrated the region. [94] Arabia and Judaea were eventually subdued. [94] Palmyrene dominance of Arabia is confirmed by many milestones bearing Vaballathus' name. [91] Syrian subjugation required less effort because Zenobia had substantial support there, particularly in Antioch, [95] Syria's traditional capital. [79] The invasion of Arabia coincided with the cessation of coin production in Claudius' name by the Antiochean mint , indicating that Zenobia had begun tightening her grip on Syria. [95] By November 270, the mint began issuing coinage in Vaballathus' name. [96]
The Arabian milestones presented the Palmyrene king as a Roman governor and commander, referring to him as vir clarissimus rex consul imperator dux Romanorum . [91] The assumption of such titles was probably meant to legitimize Zenobia's control of the province, not yet a usurpation of the imperial title. [97] Until now, Zenobia could say that she was acting as a representative of the emperor (who was securing the eastern lands of the empire) while the Roman monarch was preoccupied with struggles in Europe. [98] Although Vaballathus' use of the titles amounted to a claim to the imperial throne, Zenobia could still justify them and maintain a mask of subordination to Rome; [72] an "imperator" was a commander of troops, not the equal of an emperor ( "imperator caesar" ). [97]

Annexation of Egypt and the campaigns in Asia Minor
The invasion of Egypt is sometimes explained by Zenobia's desire to secure an alternative trade route to the Euphrates, which was cut because of the war with Persia; [99] This theory ignores the fact that the Euphrates route was only partially disrupted, and overlooks Zenobia's ambition. [94] The date of the campaign is uncertain; Zosimus placed it after the Battle of Naissus and before Claudius' death, which sets it in the summer of 270. [100] Watson, emphasizing the works of Zonaras and Syncellus and dismissing Zosimus' account, places the invasion in October 270 (after Claudius' death). [101] According to Watson, the occupation of Egypt was an opportunistic move by Zenobia (who was encouraged by the news of Claudius' death in August). [94] [102] The appearance of the Palmyrenes on Egypt's eastern frontier would have contributed to unrest in the province, whose society was fractured; Zenobia had supporters and opponents among local Egyptians. [94]
The Roman position was worsened by the absence of Egypt's prefect , Tenagino Probus , who was battling pirates. [94] [100] According to Zosimus, the Palmyrenes were helped by an Egyptian general named Timagenes; Zabdas moved into Egypt with 70,000 soldiers, defeating an army of 50,000 Romans. [102] [90] After their victory, the Palmyrenes withdrew their main force and left a 5,000-soldier garrison. [90] By early November, [94] Tenagino Probus returned and assembled an army; he expelled the Palmyrenes and regained Alexandria, prompting Zabdas to return. [90] The Palmyrene general aimed a thrust at Alexandria, where he seems to have had local support; the city fell into Zabdas' hands, and the Roman prefect fled south. [94] The last battle was at the Babylon Fortress , where Tenagino Probus took refuge; the Romans had the upper hand, since they chose their camp carefully. [95] Timagenes, with his knowledge of the land, ambushed the Roman rear; Tenagino Probus committed suicide, and Egypt became part of Palmyra. [95] In the Augustan History the Blemmyes were among Zenobia's allies, [103] and Gary K. Young cites the Blemmyes attack and occupation of Coptos in 268 as evidence of a Palmyrene-Blemmyes alliance. [104]
Only Zosimus mentioned two invasions, contrasting with many scholars who argue in favor of an initial invasion and no retreat (followed by a reinforcement, which took Alexandria by the end of 270). [90] During the Egyptian campaign, Rome was entangled in a succession crisis between Claudius' brother Quintillus and the general Aurelian . [96] Egyptian papyri and coinage confirm Palmyrene rule in Egypt; the papyri stopped using the regnal years of the emperors from September to November 270, due to the succession crisis. [96] By December regnal dating was resumed, with the papyri using the regnal years of the prevailing emperor Aurelian and Zenobia's son Vaballathus. [96] Egyptian coinage was issued in the names of Aurelian and the Palmyrene king by November 270. [96] There is no evidence that Zenobia ever visited Egypt. [105]
Although the operation may have commenced under Septimius Zabbai, Zabdas' second-in-command, the invasion of Asia Minor did not fully begin until Zabdas' arrival in the spring of 271. [106] The Palmyrenes annexed Galatia and, according to Zosimus, reached Ancyra . [37] Bithynia and the Cyzicus mint remained beyond Zenobia's control, and her attempts to subdue Chalcedon failed. [106] The Asia Minor campaign is poorly documented, but the western part of the region did not become part of the queen's authority; [37] [107] no coins with Zenobia or Vaballathus' portraits were minted in Asia Minor, and no royal Palmyrene inscriptions have been found. [107] By August 271 Zabdas was back in Palmyra, with the Palmyrene empire at its zenith. [106]

Governance
Zenobia ruled an empire of different peoples; as a Palmyrene, she was accustomed to dealing with multilingual and multicultural diversity since she hailed from a city which embraced many cults. [108] The queen's realm was culturally divided into eastern-Semitic and Hellenistic zones; Zenobia tried to appease both, and seems to have successfully appealed to the region's ethnic, cultural and political groups. [109] The queen projected an image of a Syrian monarch, a Hellenistic queen and a Roman empress, which gained broad support for her cause. [110]

Culture
Zenobia turned her court into a center of learning, with many intellectuals and sophists reported in Palmyra during her reign. [111] As academics migrated to the city, it replaced classical learning centers such as Athens for Syrians. [111] The best-known court philosopher was Longinus , [112] who arrived during Odaenathus' reign and became Zenobia's tutor in paideia (aristocratic education). [113] [111] Many historians, including Zosimus, accused Longinus of influencing the queen to oppose Rome. [114] [113] This view presents the queen as malleable, [113] but, according to Southern, Zenobia's actions "cannot be laid entirely at Longinus' door". [31] Other intellectuals associated with the court included Nicostratus of Trapezus and Callinicus of Petra. [115]
From the second to the fourth centuries, Syrian intellectuals argued that Greek culture did not evolve in Greece but was adapted from the Near East . [115] According to Iamblichus , the great Greek philosophers reused Near Eastern and Egyptian ideas. [116] The Palmyrene court was probably dominated by this school of thought, with an intellectual narrative presenting Palmyra's dynasty as a Roman imperial one succeeding the Persian, Seleucid and Ptolemaic rulers who controlled the region in which Hellenistic culture allegedly originated. [116] Nicostratus wrote a history of the Roman Empire from Philip the Arab to Odaenathus, presenting the latter as a legitimate imperial successor and contrasting his successes with the disastrous reigns of the emperors. [115]
Zenobia embarked on several restoration projects in Egypt. [117] One of the Colossi of Memnon was reputed in antiquity to sing; the sound was probably due to cracks in the statue, with solar radiation interacting with dew in the cracks. [118] Historian Glen Bowersock proposed that the queen restored the colossus ("silencing" it), which would explain third-century accounts of the singing and their disappearance in the fourth. [119]

Religion
The Palmyrenes were pagans and worshiped a number of Semitic gods , with Bel at the head of their pantheon. [120] Zenobia accommodated Christians and Jews , [108] and ancient sources made many claims about the queen's beliefs; [34] Manichaeist sources alleged that Zenobia was one of their own. [121] It is more likely, however, that Zenobia tolerated all cults in an effort to attract support from groups marginalized by Rome. [34]
Bishop Athanasius of Alexandria wrote that Zenobia did not "hand over churches to the Jews to make them into synagogues"; [122] although the queen was not a Christian, she understood the power of bishops in Christian communities. [123] In Antioch—considered representative of political control of the East and containing a large Christian community—Zenobia apparently maintained authority over the church by bringing influential clerics, probably including Paul of Samosata , under her auspices. [123] She may have bestowed on Paul the rank of ducenarius (minor judge); he apparently enjoyed the queen's protection, which helped him keep the diocesan church after he was removed from his office as bishop of Antioch by a synod of bishops in 268. [note 12] [127]

Judaism
Less than a hundred years after Zenobia's reign, Athanasius of Alexandria called her a "Jewess" in his History of the Arians . [122] In 391, archbishop John Chrysostom wrote that Zenobia was Jewish; so did a Syriac chronicler around 664 and bishop Bar Hebraeus in the thirteenth century. [122] According to French scholar Javier Teixidor , Zenobia was probably a proselyte ; this explained her strained relationship with the rabbis. [128] Teixidor believed that Zenobia became interested in Judaism when Longinus spoke about the philosopher Porphyry and his interest in the Old Testament . [128] Although Talmudic sources were hostile to Palmyra because of Odaenathus' suppression of the Jews of Nehardea , [129] Zenobia apparently had the support of some Jewish communities (particularly in Alexandria). [106] In Cairo , [130] a plaque originally bearing an inscription confirming a grant of immunity to a Jewish synagogue in the last quarter of the first millennium BC by King Ptolemy Euergetes ( I or II ) was found. [130] At a much later date, the plaque was re-inscribed to commemorate the restoration of immunity "on the orders of the queen and king". [117] [130] Although it is undated, the letters of the inscription date to long after Cleopatra and Anthony's era; Zenobia and her son are the only candidates for a king and a queen ruling Egypt after the Ptolemies. [117] [131]
Historian E. Mary Smallwood wrote that good relations with the diaspora community did not mean that the Jews of Palestine were content with Zenobia's reign, and her rule was apparently opposed in that region. [129] The Terumot tells the story of Rabbi "Ammi" and Rabbi "Samuel bar Nahmani", who visited Zenobia's court and asked for the release of a Jew ("Zeir bar Hinena") detained on her orders. [132] The queen refused, saying: "Why have you come to save him? He teaches that your creator performs miracles for you. Why not let God save him?" [133] During Aurelian's destruction of Palmyra, Palestinian conscripts with "clubs and cudgels" (who may have been Jews) played a vital role in Zenobia's defeat and the destruction of her city. [134]
There is no evidence of Zenobia's birth as a Jew; the names of her and her husband's families belonged to the Aramaic onomasticon (collection of names). [128] The queen's alleged patronage of Paul of Samosata (who was accused of "Judaizing"), [129] may have given rise to the idea that she was a proselyte. [34] Only Christian accounts note Zenobia's Jewishness; no Jewish source mentions it. [135]

Administration
The queen probably spent most of her reign in Antioch, [105] Syria's administrative capital. [79] Before the monarchy, Palmyra had the institutions of a Greek city ( polis ) and was ruled by a senate which was responsible for most civil affairs. [136] [137] Odaenathus maintained Palmyra's institutions, as did Zenobia; [138] a Palmyrene inscription after her fall records the name of Septimius Haddudan, a Palmyrene senator. [139] However, the queen apparently ruled autocratically ; Septimius Worod , Odaenathus' viceroy and one of Palmyra's most important officials, disappeared from the record after Zenobia's ascent. [140] The queen opened the doors of her government to Eastern nobility. [108] Zenobia's most important courtier and advisers were her generals, Septemius Zabdas and Septimius Zabbai; [112] both of whom were generals under Odaenathus and received the gentilicium (surname) "Septimius" from him. [141]
Odaenathus respected the Roman emperor's privilege of appointing provincial governors, [142] and Zenobia continued this policy during her early reign. [143] Although the queen did not interfere in day-to-day administration, she probably had the power to command the governors in the organization of border security. [144] During the rebellion, Zenobia maintained Roman forms of administration, [37] but appointed the governors herself (most notably in Egypt, [145] where Julius Marcellinus took office in 270 and was followed by Statilius Ammianus in 271). [note 13] [144]

Agreement with Rome
Zenobia initially avoided provoking Rome by claiming for herself and her son the titles, inherited from Odaenathus, of subject of Rome and protector of its eastern frontier. [82] After expanding her territory, she seems to have tried to be recognized as an imperial partner in the eastern half of the empire and presented her son as subordinate to the emperor. [147] [98] [148] In late 270, Zenobia minted coinage bearing the portraits of Aurelian and Vaballathus; Aurelian was titled "emperor", and Vaballathus "king". [147] The regnal year in early samples of the coinage was only Aurelian's. [147] By March 271, [149] despite indicating Aurelian as the paramount monarch by naming him first in the dating formulae, the coinage also began bearing Vaballathus' regnal year. [150] By indicating in the coinage that Vaballathus' reign began in 267 (three years before the emperor's), Vaballathus appeared to be Aurelian's senior colleague. [150]
The emperor's blessing of Palmyrene authority has been debated; [148] Aurelian's acceptance of Palmyrene rule in Egypt may be inferred from the Oxyrhynchus papyri, which are dated by the regnal years of the emperor and Vaballathus. [147] [151] No proof of a formal agreement exists, and the evidence is based solely on the joint coinage- and papyri-dating. [148] It is unlikely that Aurelian would have accepted such power-sharing, [147] but he was unable to act in 271 due to crises in the West. [148] [147] His apparent condoning of Zenobia's actions may have been a ruse to give her a false sense of security while he prepared for war. [148] [147] Another reason for Aurelian's tolerance may have been his desire to ensure a constant supply of Egyptian grain to Rome ; [152] it is not recorded that the supply was cut, and the ships sailed to Rome in 270 as usual. [145] Some modern scholars, such as Harold Mattingly , suggest that Cladius Gothicus had concluded a formal agreement with Zenobia which Aurelian ignored. [35]

Empress and open rebellion
An inscription, found in Palmyra and dated to August 271, called Zenobia eusebes (the pious); [149] this title, used by Roman empresses, could be seen as a step by the queen toward an imperial title. [153] Another contemporary inscription called her sebaste , the Greek equivalent of "empress" (Latin: Augusta ), but also acknowledged the Roman emperor. [153] A late-271 Egyptian grain receipt equated Aurelian and Vaballathus, jointly calling them Augusti . [153] Finally, Palmyra officially broke with Rome; [154] the Alexandrian and Antiochian mints removed Aurelian's portrait from the coins in April 272, issuing new tetradrachms in the names of Vaballathus and Zenobia (who were called Augustus and Augusta , respectively). [153]
The assumption of imperial titles by Zenobia signaled a usurpation : independence from, and open rebellion against, Aurelian. [155] The timeline of events and why Zenobia declared herself empress is vague. [156] In the second half of 271, [157] Aurelian marched to the East, but was delayed by the Goths in the Balkans; [155] this may have alarmed the queen, driving her to claim the imperial title. [156] Zenobia also probably understood the inevitability of open conflict with Aurelian, and decided that feigning subordination would be useless; [158] her assumption of the imperial title was used to rally soldiers to her cause. [158] Aurelian's campaign seems to have been the main reason for the Palmyrene imperial declaration and the removal of his portrait from its coins. [153] [88]

Downfall
The usurpation, which began in late March or early April 272, ended by August. [159] Aurelian spent the winter of 271–272 in Byzantium , [160] and probably crossed the Bosporus to Asia Minor in April 272. [161] Galatia fell easily; the Palmyrene garrisons were apparently withdrawn, and the provincial capital of Ancyra was regained without a struggle. [162] All the cities in Asia Minor opened their doors to the Roman emperor, with only Tyana putting up some resistance before surrendering; this cleared the path for Aurelian to invade Syria, the Palmyrene heartland. [163] A simultaneous expedition reached Egypt in May 272; by early June Alexandria was captured by the Romans, followed by the rest of Egypt by the third week of June. [162] Zenobia seems to have withdrawn most of her armies from Egypt to focus on Syria—which, if lost, would have meant the end of Palmyra. [161]
In May 272, Aurelian headed toward Antioch. [164] About 40 kilometres (25 mi) north of the city, he defeated the Palmyrene army (led by Zabdas) at the Battle of Immae . [164] [165] As a result, Zenobia, who waited in Antioch during the battle, retreated with her army to Emesa. [166] To conceal the disaster and make her flight safer, she spread reports that Aurelian was captured; Zabdas found a man who resembled the Roman emperor and paraded him through Antioch. [167] The following day, Aurelian entered the city before marching south. [166] After defeating a Palmyrene garrison south of Antioch, [168] Aurelian continued his march to meet Zenobia in the Battle of Emesa . [168]
The 70,000-strong Palmyrene army, assembled on the plain of Emesa, nearly routed the Romans. [168] In an initial thrill of victory they hastened their advance, breaking their lines and enabling the Roman infantry to attack their flank. [168] The defeated Zenobia headed to her capital on the advice of her war council, leaving her treasury behind. [169] In Palmyra, the queen prepared for a siege; [170] Aurelian blockaded food-supply routes, [171] and there were probably unsuccessful negotiations. [172] According to the Augustan History , Zenobia said that she would fight Aurelian with the help of her Persian allies; however, the story was probably fabricated and used by the emperor to link Zenobia to Rome's greatest enemy. [172] If such an alliance existed, a much-larger frontier war would have erupted; however, no Persian army was sent. [172] As the situation worsened, the queen left the city for Persia intending on seeking help from Palmyra's former enemy; according to Zosimus, she rode a "female camel, the fastest of its breed and faster than any horse". [169] [173]

Captivity and fate
Aurelian, learning about Zenobia's departure, sent a contingent which captured the queen before she could cross the Euphrates to Persia; [173] Palmyra capitulated soon after news of Zenobia's captivity reached the city in August 272. [note 14] [175] [139] Aurelian sent the queen and her son to Emesa for trial, followed by most of Palmyra's court elite (including Longinus). [176] According to the Augustan History and Zosimus, Zenobia blamed her actions on her advisers; however, there are no contemporary sources describing the trial, only later hostile Roman ones. [176] The queen's reported cowardice in defeat was probably Aurelian's propaganda; it benefited the emperor to paint Zenobia as selfish and traitorous, discouraging the Palmyrenes from hailing her as a hero. [176] Although Aurelian had most of his prisoners executed, he spared the queen and her son to parade her in his planned triumph . [177]
Zenobia's fate after Emesa is uncertain, since ancient historians left conflicting accounts. [178] Zosimus wrote that she died before crossing the Bosporus on her way to Rome; according to this account, the queen became ill or starved herself to death. [178] Chronicler John Malalas wrote that Aurelian humiliated Zenobia by parading her through the eastern cities on a dromedary ; in Antioch, the emperor had her chained and seated on a dais in the hippodrome for three days before the city's populace. [178] [179] Malalas concluded his account by writing that Zenobia appeared in Aurelian's triumph and was then beheaded. [180]
Most ancient historians and modern scholars agree that Zenobia was displayed in Aurelian's 274 triumph; [180] Zosimus was the only source to say that the queen died before reaching Rome, making his account questionable. [181] A public humiliation (as recounted by Malalas) is a plausible scenario, since Aurelian would probably have wanted to publicize his suppression of the Palmyrene rebellion. [178] Only Malalas, however, describes Zenobia's beheading; according to the other historians, her life was spared after Aurelian's triumph. [180] The Augustan History recorded that Aurelian gave Zenobia a villa in Tibur near Hadrian's Villa , where she lived with her children. [182] [183] Zonaras wrote that Zenobia married a nobleman, [184] and Syncellus that she married a Roman senator. [182] The house she reportedly occupied became a tourist attraction in Rome. [185]

Titles
The queen owed her elevated position to her son's minority. [186] An inscription on a milestone on the road between Palmyra and Emesa, dated to Zenobia's early reign, [187] identifies her as "illustrious queen, mother of the king of kings"; [28] this was the first inscription giving her an official position. [188] A lead token from Antioch also identifies Zenobia as queen. [189] [190] The earliest known attestation of Zenobia as queen in Palmyra is an inscription on the base of a statue erected for her by Zabdas and Zabbai, dated to August 271 and calling her "most illustrious and pious queen". [188] [191] On an undated milestone found near Byblos , Zenobia is titled Sebaste . [156] The queen was never acknowledged as sole monarch in Palmyra, although she was the de facto sovereign of the empire; [64] she was always associated with her husband or son in inscriptions, except in Egypt (where some coins were minted in Zenobia's name alone). [64] According to her coins, the queen assumed the title of Augusta (empress) in 272. [153]

Descendants
In addition to Vaballathus, Zenobia had other children; the image of a child named Hairan (II) appears on a seal impression with that of his brother Vaballathus; no name of a mother was engraved and the seal is undated. [192] Odaenathus' son Herodianus is identified by Udo Hartmann with Hairan I , a son of Odaenahtus who appears in Palmyrene inscriptions as early as 251. [193] David S. Potter, on the other hand, suggested that Hairan II is the son of Zenobia and that he is Herodianus instead of Hairan I. [194]
Herennianus and Timolaus were mentioned only in the Augustan History . [195] Herennianus may be a conflation of Hairan and Herodianus; Timolaus is probably a fabrication, [58] although historian Dietmar Kienast suggested that he might have been Vaballathus. [196]
A controversial Palmyrene inscription records Septimius Antiochus , "Zenobia's son". [197] He may have been Vaballathus' younger brother, or was presented in this manner for political reasons; Antiochus was proclaimed emperor in 273, when Palmyra revolted against Rome for a second time. [197] If Antiochus was a son of Zenobia, he was probably a young child not fathered by Odaenathus; Zosimus described him as insignificant, appropriate for a five-year-old boy. [198]
According to the Augustan History , Zenobia's descendants were Roman nobility during the reign of Emperor Valens (reigned 364–375). [199] Eutropius and Jerome chronicled the queen's descendants in Rome during the fourth and fifth centuries. [185] [183] They may have been the result of a reported marriage to a Roman spouse or offspring who accompanied her from Palmyra; both theories, however, are tentative. [200] Zonaras is the only historian to note that Zenobia had daughters; [200] he wrote that one married Aurelian, who married the queen's other daughters to distinguished Romans. [184] According to Southern, the emperor's marriage to Zenobia's daughter is a fabrication. [182]

Evaluation and legacy
An evaluation of Zenobia is difficult; the queen was courageous when her husband's supremacy was threatened and by seizing the throne, she protected the region from a power vacuum after Odaenathus' death. [201] According to Watson, she made what Odaenathus left her a "glittering show of strength". [202] In the view of Watson, Zenobia should not be seen as a total powermonger, nor as a selfless hero fighting for a cause; according to historian David Graf, "She took seriously the titles and responsibilities she assumed for her son and that her program was far more ecumenical and imaginative than that of her husband Odenathus, not just more ambitious". [202]
Zenobia has inspired scholars, academics, musicians and actors; her fame has lingered in the West, and is supreme in the Middle East . [23] As a heroic queen with a tragic end, she stands alongside Cleopatra and Boudica . [23] The queen's legend turned her into an idol, that can be reinterpreted to accommodate the needs of writers and a historians; thus, Zenobia has been by turns a freedom fighter, a hero of the oppressed and a national symbol. [12] The queen is a female role model; [203] according to historian Michael Rostovtzeff , Catherine the Great liked to compare herself to Zenobia as a woman who created military might and an intellectual court. [186] During the 1930s, thanks to an Egyptian-based feminist press, Zenobia became an icon for women's-magazine readers in the Arabic-speaking world as a strong, nationalistic female leader. [204]
Her most lasting legacy is in Syria, where the queen is a national symbol. [205] Zenobia became an icon for Syrian nationalists ; she had a cult following among Western-educated Syrians, and an 1871 novel by journalist Salim al-Bustani was entitled Zenobia malikat Tadmor ( Zenobia, Queen of Palmyra ). [206] Syrian nationalist Ilyas Matar , who wrote Syria's first history in Arabic in 1874, [207] [208] ( al-'Uqud al-durriyya fi tarikh al-mamlaka al-Suriyya ; The Pearl Necklace in the History of the Syrian Kingdom ), [209] was fascinated by Zenobia and included her in his book. [210] To Matar, the queen kindled hope for a new Zenobia who would restore Syria's former grandeur. [210] Another history of Syria was written by Jurji Yanni in 1881, [211] in which Yanni called Zenobia a "daughter of the fatherland", and yearned for her "glorious past". [212] Yanni described Aurelian as a tyrant who deprived Syria of its happiness and independence by capturing its queen. [212]
In modern Syria, Zenobia is regarded as a hero; her image appeared on banknotes , [205] and in 1997 she was the subject of the television series Al-Ababid ( The Anarchy ). [23] The series was watched by millions in the Arabic-speaking world. [23] It examined the Israeli–Palestinian conflict from a Syrian perspective, where the queen's struggle symbolized the Palestinians' struggle to gain the right of self-determination. [205] Zenobia was also the subject of a biography by Mustafa Tlass , Syria's former minister of defense and one of the country's most prominent figures. [205]

Myth, romanticism and popular culture
Harold Mattingly called Zenobia "one of the most romantic figures in history". [201] According to Southern, "The real Zenobia is elusive, perhaps ultimately unattainable, and novelists, playwrights and historians alike can absorb the available evidence, but still need to indulge in varied degrees of speculation." [213]
She has been the subject of romantic and ideologically-driven biographies by ancient and modern writers. [214] [215] The Augustan History is the clearest example of an ideological account of Zenobia's life, and its author acknowledged that it was written to criticize the emperor Gallienus . [215] According to the History , Gallienus was weak because he allowed a woman to rule part of the empire and Zenobia was an abler sovereign than the emperor. [216] The narrative changed as the Augustan History moved on to the life of Claudius Gothicus , a lauded and victorious emperor, with the author characterizing Zenobia's protection of the eastern frontier as a wise delegation of power by Claudius. [216] When the History reached the biography of Aurelian, the author's view of Zenobia changed dramatically; the queen is depicted as a guilty, insolent, proud coward. [216] Her wisdom was discredited and her actions deemed the result of manipulation by advisers. [43]
Zenobia's "staunch" beauty was emphasized by the author of the Augustan History , who ascribed to her feminine timidity and inconsistency (the reasons for her alleged betrayal of her advisers to save herself). [217] The queen's gender posed a dilemma for the History , since it cast a shadow on Aurelian's victory. [217] Its author ascribed many masculine traits to Zenobia to make Aurelian a conquering hero who suppressed a dangerous Amazon queen. [217] According to the Augustan History , Zenobia had a clear, manly voice, dressed as an emperor (rather than an empress), rode horseback, was attended by eunuchs instead of ladies-in-waiting , marched with her army, drank with her generals, was careful with money (contrary to the stereotypical spending habits of her gender) and pursued masculine hobbies such as hunting. [218] Giovanni Boccaccio wrote a fanciful 14th-century account of the queen in which she is a tomboy in childhood who preferred wrestling with boys, wandering in the forests and killing goats to playing like a young girl. [219] Zenobia's chastity was a theme of these romanticized accounts; according to the Augustan History , she disdained sexual intercourse and allowed Odaenathus into her bed only for conception. [219] Her reputed chastity impressed some male historians; Edward Gibbon wrote that Zenobia surpassed Cleopatra in chastity and valor. [219] According to Boccaccio, Zenobia safeguarded her virginity when she wrestled with boys as a child. [219]
Seventeenth-century visitors to Palmyra rekindled the Western world's romantic interest in Zenobia. [43] This interest peaked during the mid-nineteenth century, when Lady Hester Stanhope visited Palmyra and wrote that its people treated her like the queen; she was reportedly greeted with singing and dancing, and Bedouin warriors stood on the city's columns. [20] A procession ended with a mock coronation of Stanhope under the arch of Palmyra as "queen of the desert". [20] William Ware , fascinated by Zenobia, wrote a fanciful account of her life. [16] Novelists and playwrights, such as Haley Elizabeth Garwood and Nick Dear , also wrote about the queen. [16]

Selected cultural depictions

Notes

See also
WebPage index: 00003
Upper Canada Rebellion
The Upper Canada Rebellion was an insurrection against the oligarchic government of the British colony of Upper Canada (present day Ontario ) in December 1837. While public grievances had existed for years, it was the Rebellion in Lower Canada (present day Quebec ) that emboldened rebels in Upper Canada to openly revolt soon after. The Upper Canada Rebellion was largely defeated shortly after it began, although resistance lingered until 1838 (and became more violent) - mainly through the support of the Hunters' Lodges , a secret anti-British, US-based militia that emerged around the Great Lakes . They launched the Patriot War in 1838-39. The rebellion led directly to Lord Durham 's Report on the Affairs of British North America and to The British North America Act, 1840 which partially reformed the British provinces into a unitary system.
Some historians argue that the rebellions in 1837 should be viewed in the wider context of the late 18th and early 19th century Atlantic revolutions . The American Revolutionary war in 1776, the French Revolution of 1789–1799, the Haitian Revolution of 1791-1804, the Irish Rebellion of 1798 , and the independence struggles of Spanish America (1810–1825) were inspired by similar democratic ideals, although they were tinged with republicanism as well. The United Kingdom's Chartists sought similar democratic goals. [1] [2] [3]

Reform movement and rebellion organization
The Upper Canada Rebellion is sometimes dismissed as a "farmers' revolt," an opportunistic action by misled backwoodsmen. [ by whom? ] The rebellion was, rather, the unintended consequence of a sophisticated political movement that copied the organizational forms of the British reform movement . The British Reform movement, organized as "Political Unions," had achieved the Great Reform Bill of 1832 which broadened the electoral franchise and helped eliminate political corruption. [4]

Political unions
The Upper Canada Central Political Union was organized in 1832-3 by Dr Thomas David Morrison (mayor of Toronto in 1836) while William Lyon Mackenzie was in England. This union collected 19,930 signatures on a petition protesting Mackenzie's unjust expulsion from the House of Assembly by the Family Compact . [5] The Reformers won a majority in the elections held in 1834 for the Legislative Assembly of the 12th Parliament of Upper Canada and Mackenzie was again elected as member for York , but the Family Compact held the majority in the Legislative Council, and the two Houses of government were at loggerheads.
This union was reorganized as the Canadian Alliance Society in 1835. It shared a large meeting space in the market buildings with the Mechanics Institute and the Children of Peace . The Canadian Alliance Society adopted much of the platform (such as secret ballot & universal suffrage) of the Owenite National Union of the Working Classes in London, England, that were to be integrated into the Chartist movement in England. In pursuit of this democratic goal, the Chartists eventually staged a similar armed rebellion, the Newport Rising , in Wales in 1839. [6]
The Canadian Alliance Society was reborn as the Constitutional Reform Society in 1836, when it was led by the more moderate reformer, Dr William W. Baldwin . The Reformers experienced a disaster at the 1836 elections for the 13th Parliament of Upper Canada , and the Society took its final form as the Toronto Political Union in 1837. It was this group of the disenfranchised that began organizing local "Vigilance Committees" to elect delegates to a so-called Constitutional Convention in July 1837. This became the organizational structure for the Rebellion; most of the rebel organizers were elected Constitutional Convention delegates. [7]

Convention delegates and committees of vigilance
The first of those meetings to select delegates to the constitutional convention were held at Doel's Brewery in Toronto on July 28 and 31. The second meeting was called to order by Samuel Hughes, a member of the Children of Peace , three days later, on August 3 in Newmarket . The meeting appointed Hughes, Samuel Lount , Nelson Gorham, Silas Fletcher, Jeremiah Graham and John McIntosh, M.P.P. as delegates to the convention (and all, with the exception of Hughes and MacIntosh, leaders in the Rebellion). A further eight public meetings across the Home District were scheduled over the next three weeks; each of these public meetings named a local committee of vigilance to organize reform support, prepare a registry of valid electors, and name their delegates to the proposed convention.
Immediately preceding the Mackenzie rebellion John Doel's house and brewery were prominent gathering places for the Reformers. The large meetings were usually held in the brewery while smaller meetings of the leaders were held in the home. Mackenzie’s planned to take foundry-men and axe-makers and seize arms, ammunition, and the artillery from the garrison. They would then arouse the citizens of the town and country to proclaim a provincial government. Mr. Doel objected to the plan and there was a fight between Mackenzie, Doel, and Morrison. The meeting was broken up and Mackenzie left the house forever. From this point forward John Doel, his brewery, and his home were not longer part of the rebellion. [8]
The meetings in the Home District met with an increasing amount of Orange Order violence, so that the reformers began to protect themselves and resort to arms to do so. Mackenzie was accompanied by 50 young farmers from the Lloydtown meeting, for example, after they heard that an Orange riot was planned for Albion. As the violence continued, peaceable reform meetings tapered off in October, to be replaced by instances of men drilling for battle.

Issues
There is no single cause for the Rebellion, only a context. [9] The issues, from the perspective of the reformers, were to an extent summarised in The seventh report from the Select Committee of the House of Assembly of Upper Canada on grievances... , [10] and can be related as follows:

Political issues

The alien question
Both before and after the War of 1812 , the government of Upper Canada continued to fear what it suspected might be a growing interest in American-inspired republicanism in the province. Reasons for this can be found in the pattern of settlement across the province over the previous half-century. Although the British had originally hoped that an orderly settlement in Upper Canada would inspire the former American colonies to abandon their republican [11] form of government, demographic realities intervened. After an initial group of about 70,000 United Empire Loyalists were thinly settled across the province in the mid-1780s, a far larger number of American settlers came after Lieutenant-Governor John Graves Simcoe offered cheap land grants to promote settlement. Although these settlers, known as "late-Loyalists," were required to take an oath of allegiance to the Crown in order to obtain land, their fundamental political allegiances were always considered dubious. By 1812, this had become acutely problematic since the American settlers outnumbered the original Loyalists by more than ten to one. It was this reality that led American legislators to speculate that bringing Upper Canada into the American fold would be a "mere matter of marching." Following the war, the colonial government took active steps to prevent Americans from swearing allegiance, thereby making them ineligible to obtain land grants. Relations between the appointed Legislative Council and the elected Legislative Assembly became increasingly strained in the years after the war, over issues of immigration, taxation, banking and land speculation. [12]

Family Compact and political corruption
The Family Compact was a small, tightly knit group of men who dominated the government of Upper Canada and the financial and religious institutions associated with it. They were the leading members of the administration: executive councillors, legislative councillors, senior officials and some members of the judiciary. [13] Their administrative roles, however, were intimately tied to their business activities: "they were not a political elite taking political decisions in a vacuum, but an overlapping elite whose political and economic activities cannot be entirely separated from each other. They might even be called 'entrepreneurs', most of whose political views may have been highly conservative but whose economic outlook was clearly 'developmental'." For example, William Allan, one of the most powerful, "was an executive councillor, a legislative councilor, President of the Toronto and Lake Huron Railroad, Governor of the British American Fire and Life Assurance Company and President of the Board of Trade." [14]
Mackenzie frequently complained about the manner in which members of the Family Compact utilized their official positions for monetary gain, especially through corporations such as the Bank of Upper Canada , and the two land companies (the Clergy Corporation and the Canada Company ) that between them controlled two sevenths of all the land in the province. [15] The Bank of Upper Canada, for example, had been founded by William Allan and the Rev. John Strachan , key members of the Family Compact, both of whom were Executive and Legislative Councillors. Although they lacked the minimum capital needed to found the bank, they persuaded the government to subscribe for a quarter of its shares. During the 1830s, a third of the bank's board were Legislative or Executive Councillors, and the remaining all magistrates. [16] Despite repeated attempts, the elected Legislature - which had chartered the bank - could obtain no details about the bank's workings. Mackenzie saw the bank as a prop of the Government and demanded farmers withdraw their support from it, by withdrawing their specie. The small confidence in the security which most banks gave for their redemption of their issues and the managers refusal to answer reasonable questions put forth by the House resulted in public confidence plummeting. Mackenzie was attempting to drain the banks of their money as a political weapon against the Government in hopes to avoid an armed revolution. However, the bank rebounded from this attack, making this attempt at peaceful revolution a failure. [17]

Sir Francis Bond Head and the elections of 1836
Sir Francis Bond Head, the newly appointed Lt. Governor, was initially warmly greeted by the Reform movement. His first move was to broaden the representation on the Executive Council by including the advocate of " responsible government ", Robert Baldwin . Disappointment soon followed when Bond Head made it clear he had no intention of consulting the Executive Council in the daily operations of the administration. The whole Executive Council unanimously resigned, provoking widespread discontent and an election. [18]
Unlike previous Lt. Governors, Bond Head threw himself into the electoral fray in support of the Tory candidates, and utilized Orange Order violence in order to ensure their election. [19] In the face of what was believed to be widespread fraud, William Lyon Mackenzie and Samuel Lount lost their seats in the Legislature. The reformers prepared a petition to the Crown protesting the abuses, carried to London by Charles Duncombe , but the Colonial Office refused to hear him. These three men became core organizers of the Rebellion.
The now Tory dominated Legislature passed a series of laws that exacerbated tensions:

Republicanism
After the 1836 elections, political rhetoric in the province was divisive, and did not allow for dissent. The Royal Standard , a short lived Tory daily, clearly called out for repressive measures.
William Lyon Mackenzie launched a new newspaper, the Constitution , on July 4, 1836. Lest the symbolism of the name and date be missed, he began serializing the American Revolutionary, Thomas Paine 's tract, Common Sense . A year later, in July 1837, the newly formed Toronto Political Union called for a constitutional convention. The "Declaration of the Reformers of the City of Toronto" contained provocative references to the American Revolution and included a direct attack on the recently deceased monarch who they held personally responsible for the colony's unrepresentative government.
In November 1837, in the lead-up to the Political Union's Constitutional Convention, Mackenzie published a satire in the Constitution , a round table discussion by such luminaries as John Locke , Benjamin Franklin , George Washington , Oliver Goldsmith and William Pitt and others, said to be a "convention sitting in this township for the purpose of circulating political information, weighing opinions as to the best means of improving the civil institutions of the country, and endeavoring to determine whether the British Constitution, Sir F. Head's government or Independence would be the most likely to prove advantageous to the people." As part of this satire, he published a draft republican constitution for Upper Canada. This constitution closely resembled the objectives spelled out in the constitution of the Canadian Alliance Society in 1834; it called for an elected governor, legislative council (senate), House of Assembly and magistracy, all by secret ballot. It was egalitarian, prohibiting both slavery and the granting of "hereditary emoluments, privileges, or honors." It also called for a separation of church and state, and barred the clergy from seeking election, or serving in any civil or military office. It guaranteed the rights to personal property, to freedom of the press, and freedom of assembly. But tied to these rights to personal property and egalitarian democracy were severe restrictions on chartering corporations; starting from the premise that "Labour is the only means of creating wealth" it placed a constitutional prohibition on chartering either banks or trading companies. [21]

Reform of the jury system
The reformer party in the Legislative Assembly desired that the Jury system be reformed, to the extent that they passed a Jury Law Amendment Bill no less than four times over eight years. [10] This was a contentious issue, and the Legislative Council replied again for the last time in favour of the status quo on February 25, 1836. [22] The defeat of the reformers in June 20, 1836 elections for the 13th Parliament of Upper Canada silenced this legislative outlet of steam, and thus was the stage set for rebellion.

Economic issues

Collapse of the international financial system
On July 10, 1832, President Andrew Jackson vetoed the bill for the rechartering of the Second Bank of the United States , arguing that it was utilized by a "moneyed aristocracy" to oppress the common man. The dismantling of the bank plunged the Anglo-American world into an enormous depression (1836–38) that was worsened by bad wheat harvests in Upper Canada in 1836. Farmers were unable to pay their debts. Most banks - including the Bank of Upper Canada - suspended payments (i.e. declared bankruptcy) by July 1837 and requested government support. While the banks received government support, ordinary farmers and the poor did not.
Among the more than 150 lawsuits they launched that year, the Bank of Upper Canada, which served the same purpose as the Bank of the United States, launched a suit against Sheldon, Dutcher & Co., a foundry and Toronto's largest employer with over 80 employees in late 1836, bankrupting the company. [23] Not surprisingly, Mackenzie's first plan for rebellion involved calling on Sheldon & Dutcher's men to storm the city hall, where the militia's guns were stored.

Economic distress
The brunt of this economic distress was felt by the common farmers. One fifth of British immigrants arrived in Upper Canada impoverished. Most immigrant farmers lacked the capital to pay for purchased land. The large debts they owed were compounded by the bad harvest, and debt collection laws that allowed for them to be jailed indefinitely until they paid their loans off to merchants. The situation was made worse in March 1837 when the Tories passed a law making it cheaper to sue farmers: city merchants could sue in the middle of harvest, and if the farmer refused to come to court in Toronto, they would automatically forfeit the case and be subjected to a sheriff's sale. [24]

Provincial debt of Upper Canada
The Reformers were incensed at the debt that the family compact had managed to incur as the results of general improvements to the province, such as the Welland Canal . [25] These debts stemmed mostly from investments in canals . [26] A man and his team of oxen hired at two dollars per day. The population of the province was estimated at 400,000, while the debt of the province amounted to around 1,000,000 pounds. The annual revenues amounted to 60,000, a sum almost insufficient to pay the interest on the debt. The dissolution of the 12th Parliament of Upper Canada in spring of 1836 resulted from the denial of money bills by the Reformist Legislative Assembly .

Confrontation

Toronto Rebellion
When the Lower Canada Rebellion broke out on October 9, 1837, Bond Head sent all the British troops stationed in Toronto to help suppress it. At the beginning of November, a meeting of 15 reformers at John Doel's house rejected Mackenzie's call for an immediate attack on City Hall. They instead decided to send Mackenzie north to investigate public sentiment. At a secret meeting in East Gwillimbury , Samuel Lount , Silas Fletcher, Peter Matthews of Pickering, Nelson Gorham of Newmarket, Jesse Lloyd of King township and James Bolton of Albion township heard Lloyd report on the revolt in Lower Canada. All were delegates to the Constitutional Convention. They decided to set the date for a supportive Upper Canadian revolt on December 7.
On November 15, Mackenzie published his draft constitution. On November 27, Mackenzie printed a handbill declaring "Independence!" On November 29, Mackenzie set the date for the Constitutional Convention for December 21, exactly 6 months after the date of King William's death - the Tory dominated elected assembly, which refused to prorogue, would at that time become illegitimate.
The delegates to the Convention, like Samuel Lount , downplayed the armed aspect of the Rebellion to the farmers he tried to enlist. Lount called a meeting in Hope (now Sharon ), the village of the Children of Peace , where he told them "there was war in Lower Canada and there was reason to believe that Martial Law would be proclaimed… he thought the city would be taken without firing a gun." [27]
Dr. Rolph, however, had heard that the Lt. Governor had been informed of the plan, and sent a note to Lount moving the march from the north forward to December 4, 1837. When hearing about this change of plans, Mackenzie quickly tried to send a messenger to Lount to tell him not to arrive until December 7. This message was not received in time, with Lount replying that the rebels had already been ordered to march to Toronto and were on their way. [28] Barely armed with pikes and guns for hunting fowl, the farmers from York County marched from Newmarket down Yonge Street towards Toronto and Montgomery's Tavern .
Before the direct confrontation between Mackenzie’s rebels and Bond Head’s militia forces on December 7, there were various encounters between both sides which resulted in small skirmishes. On December 4, Mackenzie and some fellow rebels encountered Alderman John Powell (Canadian politician) and Archibald McDonald when riding down Yonge Street to scout the city. Upon meeting them, Mackenzie took both men prisoner and sent them to Montgomery’s Tavern. Although there were concerns over whether Powell and McDonald possessed arms, Mackenzie accepted their denials and said, “well, gentlemen, as you are my townsmen, and men of honor, I would be ashamed to show that I question your words by ordering you to be searched.” [29] Despite such assurances, Powell had hidden a pistol and shot rebel Captain Anthony Anderson before escaping back to Toronto, thereby dealing a large blow to the rebel’s military expertise. [30]
As Mackenzie and his forces marched towards Toronto, Bond Head sent a flag to the rebels and asked for their demands, to which Mackenzie demanded “Independence and a convention to arrange details.” By the time Mackenzie and his followers had reached College Street, Bond Head sent another party to tell Mackenzie that his demands had been rejected. [31] That same day, Colonel Moodie attempted to ride through a roadblock to warn Bond Head, but the rebels shot him.
With the truce faltering, Mackenzie and his forces continued into Toronto, eventually confronting a small loyalist force estimated to be between 15 and 30 members strong. In spite of being vastly outnumbered, Mackenzie’s forces dispersed after the first round of firing in panic because they thought the rebel’s front row had been killed when they were simply dropping to the ground to allow those behind them to fire. [32]
The last real engagement prior to the Battle of Montgomery’s Tavern occurred on December 6 via a raid on a mail coach which was suspected to have government intelligence regarding future actions towards the rebels. It was from this raid that the rebels learned of government plans to soon attack Montgomery’s Tavern. [33]
When the revolt began, Mackenzie hesitated in attacking the city until December 7, when his military leader, Anthony Van Egmond , arrived. Van Egmond, a veteran on both sides of the Napoleonic Wars , advised immediate retreat, but Mackenzie remained hesitant. Mackenzie waited for Bond Head's force of about 1000 men and one cannon, led by Colonel James FitzGibbon , which outnumbered Mackenzie's approximately 400 rebels. When the battle started, Mackenzie split his troops into two groups and put one group on each side of Yonge Street, with the western flank taking the brunt of Bond Head’s assault. There are varying accounts on the length of the battle. Some say it was very short while others say the fighting lasted an hour. However, all accounts agree that the rebels were outmatched, both in weaponry and skill. [34] This can be attributed mostly to the unfortunate perception among the rebels that, when their counterparts in the front ranks fell down to reload, they perceived them to have been hit by enemy fire. In less than half an hour the confrontation was over, and the rebel forces dispersed. [35]

London Rebellion
News of the intended rebellion had reached London and the surrounding townships by December 7. It was initially thought that the Toronto rebellion was successful, contributing to Charles Duncombe wanting to rise up as well. [36] Upon hearing more details about the rebellion in Toronto, Duncombe convened a series of public meetings to spread news of the supposed atrocities committed by Bond Head against all suspected reformers to help increase anti-government support. It is estimated that there were between 400-500 rebels who assembled under Duncombe [37] Colonel Allan MacNab , who had just finished leading Upper Canadian militiamen during the Battle of Montgomery's Tavern, was sent to engage Duncombe's uprising. He left Hamilton, Ontario on December 12 and arrived in Brantford on December 13. Although many rebels, including Duncombe, had fled prior to the upcoming battle due to hearing about the failure of Mackenzie in Toronto and general disorganization, there were still some present in Scotland, Ontario and MacNab commenced his attack on Scotland on December 14, causing the remaining rebels to flee after only a few shots were fired. [38] The victorious Tory supporters burned homes and farms of known rebels and suspected supporters. In the 1860s, some of the former rebels were compensated by the Canadian government for their lost property in the rebellion aftermath.

Rebellion by other means
Mackenzie, Duncombe, John Rolph and 200 supporters fled to Navy Island in the Niagara River , where they declared themselves the Republic of Canada on December 13. They obtained supplies from supporters in the United States, resulting in British reprisals (see Caroline affair ). On January 13, 1838, under attack by British armaments, the rebels fled. Mackenzie went to the United States where he was arrested and charged under the Neutrality Act . [39] The other major leaders, Van Egmond, Samuel Lount , and Peter Matthews were arrested by the British; Van Egmond died in prison, and Lount and Matthews were executed at 8 AM on April 12, 1838, in Toronto. Their last words were: "Mr. Jarvis, do your duty; we are prepared to meet death and our Judge."
The rebels continued their raids into Canada, however, using the U.S. as a base of operations and cooperating with the U.S. Hunters' Lodges , dedicated to the overthrow of British rule in Canada. The raids did not end until the rebels and Hunters were decisively defeated at the Battle of the Windmill , nearly a year after the initial battle at Montgomery's Tavern.

Consequences: execution or transportation
Compared to the Lower Canada Rebellion, the initial portion of the Upper Canada Rebellion was short and disorganized. However, the British government in London was very concerned about the rebellion, especially in light of the strong popular support for the rebels in the United States and the more serious crisis in Lower Canada. Bond Head was recalled in late 1837 and replaced with Sir George Arthur who arrived in Toronto in March 1838. Parliament also sent Lord Durham to become Governor-in-Chief of the British North American colonies, [40] so that Arthur reported to Durham. Durham was assigned to report on the grievances among the British North American colonists and find a way to appease them. His report eventually led to greater autonomy in the Canadian colonies, and the union of Upper and Lower Canada into the Province of Canada in 1840. The populations of Upper and Lower Canada are listed on the Province of Canada wiki, and that of Canada West was not to exceed that of Canada East until 1850.
A number of the rebels were hanged including Samuel Lount and Peter Matthews , others were shot. [41] Their deaths were a strong motivation for the continuing Patriot War . Many more prisoners were transported , but most were pardoned , e.g. Enoch Moore (Loyalist turned rebel) . A general pardon (for everyone but Mackenzie) was issued in 1845, and Mackenzie himself was pardoned in 1849 and allowed to return to Canada, where he resumed his political career. Mackenzie was strongly disillusioned after his time in the United States, writing to his son that "after what I have seen here, I frankly confess to you that, had I passed nine years in the United States before, instead of after, the outbreak, I am sure I would have been the last man in America to be engaged in it." [42] In later life however, Mackenzie advocated annexation of Canada by the United States. [43]
In total 93 Americans and 58 Canadiens prisoners from Lower Canada were transported to Australia after being convicted in Montreal in late 1838 or early 1839. Almost all were taken on the HMS Buffalo , leaving Quebec in September 1839 and arriving off Hobart , Van Diemen's Land in February 1840. The Americans were disembarked at Hobart but the French-Canadians were taken to Sydney, New South Wales. They were interned near the present day suburb of Concord , giving rise to the names Canada Bay , France Bay and Exile Bay . The French-Canadians were treated better than the Americans, liberated sooner and assisted in getting home. Of the 93 Americans, 14 died as a direct result of transportation and penal servitude. By the end of 1844, half of those in Van Diemen's Land had been granted pardons, nearly all were pardoned by 1848, but five remained in penal servitude until at least 1850. None chose to stay in Van Diemen's Land after being pardoned. [44] [45]
From Upper Canada 150 were sent to the penal colony of Van Diemen's Land and Sydney, Australia . [41] In December 1838, more than a dozen convicts, amongst whom Grant, Miller, Reynolds, Parker, Malcolm, Walker, Bedford, Wixon, Watson, Brown, Anderson and Alves, were transferred through Liverpool , where those named interested in their case a local Member of Parliament, Joseph Hume , who brought an affidavit and petition of Habeas Corpus on their behalf. Grant had been sentenced in Niagara to death but pardoned if he would be transported. Miller and Reynolds were convicted in Niagara of felony to the same effect. The nine others were convicted in Toronto to the same effect. They depended, amongst other artifices, on the difference in status between convicted as they had been and pardoned by the time they were in Liverpool. But, in the end, the judges confirmed their transportation. [46]

Historical significance
The Rebellion – a "fact that every school child knows" – has overshadowed all else in the Canadian narratives on the struggle for democracy and responsible government . Allan Greer has argued that "though the 'Progress of Liberty' was a favorite theme of history for earlier generations, it is difficult today to get anyone interested in the history of democracy… Canadians in particular, taught in school to see their national past as a story dominated by transcontinental railways and Fathers of Confederation, have trouble imagining the struggle for democracy as an important historical theme. The history of democracy, we tend to believe, happened somewhere else." [47]
Paul Romney explains this failure of historical imagination as the outcome of an explicit strategy adopted by reformers in the face of charges of disloyalty to Britain in the wake of the Rebellions of 1837. In recounting the “myths of responsible government”, Romney emphasized that after the ascendancy of Loyalism as the dominant political ideology of Upper Canada any demand for democracy or for responsible government became a challenge to colonial sovereignty. The linkage of the "fight for responsible government" with disloyalty was solidified by the Rebellion of 1837, as reformers took up arms to finally break the "baneful domination" of the mother country. Struggling to avoid the charge of sedition, reformers later purposefully obscured their true aims of independence from Britain and focused on their grievances against the Family Compact. Thus, responsible government became a "pragmatic" policy of alleviating local abuses, rather than a revolutionary anti-colonial moment. [48]

See also

Notes

Further reading

Primary sources

External links
WebPage index: 00004
Theoris of Lemnos
Theoris of Lemnos (died before 338 BC) was an ancient Greek woman who was accused of witchcraft . She was executed along with her children, though the precise details of her offence are unclear. The evidence of her prosecution is the most detailed account of a witch trial to survive from Classical Greece . [1]

Accounts
The earliest and most detailed source on the trial of Theoris is the Pseudo-Demosthenic speech Against Aristogeiton , [2] which appears to have been addressed to jurors in the trial of Aristogeiton , an Athenian orator. The relevant passage says:
Two later testimonia also survive: one account by Philochorus , and one by Plutarch . Both of these accounts are based on the one in Against Aristogeiton . [4] Plutarch's account of the case seems to conflate the story of Theoris with that of another woman mentioned in the speeches of Demosthenes, Nino, who was executed in the 350s or 340s – apparently for performing rites which mocked the Dionysian mysteries . [5]
Theoris was originally from the island of Lemnos , but lived in Athens. [6] She had children, but there is no mention of a husband in the ancient sources. [7] Her children may have been by Eunomus, the brother of Aristogeiton, [8] though Demosthenes' text is not clear on this. [9]
Some time before 338 BC Theoris was put on trial in Athens, convicted, and executed along with her children. [1] It is not certain exactly what crime Theoris was charged with, as the surviving ancient sources differ. [10] According to Pseudo-Demosthenes it was for casting incantations and using harmful drugs; [1] she is described as a pharmakis , literally a provider of drugs and potions but in this context meaning a witch or sorceress. [11] Philochorus calls her a mantis or seeress [11] and reports that she was charged with impiety; [6] and Plutarch, who calls her a hiereia or priestess (though does not identify the deity she served), [11] says that she was convicted of "committing many misdeeds and teaching the slaves to deceive". [12] According to Plutarch, it was Demosthenes himself who prosecuted her. [11]

Analysis
Derek Collins suggests that Theoris was probably charged with intentional homicide by poisoning, in which case she would have been tried before the Areopagus . [13] Alternatively, she may have been charged with Βουλευσις ("planning" [14] ) to commit homicide, and been tried at the Palladion . [15] However, Collins thinks that the former scenario is more likely, as Theoris' family were executed with her. [15] Esther Eidinow suggests that Theoris's offences were more to do with offending religious or social sensibilities. The varying accounts given by classical Greek authors suggest that she may have been a self-proclaimed healer of the type that Hippocratic authors condemned, [16] may have transgressed some standard of social control relating to slaves, or may have engaged in "impiety", a vague term often used by politicians to attack rivals and in this case possibly set in the context of Theoris engaging in foretelling the future. [17]
Viewed in this light, Julia Kindt suggests that the trial and execution of Theoris may have been an instance of individuals within the polis seeking "to draw the line between religion and magic, between acceptable and unacceptable religious practices and religious power with the help of the law courts". [18] Michael A. Rinella points out that she must have been a figure of "some renown or notoriety", as the Pseudo-Demosthenic speaker clearly assumes that her name will be recognised. He notes that her prosecution itself indicates that she had some importance, either because she was important in her own right or because it was to someone's advantage to prosecute her. The account suggests that she was literate, setting her apart from most people, and that she had sufficient economic means to have a maidservant. [19]
WebPage index: 00005
Prostate cancer
Prostate cancer is the development of cancer in the prostate , a gland in the male reproductive system . [6] Most prostate cancers are slow growing; however, some grow relatively quickly. [3] [1] The cancer cells may spread from the prostate to other parts of the body, particularly the bones and lymph nodes . [7] It may initially cause no symptoms. [1] In later stages it can lead to difficulty urinating , blood in the urine, or pain in the pelvis , back or when urinating. [2] A disease known as benign prostatic hyperplasia may produce similar symptoms. Other late symptoms may include feeling tired due to low levels of red blood cells . [1]
Factors that increase the risk of prostate cancer include: older age, a family history of the disease, and race . About 99% of cases occur in those over the age of 50. Having a first-degree relative with the disease increases the risk two to threefold. In the United States it is more common in the African American population than the white American population. Other factors that may be involved include a diet high in processed meat , red meat , or milk products or low in certain vegetables . [3] An association with gonorrhea has been found, but a reason for this relationship has not been identified. [8] Prostate cancer is diagnosed by biopsy . Medical imaging may then be done to determine if the cancer has spread to other parts of the body. [2]
Prostate cancer screening is controversial. [3] [1] Prostate-specific antigen (PSA) testing increases cancer detection but does not decrease mortality. [9] The United States Preventive Services Task Force recommends against screening using the PSA test, due to the risk of overdiagnosis and overtreatment, as most cancer diagnosed would remain asymptomatic. The USPSTF concludes that the potential benefits of testing do not outweigh the expected harms. [10] While 5α-reductase inhibitors appear to decrease low-grade cancer risk they do not affect high-grade cancer risk and thus are not recommended for prevention. [3] Supplementation with vitamins or minerals does not appear to affect the risk. [3] [11]
Many cases can be safely followed with active surveillance or watchful waiting . Other treatments may include a combination of surgery, radiation therapy , hormone therapy or chemotherapy . [2] When it only occurs inside the prostate it may be curable. [1] In those in whom the disease has spread to the bones, pain medications , bisphosphonates and targeted therapy, among others, may be useful. Outcomes depend on a person's age and other health problems as well as how aggressive and extensive the cancer is. Most people with prostate cancer do not end up dying from the disease. [2] The 5-year survival rate in the United States is 99%. [4] Globally it is the second most common type of cancer and the fifth leading cause of cancer-related death in men. [5] In 2012 it occurred in 1.1 million men and caused 307,000 deaths. [5] It was the most common cancer in males in 84 countries, [3] occurring more commonly in the developed world . Rates have been increasing in the developing world . [12] Detection increased significantly in the 1980s and 1990s in many areas due to increased PSA testing. [3] Studies of males who died from unrelated causes have found prostate cancer in 30% to 70% of those over age 60. [1]

Signs and symptoms
Early prostate cancer usually has no clear symptoms. Sometimes, however, prostate cancer does cause symptoms, often similar to those of diseases such as benign prostatic hyperplasia . These include frequent urination, nocturia (increased urination at night), difficulty starting and maintaining a steady stream of urine, hematuria (blood in the urine), and dysuria (painful urination). A study based on the 1998 Patient Care Evaluation in the US found that about a third of patients diagnosed with prostate cancer had one or more such symptoms, while two-thirds had no symptoms. [13]
Prostate cancer is associated with urinary dysfunction as the prostate gland surrounds the prostatic urethra . Changes within the gland, therefore, directly affect urinary function. Because the vas deferens deposits seminal fluid into the prostatic urethra, and secretions from the prostate gland itself are included in semen content, prostate cancer may also cause problems with sexual function and performance, such as difficulty achieving erection or painful ejaculation . [13]
Metastatic prostate cancer that has spread to other parts of the body can cause additional symptoms. The most common symptom is bone pain , often in the vertebrae (bones of the spine), pelvis , or ribs . Spread of cancer into other bones such as the femur is usually to the proximal or nearby part of the bone. Prostate cancer in the spine can also compress the spinal cord , causing tingling, leg weakness and urinary and fecal incontinence . [14]

Risk factors
A complete understanding of the causes of prostate cancer remains elusive. [15] The primary risk factors are obesity, age and family history. Prostate cancer is very uncommon in men younger than 45, but becomes more common with advancing age. The average age at the time of diagnosis is 70. [16] However, many men never know they have prostate cancer. Autopsy studies of Chinese, German, Israeli, Jamaican, Swedish, and Ugandan men who died of other causes have found prostate cancer in 30% of men in their fifties, and in 80% of men in their seventies. [17] Men who have first-degree family members with prostate cancer appear to have double the risk of getting the disease compared to men without prostate cancer in the family. [18] This risk appears to be greater for men with an affected brother than for men with an affected father. In the United States in 2005, there were an estimated 230,000 new cases of prostate cancer and 30,000 deaths due to prostate cancer. [19] Men with high blood pressure are more likely to develop prostate cancer. [20] There is a small increased risk of prostate cancer associated with lack of exercise. [21] A 2010 study found that prostate basal cells were the most common site of origin for prostate cancers. [22]

Genetic
Genetic background may contribute to prostate cancer risk, as suggested by associations with race, family, and specific gene variants. Men who have a first-degree relative (father or brother) with prostate cancer have twice the risk of developing prostate cancer, and those with two first-degree relatives affected have a fivefold greater risk compared with men with no family history. [23] In the United States, prostate cancer more commonly affects black men than white or Hispanic men, and is also more deadly in black men. [24] [25] In contrast, the incidence and mortality rates for Hispanic men are one third lower than for non-Hispanic whites. Studies of twins in Scandinavia suggest that 40% of prostate cancer risk can be explained by inherited factors . [26]
No single gene is responsible for prostate cancer; many different genes have been implicated. Mutations in BRCA1 and BRCA2 , important risk factors for ovarian cancer and breast cancer in women, have also been implicated in prostate cancer. [27] Other linked genes include the Hereditary Prostate cancer gene 1 (HPC1), the androgen receptor, and the vitamin D receptor . [24] TMPRSS2 - ETS gene family fusion , specifically TMPRSS2- ERG or TMPRSS2- ETV1 /4 promotes cancer cell growth. [28]
Two large genome-wide association studies linking single nucleotide polymorphisms (SNPs) to prostate cancer were published in 2008. [29] [30] These studies identified several SNPs which substantially affect the risk of prostate cancer. For example, individuals with TT allele pair at SNP rs10993994 were reported to be at 1.6 times higher risk of prostate cancer than those with the CC allele pair. This SNP explains part of the increased prostate cancer risk of African American men as compared to American men of European descent, since the C allele is much more prevalent in the latter; this SNP is located in the promoter region of the MSMB gene, thus affects the amount of MSMB protein synthesized and secreted by epithelial cells of the prostate. [31]

Dietary
While some dietary factors have been associated with prostate cancer the evidence is still tentative. [32] Evidence supports little role for dietary fruits and vegetables in prostate cancer occurrence. [33] Red meat and processed meat also appear to have little effect in human studies. [34] Higher meat consumption has been associated with a higher risk in some studies. [35]
Lower blood levels of vitamin D may increase the risk of developing prostate cancer. [36]
Folic acid supplements have no effect on the risk of developing prostate cancer. [37]

Medication exposure
There are also some links between prostate cancer and medications, medical procedures, and medical conditions. [38] Use of the cholesterol-lowering drugs known as the statins may also decrease prostate cancer risk. [39]
Infection or inflammation of the prostate ( prostatitis ) may increase the chance for prostate cancer while another study shows infection may help prevent prostate cancer by increasing blood to the area. In particular, infection with the sexually transmitted infections chlamydia , gonorrhea , or syphilis seems to increase risk. [40] Finally, obesity [41] and elevated blood levels of testosterone [42] may increase the risk for prostate cancer. There is an association between vasectomy and prostate cancer; however, more research is needed to determine if this is a causative relationship. [43]
Research released in May 2007, found that US war veterans who had been exposed to Agent Orange had a 48% increased risk of prostate cancer recurrence following surgery. [44]

Infectious disease
An association with gonorrhea has been found, but a mechanism for this relationship has not been identified. [8]
In 2006, a previously unknown retrovirus, Xenotropic MuLV-related virus (XMRV), was associated with human prostate tumors, [45] but subsequent reports on the virus were contradictory, [46] [47] and the original 2006 finding was instead due to a previously undetected contamination. [48] The journals Science and PlosONE both retracted XMRV related articles. [49] [50]

Sexual factors
Several case-control studies have shown that having many lifetime sexual partners or starting sexual activity early in life substantially increases the risk of prostate cancer. [51] [52] [53]
While the available evidence is weak, [54] tentative results suggest that frequent ejaculation may decrease the risk of prostate cancer. [55] A study, over eight years, showed that those that ejaculated most frequently (over 21 times per month on average) were less likely to get prostate cancer. However, the researchers asserted ejaculation frequency was not statistically significantly associated with risk of advanced prostate cancer and concluded our results suggest that ejaculation frequency is not related to increased risk of prostate cancer . [56] The results were broadly similar to the findings of a smaller Australian study. [57]

Pathophysiology
The prostate is a part of the male reproductive system that helps make and store seminal fluid . In adult men, a typical prostate is about 3 centimeters long and weighs about 20 grams. [58] It is located in the pelvis , under the urinary bladder and in front of the rectum . The prostate surrounds part of the urethra , the tube that carries urine from the bladder during urination and semen during ejaculation . [59] Because of its location, prostate diseases often affect urination, ejaculation, and rarely defecation . The prostate contains many small glands which make about 20% of the fluid constituting semen . [60] In prostate cancer, the cells of these prostate glands mutate into cancer cells. The prostate glands require male hormones , known as androgens , to work properly. Androgens include testosterone , which is made in the testes ; dehydroepiandrosterone , made in the adrenal glands ; and dihydrotestosterone , which is converted from testosterone within the prostate itself. Androgens are also responsible for secondary sex characteristics such as facial hair and increased muscle mass.
Prostate cancer is classified as an adenocarcinoma , or glandular cancer, that begins when normal semen-secreting prostate gland cells mutate into cancer cells. The region of prostate gland where the adenocarcinoma is most common is the peripheral zone. Initially, small clumps of cancer cells remain confined to otherwise normal prostate glands, a condition known as carcinoma in situ or prostatic intraepithelial neoplasia (PIN). Although there is no proof that PIN is a cancer precursor, it is closely associated with cancer. Over time, these cancer cells begin to multiply and spread to the surrounding prostate tissue (the stroma ) forming a tumor . Eventually, the tumor may grow large enough to invade nearby organs such as the seminal vesicles or the rectum , or the tumor cells may develop the ability to travel in the bloodstream and lymphatic system . Prostate cancer is considered a malignant tumor because it is a mass of cells that can invade other parts of the body. This invasion of other organs is called metastasis . Prostate cancer most commonly metastasizes to the bones , lymph nodes , and may invade rectum, bladder and lower ureters after local progression. The route of metastasis to bone is thought to be venous as the prostatic venous plexus draining the prostate connects with the vertebral veins. [61]
The prostate is a zinc-accumulating, citrate -producing organ. The protein ZIP1 is responsible for the active transport of zinc into prostate cells. One of the zinc's important roles is to change the metabolism of the cell in order to produce citrate, an important component of semen. The process of zinc accumulation, alteration of metabolism, and citrate production is energy inefficient, and prostate cells sacrifice enormous amounts of energy (ATP) in order to accomplish this task. Prostate cancer cells are generally devoid of zinc. This allows prostate cancer cells to save energy not making citrate, and utilize the new abundance of energy to grow and spread. The absence of zinc is thought to occur via a silencing of the gene that produces the transporter protein ZIP1. ZIP1 is now called a tumor suppressor gene product for the gene SLC39A1 . The cause of the epigenetic silencing is unknown. Strategies which transport zinc into transformed prostate cells effectively eliminate these cells in animals. Zinc inhibits NF-κB pathways, is anti-proliferative and induces apoptosis in abnormal cells. Unfortunately, oral ingestion of zinc is ineffective since high concentrations of zinc into prostate cells is not possible without the active transporter, ZIP1. [62]
Loss of cancer suppressor genes, early in the prostatic carcinogenesis, have been localized to chromosomes 8p , 10q , 13q , and 16q . P53 mutations in the primary prostate cancer are relatively low and are more frequently seen in metastatic settings, hence, p53 mutations are a late event in the pathology of prostate cancer. Other tumor suppressor genes that are thought to play a role in prostate cancer include PTEN (gene) and KAI1 . "Up to 70 percent of men with prostate cancer have lost one copy of the PTEN gene at the time of diagnosis" [63] Relative frequency of loss of E-cadherin and CD44 has also been observed.
RUNX2 is a transcription factor that prevents cancer cells from undergoing apoptosis thereby contributing to the development of prostate cancer. [64]
The PI3k/Akt signaling cascade works with the transforming growth factor beta / SMAD signaling cascade to ensure prostate cancer cell survival and protection against apoptosis. [65] X-linked inhibitor of apoptosis ( XIAP ) is hypothesized to promote prostate cancer cell survival and growth and is a target of research because if this inhibitor can be shut down then the apoptosis cascade can carry on its function in preventing cancer cell proliferation. [66] Macrophage inhibitory cytokine-1 (MIC-1) stimulates the focal adhesion kinase (FAK) signaling pathway which leads to prostate cancer cell growth and survival. [67]
The androgen receptor helps prostate cancer cells to survive and is a target for many anti cancer research studies; so far, inhibiting the androgen receptor has only proven to be effective in mouse studies. [68] Prostate specific membrane antigen (PSMA) stimulates the development of prostate cancer by increasing folate levels for the cancer cells to use to survive and grow; PSMA increases available folates for use by hydrolyzing glutamated folates. [69]

Diagnosis
The American Cancer Society 's position regarding early detection is "Research has not yet proven that the potential benefits of testing outweigh the harms of testing and treatment. The American Cancer Society believes that men should not be tested without learning about what we know and don’t know about the risks and possible benefits of testing and treatment. Starting at age 50, (45 if African American or brother or father suffered from condition before age 65) talk to your doctor about the pros and cons of testing so you can decide if testing is the right choice for you." [70]
The only test that can fully confirm the diagnosis of prostate cancer is a biopsy , the removal of small pieces of the prostate for microscopic examination. However, prior to a biopsy, less invasive testing can be conducted.
There are also several other tests that can be used to gather more information about the prostate and the urinary tract. Digital rectal examination (DRE) may allow a doctor to detect prostate abnormalities. Cystoscopy shows the urinary tract from inside the bladder, using a thin, flexible camera tube inserted down the urethra . Transrectal ultrasonography creates a picture of the prostate using sound waves from a probe in the rectum.

Prostate imaging
Ultrasound (US) and magnetic resonance imaging (MRI) are the two main imaging methods used for prostate cancer detection. Urologists use transrectal ultrasound during prostate biopsy and can sometimes see a hypoechoic area (tissues or structures that reflect relatively less of the ultrasound waves directed at them). However, the US has poor tissue resolution and thus, is generally not clinically used.
Prostate MRI has better soft tissue resolution than ultrasound. [71]
MRI in those who are at low risk might help people choose active surveillance, in those who are at intermediate risk it may help with determining the stage of disease, while in those who are at high risk it might help find bone disease. [72]
Currently (2011), MRI is used to identify targets for prostate biopsy using fusion MRI with ultrasound (US) or MRI-guidance alone. In men who are candidates for active surveillance, fusion MR/US guided prostate biopsy detected 33% of cancers compared to 7% with standard ultrasound guided biopsy. [73]
Prostate MRI is also used for surgical planning for men undergoing robotic prostatectomy. It has also shown to help surgeons decide whether to resect or spare the neurovascular bundle, determine return to urinary continence, and help assess surgical difficulty. [74]
For Prostate MRI exists the PI-RADS Reporting system. PI-RADS is an acronym for Prostate Imaging-Reporting and Data System, defining standards of high-quality clinical service for multi-parametric Magnetic Resonance Imaging (mpMRI), including image creation and reporting.

Biopsy
If cancer is suspected, a biopsy is offered expediently. During a biopsy a urologist or radiologist obtains tissue samples from the prostate via the rectum. A biopsy gun inserts and removes special hollow-core needles (usually three to six on each side of the prostate) in less than a second. Prostate biopsies are routinely done on an outpatient basis and rarely require hospitalization. Antibiotics should be used to prevent complications like fever, urinary tract infections, and sepsis. [75] Fifty-five percent of men report discomfort during prostate biopsy. [76]

Gleason score
The tissue samples are then examined under a microscope to determine whether cancer cells are present, and to evaluate the microscopic features (or Gleason score ) of any cancer found. Prostate specific membrane antigen is a transmembrane carboxypeptidase and exhibits folate hydrolase activity. [77] This protein is overexpressed in prostate cancer tissues and is associated with a higher Gleason score . [77]

Tumor markers
Tissue samples can be stained for the presence of PSA and other tumor markers in order to determine the origin of malignant cells that have metastasized. [78]
Small cell carcinoma is a very rare (1% [79] ) type of prostate cancer that cannot be diagnosed using the PSA. [79] [80] As of 2009 [update] researchers were researching ways to screen for this type of prostate cancer, because it is relatively unknown and rare, but very serious and quick to spread to other parts of the body. [80] Possible methods include chromatographic separation methods by mass spectrometry, or protein capturing by immunoassays or immunized antibodies. The test method will involve quantifying the amount of the biomarker PCI , with reference to the Gleason Score . This test quick and sensitive. It can detect patients in the diagnostic grey zone, particularly those with a serum free to total Prostate Specific Antigen ratio of 10-20%. [81]
The oncoprotein BCL-2 is associated with the development of androgen-independent prostate cancer, due to its high levels of expression in androgen-independent tumours in advanced stages of the pathology. The upregulation of BCL-2 after androgen ablation in prostate carcinoma cell lines and in a castrated-male rat model further established a connection between BCL-2 expression and prostate cancer progression. [82]
The expression of Ki-67 by immunohistochemistry may be a significant predictor of patient outcome for men with prostate cancer. [83]
ERK5 is a protein that may be used as a marker. It is present in abnormally high levels in cases of prostate cancer, including invasive cancer that has metastasized. It is also present in relapsed cancer following previous hormone therapy. Reducing the amount of ERK5 in cancerous cells reduces their invasiveness. [84]

Staging
An important part of evaluating prostate cancer is determining the stage , or how far the cancer has spread. Knowing the stage helps define prognosis and is useful when selecting therapies. The most common system is the four-stage TNM system (abbreviated from Tumor/Nodes/Metastases). Its components include the size of the tumor, the number of involved lymph nodes , and the presence of any other metastases . [85]
The most important distinction made by any staging system is whether or not the cancer is still confined to the prostate. In the TNM system, clinical T1 and T2 cancers are found only in the prostate, while T3 and T4 cancers have spread elsewhere. Several tests can be used to look for evidence of spread. Medical specialty professional organizations recommend against the use of PET scans , CT scans , or bone scans when a physician stages early prostate cancer with low risk for metastasis. [86] Those tests would be appropriate in such cases as when a CT scan evaluates spread within the pelvis, a bone scan look for spread to the bones, and endorectal coil magnetic resonance imaging to closely evaluate the prostatic capsule and the seminal vesicles . Bone scans should reveal osteoblastic appearance due to increased bone density in the areas of bone metastasis —opposite to what is found in many other cancers that metastasize.
After a prostate biopsy, a pathologist looks at the samples under a microscope. If cancer is present, the pathologist reports the grade of the tumor. The grade tells how much the tumor tissue differs from normal prostate tissue and suggests how fast the tumor is likely to grow. The Gleason system is used to grade prostate tumors from 2 to 10, where a Gleason score of 10 indicates the most abnormalities. The pathologist assigns a number from 1 to 5 for the most common pattern observed under the microscope, then does the same for the second-most-common pattern. The sum of these two numbers is the Gleason score. The Whitmore-Jewett stage is another method sometimes used.

Prevention

Diet and lifestyle
The data on the relationship between diet and prostate cancer is poor. [87] In light of this the rate of prostate cancer is linked to the consumption of the Western diet. [87] There is little if any evidence to support an association between trans fat, saturated fat and carbohydrate intake and risk of prostate cancer. [87] [88] Evidence regarding the role of omega-3 fatty acids in preventing prostate cancer does not suggest that they reduce the risk of prostate cancer, although additional research is needed. [87] [89] Vitamin supplements appear to have no effect and some may increase the risk. [11] [87] High calcium intake has been linked to advanced prostate cancer. [90] Consuming fish may lower prostate cancer deaths but does not appear to affect its occurrence. [91] Some evidence supports lower rates of prostate cancer with a vegetarian diet. [92] There is some tentative evidence for foods containing lycopene and selenium . [93] Diets rich in cruciferous vegetables, soy, beans and other legumes may be associated with a lower risk of prostate cancer, especially more advanced cancers. [94]
Men who get regular exercise may have a slightly lower risk, especially vigorous activity and the risk of advanced prostate cancer. [94]

Medications
In those who are being regularly screened 5-alpha-reductase inhibitor ( finasteride and dutasteride ) reduce the overall risk of being diagnosed with prostate cancer however there is insufficient data to determine if they have an effect on the risk of death and may increase the chance of more serious cases. [95]

Screening
Prostate cancer screening is an attempt to find unsuspected cancers. Initial screens may lead to more invasive follow-up tests such as a biopsy . [96] Options include the digital rectal exam (DRE) and the prostate-specific antigen (PSA) blood test. Such screening is controversial and, in some people, may lead to unnecessary disruption and possibly harmful consequences. [97] Routine screening with either a DRE or PSA is not supported by the evidence as there is no mortality benefit from screening. [9]
The United States Preventive Services Task Force ( USPSTF ) recommends against the PSA test for prostate cancer screening in healthy men regardless of age. [98] They concluded that the potential benefit of testing does not outweigh the expected harms. [10] [99] The Centers for Disease Control and Prevention shared that conclusion. [100] The American Society of Clinical Oncology and the American College of Physicians discourages screening for those who are expected to live less than ten to fifteen years, while in those with a greater life expectancy a decision should be made by the person in question based on the potential risks and benefits. [101] In general, they concluded, "it is uncertain whether the benefits associated with PSA testing for prostate cancer screening are worth the harms associated with screening and subsequent unnecessary treatment." [102] American Urological Association (AUA 2013) guidelines call for weighing the benefits of preventing prostate cancer mortality in 1 man for every 1,000 men screened over a ten-year period against the known harms associated with diagnostic tests and treatment. The AUA recommends screening decisions in those 55 to 69 be based on shared decision making, and that if screening is performed it should occur no more often than every two years. [103]

Management
The first decision to be made in managing prostate cancer is whether treatment is needed. Prostate cancer, especially low-grade forms found in elderly men, often grows so slowly that no treatment is required. [104] Treatment may also be inappropriate if a person has other serious health problems or is not expected to live long enough for symptoms to appear.
Which option is best depends on the stage of the disease, the Gleason score, and the PSA level. Other important factors are age, general health, and a person's views about potential treatments and their possible side effects. Because most treatments can have significant side effects , such as erectile dysfunction and urinary incontinence , treatment discussions often focus on balancing the goals of therapy with the risks of lifestyle alterations. A combination of the treatment options is often recommended for managing prostate cancer. [105] [106] [107]
Guidelines for treatment for specific clinical situations requires a good estimation of a person's long-term life expectancy. [108] People can also use an 18-item questionnaire to learn whether they have good knowledge and understanding about their treatment options before they choose. Most of those who are newly diagnosed and made a treatment choice can not correctly answer over half of the questions. [108]
If radiation therapy is done first, and fails, then radical prostatectomy becomes a very technically challenging surgery and may not be feasible. On the other hand, radiation therapy done after surgical failure may have many complications. [109] It is associated with a small increase in bladder and colon cancer. [110]
In localized disease, it is unknown if radical prostatectomy is better or worse than watchful waiting. [111]
A meta-analysis on the effects of voiding position during urination in males with prostate enlargement showed that sitting was superior to standing. Bladder emptying was significantly improved, while there was a trend towards a higher urinary flow and shorter voiding time. [112]

Surveillance
Many men diagnosed with low-risk prostate cancer are eligible for active surveillance . This term implies careful observation of the tumor over time, with the intention of treatment for a cure if there are signs of cancer progression. Active surveillance is not synonymous with watchful waiting , an older term which implies no treatment or specific program of monitoring, with the assumption that palliative , not curative, treatment would be used if advanced, symptomatic disease develops.
Active surveillance involves monitoring the tumor for signs of growth or the appearance of symptoms. The monitoring process may involve serial PSA, physical examination of the prostate, and/or repeated biopsies. The goal of surveillance is to avoid overtreatment and the sometimes serious, permanent side effects of treatment for a slow-growing or self-limited tumor that would never cause any problems for the person. This approach is not used for aggressive cancers, but it may cause anxiety for people who wrongly believe that all cancer is deadly or themselves to have life-threatening cancer. For 50% to 75% of people with prostate cancer it will cause no harm before a person dies from other causes. [113]

Aggressive cancer
Treatment of aggressive prostate cancers may involve surgery (i.e. radical prostatectomy), radiation therapy including brachytherapy ( prostate brachytherapy ) and external beam radiation therapy, high-intensity focused ultrasound (HIFU), chemotherapy , oral chemotherapeutic drugs (Temozolomide/TMZ), cryosurgery , hormonal therapy , or some combination. [114] [115]
Although the widespread use of prostate-specific antigen (PSA) screening in the US has resulted in diagnosis at earlier age and cancer stage, the vast majority of cases are still diagnosed in men older than 65 years, and approximately 25% of cases are diagnosed in men older than 75 years. [116] Though US National Comprehensive Cancer Network guidelines recommend using life expectancy greater than or less than 10 years to help make treatment decisions, in practice, many elderly patients are not offered curative treatment options such as radical prostatectomy or radiation therapy and are instead treated with hormonal therapy or watchful waiting. [117] This pattern can be attributed to factors such as medical co-morbidity and patient preferences is regard to quality of life in addition to prostate cancer specific risk factors such as pretreatment PSA, Gleason score and clinical stage. As the average life expectancy increases due to advances in the treatment of cardiovascular, pulmonary and other chronic diseases, it is likely that more elderly patients will be living long enough to suffer the consequences of their prostate cancer. Therefore, there is currently much interest in the role of aggressive prostate cancer treatment modalities such as with surgery or radiation in the elderly population who have localized disease.
If the cancer has spread beyond the prostate, treatment options significantly change, so most doctors that treat prostate cancer use a variety of nomograms to predict the probability of spread. Treatment by watchful waiting/active surveillance, external beam radiation therapy, brachytherapy, cryosurgery, HIFU, and surgery are, in general, offered to men whose cancer remains within the prostate. Hormonal therapy and chemotherapy are often reserved for disease that has spread beyond the prostate. However, there are exceptions: radiation therapy may be used for some advanced tumors, and hormonal therapy is used for some early stage tumors. Cryotherapy (the process of freezing the tumor), hormonal therapy , and chemotherapy may also be offered if initial treatment fails and the cancer progresses.
Sipuleucel-T , a cancer vaccine has been found to result in a benefit (a four-month increase in survival) for men with metastatic prostate cancer. [118]

Castration-resistant
Most hormone dependent cancers become resistant to treatment after one to three years and resume growth despite hormone therapy. Previously considered "hormone-refractory prostate cancer" or "androgen-independent prostate cancer", the term castration-resistant has replaced "hormone refractory" because while they are no longer responsive to castration treatment (reduction of available androgen / testosterone / DHT by chemical or surgical means), these cancers still show reliance upon hormones for androgen receptor activation. [119]
The cancer chemotherapic docetaxel has been used as treatment for CRPC with a median survival benefit of 2 to 3 months. [120] [121] A second-line chemotherapy treatment is cabazitaxel . [122] A combination of bevacizumab , docetaxel , thalidomide and prednisone appears effective in the treatment of CRPC. [123]
The immunotherapy treatment with sipuleucel-T in CRPC increases survival by 4 months. [124] The second line hormonal therapy abiraterone increases survival by 4.6 months when compared to placebo. [125] Enzalutamide is another second line hormonal agent with a 5-month survival advantage over placebo. Both abiraterone and enzalutamide are currently being tested in clinical trials in those with CRPC who have not previously received chemotherapy. [126] [127]
Only a subset of people respond to androgen signaling blocking drugs and certain cells with characteristics resembling stem cells remain unaffected. [128] [129] Therefore, the desire to improve outcome of people with CRPC has resulted in the claims of increasing doses further or combination therapy with synergistic androgen signaling blocking agents. [130] But even these combination will not affect stem-like cells that do not exhibit androgen signaling. It is possible that for further advances, a combination of androgen signaling blocking agent with stem-like cell directed differentiation therapy drug would prove ideal. [131]

Palliative care
Palliative care is medical care which focuses on treatment of symptoms of serious illness, like cancer, and improving quality of life. [132] One of the goals of treatment in palliative care is symptom control rather than a cure of the underlying cancer. Pain is common in metastatic prostate cancer, and cancer pain related to bone metastases can be treated with bisphosphonates , medications such as opioids , and palliative radiation therapy to known metastases. Spinal cord compression can occur with metastases to the spine and can be treated with steroids , surgery, or radiation therapy. Other symptoms that can be addressed through palliative care include fatigue, delirium , lymphedema in the scrotum or penis, nausea, vomiting, and weight loss. [133]

Prognosis
Prostate cancer rates are higher in developed countries than in the rest of the world. Many of the risk factors for prostate cancer are more common including longer life expectancy and diets high in red meat. Also, where there is more access to screening programs, there is a higher detection rate.
In the United States , prostate cancer that is local or regional at the time of diagnosis has a 5-year survival rate of nearly 100%, while those with distant metastases have a 5-year survival rate of 29%. [134] In Japan , death from prostate cancer was one-fifth to one-half the rates in the United States and Europe in the 1990s. [135] In India in the 1990s, half of the people with prostate cancer confined to the prostate died within 19 years. [136] African-American men have 50–60 times more prostate cancer and prostate cancer deaths than men in Shanghai , China . [137] In Nigeria , 2% of men develop prostate cancer, and 64% of them are dead after 2 years. [138]
In patients who undergo treatment, the most important clinical prognostic indicators of disease outcome are the stage, pretherapy PSA level, and Gleason score. In general, the higher the grade and the stage, the poorer the prognosis. Nomograms can be used to calculate the estimated risk of the individual patient. The predictions are based on the experience of large groups of patients suffering from cancers at various stages. [139]
In 1941, Charles Huggins reported that androgen ablation therapy causes regression of primary and metastatic androgen-dependent prostate cancer. [140] He was awarded the 1966 Nobel Prize for Physiology or Medicine for this discovery. Androgen ablation therapy causes remission in 80-90% of patients undergoing therapy, resulting in a median progression-free survival of 12 to 33 months. After remission, an androgen-independent phenotype typically emerges, wherein the median overall survival is 23–37 months from the time of initiation of androgen ablation therapy. [141] It is not clear how the prostate cancer becomes androgen-independent or how it reestablishes progression, although a few possibilities (on how) have been proposed. [142] And the way the cancer changes, to overcome the lack of androgen, may vary between individual patients.

Classification systems
Many prostate cancers are not destined to be lethal, and most men will ultimately not die as a result of the disease. Decisions about treatment type and timing may, therefore, be informed by an estimation of the risk that the tumor will ultimately recur after treatment and/or progress to metastases and mortality. Several tools are available to help predict outcomes, such as pathologic stage and recurrence after surgery or radiation therapy. Most combine stage, grade, and PSA level, and some also add the number or percentage of biopsy cores positive, age, and/or other information.

Life expectancy
Life expectancy projections are averages for an entire male population, and many medical and lifestyle factors modify these numbers. For example, studies have shown that a 40-year-old man will lose 3.1 years of life if he is overweight (BMI 25-29) and 5.8 years of life if he is obese (BMI 30 or more), compared to men of normal weight. If he is both overweight and a smoker, he will lose 6.7 years, and if obese and a smoker, he will lose 13.7 years. [149]
At this time, there is no evidence that either surgery or beam radiation has an advantage over the other in this regard, the lower death rates reported with surgery appear to occur because surgery is more likely to be offered to younger men with less serious forms of cancer. Insufficient information is available to determine whether seed radiation extends life more readily than the other treatments, but data so far do not suggest that it does. [150]
People with low-grade disease (Gleason 2-4) were unlikely to die of prostate cancer within 15 years of diagnosis. Older men (age 70-75) with low-grade disease had an approximately 20% overall survival at 15 years due to deaths from competing causes. Men with high-grade disease (Gleason 8-10) experienced high prostate cancer mortality within 15 years of diagnosis, regardless of their age at diagnosis, underscoring the very aggressive nature of poorly differentiated prostate cancer. [151]

Epidemiology
As of 2012, prostate cancer is the second most frequently diagnosed cancer (at 15% of all male cancers) [153] and the sixth leading cause of cancer death in males worldwide. [154] In 2010 it resulted in 256,000 deaths up from 156,000 deaths in 1990. [155] Rates of prostate cancer vary widely across the world. Although the rates vary widely between countries, it is least common in South and East Asia, and more common in Europe, North America, Australia and New Zealand. [156] Prostate cancer is least common among Asian men and most common among black men, with figures for white men in between. [157] [158] The average annual incidence rate of prostate cancer between 1988 and 1992 among Chinese men in the United States was 15 times higher than that of their counterparts living in Shanghai and Tianjin. [157] [158] [159] However, these high rates may be affected by increasing rates of detection. [160] Many suggest that prostate cancer may be under reported, yet BPH incidence in China and Japan is similar to rates in Western countries. [161] [162] In Europe in 2012 it was the 3rd most diagnosed cancer after breast and colorectal at 417,000 cases. [163]
Prostate cancer develops primarily in men over fifty. It is the most common type of cancer in men in the United States, with 186,000 new cases in 2008 and 28,600 deaths. [164] [165] It is the second leading cause of cancer death in U.S. men after lung cancer . In the United Kingdom it is also the second most common cause of cancer death after lung cancer, where around 35,000 cases are diagnosed every year and of which around 10,000 die of it. [166]
More than 80% of men will develop prostate cancer by the age of 80. [167] However, in the majority of cases, it will be slow-growing and harmless. In such men, diagnosing prostate cancer is overdiagnosis —the needless identification of a technically aberrant condition that will never harm the patient—and treatment in such men exposes them to all of the adverse effects, with no possibility of extending their lives. [168]

History
Although the prostate was first described by Venetian anatomist Niccolò Massa in 1536, and illustrated by Flemish anatomist Andreas Vesalius in 1538, prostate cancer was not identified until 1853. [169] Prostate cancer was initially considered a rare disease, probably because of shorter life expectancies and poorer detection methods in the 19th century. The first treatments of prostate cancer were surgeries to relieve urinary obstruction. [170] Removal of the entire gland (radical perineal prostatectomy ) was first performed in 1904 by Hugh H. Young at Johns Hopkins Hospital . [171] Surgical removal of the testes ( orchiectomy ) to treat prostate cancer was first performed in the 1890s, but with limited success. Transurethral resection of the prostate (TURP) replaced radical prostatectomy for symptomatic relief of obstruction in the middle of the 20th century because it could better preserve penile erectile function. Radical retropubic prostatectomy was developed in 1983 by Patrick Walsh. [172] This surgical approach allowed for removal of the prostate and lymph nodes with maintenance of penile function.
In 1941, Charles B. Huggins published studies in which he used estrogen to oppose testosterone production in men with metastatic prostate cancer. This discovery of "chemical castration " won Huggins the 1966 Nobel Prize in Physiology or Medicine . [173] The role of the gonadotropin-releasing hormone (GnRH) in reproduction was determined by Andrzej W. Schally and Roger Guillemin , who both won the 1977 Nobel Prize in Physiology or Medicine for this work. GnRH receptor agonists, such as leuprolide and goserelin , were subsequently developed and used to treat prostate cancer. [174] [175]
Radiation therapy for prostate cancer was first developed in the early 20th century and initially consisted of intraprostatic radium implants. External beam radiotherapy became more popular as stronger [X-ray] radiation sources became available in the middle of the 20th century. Brachytherapy with implanted seeds (for prostate cancer) was first described in 1983. [176]
Systemic chemotherapy for prostate cancer was first studied in the 1970s. The initial regimen of cyclophosphamide and 5-fluorouracil was quickly joined by multiple regimens using a host of other systemic chemotherapy drugs. [177]

Cell-of-origin
A series of studies published in Science involved introduced viruses known to cause cancerous mutation in prostate cells: AKT, ERG, and AR into isolated samples of basal and luminal cells and grafted the treated tissue into mice. After 16 weeks, none of the luminal samples had undergone malignant mutation, while the basal samples had mutated into prostate-like tubules which had then developed malignancy and formed cancerous tumors, which appeared identical to human samples under magnification. This led to the conclusion that the prostate basal cell may be the most likely "site of origin" of prostate cancer. [22]

Society and culture
People with prostate cancer generally encounter significant disparities in awareness, funding, media coverage, and research—and therefore, inferior treatment and poorer outcomes—compared to other cancers of equal prevalence. [178] In 2001, The Guardian noted that Britain had 3,000 nurses specializing in breast cancer , compared to only one for prostate cancer. It also discovered that the waiting time between referral and diagnosis was two weeks for breast cancer but three months for prostate cancer. [179] A 2007 report by the U.S.-based National Prostate Cancer Coalition stated that for every prostate cancer drug on the market, there were seven used to treat breast cancer. The Times also noted an "anti-male bias in cancer funding" with a four-to-one discrepancy in the United Kingdom by both the government and by cancer charities such as Cancer Research UK . [178] [180] Equality campaigners such as author Warren Farrell cite such stark spending inequalities as a clear example of governments unfairly favouring women's health over men's health. [181]
Disparities also extend into areas such as detection, with governments failing to fund or mandate prostate cancer screening while fully supporting breast cancer programs. For example, a 2007 report found 49 U.S. states mandate insurance coverage for routine breast cancer screening, compared to 28 for prostate cancer. [178] [182] Prostate cancer also experiences significantly less media coverage than other, equally prevalent cancers, with a study by Prostate Coalition showing 2.6 breast cancer stories for each one covering cancer of the prostate. [178]
Prostate Cancer Awareness Month takes place in September in a number of countries. A light blue ribbon is used to promote the cause. [183] [184]

Research

CRPC
MDV3100 was in phase III trials for CRPC (chemo-naive and post-chemo patient populations) [185] and gained FDA approval in 2012 as enzalutamide for the treatment of castration-resistant prostate cancer. [126] [127]
Alpharadin completed a phase 3 trial for CRPC patients with bone metastasis. A pre-planned interim analysis showed improved survival and quality of life. The study was stopped for ethical reasons to give the placebo group the same treatment. Alpharadin uses bone targeted Radium-223 isotopes to kill cancer cells by alpha radiation. [186] It was approved by the U.S. Food and Drug Administration (FDA) on May, 15th 2013 ahead of schedule under the priority review program. [187] Alpharadin still waits for approval by the European Medicines Agency (EMA).
As of 2016 [update] PARP inhibitor olaparib has shown promise in clinical trials for CRPC. [188] Also in trials for CRPC are : checkpoint inhibitor ipilimumab , CYP17 inhibitor galeterone (TOK-001), and immunotherapy PROSTVAC . [188]

Pre-clinical
Arachidonate 5-lipoxygenase has been identified as playing a significant role in the survival of prostate cancer cells. [189] [190] [191] Medications which target this enzyme may be an effective therapy for limiting tumor growth and cancer metastasis as well as inducing programmed cell death in cancer cells. [189] [190] [191] In particular, arachidonate 5-lipoxygenase inhibitors produce massive, rapid programmed cell death in prostate cancer cells. [189] [190] [191]

Cancer models
Scientists have established a few prostate cancer cell lines to investigate the mechanism involved in the progression of prostate cancer. LNCaP , PC-3 ( PC3 ), and DU-145 ( DU145 ) are commonly used prostate cancer cell lines. The LNCaP cancer cell line was established from a human lymph node metastatic lesion of prostatic adenocarcinoma. PC-3 and DU-145 cells were established from human prostatic adenocarcinoma metastatic to bone and to brain, respectively. LNCaP cells express androgen receptor (AR); however, PC-3 and DU-145 cells express very little or no AR. AR, an androgen-activated transcription factor , belongs to the steroid nuclear receptor family. Development of the prostate is dependent on androgen signaling mediated through AR, and AR is also important during the development of prostate cancer. The proliferation of LNCaP cells is androgen -dependent but the proliferation of PC-3 and DU-145 cells is androgen -insensitive. Elevation of AR expression is often observed in advanced prostate tumors in patients. [192] [193] Some androgen-independent LNCaP sublines have been developed from the ATCC androgen-dependent LNCaP cells after androgen deprivation for study of prostate cancer progression. These androgen -independent LNCaP cells have elevated AR expression and express prostate specific antigen upon androgen treatment. The paradox is that androgens inhibit the proliferation of these androgen -independent prostate cancer cells. [194] [195] [196]

Diagnosis
At present, an active area of research and non-clinically applied investigations involve non-invasive methods of prostate tumor detection.
A molecular test that detects the presence of cell-associated PCA3 mRNA in fluid massaged from the prostate by the doctor and first-void urinated out has also been under investigation. PCA3 mRNA is expressed almost exclusively by prostate cells and has been shown to be highly over-expressed in prostate cancer cells. The test result is currently reported as a specimen ratio of PCA3 mRNA to PSA mRNA. Although not a replacement for serum PSA level, the PCA3 test is an additional tool to help decide whether, in men suspected of having prostate cancer (especially if an initial biopsy fails to explain the elevated serum PSA), a biopsy/rebiopsy is really needed. The higher the expression of PCA3 in the sample, the greater the likelihood of a positive biopsy; i.e., the presence of cancer cells in the prostate. [197]
WebPage index: 00006
Mindanao
Mindanao ( i / m ɪ n d ə ˈ n aʊ / ; Tagalog pronunciation: [minˈdɐnaw] ) is the second largest and southernmost major island in the Philippines . It is also the name of one of the three island groups in the country (the other two being Luzon and the Visayas ), consisting of the island of Mindanao and smaller outlying islands. As of the 2010 census, the island's population itself is 20,281,545 people, while the Mindanao island group has 21,968,174 inhabitants.
Davao City is the most populous city in Mindanao hosting 1,632,991 people, followed by Zamboanga City (pop. 861,799), Cagayan de Oro City (pop. 675,950), General Santos City (594,446) and Iligan City (342,618) based on the 2015 Census of Population. [2]
Parts of south-western Mindanao island group, particularly the provinces of Maguindanao , Basilan , Lanao del Sur , Sulu , and Tawi-Tawi (part of the Autonomous Region of Muslim Mindanao (ARMM)), are home to a sizeable Muslim population, making the island group, along with Palawan , the only area of the Philippines with a significant Muslim presence. The island has seen a communist insurgency as well as armed Moro separatist movements.
Mindanao is considered the food basket of the Philippines. [3] Eight of the top 10 agri-commodities exported from the Philippines come from here. Mindanao is also dubbed with the monikers The Philippines' Land of Promise and The Filipino Rust Belt . [4]

History
Mindanao is a once sovereign territory of a Sultanate named after the Maguindanaons who constituted the largest Sultanate historically, and evidence from maps made during the 17th and 18th centuries suggests that the name was used to refer to the island by the powerful natives at the time. Although many attempts made, it was never occupied by Spain for their 333 years of stay in Luzon and Visayas.
Yet during Spain's defeat and Treaty of Paris in 1898, they illegally included by coordinates Mindanao and Sulu to its supposed claim of colonial right of conquest. Yet once the Americans are on the ground they had proven that the claim was untrue but did a political maneuvering to still include Mindanao and Sulu, another sovereign and allow it to be absorbed by their nation construct Philippines.
Evidence of human occupation dates back tens of thousands of years. In prehistoric times the Negrito people arrived. Sometime around 1500 BC, Austronesian peoples spread throughout the Philippines and far beyond. Native people of the Maluku Islands refer the island as Maluku Besar ( Great Moluccas ).
Mindanao Island is also a sacred home of Paramata Bantogen , Mabaning Gandamatu and Daranda Mabagani the Meranaw native people from Kiaranda a Ragat a Tiongcopa Layagen before Islamic Da wah, the largest non-Muslim tribe, and the Subanon Tribe; [ clarification needed ] the aborigine of the Zamboanga Peninsula's Zamboanga del Norte , Zamboanga del Sur , Zamboanga Sibugay , Island of Basilan , and northern provinces of Misamis Occidental , Lanao del Norte , and Misamis Oriental .

Neolithic and Bronze Age
The Subanon are believed to have established themselves on Mindanao Island during the Neolithic Era, or New Stone Age, the period in the development of human technology beginning around 10,000 BC according to the ASPRO chronology (between 4,500 and 2,000 BC). [ clarification needed ] [5] The evidence of old stone tools in Zamboanga del Norte may indicate a late Neolithic presence. Ceramic burial jars, both unglazed and glazed, as well as Chinese celadons, have been found in caves, together with shell bracelets, beads, and gold ornaments. Many of the ceramic objects are from the Yuan and Ming periods. Evidently, there was a long history of trade between the Subanon and the Chinese long before the latter's contact with Islam .

Hindu-Buddhist era
In the Classic epoch of Philippine history (900AD onwards), the people of Mindanao were heavily exposed to Hindu and Buddhist influence and beliefs from Indonesia and Borneo. Indianized abugida scripts such as Kawi and Baybayin had been introduced through Sulawesi and Java, and the cultural icons of the sarong (known as malong or patadyong), the pudong turban, silk , and batik and ikat weaving and dyeing methods introduced. Artifacts found from this era include the Golden kinnara , Golden Tara, and the Ganesh pendant. These cultural traits passed through Mindanao into the Visayas and Luzon , lost or heavily modified in these areas after the Spanish arrival in the 16th century.
In coastal areas, the Hindu-Buddhist cultural revolution was strongest, whereas in interior parts, influences were indigenized into local animist beliefs and customs and appeared more subtly.
The Darangen epic of the Maranao people harkens back to this era as the most compete local version of the Ramayana . The Maguindanao at this time also had strong Hindu beliefs, evidenced by the Ladya Lawana (Rajah Ravana ) epic saga that survives to the modern day, albeit highly islamized from the 17th century onwards.
The Rajahnate of Butuan , a fully-Hindu kingdom mentioned in Chinese records as a tributary state in the 10th century AD, was concentrated along the northeastern coast of the island around Butuan . [6]

Coming of Islam
The coming of Islam happened in the 14th century. The first mosque in the Philippines was built in the mid-14th century in the town of Simunul . [6] The Philippine sultanates of Sulu , Lanao and Maguindanao were subsequently established in the 15th and 16th centuries, respectively from Hindu-Buddhist Rajahnates. In the late 16th to early 17th centuries, the first contact with Spain occurred. By this time, Islam was well established in Mindanao and had started influencing groups on the big islands of the north and present-day Manila on the island of Luzon . [6] Manila itself once was Muslim when the Sultanate of Brunei annexed it. [7]

Spanish arrival
Upon the Spaniards' arrival to the Philippines, they were dismayed to find such a strong Muslim presence on the island, having just expelled the Moors from Spain after centuries of fighting under the Reconquista . In fact, the name Moros (the Spanish word for "Moors") was given to the Muslim inhabitants by the Spanish. [6] [8] Caesarea Caroli was the name given by Villalobos to the island of Mindanao when he reached the sea near it. This was named after Charles V of the Holy Roman Empire (and I of Spain).
Spain was forced to abandon Zamboanga in Mindanao temporarily and to withdraw its soldiers to Manila in 1662 after the Chinese under Koxinga threatened to invade the Spanish Philippines.

Modern history
After the Spanish–American War , the Americans fought numerous battles against the citizens of the island, including those of the Moro people who started fighting with the colonizers of the Philippines since the start of the Spanish colonization. At the start of World War II , Japanese forces defeated Gen. William F. Sharp's forces, including Gen. Guy O. Fort 's 81st Division, after a battle which started at Malabang , near in Gandamatu Macadar, Lanao , on 29 April 1942, and ended near Ganassi, Lanao , on 10 May 1942. [9] However, Filipino soldiers and local guerrilla fighters were active until liberation at the conclusion of the Battle of Mindanao .
The native Moro Muslims and Lumads were supplanted by first the Spanish then American colonization programs, with Christians, settlers and converts alike, taking control of key areas and disrupting the natives' administrative structures and control over resources. The Americans chose Christians to become officials of settler-populated townships instead of Lumads and Muslims. This behaviour somewhat followed the pattern seen in India under British colonialism, as discussed by Iyer and Banerjee. There, Britain empowered those who held strategic positions within the de facto political context or administration. When the British were not able to identify a definitive group in power, they could still choose to provide distinct peoples that would support them, with the benefit of British power and backing as an incentive to remain loyal. [10] In Mindanao, these conditions were at play for the Americans, who consequently empowered Filipino Christians, instead of the local power-holding groups, to support the United States' dominion and extraction. Due to the activities of the settlers, [ clarification needed ] including logging, the environment has suffered significant damage. As in India, this disruption in the former balance disturbed the established land and rent policies, possibly leading to the environmental harm and lower levels of development seen in Mindanao presently. [10] However, as with the rest of the world at the turn of the 20th century, this is inevitable nevertheless because of industrialization. [11]
The Americans continued the colonization program on Mindanao started by Spain for foreign agricultural companies and Christian settlers against the natives of Mindanao, in order to secure the area with a Christian presence and help the American military assert control over the area once it was conquered. [12] The 1905 Public Land Act, 1903 Philippine Commission Act 718 and 1902 Land Registration Act by the Americans further spurred negative results for the locals. [13] Europeans and Japanese were suggested as potential immigrants along with Filipino Christians by the American General Wood. [14]
Davao in Mindanao had a sizable population of Japanese immigrants who acted as a fifth column , welcoming the Japanese invaders during World War II. These Japanese were hated by the Moros and disliked by the Chinese. [15] [16] The Moros were judged as "fully capable of dealing with Japanese fifth columnists and invaders alike." [17] The Moros were to fight the Japanese invaders when they landed at Davao on Mindanao. [18] [19] [20] [21] [22] [23] The Japanese went back to their ships at night to sleep since the Moros struck so much fear into them, even though the Moros were outnumbered by the Japanese. [24] [25] [26] [27] [28] [29] [30]
A large portion of Mindanao's population consisted of native Moro Muslims to the west and Lumads to the east at the start of the 20th century, but the colonization of Mindanao by the American and Philippine governments made Christianity the religion of around 70–75% of the population through settling and mass conversions initiated by Spain, with the American colonial government giving the land titles to Christian colonists. [31] Media compared the American conquest of the west from the Native Americans to the Filipino conquest and settlement of Mindanao from the Muslims, the Philippine government, Philippine military and Filipino militias used extremely violent tactics against natives to support the settlers. [32]
The Americans used their control over property and land laws to let American corporations and Christian settlers take over native resources and land and depriving them of self-governance after eliminating the sovereignty of the Moro Sultanates in the west, and ignoring Moro requests for their own independence, with the Philippine government continuing the colonization program after independence leading to a big number [ vague ] of Filipino settlers, consisting mostly of Ilokanos, Cebuanos, and Illongos, streaming into Moro territories in western and central portions of Mindanao, and thus led to native Moros making moves for independence and armed struggle against the Philippines. [33] The natives, especially those who refused to convert to Christianity, became victims of land-grabs by the migrants who were promised big and fertile lands by the government. [34] [35]
Massive settlement by Filipino Christian colonists continued after independence was granted and rule passed to Christian Filipinos from the Americans, and land disputes the Christian settlers had with the Muslim and tribal natives broke out in violence; eventually the colonization, along with the Jabidah massacre , led to the formation of the Moro National Liberation Front and Moro armed insurgency against Philippine rule. [36] [37] Because of this strife between the two groups, The Philippine government encouraged Filipino Christians in Mindanao to form militias called Ilaga to counter resistances by the Moros. The Ilaga engaged in massacres and atrocities and were responsible for Manili massacre of 65 Moro Muslim civilians in a Mosque on June 1971.
After decades of "low intensity conflict" in Maguindanao between 1976 and 2000, President Estrada's "All Out War" strategy declared in 2000 led to the displacement of more than 930,000 individuals. The decade that followed has been marked by a cycle of violence and resumption of peace talks between the government and the Moro Islamic Liberation Front that sought to establish an independent Islamic state in Maguindanao. The fighting led to several periods of mass population displacement at the very latest even until the term of President Gloria Macapagal Arroyo displacing another 150,000 individuals mostly of Moro and Lumad communities. [38] Acemoglu and Robinson would argue that these failures are not tied simply to certain pre-conditions, such as climate, resources, or religion especially, as many Filipino citizens claim. The failure of other parts of the Philippines to keep pace with Luzon and the Metro Manila area could be due not so much to localized fixed effects from Mindanao, but more so from the lack of inclusion of the constituent groups within the political process. The Spanish and Americans consistently vested power in small groups of non-representative persons that formed exploitive institutions for their own benefit. [39] This outcome supplies further evidence supporting Alesina et al.'s model, where some circumstances lead to artificial borders that only indicates de jure control by Filipino Christians and other unrelated groups, which prolongs conflict and a lack of accountability in the area, ultimately leading to the historically poorer governmental and economic performance see in Mindanao. [40]
Between 2000 and 2010, four out of ten households (41%) reported having experienced displacement: 29% reported displacement caused by armed groups' movements, 9% identified ridos (blood feuds), and 9% identified other causes, such as economic displacement (3%) or natural disasters (2%). Armed groups' movements were by far the most frequent cause of displacement and also the most damageable. Some provinces were more affected than others, mostly of the Moro as they are the most active in resistance to what they perceived to be an extension of Spanish colonialism now perpetuated by the hands of the Philippine Government . Areas that suffered most damage and displacement are Maguindanao (82%), Lanao del Norte (48%) and Lanao del Sur (47%). Other forms of violence have also been prevalent. For example, in Maguindanao, 45% of the total population reported the destruction of their home. Other forms of violence reported in that province include the destruction of goods (37%), being attacked by someone with a weapon (20%), witness looting (32%), and witness killing (16%). [41]
Communal ownership by the Moros was attacked by the Regalian doctrine of Spain. The area of Bangsamoro is 5% Lumad. [42]
A number of livelihood intervention projects, from organisations such as USAID and the Emergency Livelihood Assistance Program (ELAP), have been beneficial in the reconstruction of those areas affected by constant battles in the Autonomous Region of Muslim Mindanao. [43]
In May 2017, Philippine president Rodrigo Duterte declared martial law on Mindanao following the clashes in Marawi City .

Geography
Mindanao is the second largest island in the Philippines at 104,630 square kilometers, and is the eighth most populous island in the world . The island of Mindanao is larger than 125 countries worldwide, including the Netherlands , South Korea , Austria , Portugal , Czech Republic , Hungary , and Ireland . The island is mountainous, and is home to Mount Apo , the highest mountain in the country. Mindanao is surrounded by 4 seas: the Sulu Sea to the west, [44] the Philippine Sea to the east, and the Celebes Sea to the south, and the Mindanao Sea to the north. Of all the islands of the Philippines , Mindanao shows the greatest variety of physiographic development. High, rugged, faulted mountains; almost isolated volcanic peaks; high rolling plateaus; and broad, level, swampy plains are found there.
The Mindanao island group is an arbitrary grouping of islands in southern Philippines which comprises the Mindanao mainland , the Sulu Archipelago to the southwest, consisting of the major islands of Basilan , Sulu , and Tawi-tawi , plus the outlying islands of Camiguin , Dinagat , Siargao , and Samal in other areas.
The mountains of Mindanao can be conveniently grouped into ten ranges, including both complex structural mountains and volcanoes. The structural mountains on the extreme eastern and western portions of the island show broad exposures of Mesozoic rock with ultrabasic rocks at the surface in many places along the east coast. Other parts of the island consists mainly of Cenozoic and Quaternary volcanic or sedimentary rocks.
Paralleling the east coast, from Bilas Point in Surigao del Norte to Cape Agustin in southeast Davao, is a range of complex mountains known in their northern portion as the Diwata Mountains . This range is low and rolling in its central portion. A proposed road connecting Bislig on the east coast with the Agusan River would pass through a 16 kilometres (9.9 mi) broad saddle across the mountains at a maximum elevation of less than 250 metres (820 ft), while the existing east-west road from Lianga, 30 miles (48 km) north of Bislig , reaches a maximum elevation of only 450 metres (1,480 ft). The Diwata Mountains, north of these low points, are considerably higher and more rugged, reaching an elevation of 2,012 metres (6,601 ft) in Mount Hilong-Hilong, 17 miles (27 km) along the eastern portion of Cabadbaran City . The southern portion of this east coast range is broader and even more rugged than the northern section. In eastern Davao, several peaks rise above 2,600 metres (8,500 ft) and one mountain rises to 2,910 metres (9,550 ft).
The east-facing coastal regions of Davao and Surigao del Sur are marked by a series of small coastal lowlands separated from each other by rugged forelands which extend to the water’s edge. Offshore are numerous coral reefs and tiny islets . This remote and forbidding coast is made doubly difficult to access during the months from October to March by the heavy surf driven before the northeast trade winds. A few miles offshore is found the Mindanao or Philippine Deep . This ocean trench, reaching measured depths of 34,696 feet (10,575 m), is the third deepest trench, (after the Mariana Trench and Tonga Trench ) on the earth’s surface.
A second north-south range extends along the western borders of the Agusan ( del Norte and del Sur ) and Davao provinces from Camiguin Island in the north to Tinaca Point , the southernmost point of Mindanao. This range is mainly structural in origin, but it also contains at least three active volcano peaks. In the central and northern portions of this range, there are several peaks between 2,000 and 2,600 metres (6,600 and 8,500 ft), and here the belt of mountains is about 30 miles (48 km) across. West of Davao City are two inactive volcanoes: Mount Talomo at 2,893 metres (9,491 ft) and Mount Apo at 2,964 metres (9,724 ft), which is the highest point in the Philippines and dominates the skyline. South of Mount Apo, this central mountain belt is somewhat lower than it is to the north, with peaks averaging only 1,100 to 1,800 metres (3,600 to 5,900 ft).
In Western Mindanao, a range of complex structural mountains forms the long, hand-like Zamboanga Peninsula . These mountains, reaching heights of only 1,200 meters (3,900 feet), are not as high as the other structural belts in Mindanao. In addition, there are several places in the Zamboanga Mountains where small inter-mountain basins have been created, with some potential for future agricultural development. The northeastern end of this range is marked by the twin peaks of the now extinct volcano, Mount Malindang , which rise behind Ozamis City to a height of 2,425 metres (7,956 ft). Mount Dapia is the highest mountain in the Zamboanga Peninsula, reaching a height of 2,617 meters (8,586 feet). Meanwhile, Batorampon Point is the highest mountain of the southernmost end of the peninsula, reaching a height of only 1,335 meters (4,380 feet); it is located in the boundary of Zamboanga City .
A series of volcanic mountains is found near Lake Lanao in a broad arc through Lanao del Sur , northern Cotabato and western Bukidnon provinces. At least six of the twenty odd peaks in this area are active and several are very impressive as they stand in semi-isolation. The Butig Peaks, with their four crater lakes, are easily seen from Cotabato. Mount Ragang , an active volcano cone reaching 2,815 metres (9,236 ft), is the most isolated, while the greatest height is reached by Mount Kitanglad at 2,889 metres (9,478 ft).
In southwestern Cotabato , still another range of volcanic mountains is found, this time paralleling the coast. These mountains have a maximum extent of 110 miles (180 km) from northwest to southeast and measure some 30 miles (48 km) across. One of the well-known mountains here is Mount Parker , whose almost circular crater lake measures a mile and a quarter in diameter and lies 300 metres (980 ft) below its 2,040 metres (6,690 ft) summit. Mount Matutum is a protected area and is considered as one of the major landmarks of South Cotabato Province.
A second important physiographic division of Mindanao is the series of upland plateaus in Bukidnon and Lanao del Sur provinces. These plateaus are rather extensive and almost surround several volcanoes in this area. The plateaus are made up of basaltic lava flows interbedded with ash and volcanic tuff. Near their edges, the plateaus are cut by deep canyons , and at several points spectacular waterfalls drop to the narrow coastal plain. These falls hold considerable promise for development of hydroelectric energy. Indeed, one such site at Maria Cristina Falls has already become a major producer. Because the rolling plateaus lie at an elevation averaging 700 meters above sea level, they offer relief from the often oppressive heat of the coastal lowlands. Lake Lanao occupies the major portion of one such plateau in Lanao del Sur . This largest lake on Mindanao and second in the country is roughly triangular in shape with an 18-mile (29 km)-long base. Having a surface at 780 meters above sea level, and being rimmed on the east, south and west by series of peaks reaching 2,300 meters, the lake provides a scenic grandeur and pleasant temperature seldom equaled in the country. [ citation needed ] Marawi City , at the northern tip of the lake, is bisected by the Agus River , which feeds the Maria Cristina Falls .
Another of Mindanao’s spectacular waterfall sites is located in Malabang, 15 miles (24 km) south of Lake Lanao . Here the Jose Abad Santos Falls present one of the nation’s scenic wonders at the gateway to a 200-hectare national park development.
The Limunsudan Falls, with an approximate height of 800 ft (240 m), is the highest waterfalls in the Philippines; it is located at Iligan City .
Mindanao contains two large inland lowland areas, the valleys of the Agusan and Mindanao rivers in Agusan and Cotabato Provinces, respectively. There is some indication that the Agusan Valley occupies a broad syncline between the central mountains and the east-coast mountains. This valley measures 110 miles (180 km) from south to north and varies from 20 to 30 miles (32 to 48 km) in width. 35 miles (56 km) north of the head of Davao Gulf lies the watershed between the Agusan and the tributaries of the Libuganon River, which flows to the Gulf. The elevation of this divide is well under 200 metres (660 ft), indicating the almost continuous nature of the lowland from the Mindanao Sea on the north to the Davao Gulf .
The Rio Grande de Mindanao and its main tributaries, the Catisan and the Pulangi , form a valley with a maximum length of 120 miles (190 km) and a width which varies from 12 miles (19 km) at the river mouth to about 60 miles (97 km) in central Cotabato . The southern extensions of this Cotabato Valley extend uninterrupted across a 350 metres (1,150 ft) watershed from Illana Bay on the northwest to Sarangani Bay on the southeast.
Other lowlands of a coastal nature are to be found in various parts of Mindanao. Many of these are tiny isolated pockets, as along the northwest coast of Zamboanga . In other areas such as the Davao Plain, these coastal lowlands are as much as 16 kilometres (9.9 mi) wide and several times that length.
From Dipolog City eastward along the northern coast of Mindanao almost to Butuan City extends a rolling coastal plain of varying width. In Misamis Occidental , the now dormant Mount Malindang has created a lowland averaging 13 kilometres (8.1 mi) in width. Shallow Panquil Bay divides this province from Lanao del Norte , and is bordered by low-lying, poorly drained lowlands and extensive mangroves. In Misamis Oriental , the plain is narrower and in places almost pinched out by rugged forelands which reach to the sea. East of Cagayan de Oro , a rugged peninsula extends well into the Mindanao Sea .

Administrative divisions
The island is covered by 6 administrative regions , [45] 22 provinces , and 30 cities (27 provinces and 33 cities if associated islands are included).

Culture
Mindanao is the most culturally diverse island in the Philippines where people of different languages, tribes and races meet. As the Moro and Lumad alliance provided an effective resistance to Spanish rule, Mindanao became a melting pot of different cultures, it creates a more distinct culture which is not present in other island groups in the country. Mindanao has been the seat of three great Sultanates namely the Sultanate of Sulu , the Sultanate of Lanao and the Sultanate of Maguindanao , a Rajahnate (The Rajahnate of Butuan ) along with the most hispanized city in Asia , the strategic Zamboanga City (A city that speaks Chavacano, a creole of Mexican-Spanish). A considerable number of Buddhist and Taoist temples and the indigenous tribes known as Lumad people which makes it more diverse.
Today, Cebuano is spoken by the majority of people in Mindanao. Cebuano is generally the lingua franca in many regions, except for the ARMM , Zamboanga City, parts of Soccsksargen and the northeast tip of Mindanao . English and Tagalog are also widely understood and spoken among the people, with English important in business and the academia. Hiligaynon/Ilonggo is widely spoken in South Cotabato , Sultan Kudarat and a large part of North Cotabato , as well as scattered areas around the island. English is also widely spoken.
The Spanish-based creole , Zamboangueño Chavacano is the main language spoken in Zamboanga City and Basilan , scatteredly spoken around Zamboanga del Sur , Zamboanga del Norte , Zamboanga Sibugay , parts of Sulu and Tawi-Tawi . The Zamboangueño dialect is one of the six dialects of Chavacano language (spoken by a distinct Ethnolinguistic group, the Zamboangueños ). Other spoken dialects of Chavacano language are the following: Cotabateño in Cotabato City and Castellano Abakay/Davaoeño in Davao Region .
Christians, concentrated in Northern, Southern and Eastern Mindanao, form the majority, with 63% of the population; Muslims, concentrated in the ARMM with varying numbers around the rest of Mindanao, forms 32% the population meanwhile the remaining 5% are those of the Lumads. The native Maguindanaon and other native Moro or Lumad groups of Mindanao have a culture that is different from the main culture of the Philippines.

Religion
More than 70% of the population of Mindanao adhere to Christianity. Roman Catholicism is the largest single religious affiliation at 60.9 percent of the total household population. Islam comprises 20.44%, while a figure as high as 40% has been cited. [48] Other religions are as follows: Evangelical (5.34%), Aglipayan (2.16%), Iglesia ni Cristo (1.66%), and Seventh Day Adventist (1.65%). [49]

Energy
Many areas in Mindanao suffer rotating 12-hour blackouts due to the island’s woefully inadequate power supply. The island is forecast to continue suffering from a 200-megawatt power deficit until 2015, when the private sector begins to operate new capacity. Aboitiz Equity Ventures, a publicly listed holdings company, has committed to supplying 1,200 megawatts through a coal-fired plant on the border of Davao City and Davao del Sur that is slated for operation by 2018. [50] The Agus-Pulangui hydropower complex, which supplies more than half of Mindanao’s power supply, is currently producing only 635 megawatts of its 982 megawatts capacity due to the heavy siltation of the rivers that power the complex. Zamboanga City , an urbanised center in southwest Mindanao, is expected to begin experience daily three-hour brownouts due to the National Power Corporation ’s decision to reduce power supply in the city by 10 megawatts. [51] The Manila Electric Company (Meralco), the largest power distributor in the Philippines , and Global Business Power Corp (GBPC), also a major provider, have announced plans to enter Mindanao for the first time to establish solutions for the power problems within the island. [51]

See also
WebPage index: 00007
Manchester Arena
Manchester Arena is an indoor arena in Hunts Bank, Manchester , England. Situated immediately north of the city centre , much of the arena is situated above Manchester Victoria station in air rights space.
The arena has the highest seating capacity of any indoor venue in the United Kingdom, and second largest in the European Union with a capacity of 21,000 and is one of the world's busiest indoor arenas, hosting music and sporting events such as boxing and swimming. [2] The arena was a key part of Manchester's bids to host the Olympic Games in 1996 and 2000 and was eventually used for the 2002 Commonwealth Games .

Arena design
The structure was designed by DLA Ellerbe Beckett, Ove Arup & Partners , and Austin-Smith:Lord . The arena is sited in air rights space over the station and was constructed without disrupting use of the station. The original plans included a glass tower which was not built. It originally hosted a seven screen multiplex cinema (1996–2000), a multi-purpose arena and multi-storey parking. The former multiplex cinema is now used as a call centre.
A large truss measuring 105 metres spans the roof. Reinforced concrete is used to increase sound insulation. The upper parts of the building are clad in purple-grey with green glass. [3] The arena was opened on 15 July 1995. [4]
The arena was one of the first indoor venues in Europe to be built following layout of 360 degree seating, [5] and is the only arena in the UK to have this feature (London's The O2 also has 360 degrees seating, but only on its lower tier, whereas Manchester's arena features it on both tiers). Other European indoor venues built to the same concept include the Lanxess Arena in Cologne, Arena Zagreb in Zagreb, Spaladium Arena in Split, Kombank Arena in Belgrade, O2 Arena in Prague, and Barclaycard Arena in Hamburg.

Background
The arena was constructed as part of the city's unsuccessful bid for the 2000 Summer Olympics . [6] Construction cost £52 million of which £35.5m was provided by government grants and £2.5m from the European Regional Development Fund . Although built as an American style sports arena it has been more successful hosting large music events. [7]
The arena opened in July 1995, sponsored by NYNEX CableComms as NYNEX Arena , and was renamed the Manchester Evening News Arena in July 1998. In December 2011, the Manchester Evening News ended its thirteen-year sponsorship, and the arena was renamed Manchester Arena in January 2012. [8] In July 2013, in a multimillion-pound sponsorship deal by mobile phone company Phones 4u , the arena was renamed Phones 4u Arena , [9] but this deal ended when Phones 4u went out of business, renaming the arena back to Manchester Arena, effective 14 January 2015. [10]
On the opening night, 15,000 spectators watched Jayne Torvill and Christopher Dean perform; the crowd was a record for an ice event. [11] Attendance records were set in 1997 when 17,425 people watched Manchester Storm play Sheffield Steelers , a record for an ice hockey match in Europe. When 14,151 people watched Manchester Giants play London Leopards , it set a British record for attendance at a basketball match. [11]
The venue attracts over a million customers each year for concerts and family shows, making it one of the world's busiest indoor arenas, and was named "International Venue Of The Year" in 2002 in the 'Pollstar' awards, and was nominated in the same category in 2002, 2003, 2004, 2005, 2006, 2007, 2008 and 2009. The arena was named "Busiest Arena Venue In The World", based on ticket sales for concerts in 2003, 2004, 2005, 2006 and 2007 ahead of other indoor arenas including the Madison Square Garden and Wembley Arena . The arena was the 'World's Busiest Arena' from 2001 until 2007 based on ticket sales for concerts, attracting five and a half million customers. It was voted 'Europe's Favourite Arena' at the TPi Awards in 2008 by the touring companies that bring the shows to the venue.
In 2008, the arena was world's third busiest arena behind London's The O2 Arena and New York's Madison Square Garden. In 2009, it was the world's second busiest arena behind London's The O2 and ahead of Antwerp's Sportpaleis and Madison Square Garden. Although second to London's The O2, Manchester's arena had its busiest year with over 1,500,000 people attending concerts and family shows. The arena hosts over 250 events annually including comedy, live music and tours, sporting events, and occasionally musicals. [12]

Events

Music
As one of the largest venues in the UK, the arena has hosted music concerts since opening in 1995 and is the arena's primary source of visitors. [ citation needed ]
On 26 March 2000, English boy band Five performed at this venue as part of their Invincible Tour . The show was also filmed for a concert special , called Five Live , that was released on DVD and VHS later that same year. [14]
Janet Jackson performed there on 31 May 1998 as part of her The Velvet Rope Tour . Jackson was scheduled to perform during her All for You Tour on 5 December 2001, but the show was cancelled with the rest of her European tour because of possible terrorist threats. [15] The same happened on her 2016 Unbreakable World Tour because of scheduling conflicts.
Britney Spears performed at the arena for the first time on October 13 and 14, 2000 during her Oops!...I Did It Again Tour . She returned on May 1, 2004 on her The Onyx Hotel Tour and on June 17, 2009 during her The Circus Starring Britney Spears . After 2 years, she returned for Femme Fatale Tour .
In 2002, Kylie Minogue performed on the 1, 2, 3, 4, 11 and 12 May as part of her KylieFever2002 tour. Minogue also performed part of her Showgirl Tour on 23, 24, 26, 27 and 28 April 2005. In 2007, she performed on 12, 13, 18, 19, 21, 22 and 23 January as the final part of her Homecoming Tour . In 2008, she came back to perform on 11, 12, 14, 15, 17 and 18 July as part of her X world tour . Minogue came back on 1, 2, 4 and 5 April 2011 as part of her Aphrodite World Tour . Minogue performed again at the arena on 26 September 2014. The performance marked the 30th time Minogue has performed at the arena, a record for the venue as its most performed artist. [16] It is also a record for Minogue, being the venue she has played to most in the world; she has played to 400,000 fans in total in the Manchester Arena. [17] The Manchester Evening News had previously described Minogue as the "undoubted queen of the Manchester Arena". [18]
In July 2010, the arena celebrated its 15th birthday with a multi-artist gig, presented by Real Radio (North West) . [19] An audience of nearly 10,000 was entertained by Scouting for Girls, Pixie Lott, The Script, Alexandra Burke, The Hoosiers, The Saturdays, Gabriella Cilmi, Taio Cruz, Craig David, Beverley Knight, Olly Murs, Amy McDonald, The Baseballs and Fyfe Dangerfield. Former steward, Peter Kay was a surprise guest which was hosted by Real Radio breakfast presenters Ditchy and Salty.
American entertainer Beyoncé performed three sold out shows at the arena as part of her The Mrs. Carter Show World Tour on 7, 8 and 9 May 2013. She returned on 25 and 26 February 2014 for two more sold out shows. The X Factor winner Sam Bailey was the opening act. Both shows became the fastest concert to sell out the entire arena in history. This was the fifth tour Beyoncé has performed at the arena following concerts for her Dangerously in Love Tour (2003), Destiny Fulfilled...and Lovin' It (2005), The Beyoncé Experience (2007) and the I Am... World Tour (2009).
As of 2015 British pop group Take That , who were formed in Manchester , hold the record for the most number of performances. [20]
Olly Murs performed at the arena on 17 and 18 March 2017, as part of the first leg for his new UK tour, Spring & Summer Tour 2017 .
On 25 June 2017, Celine Dion will bring her Celine Dion Live 2017 tour here.
On 17 October 2017, Lady Gaga will perform her Joanne World Tour here.

Sports
The arena has been the home of three sports teams: the Manchester Storm and Manchester Phoenix ice hockey teams, and the Manchester Giants basketball team with limited success, as it is no longer used by sports teams but is used for one-off sporting events such as boxing and football masters.
Many boxers have had bouts in the arena, such as Amir Khan , Jermaine Johnson, Ricky Hatton , Joe Calzaghe , Mike Tyson , and David Haye . Hatton, from Manchester, became a regular and favourite at the arena.
The arena hosted a few WWE events such as Mayhem in Manchester in 1998, the UK version of No Mercy in 1999 , and Rebellion in 2001 and 2002.
The arena hosted mixed martial arts events. UFC 70 on 21 April 2007, and UFC 105 on 14 November 2009 for which it set the European record attendance for the largest UFC event outside the USA with 16,000 spectators. The arena also hosted UFC Fight Night: Machida vs. Munoz on 26 October 2013. The World Taekwondo Qualification Event for the Beijing Olympic Games was held there on 28–30 September 2007 when 103 countries competed for 24 places at the Beijing Olympic Games in 2008. In April 2008, the arena hosted the FINA Short Course World Swimming Championships , the first time the event has been held in the UK. The arena was transformed with two 25 m swimming pools constructed in 18 days and seating provided for 17,250 spectators. [21]
Monster truck racing events have been staged but the floor space has to be extended and the front section of seating in the lower tier removed. [22]
Since 2008, it has played host to a week of the Premier League Darts.
On 26 February 2011, it played host to BAMMA 5 .
In May 2011, the arena hosted a basketball contest between the Atlanta Dream ( WNBA ) and the Great Britain women's basketball team , billed as "WNBA Live", the first time a WNBA team had played in Europe. In July 2012, the arena hosted an international between Great Britain men's basketball team and the United States men's basketball team in the buildup to the 2012 Summer Olympics .

Comedy
The first stand-up comedy performance was Peter Kay 's final performance of his Mum wants a bungalow Tour in July 2003. He worked at the arena when it opened in 1996 and the performance was filmed for DVD release as Peter Kay at the Manchester Arena . [23] In 2005, Lee Evans set a world record for performing to the biggest audience in front of a crowd of 10,108. [24] Peter Kay 's The Tour That Doesn't Tour Tour...Now On Tour ran for 20 consecutive nights and 20 nights at the end of the tour – a record for the venue. [25] Alan Carr filmed the DVD for Spexy Beast in Manchester.

Other
On 19 July 2011, (with a final dress rehearsal in front of an audience on 16 July 2011) the arena hosted the world premiere of Batman Live , a touring stage show, including theatrical, circus and stage-magic elements, that focuses on the DC Comics superhero Batman . [26]
The arena also hosts the annual convention of Jehovah's Witnesses . In 2014, this was held on 22–24 August.
The arena also hosted Ant & Dec's Takeaway on Tour: Live on 15–16 August 2014. Over the two days, about more than 120,000 people attended both matinee and evening shows.
UFC 204 was held at the arena on 8 October 2016, headlining was a middleweight championship match between Dan Henderson and Michael Bisping .

2017 bombing
At the end of the Dangerous Woman Tour concert by American pop singer-songwriter Ariana Grande on 22 May 2017, a suicide bombing occurred in a public space outside the arena. Greater Manchester Police confirmed 22 fatalities and 120 injuries. [27] [28]

Technical facts

Transport
The arena adjoins Manchester Victoria station which is served by Northern , TransPennine Express , and Metrolink .
The arena car park is operated by National Car Parks , and has 958 standard and 65 disabled spaces.
WebPage index: 00008
Hassan Rouhani
Hassan Rouhani ( Persian : حسن روحانی ‎‎, pronunciation ( help · info ) , Standard Persian : pronounced [roʊhɒːˈniː] ; born Hassan Fereydoun ( Persian : حسن فریدون ‎‎) on 12 November 1948) [7] [8] is the seventh and current President of Iran , a position he has held since 2013. He is also a lawyer, [9] academic, former diplomat and Islamic cleric. He has been a member of Iran's Assembly of Experts since 1999, [10] member of the Expediency Council since 1991, [11] and a member of the Supreme National Security Council since 1989. [3] [12]
Rouhani was deputy speaker of the fourth and fifth terms of the Parliament of Iran ( Majlis ) and Secretary of the Supreme National Security Council from 1989 to 2005. [3] In the latter capacity, he was the country's top negotiator with the EU three , UK, France, and Germany, on nuclear technology in Iran , and has also served as a Shi'ite [13] ijtihadi cleric , [14] and economic trade negotiator. [15] [16] :138 He has expressed official support for upholding the rights of ethnic and religious minorities. [17] In 2013, he appointed former industries minister Eshaq Jahangiri as his first vice-president. [18]
On 7 May 2013, Rouhani registered for the presidential election that was held on 14 June 2013. [19] He said that, if elected, he would prepare a "civil rights charter", restore the economy and improve rocky relations with Western nations . [20] [21] Rouhani is frequently described as a moderate. He was elected as President of Iran on 15 June, defeating Tehran mayor Mohammad Bagher Ghalibaf and four other candidates. [22] [23] [24] He took office on 3 August 2013. [25] In 2013, Time magazine named him in its list of the 100 Most Influential People in the World . In domestic policy, he encourages personal freedom and free access to information, has improved women's rights by appointing female foreign ministry spokespeople, and has been described as a centrist and reformist who has improved Iran's diplomatic relations with other countries through exchanging conciliatory letters. [26] [27] [28] Rouhani won re-election in the 2017 election with 23,549,616 votes (57.1%). He became the second Iranian President, after Mohammad Khatami , to win a presidential victory as an incumbent with an increased electoral mandate.

Name
His name is also spelled as Hasan Rouhani , Hassan Rohani , Hasan Rohani , Hassan Rowhani or Hasan Rowhani .
He was born Hassan Fereydoun (or Fereydun , in reference to a just king in Persian mythology , Persian : ‌حسن فریدون ‎‎, Persian pronunciation: [hæˌsæn-e feɾejˈdun] ) and later changed his last name to Rouhani , which means 'spiritual' or 'cleric'; [29] also transliterated as Rowhani , Ruhani , or Rohani ). It is not clear when he officially changed his last name. He was named as "Hassan Fereydoun Rouhani" ( Persian : حسن فریدون روحانی ‎‎) in a list of Majlis representatives on 5 July 1981, [30] while photos of his identification card (in Persian transliteration: shenasnameh ) taken around his presidential campaign in 2013 only mention "Rouhani" as his last name. [8]

Early life and education
Hassan Rouhani (born Hassan Fereydoun) was born on 12 November 1948 [8] in Sorkheh , near Semnan , into a religious family. [31] His father, Haj Asadollah Fereydoun (died 2011), [32] had a spice shop in Sorkheh [33] and his mother lived in Semnan until her death in 2015 with her daughters and sons-in-law. [8] [34] Asadollah Fereydoun is reported to have been politically active against Mohammad Reza Shah Pahlavi , the Shah of Iran , and arrested first in 1962, and then more than twenty times before the Iranian Revolution in 1979. [35]
Rouhani started religious studies in 1960, first at Semnan Seminary [9] :55 before moving on to the Qom Seminary in 1961. [9] :76 He attended classes taught by prominent scholars of that time including Mostafa Mohaghegh Damad , Morteza Haeri Yazdi , Mohammad-Reza Golpaygani , Soltani, Mohammad Fazel Lankarani , and Mohammad Shahabadi . [9] :81 In addition, he studied modern courses, and was admitted to the University of Tehran in 1969, and obtained a BA degree in Judicial Law in 1972. [3] [9] :309–312 In 1973, Rouhani entered military service in the city of Nishapur . [36]
Rouhani continued his studies at Glasgow Caledonian University in Scotland, graduating in 1995 with an M.Phil. degree in Law with his thesis entitled The Islamic legislative power with reference to the Iranian experience and a PhD degree in Constitutional Law in 1999 for a thesis titled The Flexibility of Shariah (Islamic Law) with reference to the Iranian experience . [37] [38] Rouhani's Caledonian research was initially supervised by Iranian lawyer and scholar Professor Sayed Hassan Amin and later by Islamic law scholar Dr Mahdi Zahraa. [39]
The website of the Center for Strategic Research, a think-tank headed by Rouhani, misattributed his PhD to Glasgow University rather than Glasgow Caledonian University and confusion ensued as a result on whether he was a graduate of either university, especially as he was known during his student years by his birth name "Hassan Fereydoun". [40] Glasgow Caledonian University carried out an internal investigation to confirm Rouhani's alumnus status and after confirming it, it published Rouhani's theses abstracts and a video showing him being capped, as Scottish academic tradition provides, during the University's 1999 graduation ceremony. [41] [42]

PhD thesis plagiarism allegation
In 2013, closely matched sentences of Rouhani's PhD thesis with sentences in a book by Mohammad Hashim Kamali , an Afghan author, led to "submitting a petition calling on the university to cancel the PhD", according to Behdad Morshedi, a London-based writer. Charles McGhee, a spokesman for Glasgow Caledonian University, said that the university had received similar allegations from another activist in the US and would consider the case. [43]
In 2017 fresh claims of Rouhani's plagiarism were raised amid the Iranian 2017 presidential elections . [44] Ayatollah Kalantari called on the education commission of Iran’s parliament to investigate the thesis. [45] [46]

Political activities before the Iranian Revolution
As a young cleric Hassan Rouhani started his political activities by following the Ayatollah Ruhollah Khomeini during the beginning of the Iranian Islamist movement. In 1965, he began traveling throughout Iran making speeches against the government of the Mohammad Reza Shah Pahlavi , the Shah (king) of Iran. During those years he was arrested many times and was banned from delivering public speeches. [9] :232
In November 1977, during a public ceremony held at Tehran's Ark Mosque to commemorate the death of Mostafa Khomeini (the elder son of the Ayatollah Khomeini), Rouhani used the title "Imam" for the Ayatollah Khomeini, the then exiled leader of the Islamist movement, for the first time. [9] :375 [31] It has been suggested that the title has been used for Khomeini by others before, including by the Grand Ayatollah Mohammad Baqir al-Sadr , although Rouhani was influential in publicizing the title. [47] [48] [49]
Since he was under surveillance by SAVAK (Iran's pre-revolution intelligence agency), the Ayatollah Mohammad Beheshti and the Ayatollah Morteza Motahhari advised him to leave the country. [9] :385
Outside Iran he made public speeches to Iranian students studying abroad and joined Khomeini upon arriving in France. [9] :410

Political career during the 1980s and 1990s

Early years of Islamic Republic
Following the 1979 Iranian Revolution in Iran, Rouhani, who had been engaged in revolutionary struggles for about two decades, did his best to stabilize the nascent Islamic Republic and as a first step, he started with organizing the disorderly Iranian army and military bases. [9] :515 He was elected to the Parliament of Iran ( Majlis ) in 1980.
During five terms in the Majlis and for a total period of 20 years (from 1980 to 2000), he served in various capacities including deputy speaker of the Majlis (in 4th and 5th terms), as well as the head of defense committee (1st and 2nd terms), and foreign policy committee (4th and 5th terms). [31]
Among responsibilities shouldered by him in the post-revolution era was leadership of the supervisory council of the Islamic Republic of Iran Broadcasting (IRIB) from 1980 to 1983. [3] In July 1983, while Rouhani was heading the council, the council members and Rouhani had conflicts [50] with Mohammad Hashemi Rafsanjani the then head of IRIB, which led to temporary replacement of Hashemi by first Rouhani and then immediately Mohammad Javad Larijani . [51] The conflict was resolved by the Ayatollah Khomeini intervening and insisting on Rafsanjani staying as the head of IRIB. [52]

Iran–Iraq war
During the Iran–Iraq war , Rouhani was a member of the Supreme Defense Council (1982–1988), member of the High Council for Supporting War and headed its Executive Committee (1986–1988), deputy commander of the war (1983–1985), commander of the Khatam-ol-Anbiya Operation Center (1985–1988), and commander of the Iran Air Defense Force (1986–1991). [3] He was appointed as Deputy to Second-in-Command of Iran's Joint Chiefs of Staff (1988–1989). [3]
When Robert C. McFarlane, Reagan' national security adviser, came to Tehran in May 1986, Rouhani was one of the three people who talked to McFarlane about buying weapons. Eventually, this weapons sale became known as the Iran-Contra affair . [53] [54]
At the end of the war, Hassan Rouhani was awarded the second-grade Fath (Victory) Medal along with a group of commanders of the Iranian Army and the Revolutionary Guards . In another ceremony on the occasion of the liberation of Khoramshahr , he and a group of other officials and military commanders who were involved in the war with Iraq were awarded first-grade Nasr Medal by the Commander-in-Chief of the Armed Forces Ayatollah Khamenei.

After the war
Rouhani was offered and turned down the post of Minister of Intelligence of Iran in 1989. [55]
After the Constitution of the Islamic Republic of Iran was amended and the Supreme National Security Council (SNSC) came into being up to the present time, he has been representative of the Supreme Leader, Ayatollah Khamenei , at the council. [3] Rouhani was the first secretary of the SNSC and kept the post for 16 years from 1989 to 2005. He was also national security advisor – to President Hashemi and President Khatami – for 13 years from 1989 to 1997 and from 2000 to 2005. [3] In 1991, Rouhani was appointed to the Expediency Council and has kept that post up to the present time. He heads the Political, Defense, and Security Committee of the Expediency Council. [3]
After the Iran student protests, July 1999 he, as secretary of Supreme National Security Council, stated in a pro-government rally that "At dusk yesterday we received a decisive revolutionary order to crush mercilessly and monumentally any move of these opportunist elements wherever it may occur. From today our people shall witness how in the arena our law enforcement force . . . shall deal with these opportunists and riotous elements, if they simply dare to show their faces." [56] and led the crackdown. [57]
In the midterm elections for the third term of the Assembly of Experts which was held on 18 February 2000, Rouhani was elected to the Assembly of Experts from Semnan Province . He was elected as Tehran Province 's representative to the Assembly's fourth term in 2006 and is still serving in that capacity. He was the head of the political and social committee of the assembly of experts (from 2001 to 2006), member of the presiding board, and head of Tehran office of the secretariat of the assembly (from 2006 to 2008). On 5 March 2013 he was elected as a member of the Assembly's "Commission for investigating ways of protecting and guarding Velayat-e Faqih ". [58]
In addition to executive posts, Rouhani kept up his academic activities. From 1995 to 1999, he was a member of the board of trustees of Tehran Universities and North Region. Rouhani has been running the Center for Strategic Research since 1991. He is the managing editor of three academic and research quarterlies in Persian and English, which include Rahbord (Strategy), Foreign Relations , and the Iranian Review of Foreign Affairs .

Nuclear dossier
Rouhani was secretary of the Supreme National Security Council (SNSC) for 16 years. His leading role in the nuclear negotiations which brought him the nickname of "Diplomat Sheikh", first given to him by the nascent Sharq newspaper in November 2003 and was frequently repeated after that by domestic and foreign Persian-speaking media. His career at the Council began under President Hashemi Rafsanjani and continued under his successor, President Khatami . Heinonen, former senior IAEA official, said that Rouhani used to boast of how he had used talks with Western powers to "buy time to advance Iran's programme." [59] His term as Iran's top nuclear negotiator, however, was limited to 678 days (from 6 October 2003 to 15 August 2005). That period began with international revelations about Iran's nuclear energy program and adoption of a strongly worded resolution by the International Atomic Energy Agency (IAEA). In June 2004, the board of governors of the IAEA issued a statement which was followed by a resolution in September of the same year, which focused on Iran's nuclear case with the goal of imposing difficult commitments on Iran. That development was concurrent with the victory of the United States in Iraq war and escalation of war rhetoric in the region. The international community was experiencing unprecedented tensions as a result of which Iran's nuclear advances were considered with high sensitivity. [16] :120–126
As tensions increased and in view of the existing differences between Iran's Ministry of Foreign Affairs and Atomic Energy Organization , a proposal was put forth by the foreign minister, Kamal Kharazi , which was accepted by the president and other Iranian leaders. According to that proposal, a decision was made to establish a politically, legally, and technically efficient nuclear team with Hassan Rouhani in charge. The team was delegated with special powers in order to formulate a comprehensive plan for Iran's interactions with the IAEA and coordination among various concerned organizations inside the country. Therefore, on the order of President Khatami with the confirmation of Ali Khamenei , Hassan Rouhani took charge of Iran's nuclear case on 6 October 2003. [16] :138–140 Subsequently, negotiations between Iran and three European states started at Saadabad in Tehran and continued in later months in Brussels , Geneva and Paris.
Rouhani and his team, whose members had been introduced by Velayati and Kharazi as the best diplomats in the Iranian Foreign Ministry, [16] :109,141 based their efforts on dialogue and confidence building due to political and security conditions. As a first step, they prevented further escalation of accusations against Iran in order to prevent reporting Iran's nuclear case to the United Nations Security Council . Therefore, and for the purpose of confidence building, certain parts of Iran's nuclear activities were voluntarily suspended at several junctures.
In addition to building confidence, insisting on Iran's rights, reducing international pressures and the possibility of war, and preventing Iran's case from being reported to the UN Security Council, Iran succeeded in completing its nuclear fuel cycle and took groundbreaking steps. [16] :660–667 However, decisions made by the nuclear team under the leadership of Rouhani were criticized by certain circles in later years. [60] [61]
Following the election of Mahmoud Ahmadinejad as president, Rouhani resigned his post as secretary of the Supreme National Security Council after 16 years on 15 August 2005, [16] :594,601 and was succeeded by Ali Larijani as the new secretary who also took charge of Iran's nuclear case. Larijani, likewise, could not get along with the policies of the new government and resigned his post on 20 October 2007, to be replaced by Saeed Jalili . Rouhani then was appointed by the Supreme Leader as his representative at the SNSC. [62]

2013 presidential campaign
Rouhani was considered a leading candidate in the June election because of his centrist views yet close ties to Iran's ruling clerics and the Green Movement . [64] He announced his presidential candidacy on 11 March 2013 and registered as a presidential candidate on 7 May. Amid the run-up to the election, former presidents Mohammad Khatami and Akbar Hashemi Rafsanjani , together with reformists supported Rouhani on the presidential race after pro-reform candidate Mohammad Reza Aref dropped out of the presidential race after Khatami advised him to quit in favor of Rouhani. [65] On 10 June, Mehr news agency and Fars news agency , suggested that Rouhani might be disqualified prior to the election [66] and The Washington Post , in an editorial, claimed that Rouhani "will not be allowed to win". [67] [68] On 15 June 2013, Interior Minister Mostafa Mohammad Najjar announced the results of the election, with a total number of 36,704,156 ballots cast; Rouhani won 18,613,329 votes, while his main rival Mohammad Bagher Ghalibaf secured 6,077,292 votes. [69] [70] Rouhani performed well with both the middle class and youth, even garnering majority support in religious cities such as Mashhad and Qom (an important seat of Shia Islam and the clergy, many of whom surprisingly do not support conservatives) [71] as well as small towns and villages. [22] Rouhani's electoral landslide victory was widely seen as the result of the Green Movement from the 2009 elections , with crowds chanting pro-reform slogans. Religious Iranians equally celebrated Rouhani's victory, demonstrating what analysts described as a thorough rejection of the policies of the conservative factions. [22]

Presidency (2013–present)
In his press conference one day after election day, Rouhani reiterated his promise to recalibrate Iran's relations with the world. He promised greater openness and to repair the country's international standing, offering greater nuclear transparency in order to restore international trust. [72] Revolutionary Guards Major General Mohammad Jafari criticised Rouhani's administration. "The military, systems and procedures governing the administrative system of the country are the same as before, [but it] has been slightly modified and unfortunately infected by Western doctrine, and a fundamental change must occur. The main threat to the revolution is in the political arena and the Guards cannot remain silent in the face of that." In May 2017, Rouhani was re-elected as President with 23.5 million votes. [73]
He was announced the winner on the day following the election. He received his presidential precept from his predecessor, Mahmoud Ahmadinejad on 3 August 2013 and entered Sa'dabad Palace in a private ceremony. His work as president officially began on the same day at 17:00 IRDT . He was inaugurated as the seventh president of Iran on 4 August in House of the Parliament . [74]

Cabinet
Rouhani announced his cabinet on 4 August. He had a ten-day mandate for introducing his cabinet members to the parliament but he did not use this. Then, parliament voted on his cabinet, which was scheduled on 14–19 August. Between three reformist politicians ( Mohammad Reza Aref , Eshaq Jahangiri or Mohammad Shariatmadari ) that were likely for the vice presidency, Rouhani appointed Jahangiri for the position. There were also many candidates for ministry of foreign affairs: Ali Akbar Salehi , Kamal Kharazi , Sadegh Kharazi , Mohammad Javad Zarif and Mahmoud Vaezi but Zarif became Rouhani's final nominee. [75] Although several names were being circulated for the other ministerial posts before the final announcement, the office of president-elect denied these speculations. On 23 July 2013, it was reported that eight members of Rouhani's cabinet had been finalized: Jahangiri as first vice president, Zarif as foreign minister, Rahmani Fazli as interior minister, Tayebnia as finance minister, Dehghan as defense minister, Namdar Zanganeh as petroleum minister, Najafi as education minister, Chitchian as energy minister, Nematzadeh as industries minister, Hassan Hashemi as health minister and Akhondi as transportation minister. [76] This become official after Rouhani presented the list of his ministry nominates to the parliament on his inauguration day. He also appointed Mohammad Nahavandian as his chief of staff.

Domestic policy

Economic
The economic policy of Hassan Rouhani focuses on the long-term economic development of Iran. It deals with increasing the purchasing power of the public, economic growth, raising sufficient funds , implementation of the general policies of 44th Principle of the Constitution of the Islamic Republic of Iran and improving the business environment in the short term. [77] Rouhani believes that improving the economic conditions of the people should be accomplished by boosting the purchasing power of the people, reducing the wealth gap. He also thinks that equitable distribution of national wealth and economic growth lead to all mentioned economic goals. He states that if national wealth was not created, poverty would be distributed . National wealth creation causes an increase in real income per capita and equitable distribution of wealth. His plan is targeted to increase direct and indirect assistance to low-income groups. [78]
Rouhani is urgently going to regenerate the Management and Planning Organization of Iran . His economic policies also comprise optimal distribution of subsidies , control of liquidity and inflation, speeding economic growth and reducing import. He believes that inflation results in damaging effects on the economy of families and hopes to deflate that in Foresight and Hope Cabinet . [79]
Rouhani plans urgent economic priorities such as control of high inflation, increasing purchasing power and cutting down high unemployment. [80]

Culture and media
According to a March 2014 report by Center for International Media Assistance , since Rouhani takeover in 2013, "Censorship of the Internet has only gotten worse, but it's more and more clear that Rouhani does not have complete control over this process". [81]
Regarding internet censorship, he has stated: "Gone are the days when a wall could be built around the country. Today there are no more walls." He has also criticized Islamic Republic of Iran Broadcasting for showing trivial foreign news, while ignoring pressing national matters. [82] Rouhani also appeared to pledge his support for increasing Internet access and other political and social freedoms. In an interview, he said: "We want the people, in their private lives, to be completely free, and in today’s world having access to information and the right of free dialogue, and the right to think freely, is the right of all peoples, including the people of Iran." [83]

Human and women's rights
Rouhani has maintained a policy of not publicly addressing human rights issues, on which he may have limited powers. [84]
Rouhani is a supporter of women's rights . In a speech after he was elected as the President of Iran, he said:
Rouhani's government appointed Elham Aminzadeh , Shahindokht Molaverdi and Masoumeh Ebtekar as vice presidents; as well as Marzieh Afkham , the first female spokesperson for the foreign ministry. Rouhani has promised to set up a ministry for women. Many women's rights activists, however, are reluctant about a ministry for women; because they feel that this ministry may isolate women's issues. It has also been suggested that Rouhani will require a deputy minister position within each ministry to address gender issues and issues pertaining to women. [86]
In September 2013, eleven political prisoners were freed including noted human rights lawyer Nasrin Sotoudeh and Mohsen Aminzadeh . The move came just days before his visit to the United States for the United Nations General Assembly . [87]
Critics say that little has changed in domestic policy since Rouhani took office. Iranian authorities executed 599 people during Rouhani's first 14 months in power, compared with 596 during the last year in office of his predecessor, Mahmoud Ahmadinejad. Iran has the highest number of executions anywhere in the world, apart from China. [88] Nobel Peace Prize winner Shirin Ebadi has criticized Rouhani's human rights record. She cited the increase in executions, Abdolfattah Soltani 's hunger strike, and the continued house arrest of Mir Hossein Mousavi and Mahdi Karroubi . An Iranian spokesperson said Ebadi's comments would end up provoking animosity towards Iran. [89] [90] [91]
In 2015, Rouhani appointed Marzieh Afkham and Saleh Adibi , as the first female since the 1979 (the second in history) and the first Sunni Kurd respectively, to hold office as ambassadors. [92] [93]

Foreign policy
Rouhani's foreign policy has been contained by the conservatism of Iranian Principlists , who fear change, while also realizing it is necessary. Furthermore, Iran's foreign policy, which was deadlocked by the efforts of Mahmoud Ahmadinejad, needs new predecessor by cautious and decisive efforts of Rouhani. [ clarification needed ] The main task of Rouhani is only to develop dialogues between Iran and Political rivals including P5+1 . This course can help lift sanctions that damaged the Iranian economy. [94]
In March 2015 Rouhani sent a letter to President Obama and the heads of the other five countries negotiating with Iran, explaining Iran's stance. He announced it on his Twitter account. The US National Security Council confirmed that the letter had been passed on to the U.S. negotiating team, but its contents were not released. Rouhani also spoke by phone with the leaders of all the nations involved in the negotiations, except for the United States. [95]

Nuclear talks

United Kingdom
Rouhani met with British Prime Minister David Cameron , marking the first time since the 1979 Islamic revolution that the leaders of Iran and the United Kingdom have met. [96] On 20 February 2014 the Iranian Embassy in London was restored and the two countries agreed to restart diplomatic relations. [97] On 23 August 2015 the embassy was officially reopened. [98] Rouhani was deputy speaker of the fourth and fifth terms of the Parliament of Iran (Majlis) and Secretary of the Supreme National Security Council from 1989 to 2005.[3] In the latter capacity, he was the country's top negotiator with the EU three, UK, France, and Germany, on nuclear technology in Iran, and has also served as a Shi'ite[13] ijtihadi cleric,[14] and economic trade negotiator.[15][16]:138 He has expressed official support for upholding the rights of ethnic and religious minorities.[17] In 2013, he appointed former industries minister Eshaq Jahangiri as his first vice-president.[18

United States
Rouhani's visit to New York City in September 2013 was hailed [ who? ] as major progress in Iran's relations with the United States. He previously said that his government is ready to hold talks with the United States after thirty-two years. Rouhani denied reports that during his trip he had refused a meeting with U.S. President Barack Obama , [99] and felt more time was needed to coordinate such a meeting. [99] On 27 September 2013, a day after the two countries foreign ministers met during the P5+1 and Iran talks, Rouhani had a phone call with President Obama that marked two countries' highest political exchange since 1979. [99] [100] [101] However, due to this phone call Rouhani was protested by conservatives who chanted " death to America " when he returned to Tehran. [99]

Syria
It is generally assumed that he will follow the ruling establishment in completely supporting Bashar al-Assad , Syria's contentious president, in the Syrian civil war , as well as "strengthening the Shia Crescent " that runs from southern Lebanon, through Syria, Iraq and into Iran. [102] In his first press conference after winning the presidential election, Rouhani said that "the ultimate responsibility to resolve the Syrian civil war should be in the hands of the Syrian people." [103]

Iraq
Rouhani has termed Iran-Iraq relations "brotherly" and signed several agreements with Iraq. [104] Right after the Northern Iraq offensive , Iran was the first country to send support for Iraq [105] and is a "key player" in Military intervention against the ISIL . [106]

Saudi Arabia
On Iran's relationship to Saudi Arabia, Rouhani wrote that during the Khatami administration, he, as the secretary-general of the National Security Council at that time, reached "a comprehensive and strategic agreement" with the Saudis, but that this agreement was not upheld during the Ahmadinejad's government . Specifically, while discussing the episode, he stated:
Rouhani has criticized Saudi Arabian-led military intervention in Yemen , saying: "Don't bomb children, elderly men and women in Yemen. Attacking the oppressed will bring disgrace." [108]

Israel and Palestine
Rouhani describes Israel as "an occupier and usurper government" that "does injustice to the people of the region, and has brought instability to the region, with its warmongering policies." When asked to clarify his opinion about the Holocaust, Rouhani replied: "... in general, I can tell you that any crime that happens in history against humanity, including the crime the Nazis created towards the Jews as well as non-Jews is reprehensible and condemnable. Whatever criminality they committed against the Jews, we condemn". [109] In an interview with CNN, it was claimed by the CNN translator that Rouhani had acknowledged the existence of the Holocaust, however CNN's statements were accused by Iranian state media as a fabrication created by a deliberate mistranslation by CNN. [110] Other sources, such as the Wall Street Journal, argued that their independent translators corroborated Iranian media's position, and described CNN's translation as highly inaccurate, having added to their translation many words (such as 'holocaust') that he had not said. [111]

Public image and perception
According to a poll conducted in March 2016 by Information and Public Opinion Solutions LLC (iPOS) among Iranian citizens, Rouhani has 75% approval and 12% disapproval ratings and thus a +54% net popularity, making him the second most popular politician in Iran, after Mohammad Javad Zarif with +69% net popularity. Rouhani surpasses Hassan Khomeini (+52%), Mohammad Khatami (+43%) and Akbar Hashemi Rafsanjani (+38%) who take the following places. The firm states with 95% confidence that the margin of sampling error is ±3 percentage points. [112]

Job approval
Rouhani began his presidency in November 2013 with approval and disapproval ratings near 58% and 27% respectively, [113] according to Information and Public Opinion Solutions LLC (iPOS) which is assessing it on a quarterly basis. It gradually fell down to 48% and he recorded a 33% disapproval rating in May 2015. [113] His job approval boosted after Joint Comprehensive Plan of Action , according to the survey conducted by IranPoll for the University of Maryland's Center for International and Security Studies (CISSM), standing on 88% with a large majority (61%) expressing a "very favorable view" of him (up from 51% in July 2014) and a ±3.2 margin of sampling error. The poll also indicated Rouhani has a "tough challenge" in maintaining the support due to the fact that people have high economic expectations from the deal, and it could become his Achilles' heel . [114] iPOS has recorded a 54% approval and 24% disapproval, days after the deal in August 2015. [113] The trend has continued until February 2016, with 67% and 18% approval and disapproval ratings, marking the highest level since he took office. [115]

2017 presidential election
Rouhani saw off a strong challenge from hardline Ebrahim Raisi at the 2017 election , a fellow cleric with radically different politics, who stirred up populist concerns about the sluggish economy, lambasted Rouhani for seeking foreign investment and appealed to religious conservatives. He had gathered momentum as conservatives keen to win back control of the government coalesced behind Raisi's initially lacklustre campaign. His other rivals were Mostafa Mir-Salim and Mostafa Hashemitaba .
Rouhani ultimately won the election in a landslide, providing a ringing endorsement of his efforts to re-engage with the West and offer greater freedoms. [118] He received 23,549,616 of the votes, in an election that had 73.07% turnout.

Political positions
Rouhani is considered to be a moderate and pragmatic politician. [22] In 2000, Washington Institute for Near East Policy described him as "power-hungry". [119] He was elected as president with heavy reformist support, and he pledged to follow through with reformist demands and to bridge divides between reformists and conservatives. [120]
During the 2017 presidential election , Rouhani's views moved more to the left and he fully aligned with the reformists faction. [121]

Electoral history

Personal life
Rouhani married his cousin, Sahebeh Erabi (Rouhani) [122] who is six years younger, when he was around 20 years old [34] [123] and has five children. [124] Rouhani's wife changed her last name from "Arabi" ( Persian : عربی ‎‎) to "Rouhani" some time after marriage. [33] Born in 1954, she is not politically active. [122] The Guardian and the Financial Times reported that Rouhani also had a fifth child, a son who has died in unknown circumstances. [125] [126] Based on a comment by Alireza Nourizadeh , some sources reported that he committed suicide "in protest of his father's close connection with Supreme Leader Ali Khamenei ". [127] [128] This claim, apparently originating from Nourizadeh's report in the Saudi-owned newspaper Asharq Al-Awsat , included the following text it alleged came from the son's suicide note : "I hate your government, your lies, your corruption, your religion, your double standard and your hypocrisy...I was forced to lie to my friends each day, telling them that my father isn't part of all of this. Telling them my father loves this nation, whereas I believe this to be untrue. It makes me sick seeing you, my father, kiss the hand of Khamenei." [129] [130]
Rouhani has three sisters and a brother. [34] Rouhani's brother, Hossein Fereydoun , is also a diplomat and politician, a former governor, ambassador, [131] and former Vice Minister of Intelligence. [132] He was Rouhani's representative to IRIB in arrangements for presidential debates. [133] Akbar Hashemi Rafsanjani , in a memoir dated 15 May 1982, mentions Hossein Fereydoun as the then governor of Karaj . [134] Rafsanjani later briefly mentions Fereydoon in a memoir dated 31 March 1984: "In Karaj, something has happened about Mr. Ferydoon Rouhani". [135]

Publications
Having the rank of research professor at Iran's Center for Strategic Research, he has written many books and articles in Persian, English and Arabic, including the following: [3]
WebPage index: 00009
Eurovision Song Contest 2017
WebPage index: 00010
Jacque Fresco
Jacque Fresco (March 13, 1916 – May 18, 2017) was an American futurist [2] and self-described social engineer . [3] Self-taught , he worked in a variety of positions related to industrial design .
Fresco wrote and lectured his views on sustainable cities , energy efficiency , natural-resource management, cybernetic technology, automation , and the role of science in society. He directed the Venus Project [6] and advocated global implementation of a socioeconomic system which he referred to as a "resource-based economy". [7] [8]

Early life
Jacque Fresco was born on March 13, 1916, [9] and grew up in a Sephardi Jewish household, [10] at the family's home in Bensonhurst , in the Brooklyn borough of New York City. [11] A teenager during the Great Depression , he spent time with friends discussing Charles Darwin , Albert Einstein , science, and the future. [12] Fresco attended the Young Communist League before being "physically ejected" for loudly stating that "Karl Marx was wrong!" after a discussion with the league president during a meeting [13] He left home at the age of 14, hitchhiking and "jumping" trains as one of the so-called " Wild Boys of the Road ". [14] He later turned his attention to technocracy . [12]

Career

Aircraft industry
Fresco worked at Douglas Aircraft Company in California during the late 1930s. [13] [15] He presented designs including a flying wing [16] and a disk-shaped aircraft. Some of his designs were considered impractical at the time and Fresco's design ideas were not adopted. [17] Fresco resigned from Douglas because of design disagreements. [13] [17]
In 1942, Fresco was drafted into the United States Army. [12] [18] He was assigned technical design duties for the United States Army Air Forces at Wright Field design laboratories in Dayton, Ohio . [12] [17] [19] [20] One design he produced was a "radical variable camber wing" with which he attempted to optimize flight control by allowing the pilot to adjust the thickness and lift of the wings during flight. [21] [22] Fresco did not adjust to military life and was discharged. [12]

Trend Home
Fresco was commissioned by Earl "Madman" Muntz , to design low cost housing. Muntz invested $500,000 seed money in the project. Fresco, 32 years old at the time, along with his associates Harry Giaretto and Eli Catran conceived, designed and engineered a project house called the Trend Home . [23] Fresco came closest to traditional career success with this project. Built mostly of aluminum and glass, it was on prominent display at Stage 8 of the Warner Bros. Sunset Lot in Hollywood for three months. The home could be toured for one dollar, with proceeds going to the Cancer Prevention Society. In the summer of 1948, a Federal Housing Administration official met Muntz about the project. The official's proposal, according to Muntz, would add a bureaucratic overhead negating the low production costs. Without federal or further private funding the project did not go into mass production. This experience led Fresco to the conclusion that society would have to be changed for his inventions to reach their potential. [11] [24]

Scientific Research Laboratories
In the late 1940s, Fresco created and was director of Scientific Research Laboratories in Los Angeles. [20] [25] Here he also gave lectures, and taught technical design, [13] meanwhile researching and working on inventions as a freelance inventor and scientific consultant. [26] During this period, Fresco struggled to get his research funded [27] and faced setbacks and financial difficulties. In 1955, Fresco left California after his laboratory was removed to build the Golden State Freeway . [13] [15]

Midlife
In 1955 Fresco moved to Miami , Florida . He opened a business as a psychological consultant, but had no formal schooling in the subject. [15] Receiving a "barrage of criticism" from the American Psychological Association Fresco stopped that business. [15] In a newspaper article from that time period Fresco claimed to have a degree from Sierra University, Los Angeles, California, which is unverified. [28]
Fresco described white supremacist organizations he joined to test the feasibility of changing people. He tells of joining a local Ku Klux Klan and White Citizens Council in an attempt to change their views about racial discrimination. [29]
In Miami Fresco presented designs of a circular city. [30] Fresco made his living working as an industrial designer for various companies such as Alcoa and the Major Realty Corporation. [15]
In 1961, with Pietro Belluschi and C. Frederick Wise, [31] Fresco collaborated on a project, known as the Sandwich House. [15] Consisting of mostly prefabricated components, partitions, and aluminum, it sold for $2,950, or $7,500 with foundation and all internal installations. [31] During this period, Fresco supported his projects by designing prefabricated aluminum devices through Jacque Fresco Enterprises Inc. [32]
From 1955 to 1969 Fresco named his social ideas "Project Americana".

Looking Forward
Looking Forward was published in 1969. Author Ken Keyes Jr. , and Jacques Fresco coauthored the book. Looking Forward, is a speculative look at the future. The authors picture an ideal 'cybernetic society in which want has been banished and work and personal possessions no longer exist; individual gratification is the total concern'. [33]

Sociocyberneering, Inc.
Fresco formed "Sociocyberneering", a membership organization claiming 250 members, according to an interview with Fresco. [34] He hosted lectures in Miami Beach and Coral Gables [35] [36] Fresco promoted his organization by lecturing at universities [37] and appearing on radio and television. [38] [39] Although Fresco is presented as a 'Doctor' on the Larry King show there is no evidence of that being the case. Fresco did not complete high school. [40] Fresco's "sociocyberneering" as a membership group was discontinued and land was purchased at another location in rural Venus, Florida . He established his home and research center there. [41]

The Venus Project and later career
Fresco, with Meadows, supported the project in the 1990s through freelance inventing, [42] industrial engineering, conventional architectural modeling, and invention consultations. [11]
In 2002, Fresco published his main work The Best That Money Can't Buy . In 2006, William Gazecki directed the semi-biographical film about Fresco, Future by Design . [43] In 2008, Peter Joseph featured Fresco in the film Zeitgeist Addendum where his ideas of the future were given as possible alternatives. Peter Joseph, founder of the Zeitgeist Movement began advocating Fresco's approach. In April 2012, the two groups disassociated due to disagreements regarding goals and objectives. [11]
In 2010, Fresco attempted to trademark the phrase " resource-based economy ". [44] The phrase was reviewed and found to be too generic, so the trademark was denied.
Throughout 2010, Fresco traveled with Meadows, worldwide to promote interest in the Venus Project. [45] [46] On January 15, 2011, Zeitgeist: Moving Forward was released in theaters, featuring Fresco. [47]
In November 2011, Fresco spoke to protesters at the "occupy Miami" site at Government Center in Miami. [48] In April 2012, Roxanne Meadows released a film, Paradise or Oblivion , summarizing the goals and proposals of the Venus Project. [49] In June 2012, Maja Borg screened her film, Future My Love , at the Edinburgh International Film Festival featuring the work of Fresco and Roxanne Meadows. [50] [51]
Fresco held lectures and tours at the Venus Project location. [52]

Personal life and family
Fresco was born to immigrants from the Middle East, Isaac and Lena Fresco. [9] His father was born in 1880 [53] and around 1905 immigrated from Istanbul to New York where he worked as a horticulturalist . [9] He died in 1963. [53] Fresco's mother was born in 1887 [54] in Jerusalem and also migrated to New York around 1904. [9] She died in 1988. [54] Fresco was brother to two siblings, [9] a sister, Freda, and a brother, David.
Fresco had two marriages when he lived in Los Angeles and carried his second marriage through his first couple of years in Miami. [20] He divorced his second wife in 1957 and remained unmarried thereafter. [55] His second wife, Patricia, gave birth to a son, Richard, in 1953 and a daughter, Bambi, in 1956. Richard was an army private [56] and died in 1976. [57] Bambi died of cancer in 2010. [58]
Fresco died on May 18, 2017 in his sleep at his home in Sebring, Florida , from complications of Parkinson's disease at the age of 101. [59] [1]
Roxanne Meadows assisted Fresco from 1976. As Fresco's domestic partner and administrative colleague, she oversees much of the management of the Venus Project. [11]

Critical appraisals
It's a "lack of professional engagement", William Gazecki who in 2006 completed Future by Design , a feature-length profile of Jacque Fresco says, that hurt Fresco the most. "The real missing link in Jacque's world is having put Jacque to work," Gazecki says, "[It's] exemplified when people say: ‘Well, show me some buildings he's built. And I don't mean the domes out in Venus. I mean, let's see an office building, let's see a manufacturing plant, let's see a circular city.' And that's where he should have been 30 years ago. He should have been applying his work, in the real world ... [but] he's not a collaborator, and I think that's why he's never had great public achievements." [60]
When asked by a reporter why he had such difficulty actualizing his many ideas, Fresco responded, "Because I can't get to anybody." [61]

Views on Fresco
Fresco's critical view of modern economics has been compared to Thorstein Veblen 's concept of "the predatory phase in human development", according to an article in the journal Society and Business Review. [62] [63] Grønborg has labeled other facets of Fresco's ideology a " tabula rasa approach". [64]
Synergetics theorist Arthur Coulter called Fresco's city designs "organic" and "evolutionary", rather than revolutionary. [65] Coulter posits such cities as the answer to Walter B. Cannon 's idea of achieving homeostasis for society. [65]

Hypothetical form of government
Fresco described his form of governance in this way: "The aims of The Venus Project have no parallel in history, not with communism, socialism, fascism or any other political ideology. This is true because cybernation is of recent origin. With this system, the system of financial influence and control will no longer exist." [64]
Ludwig von Mises Institute scholar Robert P. Murphy has raised the economic calculation problem against a resource-based economy. [66] In a resource-based economy, Murphy claims there is no ability to calculate the availability and desirability of resources because the price mechanism is not utilized. Addressing this aspect, another article in the Quarterly Journal of Austrian Economics , states criticism of "central plannings" computation problem applies to the ideas of Fresco. [67]

Question of utopianism
The Venus Project states on its website that it is not utopian . [68] Nikolina Olsen-Rule, writing for the Copenhagen Institute for Futures Studies , supports this idea,
Morten Grønborg, also of Copenhagen Institute for Futures Studies, points out the Venus Project is,

Comments on Fresco
Hans-Ulrich Obrist wrote that "Fresco's future may, of course, seem outmoded and his writings have been subject to critique for their fascistic undertones of order and similitude, but his contributions are etched in the popular psyche and his eco-friendly concepts continue to influence our present generation of progressive architects, city planners and designers." [71]
Fresco's work gained the attention of science fiction enthusiast and critic Forrest J Ackerman . [12] Fresco later attracted Star Trek animator, Doug Drexler , who worked with Fresco to produce several computer renderings of his designs. [72]
Commenting on Fresco, physicist Paul G. Hewitt wrote that Fresco inspired him toward a career in physical science. [35] [73]

Awards
In July 2016, Jacque Fresco received a NOVUS Summit award for City Design/Community. NOVUS Summit is supported by UN DESA (United Nations Department of Economic and Social Affairs). [74]

Works

Books

See also
WebPage index: 00011
Portuguese Restoration War
The Portuguese Restoration War ( Portuguese : Guerra da Restauração ; Spanish : Guerra de Restauración portuguesa ) was the name given by nineteenth-century 'romantic' historians to the war between Portugal and Spain that began with the Portuguese revolution of 1640 and ended with the Treaty of Lisbon in 1668. The revolution of 1640 ended the 60-year rule of Portugal by the Spanish Habsburgs . [4] [5] The period from 1640 to 1668 was marked by periodic skirmishes between Portugal and Spain, as well as short episodes of more serious warfare, much of it occasioned by Spanish and Portuguese entanglements with non-Iberian powers. Spain was involved in the Thirty Years' War until 1648 and the Franco–Spanish War until 1659, while Portugal was involved in the Dutch–Portuguese War until 1663.
In the seventeenth century and afterwards, this period of sporadic conflict was simply known, in Portugal and elsewhere, as the Acclamation War . The war established the House of Braganza as Portugal's new ruling dynasty, replacing the House of Habsburg . This ended the so-called Iberian Union .

Events leading to revolution
When Philip II of Portugal died, he was succeeded by Philip III , who had a different approach to Portuguese issues. Taxes on the Portuguese merchants were raised, the Portuguese nobility began to lose its influence at the Spanish Cortes , and government posts in Portugal were increasingly occupied by Spaniards. Ultimately, Philip III tried to make Portugal a Spanish province, and Portuguese nobles stood to lose all of their power.
This situation culminated in a revolution organized by the nobility and bourgeoisie , executed on 1 December 1640, sixty years after the crowning of Philip I (Philip II of Spain), the first "dual monarch". The plot was planned by Antão Vaz de Almada, Miguel de Almeida, and João Pinto Ribeiro. They, together with several associates, known as the Forty Conspirators , killed the Secretary of State , Miguel de Vasconcelos , and imprisoned the king's cousin, Margaret of Savoy , who had been governing Portugal in his name. The moment was well chosen; Philip's troops were, at the time, fighting the Thirty Years' War and also facing a revolution in Catalonia which became known as the Reapers' War .
The support of the people became apparent almost immediately, and, within a matter of hours, John, 8th Duke of Braganza was acclaimed as King John IV of Portugal; the news spread like wildfire throughout the country. By 2 December 1640, the day following the coup, John IV, acting in his capacity as sovereign of the country, had already sent a letter to the Municipal Chamber of Évora .
The ensuing conflict with Spain brought Portugal into the Thirty Years' War as, at least, a peripheral player. From 1641 to 1668, the period during which the two nations were at war, Spain sought to isolate Portugal militarily and diplomatically, and Portugal tried to find the resources to maintain its independence through political alliances and maintenance of its colonial income.

Preparations for war
Immediately after assuming the Portuguese throne, João IV took several steps to strengthen his position. On 11 December 1640, a 'Council of War' was created to organize all of the operations. Next, the king created the 'Junta of the Frontiers' to take care of the fortresses near the border, the hypothetical defense of Lisbon, and the garrisons and sea ports.
A year later, in December 1641, he created a tenancy to assure that all of the country's fortresses would be upgraded and that the improvements would be financed with regional taxes. João IV also organized the army, re-established the 'Military Laws of King Sebastian ', and undertook a diplomatic campaign focused on restoring good relations with England.
After gaining several small victories, João tried to make peace quickly. However, his demand that Philip recognize the new ruling dynasty in Portugal was not fulfilled until the reign of his son, Afonso VI , during the regency of Peter of Braganza (another of his sons who later became King Peter II of Portugal .) Confrontations with Spain lasted twenty-eight years.

Context: relations among the European powers

Relations between France and Spain
In 1640, Cardinal Richelieu , the chief adviser to Louis XIII of France , was fully aware of the fact that France was operating under strained circumstances. He was at war with Spain at that time; he had to control rebellions within France that were supported and financed by Madrid; and he had to send French armies to fight the Spanish Habsburgs on three different fronts. In addition to their shared frontier at the Pyrenees , Philip IV of Spain , formerly Philip III of Portugal as well, reigned, under various titles, in Flanders and Franche-Comté , to the north and east of France. In addition, Philip IV controlled large territories in Italy, where he could, at will, impose a fourth front by attacking French-controlled Savoy . (In Savoy, Christine Marie of France was acting as regent on behalf of her young son, Charles Emmanuel II, Duke of Savoy .)
Spain had enjoyed the reputation of having the most formidable military force in Europe, with the introduction of the arquebus and the so-called "Spanish School". This reputation and tactic had however diminished with the Thirty Years' War. Nevertheless, the consummate statesman, Richelieu, decided to force Philip IV to look to his own internal problems. In order to divert the Spanish troops besieging France, Louis XIII, on the advice of Richelieu, supported the claim of João IV of Portugal during the Acclamation War. This was done on the reasoning that a Portuguese war would drain Spanish resources and manpower.

Relations between Portugal and France
To fulfill the common foreign-policy interests of Portugal and France, a treaty of alliance between the two countries was concluded at Paris on 1 June 1641. It lasted eighteen years before Richelieu's successor as unofficial foreign minister, Cardinal Mazarin , broke the treaty and abandoned his Portuguese and Catalan allies to sign a separate peace with Madrid. The Treaty of the Pyrenees was signed in 1659, under the terms of which France received the portion of Catalonia north of the Pyrenees, known as the Roussillon , and part of the Cerdanya ( French Cerdagne ). Most important to the Portuguese, the French recognised Philip IV of Spain as the legitimate king of Portugal.
Seven years later, in the late stages of the Portuguese Restoration War, relations between the two countries thawed to the extent that the young (but sickly) Afonso VI of Portugal married a French princess, Marie Françoise of Nemours .

Relations between Portugal and the Dutch Republic
At the time of the revolution in Lisbon (1 December 1640), the Portuguese had been at war with the Dutch for nearly forty years. A good deal of the conflict can be attributed to the fact that Spain and the Dutch Republic were concurrently engaged in the Eighty Years' War (1568–1648), and, ever since hostilities between Portugal and the Dutch Republic erupted in 1602, Portugal had been ruled by a Spanish monarch.
The Dutch-Portuguese War was fought almost entirely overseas, with the Dutch mercantile surrogates, the Dutch East India Company and the Dutch West India Company , repeatedly attacking Portugal's colonial possessions in the Americas, in Africa, in India, and in the Far East. Portugal was in a defensive posture throughout, and it received very little military help from Spain.
After the acclamation of João IV, this pattern persisted all over the Portuguese Empire until the final expulsion of the Dutch from Angola (1648), São Tomé (1649), and Brazil (1654). The Dutch signed a European truce with Portugal, helping each other somewhat against their common enemy, Spain. The Dutch resumed buying salt in the Setúbal salt factories, restarting commerce between the two countries for the first time since 1580, when the Spanish branch of the Habsburgs , against whom the Dutch were in revolt , had assumed the Portuguese throne. However, Dutch attacks on Portuguese territories persisted until 1663, even after the signing of the Treaty of The Hague in 1661.

Relations between Portugal and England
England was, at this time, embroiled in its own civil war . Portuguese problems in dealing with England arose from the fact that the English Parliament fought and won its anti-royalist war while, at the same time, Portugal's royal court continued to receive and recognize English princes and nobles. These strained relations persisted during the short-lived Commonwealth period , when the republican government that had deposed Charles I ruled England and then Ireland and Scotland.
After the restoration of the Stuart dynasty , it became possible for Portugal to compensate for the lack of French support by renewing its alliance with England. This took the form of a dynastic marriage between Charles II and Afonso VI 's sister, Catherine of Braganza , which assured Portugal of outside support in its conflict with Spain. The English alliance helped peace with Spain, since Spain had been drained by the Thirty Years' War , and it had no stomach for further warfare with other European powers, especially a resurgent England.

War
Militarily, the Portuguese Restoration War consisted mainly of border skirmishes and cavalry raids to sack border towns, combined with occasional invasions and counter-invasions, many of them half-hearted and under-financed. There were only five major set-piece battles during twenty-eight years of hostilities.
The war may be considered to have had three periods:

First stage: battles
Hoping for a quick victory in Portugal, Spain immediately committed seven regiments to the Portuguese frontier, but delays by the Count of Monterrey, a commander with more interest in the comforts of life at camp than the battlefield, squandered any immediate advantage. A Portuguese counter-thrust in late 1641 failed, and the conflict soon settled into a stalemate.

Battle of Montijo
On 26 May 1644, a large column of Spanish troops and mercenaries, commanded by the Neapolitan marquis of Torrecusa, was stopped at the Battle of Montijo by the Portuguese, who were led by the Matias de Albuquerque, one of a number of experienced Portuguese colonial officers who rose to prominence during the war.

First siege of Elvas
Shortly thereafter, in November 1644, Torrecusa crossed from Badajoz , in a rare winter campaign, to attack the Portuguese town of Elvas , which he besieged for nine days. He suffered heavy losses and was forced back across the border.

Atrocities
The war now took on a peculiar character. It became a frontier confrontation, often between local forces, neighbors who knew each other well, but this familiarity did not moderate the destructive and blood-thirsty impulses of either side. The wanton nature of the combat was often exacerbated by the use of mercenaries and foreign conscripts; incidents of singular cruelty were reported on both sides. The Portuguese settled old animosities that had festered during sixty years of Spanish domination, and the Spanish often took the view that their opponents were disloyal and rebellious subjects, not an opposing army entitled to respectful treatment under the rules of combat.

Scope of the war
Three theaters of warfare were eventually opened, but most activity focused on the northern front, near Galicia, and on the central frontier between Portuguese Alentejo and Spanish Extremadura . The southern front, where the Portuguese Algarve abuts Spanish Andalusia , was a logical target for Portugal, but it was never the focus of a Portuguese attack, probably because the Portuguese queen, Luisa de Guzmán , was the sister of the Duke of Medina Sidonia , the leading noble of Andalusia.

Attrition and corruption
Spain, at first, made the war a defensive one. Portugal, for its part, felt no need to take Spanish territory in order to win, and it too was willing to make the war a defensive contest. Campaigns typically consisted of correrias (cavalry raids) to burn fields, sack towns, and steal large herds of enemy cattle and sheep. Soldiers and officers, many of them mercenaries, were primarily interested in booty and prone to desertion. For long periods, without men or money, neither side mounted formal campaigns, and when actions were taken, they were often driven as much by political considerations, such as Portugal's need to impress potential allies, as by clear military objectives. Year after year, given the problems of campaigning in the winter, and the heat and dry conditions of summer, most of the serious fighting was confined to two relatively short "campaign seasons" in the spring and fall.
The war settled into a pattern of mutual destruction. As early as December 1641, it was common to hear Spaniards throughout the country lament that " Extremadura is finished." Tax collectors, recruiting officers, billeted soldiers, and depredations by Spanish and foreign troops were loathed and feared by the Spanish population as much as raids by the enemy. In Extremadura, local militias bore the brunt of the fighting until 1659, and the absence of these part-time soldiers was extremely harmful to agriculture and local finances. Since there was often no money to pay or support the troops (or to reward their commanders), the Spanish crown turned a blind eye to the smuggling, contraband, profiteering, disorder, and destruction that had become rampant on the frontier. Similar conditions also existed among the Portuguese.

Second stage: defensive stand-off
The war was also expensive. In the 1650s, there were over 20,000 Spanish troops in Extremadura alone, compared to 27,000 in Flanders . Between 1649 and 1654, about 29 percent (over six million ducats ) of Spanish defence spending was appropriated for fighting Portugal, a figure that rose during the major campaigns of the 1660s. Portugal was able to finance its war effort because of its ability to tax the spice trade with Asia and the sugar trade from Brazil, and it received some support from the European opponents of Spain, particularly France and England.
The 1650s were indecisive militarily but important on the political and diplomatic fronts, with the brief exception of the Battle of the Lines of Elvas in 1659. The death of João IV in 1656 signalled the beginning of the regency of his wife, followed by a succession crisis and a palace coup (1662). Despite these domestic problems, the expulsion of the Dutch from Brazil (1654) and the signing of a treaty with England (also in 1654) improved Portugal's diplomatic and financial position temporarily and gave it needed protection against a naval raid on Lisbon.
Nonetheless, the overriding goal, a formal pact with France continued to evade Portugal, whose weakness and isolation had been driven home by its virtual exclusion at the negotiations for the European settlement-of-settlements, the new realpolitik of the peace of Westphalia (1648).
With this treaty and the end of hostilities in Catalonia in 1652, Spain was again ready to direct its efforts against Portugal, but it faced a lack of men, resources, and, especially, good military commanders.

Third stage: Portuguese victory
By 1662, Spain had committed itself to a major effort to end the war. John of Austria the Younger , Philip IV's illegitimate son, led 14,000 men into Alentejo , and, the following year, they succeeded in taking Évora , the major city of the region.
The Portuguese, under António Luís de Meneses, 1st Marquess of Marialva and the German soldier of fortune, Friedrich Hermann von Schönberg , Count of Mértola , who was in command of a of over 3,000 English troops, were able to turn the tide of the war with their strategic brilliance. [6]
They defeated the Spanish in a major engagement at Ameixial on 8 June 1663, and this forced John of Austria to abandon Évora and retreat across the border with heavy losses.
The Portuguese now had some 30,000 troops in the Alentejo-Extremadura theater, but they could not draw the Spanish again into a major engagement until June 1665, when a new Spanish commander, the marquis of Caracena , took over Vila Viçosa with about 23,000 men, including recruits from Germany and Italy.
The Portuguese relief column under António Luís de Meneses and Schomberg met them at Montes Claros on 17 June 1665. The Portuguese infantry and artillery emplacements broke the Spanish cavalry, and the Spanish force lost over 10,000 men, including casualties and prisoners. Shortly thereafter, the Portuguese retook Vila Viçosa. These were the last major engagements of the war.
Both sides returned to skirmishing campaigns. Portugal, with the intercession of its English ally, had sought a truce, but after the decisive Portuguese victory at Montes Claros and with the signing of a Franco-Portuguese treaty in 1667 , the Spanish Habsburgs finally agreed to recognize the House of Braganza as Portugal's new ruling dynasty on 13 February 1668.

Recapitulation
The five major battles of the war were:
The Portuguese were victorious in almost all of these engagements, and peace was concluded, with the help of English mediation, by the Treaty of Lisbon in 1668.

Timeline

Results of the war
Happily for Portugal, its restoration of independence from Spain was clearly established, and it proved that it could fend for itself, albeit with difficulty. Its victories on the battlefield had re-awakened Portuguese nationalism.
Luís de Meneses, the Count of Ericeira , economic adviser to the prince regent , advocated the development of a native textile industry based on a Flemish model. Factories were established at Covilhã , in an area of central Portugal where there was easy access to flocks of sheep and clean mountain water, but they were highly unpopular with both local consumers and traditional weavers.
Meanwhile, Portuguese attempts to develop a silk industry were undercut by the French, who wanted to monopolize that market.

See also

Notes
WebPage index: 00012
Plymouth Colony
Plymouth Colony (sometimes New Plymouth ) was an English colonial venture in North America from 1620 to 1691. The first settlement of the Plymouth Colony was at New Plymouth, a location previously surveyed and named by Captain John Smith . The settlement served as the capital of the colony, and is the modern town of Plymouth, Massachusetts . At its height, Plymouth Colony occupied most of the southeastern portion of the modern state of Massachusetts .
Plymouth Colony was founded by a group of Separatists initially known as the Brownist Emigration and Anglicans , who came to be known as the Pilgrims . It was one of the earliest successful colonies to be founded by the English in North America, along with Jamestown and other settlements in Virginia , and the first sizable permanent English settlement in the New England region. The colony was able to establish a treaty with Chief Massasoit which helped to ensure its success; in this, they were aided by Squanto , a Native American of the Patuxet people. It played a central role in King Philip's War (1675–1678), one of the earliest of the Indian Wars . Ultimately, the colony was merged with the Massachusetts Bay Colony and other territories in 1691 to form the Province of Massachusetts Bay .
Despite the colony's relatively short existence, Plymouth holds a special role in American history . A significant proportion of the citizens of Plymouth were fleeing religious persecution and searching for a place to worship as they saw fit, rather than being entrepreneurs like many of the settlers of Jamestown . The social and legal systems of the colony became closely tied to their religious beliefs, as well as English custom. Many of the people and events surrounding Plymouth Colony have become part of American folklore , including the North American tradition known as Thanksgiving and the monument known as Plymouth Rock .

History

Origins
Plymouth Colony was founded by a group of English separatists who later came to be known as the Pilgrims . The core group (roughly 40% of the adults and 56% of the family groupings [1] ) was part of a Congregationalist congregation led by William Bradford . The congregation began to feel the pressures of religious persecution while still in the English village of Scrooby , near East Retford , Nottinghamshire. In 1607, Archbishop Tobias Matthew raided homes and imprisoned several members of the congregation. [2] [3] The congregation then left England in 1609 and emigrated to the Netherlands , first to Amsterdam and then to Leiden . [4]
In Leiden, the congregation gained the freedom to worship as they chose, but Dutch society was unfamiliar to them. Scrooby had been an agricultural community, whereas Leiden was a thriving industrial center, and the pace of life was hard on the Separatists. The community remained close-knit, but their children began adopting Dutch language and customs, and some were also going into the Dutch Army . The Separatists were also still not free from the persecutions of the English Crown. English authorities came to Leiden to arrest William Brewster in 1618, after he published comments highly critical of the King of England and the Anglican Church . Brewster escaped arrest, but the events spurred the congregation to move even farther from England. [5]
The congregation obtained a land patent from the London Virginia Company in June 1619, after declining the opportunity to settle south of Cape Cod in New Netherland because of their desire to avoid the Dutch influence. [6] This land patent allowed them to settle at the mouth of the Hudson River . They then sought financing through the Merchant Adventurers , a group of businessmen who principally viewed the colony as a means of making a profit. Upon arriving in America, the Pilgrims began working to repay their debts. [7]
Using the financing secured from the Merchant Adventurers, the Colonists bought provisions and obtained passage on two ships: the Mayflower and the Speedwell . They had intended to leave early in 1620, but they were delayed several months due to difficulties in dealing with the Merchant Adventurers, including several changes in plans for the voyage and in financing. The Congregation and the other colonists finally boarded the Speedwell in July 1620 in the Dutch port of Delfshaven . [8]

Mayflower
Speedwell was re-rigged with larger masts before leaving Holland and setting out to meet Mayflower in Southampton, England , around the end of July 1620. [9] [10] The Mayflower was purchased in London. The original captains were Captain Reynolds for Speedwell and Captain Christopher Jones for Mayflower . [11] Other passengers joined the group in Southampton, including William Brewster, who had been in hiding for the better part of a year, and a group of people known to the Leiden congregation as "The Strangers." This group was largely made up of people recruited by the Merchant Adventurers to provide practical assistance to the colony and additional hands to work for the colony's ventures. The term was also used for many of the indentured servants .
Among the Strangers were Myles Standish , who was the colony's military leader, Christopher Martin , who had been designated by the Merchant Adventurers to act as shipboard governor during the trans-Atlantic trip, and Stephen Hopkins , a veteran of a failed colonial venture that may have been the inspiration for Shakespeare 's The Tempest . [12] The group that later became the Leiden Leaders after the merging of ships included John Carver, William Bradford, Edward Winslow, William Brewster, and Isaac Alberton. [13]
The departure of the Mayflower and Speedwell for America was beset by delays. Further disagreements with the Merchant Adventurers held up the departure in Southampton. A total of 120 passengers finally departed on August 5—90 on the Mayflower and 30 on the Speedwell . [14] Leaving Southampton, the Speedwell experienced significant leakage, which required the ships to immediately put in at Dartmouth . The leakage was partly caused by being over masted and being pressed too much with sail. [11] Repairs were completed, then a further delay ensued awaiting favorable winds. The two ships finally set sail on August 23 and made it only two hundred miles beyond Land's End before another major leak in the Speedwell forced the expedition to return again to England, this time to the port of Plymouth . The Speedwell was found to be unseaworthy; some passengers abandoned their attempt to emigrate, while others joined the Mayflower , crowding the already heavily burdened ship. Later, it was speculated that the crew of the Speedwell had intentionally sabotaged the ship to avoid having to make the treacherous trans-Atlantic voyage. [15] The delays had significant consequences; the cost of the repairs and port fees required that the colonists sell some of their invaluable provisions, but, more importantly, the delays meant that everyone had to spend the entire winter on board the Mayflower off Cape Cod in what could only be described as squalid conditions.
The Mayflower departed Plymouth , England on September 6, 1620 with 102 passengers and about 30 crew members in the small, 106 foot-long ship. [16] The seas were not severe during the first month in the Atlantic but, by the second month, the ship was being hit by strong north-Atlantic winter gales, causing it to be badly shaken with water leaks from structural damage. There were many obstacles throughout the trip, including multiple cases of seasickness and the bending and cracking of a main beam of the ship. One death occurred, that of William Button. [11]
After two months at sea, land was sighted on November 9 off the coast of Cape Cod . They attempted to sail south to the designated landing site at the mouth of the Hudson but ran into trouble in the region of Pollack Rip, a shallow area of shoals between Cape Cod and Nantucket Island . With winter approaching and provisions running dangerously low, the passengers decided to return north to Cape Cod Bay and abandon their original landing plans. [17]

Prior exploration and settlements
The Pilgrims were not the first people in the area. Besides the indigenous tribes, there had been nearly a century of exploration, fishing, and settlement by Europeans. John Cabot 's discovery of Newfoundland in 1497 had laid the foundation for the extensive English claims over the east coast of North America. [18] One of the earliest maps of New England was produced c. 1540 by cartographer Giacomo Gastaldi and erroneously identified Cape Breton with the Narragansett Bay . The resulting map completely omits most of the New England coast. [19] European fishermen had been plying the waters off the New England coast for much of the 16th and 17th centuries.
Frenchman Samuel de Champlain had explored the area extensively in 1605. He had specifically explored Plymouth Harbor , which he called "Port St. Louis," and made an extensive and detailed map of it and the surrounding lands. Patuxet, the native village upon which the town of Plymouth was later built, was shown by Champlain as a thriving settlement. [20] However, an epidemic wiped out up to 90% of the Native Americans along the Massachusetts coast in 1617–1619, including the Patuxet, before the arrival of the Mayflower . The epidemic has traditionally been thought to be smallpox, [21] but a recent analysis has concluded that it may have been a lesser-known disease called leptospirosis . [22] The absence of any serious native opposition to settlement by the Pilgrims may have been a pivotal event to their success and to English colonization in the Americas.
Popham Colony , also known as Fort St. George, was organized by the Plymouth Company (unrelated to Plymouth Colony) and founded in 1607. It was settled on the coast of Maine and was beset by internal political struggles, sickness, and weather problems. It was abandoned in 1608. [23]
Captain John Smith of Jamestown fame had explored the area in 1614 and is credited with naming the region of New England. He named many locations using approximations of Native American words. The future site of the Pilgrim's first settlement was originally named "Accomack" by Smith. In consultation with Prince Charles , son of King James, Smith changed "Accomack" to New Plymouth. A map published in his 1616 work A Description of New England clearly shows the site of the future Pilgrim settlement named "New Plimouth." [24]
In the Mayflower settlers' first explorations of Cape Cod, they came across evidence that Europeans had previously spent extensive time there. They discovered remains of a European fort and uncovered a grave that contained the remains of both an adult European male and a Native American child. [25]

Landings at Provincetown and Plymouth
The Mayflower anchored at Provincetown Harbor on November 11, 1620. The Pilgrims did not have a patent to settle this area; thus, some passengers began to question their right to land, complaining that there was no legal authority to establish a colony. In response to this, a group of colonists drafted and ratified the first governing document of the colony, the Mayflower Compact , while still aboard the ship as it lay off-shore. The intent of the compact was to establish a means of governing the colony, though it did little more than confirm that the colony would be governed like any English town. It did, however, serve the purpose of relieving the concerns of many of the settlers. [26] This social contract was written and signed by 41 Separatist men. It was modeled on the church covenants that Congregationalists used to form new congregations. It made clear that the colony should be governed by "just and equal laws," and those who signed it promised to keep these laws. [27]
The group remained on board the ship through the next day, a Sunday , for prayer and worship. The immigrants finally set foot on land at what became Provincetown on November 13. The first task was to rebuild a shallop , a shallow draft boat that had been built in England and disassembled for transport aboard the Mayflower . It would remain with the Pilgrims while the Mayflower returned to England. On November 15, Captain Myles Standish led a party of sixteen men on an exploratory mission, during which they disturbed a Native American grave and located a buried cache of Indian corn. The following week, Susanna White gave birth to son Peregrine White on the Mayflower . He was the first English child born to the Pilgrims in the New World. The shallop was finished on November 27, and a second expedition was undertaken using it, under the direction of Mayflower master Christopher Jones . Thirty-four men went, but the expedition was beset by bad weather; the only positive result was that they found a Native burial ground and corn that had been intended for the dead, taking the corn for future planting. A third expedition along Cape Cod left on December 6; it resulted in a skirmish with local Native Americans known as the "First Encounter" near modern-day Eastham, Massachusetts . The colonists decided to look elsewhere, having failed to secure a proper site for their settlement, and fearing that they had angered the local Native Americans by robbing their corn stores and firing upon them. The Mayflower left Provincetown Harbor and set sail for Plymouth Harbor. [28]
The Mayflower dropped anchor in Plymouth Harbor on December 16 and spent three days looking for a settlement site. They rejected several sites, including one on Clark's Island and another at the mouth of the Jones River , in favor of the site of a recently abandoned Native American settlement named Patuxet. [29] The location was chosen largely for its defensive position. The settlement would be centered on two hills: Cole's Hill, where the village would be built, and Fort Hill, where a defensive cannon would be stationed. Also important in choosing the site was that the prior Native villagers had cleared much of the land making agriculture relatively easy. Fresh water for the colony was provided by Town Brook and Billington Sea . There are no contemporaneous accounts to verify the legend, but Plymouth Rock is often hailed as the point where the colonists first set foot on their new homeland. [30] [31]
The area where the colonists settled had been identified as "New Plymouth" in maps by John Smith published in 1614. The colonists elected to retain the name for their own settlement, in honor of their final point of departure from England: Plymouth, Devon . [32]

First winter
On December 21, 1620, the first landing party arrived at the site of what later became the settlement of Plymouth . Plans to immediately begin building houses, however, were delayed by inclement weather until December 23. As the building progressed, twenty men always remained ashore for security purposes, while the rest of the work crews returned each night to the Mayflower . Women, children, and the infirm remained on board the Mayflower ; many had not left the ship for six months. The first structure was a "common house" of wattle and daub , and took two weeks to complete in the harsh New England winter. In the following weeks, the rest of the settlement slowly took shape. The living and working structures were built on the relatively flat top of Cole's Hill, and a wooden platform was constructed atop nearby Fort Hill to support the cannon that would defend the settlement.
During the winter, the Mayflower colonists suffered greatly from lack of shelter, diseases such as scurvy , and general conditions onboard ship. [6] Many of the able-bodied men were too infirm to work; 45 out of 102 pilgrims died and were buried on Cole's Hill . Thus, only seven residences (of a planned nineteen) and four common houses were constructed during the first winter. [33] By the end of January, enough of the settlement had been built to begin unloading provisions from the Mayflower . In mid-February, after several tense encounters with local Native Americans, the male residents of the settlement organized themselves into military orders; Myles Standish was designated as the commanding officer. By the end of the month, five cannons had been defensively positioned on Fort Hill. [34] John Carver was elected governor to replace Governor Martin.
On March 16, 1621, the first formal contact occurred with the Indians (or Native Americans). A Native American named Samoset , originally from Pemaquid Point in modern Maine , walked boldly into the midst of the settlement and proclaimed, "Welcome, Englishmen!" He had learned some English from interacting with English fishermen and trappers (most probably from Bristol) operating in the region. [35] It was during this meeting that the Pilgrims learned how the previous residents of the Native American village of Patuxet had died of an epidemic thought to be smallpox . They also discovered that the supreme leader of the region was a Wampanoag Native American sachem (chief) by the name of Massasoit ; [36] and they learned of the existence of Squanto (also known by his full Massachusett name of Tisquantum), a Native American originally from Patuxet. Squanto had spent time in Europe and spoke English quite well. Samoset spent the night in Plymouth and agreed to arrange a meeting with some of Massasoit's men. [37]
Massasoit and Squanto were apprehensive about the Pilgrims. In Massasoit's first contact with the English, several men of his tribe had been killed in an unprovoked attack by English sailors. He also knew of the Pilgrims' theft of the corn stores in their landings at Provincetown. [38] Squanto had been abducted in 1614 by English explorer Thomas Hunt and had spent five years in Europe, first as a slave for a group of Spanish monks, then in England. He had returned to New England in 1619, acting as a guide to explorer Capt. Robert Gorges . Massasoit and his men had massacred the crew of the ship and had taken in Squanto. [39] [40]
Samoset returned to Plymouth on March 22 with a delegation from Massasoit that included Squanto; Massasoit joined them shortly thereafter. After an exchange of gifts, Massasoit and Governor Carver established a formal treaty of peace. This treaty ensured that each people would not bring harm to the other, that Massasoit would send his allies to make peaceful negotiations with Plymouth, and that they would come to each other's aid in a time of war. [41]
On April 5, 1621, after being anchored for almost four months in Plymouth Harbor , the Mayflower set sail for England. [42] Nearly half of the original 102 passengers had died during the first winter. [43] As William Bradford wrote, "of these one hundred persons who came over in this first ship together, the greatest half died in the general mortality, and most of them in two or three months' time". [44] By November 1621, only 53 pilgrims were alive to celebrate the harvest feast which modern Americans know as "The First Thanksgiving ". [45] Of the 18 adult women, 13 died the first winter while another died in May. Only four adult women were left alive for the Thanksgiving. [46]
Several of the graves on Cole's Hill were uncovered in 1855; their bodies were disinterred and moved to a site near Plymouth Rock. [47]

"First Thanksgiving"
The autumn celebration in late 1621 that has become known as "The First Thanksgiving " was not known as such to the Pilgrims. The first "Thanksgiving" as the Pilgrims would have called it (referring to solemn ceremony of praise and thanks to God for a congregation's good fortune) did not occur until 1623, in response to the good news of the arrival of additional colonists and supplies. That event probably occurred in July and consisted of a full day of prayer and worship and probably very little revelry. [48]
The event now commemorated in the United States at the end of November each year is more properly described as a harvest festival . The original festival was probably held in early October 1621 and was celebrated by the 53 surviving Pilgrims, along with Massasoit and 90 of his men. Three contemporaneous accounts of the event survive: Of Plymouth Plantation by William Bradford; Mourt's Relation probably written by Edward Winslow; and New England's Memorial by Plymouth Colony Secretary (and Bradford's nephew) Capt. Nathaniel Morton . [49] The celebration lasted three days and featured a feast that included numerous types of waterfowl, wild turkeys and fish procured by the colonists, and five deer brought by the Native Americans. [50]

Early relations with the Native Americans
After the departure of Massasoit and his men, Squanto remained in Plymouth to teach the Pilgrims how to survive in New England, for example using dead fish to fertilize the soil. For the first few years of colonial life, the fur trade was the dominant source of income, buying furs from Native Americans and selling to Europeans, beyond subsistence farming. [51] Shortly after the departure of the Mayflower , Governor Carver suddenly died. William Bradford was elected to replace him and went on to lead the colony through much of its formative years. [52]
As promised by Massasoit, numerous Native Americans arrived at Plymouth throughout the middle of 1621 with pledges of peace. On July 2, a party of Pilgrims led by Edward Winslow (who later became the chief diplomat of the colony) set out to continue negotiations with the chief. The delegation also included Squanto, who acted as a translator. After traveling for several days, they arrived at Massasoit's capital, the village of Sowams near Narragansett Bay . After meals and an exchange of gifts, Massasoit agreed to an exclusive trading pact with the English; thus, the French were no longer welcome, though they were also frequent traders in the area. Squanto remained behind and traveled throughout the area to establish trading relations with several tribes. [53]
In late July, a boy named John Billington became lost for some time in the woods around the colony. It was reported that he was found by the Nauset , the same group of Native Americans on Cape Cod from whom the Pilgrims had unwittingly stolen corn seed the prior year upon their first explorations. The English organized a party to return Billington to Plymouth. The Pilgrims agreed to reimburse the Nauset for the corn which they had taken in return for the Billington boy. This negotiation did much to secure further peace with the Native Americans in the area. [54]
During their dealings with the Nausets over the release of John Billington, the Pilgrims learned of troubles that Massasoit was experiencing. Massasoit, Squanto, and several other Wampanoags had been captured by Corbitant , sachem of the Narragansett tribe. A party of ten men under the leadership of Myles Standish set out to find and execute Corbitant. While hunting for Corbitant, they learned that Squanto had escaped and Massasoit was back in power. Several Native Americans had been injured by Standish and his men and were offered medical attention in Plymouth. They had failed to capture Corbitant, but the show of force by Standish had garnered respect for the Pilgrims and, as a result, nine of the most powerful sachems in the area signed a treaty in September, including Massasoit and Corbitant, pledging their loyalty to King James. [55]
In May 1622, a vessel named the Sparrow arrived carrying seven men from the Merchant Adventurers whose purpose was to seek out a site for a new settlement in the area. Two ships followed shortly thereafter carrying sixty settlers, all men. They spent July and August in Plymouth before moving north to settle in modern Weymouth, Massachusetts at a settlement which they named Wessagussett . [56] The settlement of Wessagussett was short-lived, but it provided the spark for an event that dramatically changed the political landscape between the local Native American tribes and the English settlers. Reports reached Plymouth of a military threat to Wessagussett, and Myles Standish organized a militia to defend them. However, he found that there had been no attack. He therefore decided on a pre-emptive strike, an event which historian Nathaniel Philbrick calls "Standish's raid". He lured two prominent Massachusett military leaders into a house at Wessagussett under the pretense of sharing a meal and making negotiations. Standish and his men then stabbed and killed the two unsuspecting Native Americans. The local sachem named Obtakiest was pursued by Standish and his men but escaped with three English prisoners from Wessagussett, whom he then executed. [57] Within a short time, Wessagussett was disbanded, and the survivors were integrated into the town of Plymouth. [56]
Word quickly spread among the Native American tribes of Standish's attack; many Native Americans abandoned their villages and fled the area. As noted by Philbrick: "Standish's raid had irreparably damaged the human ecology of the region .... It was some time before a new equilibrium came to the region." [58] Edward Winslow reports in his 1624 memoirs Good News from New England that "they forsook their houses, running to and fro like men distracted, living in swamps and other desert places, and so brought manifold diseases amongst themselves, whereof very many are dead". [59] Lacking the trade in furs provided by the local tribes, the Pilgrims lost their main source of income for paying off their debts to the Merchant Adventurers. Rather than strengthening their position, Standish's raid had disastrous consequences for the colony, as attested by William Bradford in a letter to the Merchant Adventurers: "[W]e had much damaged our trade, for there where we had [the] most skins the Indians are run away from their habitations". [58] The only positive effect of Standish's raid seemed to be the increased power of the Massasoit-led Wampanoag tribe, the Pilgrims' closest ally in the region. [58]

Growth of Plymouth
A second ship arrived in November 1621 named the Fortune , sent by the Merchant Adventurers one year after the Pilgrims first set foot in New England. It arrived with 37 new settlers for Plymouth. However, the ship had arrived unexpectedly and also without many supplies, so the additional settlers put a strain on the resources of the colony. Among the passengers of the Fortune were several additional people of the original Leiden congregation, including William Brewster 's son Jonathan, Edward Winslow's brother John, and Philip Delano (the family name was earlier "de la Noye") whose descendants include President Franklin Delano Roosevelt . The Fortune also carried a letter from the Merchant Adventurers chastising the colony for failure to return goods with the Mayflower that had been promised in return for their support. The Fortune began its return to England laden with £500 worth of goods (equivalent to £78 thousand in 2010, or $119 thousand at PPP ), more than enough to keep the colonists on schedule for repayment of their debt. However, the Fortune was captured by the French before she could deliver her cargo to England, creating an even larger deficit for the colony. [60]
In July 1623, two more ships arrived: the Anne , under the command of Captain "Master" William Peirce and Master John Bridges; and the Little James , under the command of Captain Emanuel Altham. [61] These ships carried 96 new settlers, among them Leideners , including William Bradford 's future wife Alice, and William and Mary Brewster's daughters Patience and Fear. Some of the passengers who arrived on the Anne were either unprepared for frontier life or undesirable additions to the colony and returned to England the next year. According to Gleason Archer, [62] "those who remained were not willing to join the colony under the terms of the agreement with the Merchant Adventurers. They had embarked for America upon an understanding with the Adventurers that they might settle in a community of their own, or at least be free from the bonds by which the Plymouth colonists were enslaved. A letter addressed to the colonists and signed by thirteen of the merchants recited these facts and urged acceptance of the new comers on the specified terms." The new arrivals were allotted land in the area of the Eel River , known as Hobs Hole , which became Wellingsley, a mile south of Plymouth Rock.
In September 1623, another ship arrived carrying settlers destined to refound the failed colony at Weymouth, and they stayed temporarily at Plymouth. In March 1624, a ship arrived bearing a few additional settlers and the first cattle. A 1627 division of cattle lists 156 colonists divided into twelve lots of thirteen colonists each. [63] Another ship arrived in August 1629, also named the Mayflower , with 35 additional members of the Leiden congregation. Ships arrived throughout the period between 1629 and 1630 carrying new settlers, though the exact number is unknown; contemporaneous documents claimed that, by January 1630, the colony had almost 300 people. In 1643, the colony had an estimated 600 males fit for military service, implying a total population of about 2,000. By 1690, on the eve of the dissolution of the colony, the estimated total population of Plymouth County, the most populous, was 3,055 people. [56] It is estimated that the entire population of the colony at the point of its dissolution was around 7,000. [64] For comparison, it is estimated that more than 20,000 settlers had arrived in Massachusetts Bay Colony between 1630 and 1640 (a period known as the Great Migration ), and the English population of all New England was estimated to be about 60,000 by 1678. Plymouth was the first colony in the region but, by the time of its annexation, it was much smaller than Massachusetts Bay Colony. [65]

Military history

Myles Standish
Myles Standish was the military leader of Plymouth Colony from the beginning. He organized and led the first party to set foot in New England, an exploratory expedition of Cape Cod upon arrival in Provincetown Harbor. He also led the third expedition, during which Standish fired the first recorded shot by the Pilgrim settlers in an event known as the First Encounter. Standish had training in military engineering from the University of Leiden , and it was he who decided the defensive layout of the settlement when they finally arrived at Plymouth. Standish also organized the able-bodied men into military orders in February of the first winter. During the second winter, he helped design and organize the construction of a large palisade wall surrounding the settlement. Standish led two early military raids on Indian villages: the raid to find and punish Corbitant for his attempted coup, and the killing at Wessagussett called "Standish's raid". The former had the desired effect of gaining the respect of the local Indians; the latter only served to frighten and scatter them, resulting in loss of trade and income. [66]

Pequot War
The first major war in New England was the Pequot War of 1637. The war's roots go back to 1632, when a dispute arose between Dutch fur traders and Plymouth officials over control of the Connecticut River Valley near modern Hartford, Connecticut . Representatives from the Dutch East India Company and Plymouth Colony both had deeds which claimed that they had rightfully purchased the land from the Pequots . A sort of land rush occurred as settlers from Massachusetts Bay and Plymouth colonies tried to beat the Dutch in settling the area; the influx of English settlers also threatened the Pequot. Other confederations in the area sided with the English, including the Narragansetts and Mohegans , who were the traditional enemies of the Pequots. The event that sparked formal hostilities was the capture of a boat and the murder of its captain John Oldham in 1636, an event blamed on allies of the Pequots. In April 1637, a raid on a Pequot village by John Endicott led to a retaliatory raid by Pequot warriors on the town of Wethersfield, Connecticut , where some 30 English settlers were killed. This led to a further retaliation, where a raid led by Captain John Underhill and Captain John Mason burned a Pequot village to the ground near modern Mystic, Connecticut , killing 300 Pequots. Plymouth Colony had little to do with the actual fighting in the war. [67]
When it appeared that the war would resume, four of the New England colonies (Massachusetts Bay, Connecticut , New Haven , and Plymouth) formed a defensive compact known as the United Colonies of New England . Edward Winslow was already known for his diplomatic skills, and he was the chief architect of the United Colonies. His experience in the United Provinces of the Netherlands during the Leiden years was key to organizing the confederation. John Adams later considered the United Colonies to be the prototype for the Articles of Confederation , which was the first attempt at a national government. [68]

King Philip's War
King Philip was the younger son of Massasoit and the heir of Massasoit's position as sachem of the Pokanoket and supreme leader of the Wampanoag. (He was also known as Metacomet and other variations on that name.) He became sachem upon the sudden death of his older brother Wamsutta , also known as Alexander, in 1662. [69]
The cause of the war stems from the increasing numbers of English colonists and their demand for land. As more land was purchased from the Native Americans, they were restricted to smaller territories for themselves. Native American leaders such as King Philip resented the loss of land and looked for a means to slow or reverse it. [70] Of specific concern was the founding of the town of Swansea , which was located only a few miles from the Wampanoag capital at Mount Hope . The General Court of Plymouth began using military force to coerce the sale of Wampanoag land to the settlers of the town. [71]
The proximate cause of the conflict was the death of a Praying Indian named John Sassamon in 1675. Sassamon had been an advisor and friend to King Philip; however, Sassamon's conversion to Christianity had driven the two apart. [71] Accused in the murder of Sassamon were some of Philip's most senior lieutenants. A jury of twelve Englishmen and six Praying Indians found the Native Americans guilty of murder and sentenced them to death. [72] To this day, some debate exists whether King Philip's men actually committed the murder. [71]
Philip had already begun war preparations at his home base near Mount Hope where he started raiding English farms and pillaging their property. In response, Governor Josiah Winslow called out the militia, and they organized and began to move on Philip's position. [73] King Philip's men attacked unarmed women and children in order to receive a ransom. One such attack resulted in the capture of Mary Rowlandson . The memoirs of her capture provided historians with much information on Native American culture during this time period. [74]
The war continued through the rest of 1675 and into the next year. The English were constantly frustrated by the Native Americans' refusal to meet them in pitched battle. They employed a form of guerilla warfare that confounded the English. Captain Benjamin Church continuously campaigned to enlist the help of friendly Native Americans to help learn how to fight on an even footing with Philip's warrior bands, but he was constantly rebuffed by the Plymouth leadership who mistrusted all Native Americans, thinking them potential enemies. Eventually, Governor Winslow and Plymouth military commander Major William Bradford (son of the late Governor William Bradford) relented and gave Church permission to organize a combined force of English and Native Americans. After securing the alliance of the Sakonnet, he led his combined force in pursuit of Philip, who had thus far avoided any major battles in the war that bears his name. Throughout July 1676, Church's band captured hundreds of Native American warriors, often without much of a fight, though Philip eluded him. Church was given permission to grant amnesty to any captured Native Americans who would agree to join the English side, and his force grew immensely. [75] Philip was killed by a Pocasset Indian, and the war soon ended as an overwhelming English victory. [76]
Eight percent of the English adult male population is estimated to have died during the war, a rather large percentage by most standards. The impact on the Native Americans was far higher, however. So many were killed, fled, or shipped off as slaves that the entire Native American population of New England fell by sixty to eighty percent. [77]

Final years
In 1686, the entire region was reorganized under a single government known as the Dominion of New England ; this included the colonies of Plymouth, Rhode Island , Massachusetts Bay , Connecticut , and New Hampshire . In 1688, New York , West Jersey , and East Jersey were added. [78] The President of the Dominion Edmund Andros was highly unpopular, and the union did not last. The union was dissolved after news of the Glorious Revolution reached Boston in April 1689, and the citizens of Boston rose up and arrested Andros. [79] When news of these events reached Plymouth, its magistrates reclaimed power. [78] [80]
The return of self-rule for Plymouth Colony was short-lived, however. A delegation of New Englanders led by Increase Mather went to England to negotiate a return of the colonial charters that had been nullified during the Dominion years. The situation was particularly problematic for Plymouth Colony, as it had existed without a formal charter since its founding. Plymouth did not get their wish for a formal charter; instead, a new charter was issued, combining Plymouth Colony, Massachusetts Bay Colony, and other territories. The official date of the proclamation was October 17, 1691, ending the existence of Plymouth Colony, though it was not put into force until the arrival of the charter of the Province of Massachusetts Bay on May 14, 1692, carried by the new royal governor Sir William Phips . The last official meeting of the Plymouth General Court occurred on June 8, 1692. [78] [81] [82]

Life

Religion
The most important religious figure in the colony was John Robinson , an original pastor of the Scrooby congregation and religious leader of the separatists throughout the Leiden years. He never actually set foot in New England, but many of his theological pronouncements shaped the nature and character of the Plymouth church. [83] For example, Robinson stated that women and men have different social roles according to a law of nature, though neither was lesser in the eyes of God. Robinson taught that men and women have distinct but complementary roles in church, home, and society as a whole. He referred to women as the "weaker vessel". [84] In matters of religious understanding, he proclaimed that it was the man's role to educate and "guide and go before" women. [84] He also said that women should be "subject" to their husbands. [84] Robinson also dictated the proper methods of child rearing—he prescribed a strict upbringing with a strong emphasis on corporal punishment . He believed that a child's natural inclination towards independence was a manifestation of original sin and should thus be repressed. [85]
The Pilgrims themselves were a subset of an English religious movement known as Puritanism , which sought to "purify" the Anglican Church of its "Catholic" trappings. The movement sought to return the church to its original state and to practice Christianity as was done in the times of the Apostles . Following Martin Luther 's and John Calvin 's Reformation , Puritans believed that the Bible was the only true source of religious teaching and that any additions made to Christianity had no place in Christian practice, especially with regard to church traditions, such as clerical vestments or the use of Latin in church services. In particular, they were strongly opposed to the Anglicans' episcopal form of church government. They believed that the church was a community of Christians who made a covenant with God and with one another. Their congregations had a democratic structure. Ministers, teachers, and lay church elders were elected by and responsible to the entire congregation ( Calvinist Federalism ). Each congregation was independent of all the others and directly subject to God's (or Christ's) government ( theocracy ), hence the name Congregationalism . [86] The Pilgrims distinguished themselves from the Puritans in that they sought to "separate" themselves from the Anglican Church, rather than reform it from within. It was this desire to worship from outside of the Anglican Communion that led them first to the Netherlands and ultimately to New England. [87]
Each town in the colony was considered a single church congregation; in later years, some of the larger towns split into two or three congregations. Church attendance was mandatory for all residents of the colony, while church membership was restricted to those who had converted to the faith. In Plymouth Colony, it seems that a simple profession of faith was all that was required for acceptance. This was a more liberal doctrine than some other New England congregations, such as those of the Massachusetts Bay Colony, where it was common to subject those seeking formal membership to strict and detailed cross-examinations. There was no central governing body for the churches. Each individual congregation was left to determine its own standards of membership, hire its own ministers, and conduct its own business. [88]
The church was undoubtedly the most important social institution in the colony. The Bible was the primary religious document of the society, and it also served as the primary legal document. [89] Church attendance was not only mandatory, but membership was socially vital. Education was carried out for almost purely religious purposes. The laws of the colony specifically asked parents to provide for the education of their children, "at least to be able duly to read the Scriptures" and to understand "the main Grounds and Principles of Christian Religion". [90] It was expected that the male head of the household would be responsible for the religious well-being of all its members, children and servants alike. [90]
Most churches used two acts to sanction its members: censure and excommunication . Censure was a formal reprimand for behavior that did not conform with accepted religious and social norms, while excommunication involved full removal from church membership. Many perceived social evils, from fornication to public drunkenness, were dealt with through church discipline rather than through civil punishment. Church sanctions seldom held official recognition outside church membership and seldom resulted in civil or criminal proceedings. Nevertheless, such sanctions were a powerful tool of social control. [91]
The Pilgrims practiced infant baptism . The public baptism ceremony was usually performed within six months of birth. [92]
Marriage was considered a civil ceremony, rather than a religious one. Such an arrangement may have been a habit that had developed during the Leiden years, as civil marriage was common in the Netherlands. However, the Pilgrims saw this arrangement as biblical, there being no evidence from Scripture that a minister should preside over a wedding. [93]
Besides the theology espoused by their religious leaders, the people of Plymouth Colony had a strong belief in the supernatural. Richard Greenham was a Puritan theologian whose works were known to the Plymouth residents, and he counseled extensively against turning to magic or wizardry to solve problems. The Pilgrims saw Satan's work in nearly every calamity that befell them; the dark magical arts were very real and present for them. They believed in the presence of malevolent spirits who brought misfortune to people. For example, in 1660, a court inquest into the drowning death of Jeremiah Burroughs determined that a possessed canoe was to blame. [94] Massachusetts Bay Colony experienced an outbreak of witchcraft scares in the 17th century, but there is little evidence that Plymouth was engulfed in anything similar. Witchcraft was listed as a capital crime in the 1636 codification of the laws by the Plymouth General Court, but there were no actual convictions of witches in Plymouth Colony. The court records only show two formal accusations of witchcraft. The first, of Goodwife Holmes in 1661, never went to trial. The second, of Mary Ingram in 1677, resulted in trial and acquittal. [95]

Marriage and family life
Edward Winslow and Susanna White both lost their spouses during the harsh winter of 1620–1621, and the two became the first couple to be married in Plymouth. Governor Bradford presided over the civil ceremony. [93]
In Plymouth Colony, " courtships were usually initiated by the young people themselves, but as a relationship progressed toward something more permanent, the parents became more directly involved." [96] Parents were concerned with the moral and religious qualities of the proposed spouse, as well as the financial means of each party's family. [97] The first step toward marriage was generally a betrothal or pre-contract, a ceremony carried out before two witnesses in which the couple pledged to wed in due time. [96] Several weeks or months after the betrothal was contracted, the couple's intentions were published. [96] "A betrothed couple was considered to have a special status, not married but no longer unmarried either." [96] Sexual contact was prohibited between a betrothed couple, but the penalty for it was one-fourth of what it was for single persons, and records indicate a relatively high number of babies born less than nine months after a wedding ceremony. [98]
Marriage was considered the normal state for all adult residents of the colony. [99] Most men first married in their mid-twenties and women around age 20. [100] Second marriages were not uncommon, and widows and widowers faced social and economic pressures to remarry. On average, most widows and widowers remarried within six months to a year. Most adults who reached marriageable age lived into their sixties, so effectively two-thirds of a person's life was spent married. [101]
Women in Plymouth Colony had more extensive legal and social rights compared to 17th-century European norms. Women were considered equal to men before God from the perspective of the Church. God's grace was available equally to all professed Christians. Women were, however, expected to take traditionally feminine roles, such as child-rearing and maintaining the household, in Puritan families. [102]
Plymouth women enjoyed extensive property and legal rights, unlike in Europe where women had few rights. A wife in Plymouth could not be legally "written out" of her husband's will and was guaranteed a full third of the family's property upon his death. Women were parties to contracts in Plymouth, most notably prenuptial agreements . It was common for brides-to-be (and not, notably, their fathers) to enter into contractual agreements on the consolidation of property upon marriage. In some cases, especially in second marriages, women were given exclusive right to retain control of their property separately from their husbands. [102] [103] Women were also known to occasionally sit on juries in Plymouth, a remarkable circumstance in seventeenth century legal practice. Historians James and Patricia Scott Deetz cite a 1678 inquest into the death of Anne Batson's child, where the jury was composed of five women and seven men. [104]
Family size in the colony was large by modern American standards, [105] though childbirth was often spaced out, with an average of two years between children. Most families averaged five to six children living under the same roof, though it would not be uncommon for one family to have grown children moving out before the mother had finished giving birth. Maternal mortality rates were fairly high; one birth in thirty resulted in the death of the mother, resulting in one in five women dying in childbirth . [106] However, "the rate of infant mortality in Plymouth seems to have been relatively low. In the case of a few families for which there are unusually complete records, only about one in five children seems to have died before the age of twenty-one. Furthermore, births in the sample [of about 90 families] come for the most part with relatively few 'gaps' which might indicate a baby who did not survive. All things considered, it appears that the rate of infant and child mortality in Plymouth was no more than 25 per cent". [107]

Childhood, adolescence, and education
Children generally remained in the direct care of their mothers until the age of about eight years old, after which time it was not uncommon for the child to be placed in the foster care of another family. [108] There were any number of reasons for a child to be "put-out" in this manner. Some children were placed into households to learn a trade, others to be taught to read and write. It seems that there was a theological reason for fostering children, as with almost every decision in the colony. It was assumed that children's own parents would love them too much and would not properly discipline them. By placing children in the care of another family, there was little danger of them being spoiled. [109]
Adolescence was not a recognized phase of life in Plymouth colony, and there was not a single rite of passage that marked transition from youth to adulthood. Several important transitions occurred at various ages, but none marked a single "coming of age" event. As early as eight years old, children were expected to begin learning their adult roles in life by taking on some of the family work or by being placed in foster homes to learn a trade. [108] Most children experienced religious conversion around the age of eight as well, thus becoming church members. [110] Orphaned children were given the right to choose their own guardians at age 14. At 16, males became eligible for military duty and were also considered adults for legal purposes, such as standing trial for crimes. Age 21 was the youngest at which a male could become a freeman, though for practical purposes this occurred some time in a man's mid-twenties. Twenty-one was the assumed age of inheritance, as well, although the law respected the rights of the deceased to name an earlier age in his will. [111]
Actual schools were rare in Plymouth colony. The first true school was not founded until 40 years after the foundation of the colony. The General Court first authorized colony-wide funding for formal public schooling in 1673, but only the town of Plymouth made use of these funds at that time. By 1683, though, five additional towns had received this funding. [112]
Education of the young was never considered to be the primary domain of schools, even after they had become more common. Most education was carried out by a child's parents or foster parents. Formal apprenticeships were not the norm in Plymouth; it was expected that a foster family would teach the children whatever trades they themselves practiced. The church also played a central role in a child's education. [113] As noted above, the primary purpose of teaching children to read was so that they could read the Bible for themselves. [114]

Government and laws

Organization
Plymouth Colony did not have a royal charter authorizing it to form a government, yet some means of governance was needed. The Mayflower Compact was the colony's first governing document, signed by the 41 able-bodied Separatists aboard the Mayflower upon their arrival in Provincetown Harbor on November 21, 1620. Formal laws were not codified until 1636. The colony's laws were based on a hybrid of English common law and religious law as laid out in the Bible . [89] The colonial authorities were deeply influenced by Calvinist theology, and were convinced that democracy was the form of government mandated by God. [115]
The colony offered nearly all adult males potential citizenship. Full citizens, or "freemen", were accorded full rights and privileges in areas such as voting and holding office. To be considered a freeman, adult males had to be sponsored by an existing freeman and accepted by the General Court. Later restrictions established a one-year waiting period between nominating and granting of freeman status, and also placed religious restrictions on the colony's citizens, specifically preventing Quakers from becoming freemen. [89] Freeman status was also restricted by age; the official minimum age was 21, although in practice most men were elevated to freeman status between the ages of 25 and 40, averaging somewhere in their early thirties. [116]
The colony established a male disabled veterans' fund in 1636 to support veterans who returned from service with disabilities. [29] In 1641, the Body of Liberties developed protections for people who were unable to perform public service. [29] Another law was developed to protect married women, children, and people with cognitive disabilities from making financial decisions. This was created as these groups were considered "mentally incapable of making sound financial decisions". [29]
The colony's most powerful executive was its Governor, who was originally elected by the freemen, but was later appointed by the General Court in an annual election. The General Court also elected seven "Assistants" to form a cabinet to assist the governor. The Governor and Assistants then appointed "Constables" who served as the chief administrators for the towns, and "Messengers" who were the main civil servants of the colony. They were responsible for publishing announcements, performing land surveys, carrying out executions, and a host of other duties. [89]
The General Court was both the chief legislative and judicial body of the colony. It was elected by the freemen from among their own number and met regularly in Plymouth, the capital town of the colony. As part of its judicial duties, it would periodically call a Grand Enquest, which was a grand jury of sorts, elected from the freemen, who would hear complaints and swear out indictments for credible accusations. The General Court, and later lesser town and county courts, would preside over trials of accused criminals and over civil matters, but the ultimate decisions were made by a jury of freemen. [89]
The General Court, as the legislative and judicial bodies, and the Governor, as the chief executive of the colony, constituted a political system of division of power . It followed a recommendation in John Calvin's political theory to set up several institutions which complement and control each other in a system of checks and balances in order to avoid, or at least to minimize, the misuse of political power. [118] In 1625, the settlers had repaid their debts and thus gained complete possession of the colony. [119] The colony was de facto a republic, since neither an English company nor the King and Parliament exerted any influence—a representative democracy governed on the principles of the Mayflower Compact ("self-rule").

Laws
As a legislative body, the General Court could make proclamations of law as needed. These laws were not formally compiled anywhere in the early years of the colony; they were first organized and published in the 1636 Book of Laws . The book was reissued in 1658, 1672, and 1685. [89] These laws included the levying of "rates" or taxes and the distribution of colony lands. [120] The General Court established townships as a means of providing local government over settlements, but reserved for itself the right to control specific distribution of land to individuals within those towns. When new land was granted to a freeman, it was directed that only the person to whom the land was granted was allowed to settle it. [121] It was forbidden for individual settlers to purchase land from Native Americans without formal permission from the General Court. [122] The government recognized the precarious peace that existed with the Wampanoag, and wished to avoid antagonizing them by buying up all of their land. [123]
The laws also set out crimes and their associated punishment. There were several crimes that carried the death penalty : treason , murder , witchcraft , arson , sodomy , rape , bestiality , adultery , and cursing or smiting one's parents. [124] The actual exercise of the death penalty was fairly rare; only one sex-related crime resulted in execution, a 1642 incidence of bestiality by Thomas Granger. [125] Edward Bumpus was sentenced to death for "striking and abusing his parents" in 1679, but his sentence was commuted to a severe whipping by reason of insanity. [126] Perhaps the most notable use of the death penalty was in the execution of the Native Americans convicted of the murder of John Sassamon; this helped lead to King Philip's War. [127] Though nominally a capital crime, adultery was usually dealt with by public humiliation only. Convicted adulterers were often forced to wear the letters "A.D." sewn into their garments, much in the manner of Hester Prynne in Nathaniel Hawthorne 's novel The Scarlet Letter . [128] [129] [130]
Several laws dealt with indentured servitude , a legal status whereby a person would work off debts or be given training in exchange for a period of unrecompensed service. The law required that all indentured servants had to be registered by the Governor or one of the Assistants, and that no period of indenture could be less than six months. Further laws forbade a master from shortening the length of time of service required for his servant, and also confirmed that any indentured servants whose period of service began in England would still be required to complete their service while in Plymouth. [131]

Official Seal
The seal of the Plymouth Colony was designed in 1629 and is still used by the town of Plymouth. It depicts four figures within a shield bearing St George's Cross , apparently in Native-American style clothing, each carrying the burning heart symbol of John Calvin . The seal was also used by the County of Plymouth until 1931. [132]

Geography

Boundaries
Without a clear land patent for the area, the settlers settled without a charter to form a government and, as a result, it was often unclear in the early years what land was under the colony's jurisdiction. In 1644, "The Old Colony Line"—which had been surveyed in 1639—was formally accepted as the boundary between Massachusetts Bay and Plymouth. [133]
The situation was more complicated along the border with Rhode Island. Roger Williams settled in the area of Rehoboth in 1636, near modern Pawtucket . He was forcibly evicted in order to maintain Plymouth's claim to the area. Williams moved to the west side of the Pawtucket River to found the settlement of Providence , the nucleus for the colony of Rhode Island, which was formally established with the "Providence Plantations Patent" of 1644. Various settlers from both Rhode Island and Plymouth began to settle along the area, and the exact nature of the western boundary of Plymouth became unclear. The issue was not fully resolved until the 1740s, long after the dissolution of Plymouth Colony itself. Rhode Island had received a patent for the area in 1693, which had been disputed by Massachusetts Bay Colony. Rhode Island successfully defended the patent, and a royal decree in 1746 transferred the land to Rhode Island along the eastern shore of the Narragansett Bay, including the mainland portion of Newport County and all of modern Bristol County , Rhode Island . [134] [135] The border itself continued to be contested by Massachusetts, first as a colony and later as a state , until as late as 1898, when the boundary was settled and ratified by both states.

Counties and towns
For most of its history, the town was the primary administrative unit and political division of the colony. Plymouth Colony was not formally divided into counties until June 2, 1685, during the reorganization that led to the formation of the Dominion of New England . Three counties were composed of the following towns. [136]
Barnstable County on Cape Cod: [137]
Bristol County along the shores of Buzzards Bay and Narragansett Bay ; part of this county was later ceded to Rhode Island: [145]
Plymouth County , located along the western shores of Cape Cod Bay : [152]

Demographics

English
The English in Plymouth Colony fit broadly into three categories: Pilgrims , Strangers , and Particulars . The Pilgrims were a Protestant group that closely followed the teachings of John Calvin , like the Puritans who later founded Massachusetts Bay Colony to the north. (The Puritans wished to reform the Anglican church from within, whereas the Pilgrims saw it as a morally defunct organization, and sought to remove themselves from it. [87] ) The name "Pilgrims" was actually not used by the separatists themselves. William Bradford used the term "pilgrims" to describe the group, but he was using the term generically to define the group as travelers on a religious mission. The Pilgrims referred to themselves as the Saints , First Comers , Ancient Brethren , or Ancient Men . [159] They used such terms to indicate their place as God's elect , as they subscribed to the Calvinist belief in predestination . [160] "The First Comers" was a term more loosely used in their day to refer to any of the Mayflower passengers. [159]
There were also a number of indentured servants among the colonists. Indentured servants were mostly poor children whose families were receiving church relief and "many homeless waifs from the streets of London sent as laborers". [161] [162]
In addition to the Pilgrims, the Mayflower carried non-Pilgrim settlers ("Strangers"). This group included the non-Pilgrim settlers placed on the Mayflower by the Merchant Adventurers, and later settlers who came for other reasons throughout the history of the colony and who did not necessarily adhere to the Pilgrim religious ideals. [163] [164] A third group known as the "Particulars" consisted of later settlers who paid their own "particular" way to America, and thus were not obliged to pay the colony's debts. [165]
The presence of outsiders such as the Strangers and the Particulars was a considerable annoyance to the Pilgrims. As early as 1623, a conflict broke out between the Pilgrims and the Strangers over the celebration of Christmas , a day of no particular significance to the Pilgrims. Furthermore, a group of Strangers founded the nearby settlement of Wessagussett and the Pilgrims were highly strained, both emotionally and in terms of resources, by their lack of discipline. They looked at the eventual failure of the Wessagussett settlement as Divine Providence against a sinful people. [166]
The residents of Plymouth used terms to distinguish between the earliest settlers of the colony and those that came later. The first generation of settlers, generally thought to be those that arrived before 1627, called themselves the Old Comers or Planters . Later generations of Plymouth residents referred to this group as the Forefathers . [167]
A fairly comprehensive demographic study was done by historian John Demos for his seminal 1970 work on the Pilgrims A Little Commonwealth . He reports that the colony's average household grew from 7.8 children per family for first-generation families to 8.6 children for second-generation families, and to 9.3 for third-generation families. Child mortality also decreased over this time, with 7.2 children born to first-generation families living until their 21st birthday. That number increased to 7.9 children by the third generation. [168] Life expectancy was higher for men than for women. Of the men who survived until the age of 21, the average life expectancy was 69.2 years. Over 55 percent of these men lived past 70; less than 15 percent died before the age of 50. For women, the numbers are much lower, owing to the difficulties inherent in childbearing. The average life expectancy of women at the age of 21 was only 62.4 years. Of these women, less than 45 percent lived past 70, and about 30 percent died before the age of 50. [168]
During King Philip's War , Plymouth Colony alone lost eight percent of its adult male population. By the end of the war, one-third of New England 's approximately 100 towns had been burned and abandoned. This represented a sizable demographic effect on the English population of New England. [77]

Native Americans
The Native Americans in New England were organized into loose tribal confederations, sometimes called "nations". Among these confederations were the Nipmucks , the Massachusett , the Narragansett , the Niantics , the Mohegan , and the Wampanoag . [67] Several significant events dramatically altered the demographics of the Native American population in the region. The first was "Standish's raid" on Wessagussett, which frightened Native American leaders to the extent that many abandoned their settlements, resulting in many deaths through starvation and disease. [58] The second, the Pequot War , resulted in the dissolution of the Pequot tribe and a major shift in the local power structure. [67] The third, King Philip's War , had the most dramatic effect on local populations, resulting in the death or displacement of as much as 80% of the total number of Native Americans of southern New England and the enslavement and removal of thousands of Native Americans to the Caribbean and other locales. [77]

Black slaves
Some of the wealthier families in Plymouth Colony owned black slaves which were considered the property of their owners, unlike indentured servants , and passed on to heirs like any other property. Slave ownership was not widespread and very few families possessed the wealth necessary to own slaves. In 1674, the inventory of Capt. Thomas Willet of Marshfield includes "8 Negroes" at a value of £200. Other inventories of the time also valued slaves at £24–25 each (equivalent to £2.81 thousand in 2010, or $4,300 at PPP ), well out of the financial ability of most families. A 1689 census of the town of Bristol shows that, of the 70 families that lived there, only one had a black slave. [169] So few were black slaves in the colony that the General Court never saw fit to pass any laws dealing with them. [131]

Economy
The largest source of wealth for Plymouth Colony was the fur trade . The disruption of this trade caused by Myles Standish's raid at Wessagussett created great hardship for the colonists for many years to come, and was directly cited by William Bradford as a contributing factor to the colonists' economic difficulties in their early years. [58] The colonists attempted to supplement their income by fishing ; the waters in Cape Cod bay were known to be excellent fisheries. However, they lacked any skill in this area, and it did little to relieve their economic hardship. [170] The colony traded throughout the region, establishing trading posts as far away as Penobscot, Maine . They were also frequent trading partners with the Dutch at New Amsterdam . [171]
The economic situation improved with the arrival of cattle in the colony. It is unknown when the first cattle arrived, but the division of land for the grazing of cattle in 1627 represented one of the first moves towards private land ownership in the colony. [172] Cattle became an important source of wealth in the colony; the average cow could sell for £28 in 1638 (£3,400 in 2010, or $5,200 at PPP ). However, the flood of immigrants during the Great Migration drove the price of cattle down. The same cows sold at £28 in 1638 were valued in 1640 at only £5 (£700.00 in 2010, or $1,060 at PPP ). [173] Besides cattle, there were also pigs, sheep, and goats raised in the colony. [31]
Agriculture also made up an important part of the Plymouth economy. The colonists adopted Native American agricultural practices and crops. They planted maize , squash , pumpkins , beans , and potatoes . Besides the crops themselves, the Pilgrims learned productive farming techniques from the Native Americans, such as proper crop rotation and the use of dead fish to fertilize the soil. In addition to these native crops, the colonists also successfully planted Old World crops such as turnips , carrots , peas , wheat , barley , and oats . [174]
Overall, there was very little cash in Plymouth Colony, so most wealth was accumulated in the form of possessions. Trade goods such as furs, fish, and livestock were subject to fluctuations in price and were unreliable repositories of wealth. Durable goods such as fine wares, clothes, and furnishings represented an important source of economic stability for the residents. [175]

Legacy
The events surrounding the founding and history of Plymouth Colony have had a lasting effect on the art, traditions, mythology, and politics of the United States of America, despite its short history of fewer than 72 years.

Art, literature, and film
The earliest artistic depiction of the Pilgrims was actually done before their arrival in America; Dutch painter Adam Willaerts painted a portrait of their departure from Delfshaven in 1620. [176] The same scene was repainted by Robert Walter Weir in 1844, and hangs in the Rotunda of the United States Capitol building. Numerous other paintings have been created memorializing various scenes from the life of Plymouth Colony, including their landing and the "First Thanksgiving", many of which have been collected by Pilgrim Hall , a museum and historical society founded in 1824 to preserve the history of the Colony. [177]
Several contemporaneous accounts of life in Plymouth Colony have become both vital primary historical documents and literary classics. Of Plimoth Plantation by William Bradford and Mourt's Relation by Bradford, Edward Winslow, and others are both accounts written by Mayflower passengers that provide much of the information which we have today regarding the trans-Atlantic voyage and early years of the settlement.
Benjamin Church wrote several accounts of King Philip's War, including Entertaining Passages Relating to Philip's War , which remained popular throughout the 18th century. An edition of the work was illustrated by Paul Revere in 1772. The Sovereignty and Goodness of God provides an account of King Philip's War from the perspective of Mary Rowlandson , an Englishwoman who was captured and spent some time in the company of Native Americans during the war. [178] Later works, such as " The Courtship of Miles Standish " by Henry Wadsworth Longfellow , have provided a romantic and partially fictionalized account of life in Plymouth Colony. [179]
There are also numerous films about the Pilgrims, including the several film adaptations of " The Courtship of Miles Standish "; [180] the 1952 film Plymouth Adventure starring Spencer Tracy ; [181] and Desperate Crossings: The True Story of the Mayflower , a 2006 television documentary produced by the History Channel . [182]
In 1970, the United States Postal Service issued a three hundred and fiftieth year commemorative stamp recognizing the English dissenters first landing at the modern day settlement of Provincetown, Massachusetts in 1620.

Thanksgiving
Each year, the United States celebrates a holiday known as Thanksgiving on the fourth Thursday of November. It is a federal holiday [183] and frequently involves a family gathering with a large feast, traditionally featuring a turkey . Civic recognitions of the holiday typically include parades and football games. The holiday is meant to honor the First Thanksgiving, which was a harvest feast held in Plymouth in 1621, as first recorded in the book New England's Memorial by Nathaniel Morton , secretary of Plymouth Colony and nephew of Governor William Bradford.
The annual Thanksgiving holiday is a fairly recent creation. Throughout the early 19th century, the U.S. government had declared a particular day as a national day of Thanksgiving, but these were one-time declarations meant to celebrate a significant event, such as victory in a battle. The northeastern states began adopting an annual day of Thanksgiving in November shortly after the end of the War of 1812 . Sarah Josepha Hale , editor of Boston's Ladies' Magazine , wrote editorials beginning in 1827 which called for the nationwide expansion of this annual day of thanksgiving to commemorate the Pilgrim's first harvest feast. After nearly 40 years, Abraham Lincoln declared the first modern Thanksgiving to fall on the last Thursday in November in 1863. Franklin Delano Roosevelt and Congress ultimately moved it to the fourth Thursday in November. After some sparring as to the date, the holiday was recognized by Congress as an official federal holiday in 1941. [184] [185]
Some of the modern traditions which have developed alongside the Thanksgiving holiday are the National Football League 's Thanksgiving Day games and the annual Macy's Thanksgiving Day Parade in New York City .

Plymouth Rock
One of the enduring symbols of the landing of the Pilgrims is Plymouth Rock, a large granodiorite boulder that was near their landing site at Plymouth. However, none of the contemporary accounts of the actual landing makes any mention that the Rock was the specific place of landing. The Pilgrims chose the site for their landing, not for the rock, but for a small brook nearby that was a source of fresh water and fish. [186]
The first identification of Plymouth Rock as the actual landing site was in 1741 by 90-year-old Thomas Faunce, whose father had arrived in Plymouth in 1623, three years after the supposed event. The rock was later covered by a solid-fill pier. In 1774, an attempt was made to excavate the rock, but it broke in two. The severed piece was placed in the Town Square at the center of Plymouth. In 1880, the intact half of the rock was excavated from the pier, and the broken piece was reattached to it. Over the years, souvenir hunters have removed chunks from the rock, but the remains are now protected as part of the complex of living museums . These include the Mayflower II , a recreation of the original ship; Plimoth Plantation , a historical recreation of the original 1620 settlement; and the Wampanoag Homesite, which recreates a 17th-century Indian village. [187]

Political legacy
The democratic setup of Plymouth Colony had strong influences on the shaping of democracy in both England and America. William Bradford's History of Plimoth Plantation was widely read in the motherland. It influenced the political thought of Presbyterian politician and poet John Milton , assistant to Oliver Cromwell , and philosopher John Locke . For example, Locke referred to the Mayflower Compact in his Letters Concerning Toleration . [188] In America, Plymouth Colony initiated a democratic tradition that was soon followed by Massachusetts Bay Colony (1628), Connecticut (1636), Rhode Island (1636), New Jersey , and Pennsylvania (1681). In the latter four colonies, founded by Thomas Hooker , Roger Williams , and William Penn , respectively, religious freedom was added to democratic constitutions. These territories became safe havens for persecuted religious minorities. [189] There were strong links between 17th-century Puritanism and the political ideas of the 18th century. On the one hand, there was the congregational democracy practiced now by all Protestant churches, including to a large extent the Anglicans. On the other hand, most of the political concepts of the generation that carried out the Revolution were taken over from the radical Whig party in England ( Commonwealthmen ), which fed on the liberal political theories of Milton, Locke, and other writers. As children the Revolutionaries had experienced the Great Awakening (c. 1740). In the words of historian Robert Middlekauff : "The Awakening recalled a generation to the standards of reformed Protestantism, which had prevailed at the time of the founding of America. [...] Radical Whig perceptions of politics attracted widespread support in America because they revived the traditional concerns of a Protestant culture that had always verged on Puritanism. That moral decay threatened free government could not come as a surprise to a people whose fathers had fled England to escape sin. The importance of virtue, frugality, industry, and calling was at the heart of their moral code. [...] Radical Whiggery of the eighteenth century convinced Americans because it had been pervasive in their culture since the seventeenth." [190]

The Mayflower Society
The General Society of Mayflower Descendants, or The Mayflower Society, is a genealogical organization of individuals who have documented their descents from one or more of the 102 passengers who arrived on the Mayflower in 1620. The Society, founded at Plymouth in 1897, claims that tens of millions of Americans descend from these passengers, and it offers research services to people seeking to document such descents. [191]

See also

Locations related to Plymouth Colony

Monuments and other commemorations

Notes
WebPage index: 00013
Little ships of Dunkirk
The little ships of Dunkirk were 700 private boats that sailed from Ramsgate in England to Dunkirk in France between 26 May and 4 June 1940 as part of Operation Dynamo , helping to rescue more than 338,000 British and French soldiers who were trapped on the beaches at Dunkirk during the Second World War .

Overview
The situation of the troops, who had been cut off from their retreat into France by a pincer movement from the German army, was regarded by the British prime minister Winston Churchill as the greatest military defeat for centuries; it appeared likely to cost Britain the war, leaving the country vulnerable to invasion by Germany . [1] [2] [3] Because of the shallow waters, British destroyers were unable to approach the beaches, and soldiers were having to wade out to the warships, many of them waiting hours shoulder deep in water.
On 27 May, the small-craft section of the British Ministry of Shipping telephoned boat builders around the coast, asking them to collect all boats with "shallow draft " that could navigate the shallow waters. Attention was directed to the pleasure boats, private yachts and launches moored on the River Thames and along the south and east coasts. Some of them were taken with the owners' permission – and with the owners insisting they would sail them – while others were requisitioned by the government with no time for the owners to be contacted. The boats were checked to make sure they were seaworthy, fueled, and taken to Ramsgate to set sail for Dunkirk. They were manned by Naval Officers, Ratings and experienced volunteers. Very few owners manned their own vessels, apart from fishermen and one or two others. [2]
When they reached France, some of the boats acted as shuttles between the beaches and the destroyers, ferrying soldiers to the warships. Others carried hundreds of soldiers each back to Ramsgate, protected by the Royal Air Force from the attacks of the Luftwaffe .

Notable boats

RNLI lifeboats at Dunkirk
See also individual stations for more information in many cases.

Isle of Man Steam Packet Company
At the outbreak of war, 10 of the 16 vessels in the fleet of the Isle of Man Steam Packet Company were requisitioned. Four were lost.
Eight of the company's ships took part in the Dunkirk evacuation. Mona’s Isle was the first to leave Dover, and the first vessel to complete a round trip. By the end of operations, the fleet had rescued a total of 24,699, 1 in 14 of those evacuated from Dunkirk. [28]
Whilst the evacuation is widely regarded as the Isle of Man Steam Packet Company's "finest hour" , it also saw its blackest day. Three of its ships were lost in one day, 29 May 1940.

Dutch coasters
Thirty-nine Dutch coasters had escaped the occupation of the Netherlands by the Germans on 10 May 1940 and were asked by the Dutch shipping bureau in London or by the Royal Navy to assist. The Dutch coasters, able to approach the beaches very closely due to their flat bottoms, rescued 22,698 men in total.
The MV Rian , a 35 metres (115 ft) ship measuring 300 ton dwt and built in 1934 in the province of Groningen , saved 2,542 men between 28 and 31 May 1940 under Captain D. Buining, the most men saved amongst the Dutch coasters. The vessel had already saved the crew of the British coaster SS Highwave on 30 January 1940. Other Dutch coasters that saved more than 1,000 men each were:
Of these ships, seven were lost at Dunkirk or during the evacuation nearer the British coast. [29]

Belgian ships
The Belgian Army, commanded by King Leopold III , had surrendered to the Germans on 28 May. However, numerous ships from the fishing fleet and small Corps de Marine were involved in Operation Dynamo. In total, 65 Belgian ships participated, including 54 fishing boats, 4 Corps de Marine units, 4 tugs and 2 patrol vessels. [30] The Belgian fishing fleet itself transported 4,300 British and French soldiers to the English coast. [31]
Among the notable Belgian ships to participate in the evacuation were:

Results
In nine days, 192,226 British and 139,000 French soldiers – 331,226 in all – were rescued by the 700 little ships and around 220 warships. The rescue operation turned a military disaster into a story of heroism which served to raise the morale of the British.
It was in describing the success of the operation to the House of Commons on 4 June 1940 that Churchill made one of his most famous speeches:

Legacy
The phrase "Dunkirk spirit" is still used to describe courage and solidarity in adversity. [33]
The Association of Dunkirk Little Ships is an association for owners of Dunkirk Little Ships, founded in 1965. [34] The Association organizes a memorial crossing of Little Ships to Dunkirk every five years, escorted by the Royal Navy. Its flag is the St George's Cross defaced with the arms of Dunkirk flown from the jack staff , known [ by whom? ] as the Dunkirk jack . [35]
The Dunkirk Little Ships Restoration Trust is a registered charity [36] established in 1993 to preserve and restore Dunkirk Little Ships. Its collection includes the steam tug ST Challenge , [37] a vessel in the National Historic Fleet . [38]

See also

Notes

Further reading

External links

Ships
WebPage index: 00014
Lauda Air Flight 004
Lauda Air Flight 004 was a regularly-scheduled international passenger flight between Bangkok and Vienna. On 26 May 1991 a Boeing 767-300ER operating the flight crashed due to an uncommanded deployment of the thrust reverser on the No.1 engine in mid-flight, killing all 213 passengers and the 10 crew members on board. To date, it remains the deadliest aviation accident involving a Boeing 767 and the deadliest aviation accident in Thailand . The crash also marked the aircraft type's first fatal incident and first hull loss . [1] Lauda Air was founded and run by the former Formula One world motor racing champion Niki Lauda . Lauda was personally involved in the accident investigation.

Aircraft
The aircraft involved was a Boeing 767-300ER which had been delivered new to Lauda Air on 16 October 1989 and was only ever operated by them. [2] It wore the manufacturing number MSN 24628 , was registered as OE-LAV and was christened Mozart .

History of the flight
At the time of the accident, Lauda Air operated three weekly flights between Bangkok and Vienna. [1] On 26 May 1991, at 23:02 local time, flight NG004 (originating from Hong Kong's Kai Tak Airport ), a Boeing 767-3Z9ER , took off from Old Bangkok International Airport ( Don Mueang International Airport ) for its flight to Vienna International Airport with 213 passengers and 10 crew, under the command of Captain Thomas J. Welch of the United States and First Officer Josef Thurner of Austria.
At 23:08, Welch and Thurner received a visual warning indicating that a possible system failure would cause the thrust reverser on the number one engine to deploy in flight. Having consulted the aircraft's quick reference handbook, they determined that it was "just an advisory thing" and took no action. [3]
At 23:17, the thrust reverser on the number one engine deployed while the plane was over mountainous jungle terrain in the border area between Suphanburi and Uthai Thani provinces in Thailand. Thurner's last recorded words were, "Oh, reverser's deployed." [4] [5] The lift on the aircraft's left side was disrupted due to the reverser deployment, and the aircraft was placed in an immediate diving left turn. The aircraft went into a diving speed of Mach 0.99, and may have broken the sound barrier. The aircraft broke up in mid-air on the way down at 4,000 feet (1,200 meters). [6] Most of the wreckage was scattered over a remote forest area roughly 1 km 2 in size, at an elevation of 600 m above sea level, in what is now Phu Toei National Park , Suphanburi. The wreckage site is about 6 kilometres (3 nmi) north northeast of Phu Toey , Huay Kamin , Dan Chang District , Suphan Buri Province , [7] about 160 kilometres (100 mi) northwest of Bangkok , close to the Burma-Thailand border. [1] [8]
None of the 223 passengers and crew aboard the airliner survived. Rescuers found Welch's body still in the pilot's seat. [9]

Recovery
Volunteer rescue teams and local villagers looted the wreckage, taking electronics and jewellery, [10] so relatives were unable to recover personal possessions. The bodies were taken to a hospital in Bangkok. The storage was not refrigerated and the bodies decomposed. Dental and forensic experts worked to identify bodies. Twenty-seven bodies were never identified. [11]

Speculation
Speculation that a bomb may have destroyed the aircraft circulated. The Philadelphia Inquirer , citing wire services it did not identify, stated that, "the search for a motive is difficult because politically neutral Austria has generally stayed out of most international conflicts – such as the Persian Gulf war – that have made other countries' airlines the targets of terrorist attacks." [12] According to a security officer working at an embassy of a Western country a Lauda Air employee stationed in Bangkok had threatened to use a bomb to destroy a Lauda aircraft unless he was given money. Lauda Air fired the employee but he was later hired by Thai Airways International , which handled luggage loading and uploading for Lauda Air in Bangkok. Niki Lauda , owner of the airline, said that the airline never received a threat. [12]

Investigation
The flight data recorder was damaged to the point of being unreadable, so only the cockpit voice recorder was of use. Pradit Hoprasatsuk, the head of the Air Safety Division of the Thailand Department of Aviation , stated, "the attempt to determine why the reverser came on was hampered by the loss of the flight data recorder, which was destroyed in the crash". [13] Upon hearing of the crash, Niki Lauda traveled to Thailand. He examined the wreckage and estimated that the largest fragment was about 5 metres (16 ft) by 2 metres (6.6 ft), which was about half the size of the largest piece in the Lockerbie crash . [14] In Thailand, Lauda attended a funeral for 23 unidentified passengers, and then traveled to Seattle to meet with Boeing representatives.
The official investigation could not determine the cause of the thrust reverser deployment. Different possibilities were investigated, including a short circuit in the system. However, partly due to the destruction of much of the wiring, no definitive reason for the activation of the thrust reverser could be found. [7]
As evidence started to point towards the thrust reversers as the cause of the accident, simulator flights were made at Gatwick Airport which appeared to show that deployment of a thrust reverser was a survivable incident. Lauda said that the thrust reverser could not be the sole cause of the crash. [15] The accident report states that the "flightcrew training simulators yielded erroneous results" [16] and stated that recovery from the loss of lift from the reverser deployment "was uncontrollable for an unexpecting flight crew". [17] The incident led Boeing to modify the thrust reverser system to prevent similar occurrences by adding sync-locks, which prevent the thrust reversers from deploying when the main landing gear truck tilt angle is not at the ground position. [7] [18]
The aviation writer Macarthur Job has said that "had that Boeing 767 been of an earlier version of the type, fitted with engines that were controlled mechanically rather than electronically, then that accident could not have happened". [4]
The investigation took about eight months. [19]

Niki Lauda's visit with Boeing
Lauda said, "what really annoyed me was Boeing's reaction once the cause was clear. Boeing did not want to say anything." [19] Lauda asked Boeing to fly the scenario in a simulator. Boeing initially refused, but Lauda insisted. Lauda attempted the flight in the simulator 15 times, and in every instance he was unable to recover. He asked Boeing to issue a statement, but the legal department said it could not be issued because it would take three months to adjust the wording. Lauda asked for a press conference the following day, and told Boeing that if it was possible to recover, he would be willing to fly on a 767 with two pilots and have the thrust reverser deploy in air. Boeing told Lauda that it was not possible, so he asked Boeing to issue a statement saying that it would not be survivable, and Boeing issued the statement. Lauda said, "this was the first time in eight months that it had been made clear that the manufacturer was at fault and not the operator of the aeroplane." [19]

Previous testing of thrust reversers
When the Federal Aviation Administration (FAA) of the United States asked Boeing to do tests activating the thrust reverser in flight, [20] the FAA had allowed Boeing to establish the tests of the thrust reverser. Boeing had insisted that a deployment was not possible in flight. In 1982 Boeing established a test where the aircraft was slowed to 250 knots, and the test pilots then used the thrust reverser. The control of the aircraft had not been jeopardized. The FAA accepted the results of the test. [21]
The Lauda aircraft was traveling at a high speed when the thrust reversers deployed, causing the pilots to lose control of the aircraft. James R. Chiles, author of Inviting Disaster , said, "the point here is not that a thorough test would have told the pilots Thomas J. Welch and Josef Thumer [ sic ] what to do. A thrust reverser deploying in flight might not have been survivable, anyway. But a thorough test would have informed the FAA and Boeing that thrust reversers deploying in midair was such a dangerous occurrence that Boeing needed to install a positive lock that would prevent such an event." As a result of their findings during the investigation process of Lauda Flight 004, additional safety features such as mechanical positive locks were mandated to prevent thrust reverser deployment in flight. [22]

Passengers and crew
The passengers and crew included 83 Austrians: [23] 74 Austrian passengers and nine Austrian crew members. [24] 52 Hong Kong residents were on board the aircraft. [24] [25] Other nationalities included Thais (39), Italians (10), Swiss (7), Chinese (6), Germans (4), Portuguese (3), Taiwanese (3), Yugoslavs (3), Hungarians (2), Filipinos (2), Britons (2), Americans (2), Australian (1), Brazilian (1), Polish (1), and Turkish (1). [24] In addition, an American was the aircraft's pilot. [26]
Of the passengers, 125 had boarded in Hong Kong, while the rest boarded in Bangkok. [23] Of the passengers who boarded in Bangkok, there were 38 Thais, 34 Austrians, seven Swiss, four Germans, two Yugoslavs, one Australian, one Briton, and one Hungarian. [1] Of the passengers who boarded in Hong Kong, most were either Austrian or Chinese. [8]
Of the passengers, 10 were from South Tyrol in Italy. Six of them were students of the University of Innsbruck School of Economics, and they originated from Val Gardena (Gröden), Kiens (Chienes), Klausen (Chiusa), Mals (Malles Venosta), and Olang (Valdaora). The other four were from Bolzano (Bozen), including two public officers, a musician, and his daughter. The musician was traveling with his Chinese wife. [27]

Notable victims
Josef Thurner, the copilot, once flew as a copilot with Niki Lauda on a Lauda Boeing 767 service to Bangkok, a flight that was the subject of a Reader's Digest article in January 1990 that depicted the airline positively. Macarthur Job said that, as a result, Thurner was the better known of the crew members. [33] Thomas J. Welch, the pilot, lived in Vienna , [24] but originated from Seattle , Washington. [26]

Aftermath
About one quarter of the airline's carrying capacity was destroyed as a result of the crash. [34] Following the crash of OE-LAV, the airline had no flights to Sydney, on 1, 6, and 7 June. Flights resumed with another 767 on 13 June. [35] Niki Lauda said that the crash in 1991 and the period after was the worst time in his life. [19]
In early August 1991, Boeing issued an alert to airlines stating that over 1,600 late model 737s, 757s, 767s, and 747s had thrust-reverser systems common to that of the OE-LAV. On Monday, 9 September 1991, the Boeing Commercial Airplane Group asked its customers to replace a valve in the thrust reverser systems that could cause the thrust reverser to deploy in flight. [36]
After the crash, bookings from Hong Kong decreased by 20% but additional passengers from Vienna began booking flights, so there were no significant changes in overall bookings. [25]
Fourteen months before 25 May 1993, Boeing and Lauda Air came to a joint settlement with most of the families of the deceased victims, but by 25 May 1993, 20 families that had children as claimants had not yet received settlement money. The law firm Sinclair Roche represented almost all of the relatives of the Hong Kong residents who died in the crash.
At the crash site, which is accessible to national park visitors, a shrine was later erected to commemorate the victims. [37] Another memorial and cemetery is located at Wat Sa Kaeo Srisanpetch – GPS location: 14.492145, 100.001884, some 90 km away in Amphoe Mueang Suphanburi . [38]

In popular culture

Maps

See also

Notes
WebPage index: 00015
May 25
May 25 is the 145th day of the year (146th in leap years ) in the Gregorian calendar . There are 220 days remaining until the end of the year. This date is slightly more likely to fall on a Monday, Wednesday or Friday (58 in 400 years each) than on Saturday or Sunday (57), and slightly less likely to occur on a Tuesday or Thursday (56).

Events

Births

Deaths

Holidays and observances

External links
WebPage index: 00016
Alternative Songs
Alternative Songs (also called Alternative and formerly known as Modern Rock Tracks and Hot Modern Rock Tracks ) is a music chart in the United States that has appeared in Billboard magazine since September 10, 1988. It lists the 40 most-played songs on modern rock radio stations, most of which are alternative rock songs. The chart was introduced as a companion to the Mainstream Rock Tracks chart and its creation was prompted by the explosion of alternative music on American radio in the late 1980s.
The chart is based solely on radio airplay. As of 2012, approximately 80 radio stations are electronically monitored 24 hours a day, seven days a week by Nielsen Broadcast Data Systems . [1] Songs are ranked by a calculation of the total number of spins per week with its "audience impression", which is based upon exact times of airplay and each station's Arbitron listener data. The chart had 30 positions when it was introduced in September 1988, and was expanded to 40 positions on September 10, 1994. [2]
Many rock artists do not release commercial singles in the United States. Several popular songs which were not released as commercial singles did not qualify for the Hot 100 before December 1998, but performed very well on the Modern Rock Tracks chart.
During the first several years of the chart, it regularly featured music that did not receive commercial radio airplay anywhere but on a few modern rock radio stations. This included many electronic and post-punk artists. Gradually, as alternative rock became more "mainstream" (particularly spearheaded by the grunge explosion in the early 1990s), the Modern Rock Tracks and Mainstream Rock Tracks charts began featuring more of the same songs. Today, the Alternative chart favors more alternative rock, indie rock , and punk rock bands while the Mainstream Rock chart favors more hard rock , post-grunge and heavy metal .
The chart was renamed Alternative Songs beginning with the June 20, 2009 issue after Billboard fully absorbed Radio & Records , whose similar chart was called "Alternative" instead of "Modern Rock". [3]
The first number-one song on the Modern Rock Tracks chart was " Peek-a-Boo " by Siouxsie and the Banshees . The current number-one song, for the issue dated June 3, 2017, is " Believer " by Imagine Dragons . The Red Hot Chili Peppers hold the record for most number-one songs at thirteen, a record they have held since 2016.

Chart achievements

See also
WebPage index: 00017
Peek-a-Boo (song)
" Peek-a-Boo " is a song by English alternative rock band Siouxsie and the Banshees . It was released in 1988 as the first single from the band's ninth studio album, Peepshow . Melody Maker described the song as "a brightly unexpected mixture of black steel and pop disturbance" and qualified its genre as "thirties hip hop ". [1] "Peek-a-Boo" was rated "Single of the Week" in both Sounds and NME . Sounds wrote that it was a "brave move", "playful and mysterious". [2] NME described it as "Oriental marching band hip hop" with "catchy accordion." They then said : "If this nation was served by anything approaching a decent pop radio station, "Peek A Boo" would be a huge hit." [3]
PopMatters retrospectively placed it at number 18 on their list "The 100 Greatest Alternative Singles of the '80s", saying that its instrumentation was "inventive" with "ingenious vocal phasing". [4]
Bloc Party praised "Peek-a-Boo" and their singer Kele Okereke said: "It sounded like nothing else on this planet. This is just a pop song that they put out in the middle of their career that nobody knows about, but to me it sounded like the most current but most futuristic bit of guitar-pop music I've heard." [5]

History
The song's peculiar sound is due to its experimental recording which was based on a sample . The song was built on a loop in reverse of a brass part with drums which the group previously arranged a year before for a cover of John Cale 's "Gun". [6] The band selected different parts of that tape when played backwards, editing them and re-recording on top of it, adding a different melody plus accordion , a one-note bass and discordant guitar. Drummer Budgie also added another beat. Once the instrumental parts were finished, Siouxsie sang her lyrics over it. The lyric track was further manipulated by Siouxsie's use of a different microphone for each line of the song. [6] It took the band a year to arrive at this result. When initially composed to be an extra track for 1987's "The Passenger" single, the band realized that the song was too good to be relegated to B-side status and deserved better exposure.
"Peek-a-Boo" was one of Siouxsie and the Banshees' most recognisable and popular singles; it was also the group's first to chart in the U.S. Billboard Hot 100 , [7] reaching the No. 53 in the week of 3 December. [8] The song was very popular on alternative rock radios and received heavy play on MTV . In September 1988, Billboard magazine premiered a new Modern Rock Tracks chart, which measured radio airplay on USA modern rock stations; "Peek-a-Boo" was the chart's first No. 1 song. [9] In the UK, "Peek-a-Boo" became their fifth Top 20 UK hit, peaking at number 16 in the Singles chart . [10]
A minor controversy ensued after the single's release, as the lines to the chorus ("...Golly jeepers/Where'd you get those weepers?/Peepshow, creepshow/Where did you get those eyes?...") were found to be too similar to the lyrics in the 1938 song " Jeepers Creepers ". To remedy the situation and to avoid legal action, the band gave co-songwriting credit on "Peek-a-Boo" to Harry Warren and Johnny Mercer .

In the media
The music video was chosen by The Chart Show to be their "Best Video of the Year" for 1988. On the Beavis & Butt-head episode "Sperm Bank," Beavis noted while watching the video that "this is music for people who don't have any friends". [11] "Peek-a-Boo" was covered in 2010 by Australian artist Bertie Blackman . The song was made available as downloadable content for the Rock Band platform on 20 April 2010. The band Echo 3's cover of the song was included in the 2001 horror movie Jeepers Creepers .

Charts

See also
WebPage index: 00018
New wave music
New wave is a genre of rock music [2] popular from the late 1970s to the mid-1980s with ties to 1970s punk rock . [18] New wave moved away from smooth blues and rock and roll sounds to create pop music that incorporated electronic and experimental music , mod and disco . Initially new wave was similar to punk rock, before becoming a distinct genre . It subsequently engendered subgenres and fusions, including synth-pop , [15] college rock and gothic rock . [ not verified in body ]
New wave differs from other movements with ties to first-wave punk as it displays characteristics common to pop music, rather than the more "artsy" post-punk, [19] though it incorporates much of the original punk rock sound and ethos, [5] [20] while exhibiting greater complexity in both music and lyrics. Common characteristics of new wave music include the use of synthesizers and electronic productions, the importance of styling and the arts, as well as diversity. [19]
New wave has been called one of the definitive genres of the 1980s, [21] after it grew partially fixated on MTV ( the Buggles ' " Video Killed the Radio Star " music video was broadcast as the first music video to promote the channel's launch), [19] and the popularity of several new wave artists, attributed to their exposure on the channel. In the mid-1980s, differences between new wave and other music genres began to blur. [22] [19] New wave has enjoyed resurgences since the 1990s, after a rising "nostalgia" for several new wave-influenced artists. Subsequently, the genre influenced other genres. [23] [24] [25] [26] [27] [28] [29] [ excessive citations ] [ improper synthesis? ] During the 2000s, a number of acts, such as the Strokes , Interpol , Franz Ferdinand and The Killers explored new wave and post-punk influences. These acts were sometimes labeled " new wave of new wave ".

Etymology and usage
The catch-all nature of new wave music has been a source of much confusion and controversy. The 1985 discography Who's New Wave in Music listed artists in over 130 separate categories. [30] The New Rolling Stone Encyclopedia of Rock calls the term "virtually meaningless", [30] while AllMusic mentions "stylistic diversity". [31]
New wave first emerged as a rock genre in the early 1970s, used by critics including Nick Kent and Dave Marsh to classify such New York-based groups as the Velvet Underground and New York Dolls . [32] It gained currency beginning in 1976 when it appeared in UK punk fanzines such as Sniffin' Glue and newsagent music weeklies such as Melody Maker and New Musical Express . [33] In November 1976 Caroline Coon used Malcolm McLaren 's term "new wave" to designate music by bands not exactly punk , but related to the same musical scene. [34] The term was also used in that sense by music journalist Charles Shaar Murray in his comments about the Boomtown Rats . [35] For a period of time in 1976 and 1977, the terms new wave and punk were somewhat interchangeable. [22] [36] By the end of 1977, "new wave" had replaced "punk" as the definition for new underground music in the UK. [33]
In the United States, Sire Records chairman Seymour Stein , believing that the term "punk" would mean poor sales for Sire's acts who had frequently played the club CBGB , launched a "Don't Call It Punk" campaign designed to replace the term with "new wave". [38] As radio consultants in the United States had advised their clients that punk rock was a fad, they settled on the term "new wave". Like the filmmakers of the French new wave movement (after whom the genre was named), its new artists were anti-corporate and experimental (e.g. Ramones and Talking Heads ). At first, most U.S. writers exclusively used the term "new wave" for British punk acts. [39] Starting in December 1976, The New York Rocker , which was suspicious of the term "punk", became the first American journal enthusiastically used the term starting with British acts, later appropriating it to acts associated with the CBGB scene. [33] Part of what attracted Stein and others to new wave was the music’s stripped back style and upbeat tempos, which they viewed as a much needed return to the energetic rush of rock and roll and 1960s rock that had dwindled in the 1970s with the ascendance of overblown progressive rock and stadium spectacles. [40]
Music historian Vernon Joynson claimed that new wave emerged in the UK in late 1976, when many bands began disassociating themselves from punk. [3] Music that followed the anarchic garage band ethos of the Sex Pistols was distinguished as "punk", while music that tended toward experimentation, lyrical complexity or more polished production, came to be categorized as "new wave". In the U.S., the first new wavers were the not-so-punk acts associated with the New York club CBGB (e.g. Talking Heads , Mink DeVille and Blondie ). [23]
CBGB owner Hilly Kristal , referring to the first show of the band Television at his club in March 1974, said, "I think of that as the beginning of new wave." [41] Furthermore, many artists who would have originally been classified as punk were also termed new wave. A 1977 Phonogram Records compilation album of the same name ( New Wave ) features US artists including the Dead Boys , Ramones , Talking Heads and the Runaways . [23] [42]

US/UK differences
New wave is much more closely tied to punk and came and went more quickly in the United Kingdom than in the United States. At the time punk began, it was a major phenomenon in the United Kingdom and a minor one in the United States. Thus when new wave acts started getting noticed in America, punk meant little to the mainstream audience [43] and it was common for rock clubs and discos to play British dance mixes and videos between live sets by American guitar acts. [44]
Post-punk music developments in the UK became mainstream and were considered unique cultural events. [43] By the early 1980s, British journalists largely had abandoned the term "new wave" in favor of subgenre terms such as "synthpop". [45] By 1983, the term of choice for the US music industry had become " new music ", while to the majority of US fans it was still a "new wave" reacting to album-based rock . [46]

Synonym of synthpop
New wave proper ended in the mid-1980s, knocked out by guitar-driven rock reacting against new wave. [48] For most of the remainder of the 1980s the term "new wave" was widely applied to nearly every new pop, dance pop or pop rock artist that predominantly used synthesizers. [ citation needed ]
In the 21st century United States, "new wave" was used to describe artists such as Morrissey , Duran Duran , Cyndi Lauper and Devo . [49] Late 1970s new wave acts such as the Pretenders and the Cars were more likely to be found on classic rock playlists than on new wave playlists there. [10] [50] [51] Reflecting its British origins, the 2004 study Popular Music Genres: An Introduction had one paragraph dedicated to 1970s new wave artists in its punk chapter in contrast to a 20-page chapter on early 1980s synthpop . [45] [52]

Related styles and subgenres
New wave represented a break from the blues and rock & roll sounds of late 1960s to mid-1970s rock music. According to Simon Reynolds , the music had a twitchy, agitated feel to it. New wave musicians often played choppy rhythm guitars with fast tempos. Keyboards were common as were stop-start song structures and melodies. Reynolds noted that new wave vocalists sounded high-pitched, geeky and suburban. [20] A nervous, nerdy persona was a common characteristic of new wave fans and acts such as Talking Heads, Devo and Elvis Costello . This took the forms of robotic dancing, jittery high-pitched vocals and clothing fashions such as suits and big glasses that hid the body. [53]
This seemed radical to audiences accustomed to post-counterculture forms such as disco dancing and macho " cock rock " that emphasized a "hang loose" philosophy, open sexuality and sexual bravado. [54] The majority of American male new wave acts of the late 1970s were from Caucasian middle-class backgrounds, and Theo Cateforis of Syracuse University theorized that these acts intentionally presented these exaggerated nerdy tendencies associated with their "whiteness" either to criticize it and/or to reflect their identity. [54]
The British pub rock scene of the mid-1970s was the source of new wave acts such as Ian Dury , Nick Lowe , Eddie and the Hot Rods and Dr. Feelgood . [11]
Singer-songwriters who were "angry" and "intelligent" and who "approached pop music with the sardonic attitude and tense, aggressive energy of punk" such as Elvis Costello, Joe Jackson and Graham Parker were also part of the new wave music scene. [55]
A British revival of ska music on the 2 Tone label, led by the Specials , Madness , the English Beat , and Selecter were more politically oriented than other new wave genres. [56]
The idea of rock music as a serious art form started in the late 1960s and was the dominant view of the genre at the time of new wave's arrival. New wave looked back or borrowed in various ways from the years just prior to this occurrence. One way this was done was by taking an ironic look at consumer and pop culture of the 1950s and early 1960s. The B-52's became most noted for a kitsch and camp presentation with their bouffant wigs, beach party and sci-fi movie references. Other groups that referenced the pre- progressive rock era were the Go-Go's , Blondie and Devo. [57] [58]
In the early 1980s, new wave acts embraced a crossover of rock music with African and African-American styles. Adam and the Ants and Bow Wow Wow , both acts with ties to former Sex Pistols manager Malcolm McLaren , used Burundi -style drumming. [59] The Talking Heads album Remain in Light was marketed and positivity reviewed as a breakthrough melding of new wave and African styles, although drummer Chris Frantz said that he found out about this supposed African influence after the fact. [60] The 1981 U.S. number 1 single " Rapture " by Blondie was an homage to rap music . The song name-checked rap artists and Fab 5 Freddie appeared in the video for the song. [61] Second British Invasion acts were influenced by funk and disco . [62]
The genre produced numerous one-hit wonders . [31]

Power pop
Power pop continued the guitar-based, singles-oriented British invasion sound of the mid-1960s into the 1970s and the present day. Although the name "power pop" had been around before punk (it is believed to have been coined by Pete Townshend in 1967) it became widely associated with new wave when Bomp and Trouser Press magazines (respectively in March and April 1978) wrote cover stories touting power pop as a sound that could continue new wave's directness without the negativity associated with punk. Cheap Trick , the Romantics , the Records , Shoes , the Motors , [23] the Only Ones , the Plimsouls , the dB's , the Beat , XTC , the Vapors , 20/20 and Squeeze were groups that found success playing this style. The Jam was the prime example of the mod sensibility of British power pop. By the end of 1979 a backlash had developed against power pop in general, particularly in regards to the Los Angeles scene. The skinny ties worn by LA power pop groups, epitomized by the Knack , became symbolic of the supposed lack of authenticity of the genre. [22] [63] Power pop's association with the genre was later forgotten. [10]

Punk and post-punk
The term " post-punk " was coined to describe groups such as Public Image Ltd , Siouxsie and the Banshees , Joy Division , Gang of Four , Wire , the Fall , Magazine and the Cure , which were initially considered part of new wave but were more ambitious, serious and challenging, as well as darker and less pop-oriented. Some of these groups would later adopt synths. [64] [65] While punk rock wielded a major influence on the popular music scene in the UK, in the US the music’s stigma of violence and sexual deviance made it virtually unmarketable. [40] Although distinct, punk, new wave and post-punk all shared common ground: an energetic reaction to what they perceived as the overproduced, uninspired popular music of the 1970s. [66]

New Romantic and synthpop
The New Romantic scene developed in the London nightclubs Billy's and the Blitz in the late 1970s. Club-goers wore flamboyant, eccentric costumes and make-up derived from the historical Romantic era . Beginning at "Bowie and Roxy Music" themed nights at these clubs, the scene was spearheaded by Steve Strange of Visage , with other soon-to-be pop acts also as regular fixtures such as Boy George of Culture Club , and Spandau Ballet . Around the same time, Duran Duran emerged from a similar scene in Birmingham. [67] Many of the acts that arose from the New Romantic club scene adopted synthpop in their own music, though all would credit David Bowie and Roxy Music as primary influences, both musically and visually. [9]
Kraftwerk were acclaimed for their groundbreaking use of synthesizers. Their 1975 pop single " Autobahn " reached number 11 in the United Kingdom. In 1978, Gary Numan saw a synthesizer left by another music act and started playing around with it. In 1979 he released two number one albums and two number one singles (one of each under his band name Tubeway Army ). Numan's admitted amateurism and deliberate lack of emotion was a sea change from the masculine and professional image that professional synth players had in an era when elaborate, lengthy solos were the norm. His open desire to be a pop star broke from punk orthodoxy. The decreasing price and ease of use of the instrument led acts to follow in Kraftwerk and Numan's footsteps. While Numan also utilized conventional rock instruments, several acts that followed used only synthesizers. Synthpop (or "technopop" as it was described by the U.S. press) [68] filled a void left by disco , [27] and grew into a broad genre that included groups such as the Human League , Eurythmics , Depeche Mode , Soft Cell , a-ha , New Order , Orchestral Manoeuvres in the Dark , Yazoo , [69] Ultravox , [70] Kajagoogoo , [71] and the Thompson Twins . [70] [72] [73] [74]

United States
In the summer of 1977 both Time [75] and Newsweek wrote favorable lead stories on the "punk/new wave" movement. [76] Acts associated with the movement received little or no radio airplay or music industry support. Small scenes developed in major cities. Continuing into the next year, public support remained limited to select elements of the artistic, bohemian and intellectual population, [33] as arena rock and disco dominated the charts. [70]
Starting in late 1978 and continuing into 1979, acts associated with punk and acts that mixed punk with other genres began to make chart appearances and receive airplay on rock stations and rock discos. [77] Blondie, Talking Heads, the Police and the Cars charted during this period. [22] [70] " My Sharona ", a single from the Knack , was Billboard magazine's number one single of 1979. The success of "My Sharona" combined with the fact that new wave albums were much cheaper to produce during a time when the music industry was in its worst slump in decades, [77] prompted record companies to sign new wave groups. [22] New wave music scenes developed in Ohio [70] and Athens, Georgia . [78] 1980 saw brief forays into new wave-styled music by non-new wave artists Billy Joel , Donna Summer and Linda Ronstadt . [22]
Early in 1980, influential radio consultant Lee Abrams wrote a memo saying that with a few exceptions, "we're not going to be seeing many of the new wave circuit acts happening very big over here (in America). As a movement, we don't expect it to have much influence." Lee Ferguson, a consultant to KWST , said in an interview that Los Angeles radio stations were banning disc jockeys from using the term and noted, "Most of the people who call music new wave are the ones looking for a way not to play it." [79] Despite the success of Devo's socially critical but widely misperceived song " Whip It ", [80] second albums by artists who had successful debut albums, along with newly signed artists, failed to sell, and radio pulled most new wave programming. [22]
The arrival of MTV in 1981 would usher in new wave's most successful era in the United States. British artists, unlike many of their American counterparts, had learned how to use the music video early on. [70] [81] Several British acts on independent labels were able to outmarket and outsell American artists on major labels. Journalists labeled this phenomenon a " Second British Invasion ". [81] [82] MTV continued its heavy rotation of videos by new wave-oriented acts until 1987, when it changed to a heavy metal and rock dominated format. [83]
In a December 1982 Gallup poll , 14% of teenagers rated new wave music as their favorite type of music, making it the third most popular. [84] New wave had its greatest popularity on the West Coast. Unlike other genres, race was not a factor in the popularity of new wave music, according to the poll. [84] Urban Contemporary radio stations were the first to play dance-oriented new wave artists such as the B-52's, Culture Club , Duran Duran and ABC . [85]
New wave soundtracks were used in mainstream Brat Pack films such as Valley Girl , Sixteen Candles , Pretty in Pink , and The Breakfast Club . [70] [86] John Hughes , the director of several of these films, was enthralled with British new wave music and placed songs from acts such as the Psychedelic Furs , Simple Minds and Echo and the Bunnymen in his films, helping to keep new wave in the mainstream. Several of these songs remain standards of the era. [87] Critics described the MTV acts of the period as shallow or vapid. [70] [81] The homophobic slurs " faggot " and "art fag" were openly used to describe new wave musicians. [88] [89] Despite the criticism, the danceable quality of the music and the quirky fashion sense associated with new wave artists appealed to audiences. [70]
The use of synthesizers by new wave acts influenced the development of house music in Chicago and techno in Detroit. In September 1988, Billboard launched their Modern Rock chart. While the acts on the chart reflected a wide variety of stylistic influences, new wave's legacy remained in the large influx of acts from Great Britain and acts that were popular in rock discos, as well as the chart's name, which reflected how new wave had been marketed as "modern". [90] New wave's indie spirit would be crucial to the development of college rock and grunge / alternative rock in the latter half of the 1980s and beyond. [70]

Post-1980s revivals and influence
In the aftermath of grunge, the British music press launched a campaign to promote the New Wave of New Wave. This campaign involved overtly punk and new wave-influenced acts such as Elastica but was eclipsed by Britpop . [23] Other acts of note during the 1990s included No Doubt , Metric , [91] Six Finger Satellite and Brainiac . [24] [92] During that decade, the synthesizer-heavy dance sounds of British and European new wave acts influenced various incarnations of Euro disco and trance . [27] [70] Chris Martin was inspired to start Coldplay by a-ha . [93]
During the 2000s, a number of acts emerged that mined a diversity of new wave and post-punk influences. Among these were the Strokes , the Bravery , Interpol , Yeah Yeah Yeahs , Franz Ferdinand, the Epoxies , VHS or Beta , the Rapture , She Wants Revenge , Bloc Party , Foals , [94] Kaiser Chiefs and the Killers . These acts were sometimes labeled "New New Wave". [25] The new wave revival reached its apex during the mid-2000s with acts such as the Sounds , the Ting Tings , Melody Club , Hot Chip , [95] [96] Passion Pit , [97] the Presets , [98] La Roux , Ladytron , [99] [100] Shiny Toy Guns , [101] Hockey , [102] Gwen Stefani and Ladyhawke . [24] [25] [103] [104] [105] [106] [107] [108] [109] While some journalists and fans regarded this as a revival, others argued that the phenomenon was a continuation of the original movements. [24] [110] [111] [112]
The Drums are an example of the trend in the U.S. indie pop scene that employs both the sounds and attitudes of the British new wave era. [26] [27] [28] [113] A new wave-influenced genre called chillwave also developed in the late 2000s, exemplified by artists like Toro Y Moi , Neon Indian , Twin Shadow and Washed Out . [114] [115] [116]

In electronic music
New wave had a seminal role in the development and popularity of contemporary electronic music . [ vague ] [117] [118]
During the late 1990s, new wave received a sudden surge of attention when it was fused with electro and techno during the short-lived electroclash movement. [119] [120] [121] [122] It received popular attention from musical acts such as I-F , Peaches , Fischerspooner and Vitalic , [121] [122] but largely faded when it combined with tech house to form the electro house genre. [123]
During the mid 2000s, new rave combined new wave with elements from several other genres, such as indie rock and electro house , [124] and added aesthetic elements archetypal of a rave , such as light shows and glow sticks . [125] [126] [127] Despite the term itself stimulating controversy to the point where many affiliated artists rejected it, [128] [129] new rave as a musical genre was adopted by artists such as the Klaxons , NYPC , Shitdisco and Hadouken! [124] [125]
In the 2010s, Nostalgia for 1980s new wave has seen a resurgence in the form of synthwave , which is primarily characterized by new wave, soundtrack influences and a retrofuturistic , cyberpunk -like visual aesthetic. [130] [131] [132] This term was applied to the music of artists such as Kavinsky , College , Power Glove , [130] and Mitch Murder , and to the visual styles and soundtracks of films and video games such as Drive , Tron: Legacy , Hotline Miami , Kung Fury , Turbo Kid , and Far Cry 3: Blood Dragon . [130] [131] [ dubious – discuss ]

Parallel movements

See also
WebPage index: 00019
National Press Monument
The National Press Monument (Indonesian: Monumen Pers Nasional ) is a monument and museum to the national Indonesian press. Formally established in 1978, more than 20 years after it was first proposed, the monument is located in Surakarta , Central Java , and operated by the Ministry of Communications and Information. The complex consists of an old society building, which was constructed in 1918 and used for the first meeting of the Reporters Association of Indonesia ( Persatuan Wartawan Indonesia , or PWI), as well as several subsequent expansions; it is listed as a Cultural Property of Indonesia .
The National Press Monument has a collection of over a million newspapers and magazines, as well as a variety of exhibitions and artefacts related to the history of the press in Indonesia. Facilities include a multimedia room, free-to-read newspapers, and a library. It is promoted as a site for educational tourism through various exhibitions and Facebook , and in 2013 it was visited by over 26,000 people.

History
The building in which the National Press Monument is now housed was constructed in 1918 under the orders of Mangkunegara VII , Prince of Mangkunegaran Palace , as a society building and meeting hall. It was known as Sociëteit "Sasana Soeka " [1] and designed by Mas Abu Kasan Atmodirono. [2] In 1933 R.M. Sarsito Mangunkusumo and several other engineers met in the building and formed the basis of the Soloche Radio Vereeniging (SRV), the first public radio operated by native Indonesians . [3] Thirteen years later, on 9 February 1946, the Reporters Association of Indonesia ( Persatuan Wartawan Indonesia , or PWI) was formed in the building; [4] the date is commemorated in Indonesia as National Press Day. During the Japanese occupation of the Dutch East Indies the building housed a clinic to treat troops, and during the Indonesian National Revolution it was used as an office of the Indonesian Red Cross Society . [5]
On 9 February 1956, during an event celebrating ten years of the PWI, high-profile reporters such as Rosihan Anwar , B.M. Diah, and S. Tahsin suggested that a foundation be established which could manage a national press museum. This foundation was formalised on 22 May 1956, with its collection mostly being donated by Soedarjo Tjokrosisworo. Only some fifteen years later did the foundation begin plans for establishing a physical museum, the plans for which were formally announced by Minister of Information Budiarjo on 9 February 1971. The name "National Press Monument" was formalised in 1973, and in 1977 the land was donated to the government. The museum was formally opened on 9 February 1978, after several new buildings were added. [3] In his dedication speech, President Suharto warned the press about the dangers of freedom, stating "exercising freedom for freedom's sake is a luxury we cannot afford". [6]
In 2012 the museum was headed by Sujatmiko. [7] That year David Kristian Budhiyanto of Petra Christian University wrote that the museum was rarely visited and in some places poorly maintained. He posited this to be based on a popular view of museums as unexciting or boring places. In order to attract new visitors, the museum has initiated several competitions in 2012 and 2013, including a photography contest on the museum's Facebook page. [8] It has also undertaken mobile exhibitions, showing some of its collection in cities such as Yogyakarta and Magelang . [9] Between January and September 2013 the museum received 26,249 visitors, an increase of 250 per cent over the previous year's target; this was credited to the various promotional efforts undertaken. [10] [11] The museum is now promoted as a site for educational tourism [4] and accepts donations of materials related to the press in Indonesia. [7]

Description
The National Press Monument is located at 59 Gajah Mada Street in Surakarta, Central Java , at the corner of Gajah Mada and Yosodipuro Streets. It is west of Mangkunegaran Palace . The complex consists of the original Sasana Soeka building, two two-story buildings, as well as a four-story building; these additions were constructed much later. At the front of the museum is a parking area and two public boards where the latest editions of local newspapers (in 2013, Solo Pos , Suara Merdeka , and Republika ) can be read freely. [3] The front façade is decorated with a naga design symbolising the year 1980, the year in which construction was completed. [12]
Management of the museum is handled by the Ministry of Communications and Information ( Kementerian Komunikasi dan Informatika ). The administrative structure consists of the museum head and administrative manager, as well as divisions for customer service, conservation and preservation, and day-to-day activities. As of 2013 [update] , the museum employs 24 civil servants. [3] The building is listed as a Cultural Property of Indonesia . [1]
The museum includes a media centre, where the general public can access the internet without charge on one of nine computers; a library, with a collection of approximately 12,000 books; and a room in which digitalised copies of old newspapers and magazines can be read. Digitalisation of this media is completed on-site. [3] A microfilm room is available, though it is no longer used. [13]
The National Press Monument regularly conducts seminars regarding the press, media, and communications. It holds themed exhibitions of media based on national holidays, including Independence Day, the anniversary of the Youth Pledge , and National Press Day; the museum may also take some of its collection on a mobile exhibition. The digital collection and library is accessible to the general public, while researchers may access paper copies of the newspapers and magazines. [3]

Holdings
The museum holds over a million newspapers and magazines published in various parts of the Indonesian archipelago from colonial times until the present day. [1] It also has numerous pieces of communications technology and technology used in reporting, including aerials, typewriters, transmitters, telephones, and a large kenthongan . [13] The front of the main entrance hall holds ten busts of important figures in the history of journalism in Indonesia. This includes Tirto Adhi Soerjo , Djamaluddin Adinegoro , Sam Ratulangi , and Ernest Douwes Dekker . [13]
In the rear of the main entrance hall is a series of six dioramas illustrating communications and the press throughout Indonesian history. The first diorama shows various forms of communication and news-sharing in pre-colonial Indonesia. The second diorama shows the press in the colonial period , including the first newspaper in the Indies under the Dutch East India Company , Memories der Nouvelles (1615); the first printed newspaper in the Indies, the Bataviasche Nouvelles (1744), and the first Javanese newspaper in the Indies, Bromartani (1855). The third diorama depicts the press during the Japanese occupation, whereas the fourth depicts the press during the National Revolution – including the formation of the PWI. The fifth diorama shows the state of the press during the New Order under President Suharto, a time of great press censorship. The final diorama depicts the press after the beginning of Reformasi in 1998, in which greater freedom of the press has been granted. [13]
The museum also holds various artefacts which belonged to journalists from pre- and post-independence Indonesia. This includes an Underwood typewriter which once belonged to Bakrie Soeriatmadja, a vocal journalist for the Bandung -based Sipatahoenan ; a shirt in which Hendro Subroto was shot while covering the Indonesian occupation of East Timor in 1975; parachuting equipment used by Trisnojuwono in covering the solar eclipse of 11 June 1983 ; and a camera used by Fuad Muhammad Syafruddin , a journalist for the Yogyakarta-based Bernas who was killed after covering a corruption scandal in 1995. [13] More artefacts, from journalists such as Mochtar Lubis , were still being acquired as of October 2013. [10]

See also
WebPage index: 00020
Wikipedia (disambiguation)
Wikipedia is a multilingual Internet encyclopedia.
Wikipedia may also refer to:

See also
WebPage index: 00021
Online encyclopedia
An online encyclopedia is an encyclopedia accessible through the internet , such as the English Wikipedia . The idea to build a free encyclopedia using the Internet can be traced at least to the 1994 Interpedia proposal; it was planned as an encyclopedia on the Internet to which everyone could contribute materials. The project never left the planning stage and was overtaken by a key branch of old printed encyclopedias.

Digitization of old content
In January 1995, Project Gutenberg started to publish the ASCII text of the Encyclopædia Britannica , 11th edition (1911), but disagreement about the method halted the work after the first volume. For trademark reasons this has been published as the Gutenberg Encyclopedia . In 2002, ASCII text of and 48 sounds of music was published on Encyclopædia Britannica Eleventh Edition [1] by source; a copyright claim was added to the materials included. [ original research? ] Project Gutenberg has restarted work on digitising and proofreading this encyclopedia; as of June 2005 it had not yet been published. Meanwhile, in the face of competition from rivals such as Encarta , the latest Britannica was digitized by its publishers, and sold first as a CD-ROM and later as an online service. Other digitization projects have made progress in other titles. One example is Easton's Bible Dictionary (1897) digitized by the Christian Classics Ethereal Library . [2] Probably the most important and successful digitization of an encyclopedia was the Bartleby Project 's online adaptation of the Columbia Encyclopedia , tenth Edition, [3] in early 2000 and is updated periodically.

Creation of new content
Another related branch of activity is the creation of new, free contents on a volunteer basis. In 1991, the participants of the Usenet newsgroup alt.fan.douglas-adams [4] started a project to produce a real version of The Hitchhiker's Guide to the Galaxy , a fictional encyclopedia used in the works of Douglas Adams . It became known as Project Galactic Guide. Although it originally aimed to contain only real, factual articles, policy was changed to allow and encourage semi-real and unreal articles as well. Project Galactic Guide contains over 1700 articles, but no new articles have been added since 2000; this is probably partly due to the founding of h2g2 , a more official project along similar lines.

See also
WebPage index: 00022
Registered user
A registered user is a user of a website , program , or other system who has previously registered. Registered users normally provide some sort of credentials (such as a username or e-mail address, and a password ) to the system in order to prove their identity: this is known as logging in . Systems intended for use by the general public often allow any user to register simply by selecting a register or sign up function and providing these credentials for the first time. Registered users may be granted privileges beyond those granted to unregistered users.

Advantages of registration
User registration and login enables a system to personalize itself. For example, a website might display a welcome banner with the user's name and change its appearance or behavior according to preferences indicated by the user. The system may also allow a logged-in user to send and receive messages and to view and modify personal files and other information.123

Disadvantages of registration
Registration necessarily provides more personal information to a system than it would otherwise have. Even if the credentials used are otherwise meaningless, the system can distinguish a logged-in user from other users, and might use this property to store a history of users' actions or activity, possibly without their knowledge or consent. A system could even sell information it has gathered on its users to third parties for advertising or other purposes. Depending on the nature of the system, a user might not have any way of knowing for certain exactly what information is stored, how it is used, and with whom, if anyone, it is shared. The subject of systems' transparency in this regard is one of ongoing debate.
Registration may also be seen as an annoyance or hindrance, especially if it is not inherently necessary or important (for example, in the context of a search engine ) or if the system repeatedly prompts users to register. A system's registration process might also be time-consuming or require that the user provide information they might be reluctant to, such as a home address or social security number . [1]

See also
WebPage index: 00023
OCLC
OCLC , currently incorporated as OCLC Online Computer Library Center, Incorporated , [3] is an American nonprofit cooperative organization "dedicated to the public purposes of furthering access to the world's information and reducing information costs". [4] It was founded in 1967 as the Ohio College Library Center . OCLC and its member libraries cooperatively produce and maintain WorldCat , the largest online public access catalog (OPAC) in the world. OCLC is funded mainly by the fees that libraries have to pay for its services (around $200 million annually as of 2016). [5]

History
OCLC began in 1967, as the Ohio College Library Center, through a collaboration of Ohio university presidents, vice presidents, and library directors who wanted to create a cooperative, computerized network for Ohio libraries. The group first met on July 5, 1967 on the campus of the Ohio State University to sign the articles of incorporation for the nonprofit organization. [6] The group hired Frederick G. Kilgour , a former Yale University medical school librarian, to design the shared cataloging system. [7] Kilgour wished to merge the latest information storage and retrieval system of the time, the computer, with the oldest, the library. The plan was to merge the catalogs of Ohio libraries electronically through a computer network and database in order to streamline operations, control costs, and increase efficiency in library management. The goal of this network and database was to bring libraries together to cooperatively keep track of the world's information in order to best serve researchers and scholars. The first library to do online cataloging through OCLC was the Alden Library at Ohio University on August 26, 1971. This was the first occurrence of online cataloging by any library worldwide. [6]
Membership in OCLC is based on use of services and contribution of data. Between 1967 and 1977, OCLC membership was limited to institutions in Ohio, but in 1978, a new governance structure was established that allowed institutions from other states to join. In 2002, the governance structure was again modified to accommodate participation from outside the United States. [8]
As OCLC expanded services in the United States outside of Ohio, it relied on establishing strategic partnerships with "networks," organizations that provided training, support and marketing services. By 2008, there were 15 independent United States regional service providers. OCLC networks played a key role in OCLC governance, with networks electing delegates to serve on OCLC Members Council. During 2008, OCLC commissioned two studies to look at distribution channels; at the same time, the OCLC Members Council approved governance changes that had been recommended by the Board of Trustees which severed the tie between the networks and governance. In early 2009, OCLC negotiated new contracts with the former networks and opened a centralized support center. [9]

Services
OCLC provides bibliographic , abstract and full-text information to anyone.
OCLC and its member libraries cooperatively produce and maintain WorldCat —the OCLC Online Union Catalog, the largest online public access catalog (OPAC) in the world. WorldCat has holding records from public and private libraries worldwide. The Open WorldCat program, launched in late 2003, exposed a subset of WorldCat records to Web users via popular Internet search, bibliographic, and bookselling sites; [10] Open WorldCat later morphed into WorldCat.org. In October 2005, the OCLC technical staff began a wiki project, WikiD, allowing readers to add commentary and structured-field information associated with any WorldCat record. [11] WikiD was later phased out.
The Online Computer Library Center acquired the trademark and copyrights associated with the Dewey Decimal Classification System when it bought Forest Press in 1988. A browser [12] for books with their Dewey Decimal Classifications was available until July 2013; it was replaced by the Classify Service .
Until August 2009, when it was sold to Backstage Library Works, OCLC owned a preservation microfilm and digitization operation called the OCLC Preservation Service Center, [13] with its principal office in Bethlehem, Pennsylvania , U.S.
The reference management service QuestionPoint [14] provides libraries with tools to communicate with users. This around-the-clock reference service is provided by a cooperative of participating global libraries.
OCLC has produced catalog cards for members since 1971 with its shared online catalog; the company printed its last catalog cards on October 1, 2015. [15]

Software
OCLC commercially sells software, e.g., CONTENTdm for managing digital collections . [16] [17]

Research
OCLC has been conducting research for the library community for more than 30 years. In accordance with its mission, OCLC makes its research outcomes known through various publications. [18] These publications, including journal articles, reports, newsletters, and presentations, are available through the organization's website.

Advocacy
Advocacy has been a part of OCLC's mission since its founding in 1967. OCLC staff members meet and work regularly with library leaders, information professionals, researchers, entrepreneurs, political leaders, trustees, students and patrons to advocate "advancing research, scholarship, education, community development, information access, and global cooperation." [23] [24]
WebJunction [25] is a division of OCLC funded by a grant from the Bill and Melinda Gates Foundation , which provides training services to librarians.
OCLC's advocacy campaign "Geek the Library," started in 2009, highlights the role of public libraries. The campaign, funded by a grant from the Bill & Melinda Gates Foundation , uses a strategy based on the findings of the 2008 OCLC report, "From Awareness to Funding: A study of library support in America." [26]
Other past advocacy campaigns have focused on sharing the knowledge gained from library and information research. Such projects have included communities such as the Society of American Archivists , the Open Archives Initiative , the Institute for Museum and Library Services , the International Organization for Standardization , the National Information Standards Organization , the World Wide Web Consortium , the Internet Engineering Task Force , and Internet2 . One of the most successful contributions to this effort was the Dublin Core Metadata Initiative, "an open forum of libraries, archives, museums, technology organizations, and software companies who work together to develop interoperable online metadata standards that support a broad range of purposes and business models." [23]
OCLC partnered with search engine providers in 2003 in order to advocate for libraries and share information across the broadest possible Internet landscape. Google , Yahoo! , and Ask.com have all collaborated with OCLC in order to make the WorldCat records searchable through those search engines. [23]

Online database: WorldCat
OCLC's WorldCat database is used by librarians for cataloging and research. Contributions to WorldCat are made via the Connexion computer program, which was introduced in 2001; its predecessor, OCLC Passport, was phased out in May 2005.
WorldCat contains records in MAchine Readable Cataloging ( MARC ) format contributed by library catalogers worldwide who use OCLC as a cataloging tool, and these MARC format records can also be downloaded into other libraries' local catalog systems. This allows libraries to find and download records for materials they are adding to their local catalog, without having to undergo the lengthy process of creating a new catalog entry from scratch for each new item.
As of March 2015, the OCLC database contained over 336 million records with 2.2 billion cataloged items, and is the world's largest bibliographic database covering 72,000 libraries. [27] Connexion is available to professional librarians as a computer program or on the web at connexion.oclc.org .
WorldCat is available to the public for searching via a subscription web-based service called FirstSearch, [28] as well as through the publicly available WorldCat.org. [29]

Identifiers and linked data
OCLC assigns a unique control number (referred to as an "OCN" for "OCLC Control Number") to each new bibliographic record in the WorldCat. Numbers are assigned serially, and as of mid-2013 over a billion OCNs had been created. In September 2013, the OCLC declared these numbers to be in the public domain , removing a perceived barrier to widespread use of OCNs outside of OCLC itself. [30] The control numbers link WorldCat's records to local library system records by providing a common reference key for a record across libraries. [31]
OCNs are particularly useful as identifiers for books and other bibliographic materials that do not have ISBNs (e.g., books published before 1970). OCNs are used as identifiers often in Wikipedia and Wikidata . In October 2013, it was reported that out of 29,673 instances of Infobox Book in Wikipedia, "there were 23,304 ISBNs and 15,226 OCNs"; and regarding Wikidata: "of around 14 million Wikidata items, 28,741 were books. 5403 Wikidata items have an ISBN associated with them, and 12,262 have OCNs." [32]
OCLC also runs the Virtual International Authority File (VIAF), an international name authority file. VIAF numbers are broadly used as standard idenfitiers.

Company acquisitions
OCLC acquired NetLibrary , a provider of electronic books and textbooks in 2002 and sold it in 2010 to EBSCO Industries . [33] OCLC owns 100% of the shares of OCLC PICA , a library automation systems and services company which has its headquarters in Leiden in the Netherlands and which was renamed "OCLC" at the end of 2007. [34] In June 2006, the Research Libraries Group (RLG) was merged into OCLC. On January 11, 2008, OCLC announced [35] that it had purchased EZproxy . It has also acquired OAIster . The process started in January 2009 and from 31 October 2009, OAIster records are freely available via WorldCat.org. In January 2015, OCLC acquired Sustainable Collection Services (SCS). SCS offered consulting services based on analyzing library print collection data to help libraries manage and share materials. [36] In 2017, OCLC acquired Relais International, a library interlibrary loan service provider based in Ottawa, Canada. [37]

Criticism
OCLC has been criticized for monopolistic practices. [38] In July 2010, the company was sued by SkyRiver, a rival startup, in an antitrust suit . [39] Library automation company Innovative Interfaces joined SkyRiver in the suit. [40] The suit was dropped in March 2013, however, following the acquisition of SkyRiver by Innovative Interfaces. [41]

See also
WebPage index: 00024
English Wikipedia
The English Wikipedia is the English-language edition of the free online encyclopedia Wikipedia . Founded on 15 January 2001, it is the first edition of Wikipedia and, as of July 2016, has the most articles of any of the editions . [2] As of May 2017, nearly 12.1% of articles in all Wikipedias belong to the English-language edition. This share has gradually declined from more than 50 percent in 2003, due to the growth of Wikipedias in other languages. [3] There are 5,412,796 articles on the site (live count). [4] In October 2015, the combined text of the English Wikipedia's articles totalled 11.5 gigabytes when compressed. [5] On 1 November 2015, the English Wikipedia announced it had reached 5,000,000 articles [6] and ran a special logo to reflect the milestone. [7]
The Simple English Wikipedia is a variation in which most of the articles use only basic English vocabulary. There is also the Old English (Ænglisc/Anglo-Saxon) Wikipedia ( angwiki ). Community-produced news publications include The Signpost . [8]

Pioneering edition
The English Wikipedia was the first Wikipedia edition and has remained the largest. It has pioneered many ideas as conventions, policies or features which were later adopted by Wikipedia editions in some of the other languages. These ideas include "featured articles", [9] the neutral-point-of-view policy, [10] navigation templates, [11] the sorting of short "stub" articles into sub-categories, [12] dispute resolution mechanisms such as mediation and arbitration, [13] and weekly collaborations. [14]
The English Wikipedia has adopted features from Wikipedias in other languages. These features include verified revisions from the German Wikipedia ( dewiki ) and town population-lookup templates from the Dutch Wikipedia ( nlwiki ).
Although the English Wikipedia stores images and audio files, as well as text files, many of the images have been moved to Wikimedia Commons with the same name, as passed-through files. However, the English Wikipedia also has fair-use images and audio/video files (with copyright restrictions), most of which are not allowed on Commons.
Many of the most active participants in the Wikimedia Foundation , and the developers of the MediaWiki software that powers Wikipedia, are English users.

Users and editors
The English Wikipedia reached 4,000,000 registered user accounts on 1 April 2007, [15] just a little over a year since it had crossed a threshold of 1,000,000 registered user accounts in late February 2006. [16]
Over 800,000 editors have edited Wikipedia more than 10 times. [17] 300,000 editors edit Wikipedia every month [ citation needed ] ; of these, over 30,000 perform more than 5 edits per month, and a little over 3,000 perform more than 100 edits per month. [18] By 24 November 2011, a total of 500 million edits had been performed on the English Wikipedia. [ citation needed ]
As the largest Wikipedia edition, and because English is such a widely used language, the English Wikipedia draws many users and editors whose native language is not English. Such users may seek information from the English Wikipedia rather than the Wikipedia of their native language because the English Wikipedia tends to contain more information about general subjects. Successful collaborations have been developed between non-native English speakers who successfully add content to the English Wikipedia and native English speakers who act as copyeditors for them. [ citation needed ]

Arbitration Committee
The English Wikipedia has an Arbitration Committee (also known as ArbCom) that consists of a panel of editors that imposes binding rulings with regard to disputes between other editors of the online encyclopedia. [19] The Committee was created by Jimmy Wales on 4 December 2003 as an extension of the decision-making power he had formerly held as owner of the site. [20] [21]
When initially founded, the Committee consisted of 12 arbitrators divided into three groups of four members each. [20] [22] Since then, the Committee has gradually expanded its membership to 18 arbitrators. [23] [ not in citation given ]
Like other aspects of the English Wikipedia, some of Wikipedia's sister projects have emulated the Arbitration Committee with their own similar versions. [24] For instance, in 2007, an Arbitration Committee was founded on the German Wikipedia called the Schiedsgericht ( de ) . [25]

Controversies
Several incidents of threats of violence against high schools on Wikipedia have been reported in the mainstream press. [26] [27] [28] The Glen A. Wilson High School was the subject of such a threat in 2008, [26] [27] [28] and a 14-year-old teenager was arrested for making a threat against Niles West High School on Wikipedia in 2006. [29]
A 2013 study from Oxford University concluded that the most disputed articles on the English Wikipedia tended to be broader issues, while on other language Wikipedias the most disputed articles tended to be regional issues; this is due to the English language's status as a global lingua franca , which means that many who edit the English Wikipedia do not speak English as a native language . [ clarification needed ] The study stated that the most disputed entries on the English Wikipedia were: George W. Bush , anarchism , Muhammad , list of WWE personnel , global warming , circumcision , United States , Jesus , race and intelligence , and Christianity . [30]

Varieties of English
One controversy in the English Wikipedia concerns which national variety of the English language is to be preferred, with the most commonly advocated candidates being American English and British English . [31] Perennial suggestions range from standardizing upon a single form of English to forking the English Wikipedia project. A style guideline states, "the English Wikipedia has no general preference for a major national variety of the language" and "an article on a topic that has strong ties to a particular English-speaking nation uses the appropriate variety of English for that nation". [32] An article should use spelling and grammar variants consistently; for example, color and colour are not to be used in the same article, since they represent American and British English, respectively. The guide also states that an article must remain in its original national variant.
There has been a similar issue in the Chinese language Wikipedia concerning regional differences in writing. Efforts at a language fork for Portuguese Wikipedia have failed, and succeeded for Norwegian Wikipedia .
Andrew Lih wrote that the English Wikipedia "didn't have the chance to go through a debate over whether there should be a British English Wikipedia or an American English Wikipedia" because the English Wikipedia was the original edition. [33] [ clarification needed ] Editors agreed to use U.S. spellings for primarily American topics and British spellings for primarily British topics. In 2009 Lih wrote, "No doubt, American spellings tend to dominate by default just because of sheer numbers." [34]

Wikiprojects, and assessments of articles' importance and quality
A " WikiProject " is a group of contributors who want to work together as a team to improve Wikipedia. These groups often focus on a specific topic area (for example, women's history ), a specific location or a specific kind of task (for example, checking newly created pages). The English Wikipedia currently has over 2,000 WikiProjects and activity varies. [35]
In 2007, in preparation for producing a print version, the English Wikipedia introduced an assessment scale of the quality of articles. [36] Articles are rated by WikiProjects. The range of quality classes begins with "Stub" (very short pages), followed by "Start", "C" and "B" (in increasing order of quality). Community peer review is needed for the article to enter one of the highest quality classes: either "A", " good article " or the highest, " featured article ". Of the about 4.4 million articles and lists assessed as of March 2015, a little more than 5,000 (0.12%) are featured articles, and fewer than 2,000 (0.04%) are featured lists. One featured article per day, as selected by editors, appears on the main page of Wikipedia. [37] [38]
The articles can also be rated as per "importance" as judged by a WikiProject. Currently, there are 5 importance categories: "low", "mid", "high", "top", and "???" for unclassified/uncertain level. For a particular article, different WikiProjects may assign different importance levels.
The Wikipedia Version 1.0 Editorial Team has developed a table (shown below) that displays data of all rated articles by quality and importance, on the English Wikipedia. If an article or list receives different ratings by two or more WikiProjects, then the highest rating is used in the table, pie-charts, and bar-chart. The software regularly auto-updates the data.
Researcher Giacomo Poderi found that articles tend to reach featured status via the intensive work of a few editors. [39] A 2010 study found unevenness in quality among featured articles and concluded that the community process is ineffective in assessing the quality of articles. [40]
[Note: The table above (prepared by the Wikipedia Version 1.0 Editorial Team ) is automatically updated daily by User:WP 1.0 bot , but the bar-chart and the two pie-charts are not auto-updated. In them, new data has to be entered by a Wikipedia editor (i.e. user).]

Graphics

Internal news publications
Community-produced news publications include The Signpost . [8] The Signpost (previously known as The Wikipedia Signpost [46] ) is the English Wikipedia's newspaper. [8] [47] [48] It is managed by the Wikipedia community and is published online weekly. [8] [49] Each edition contains stories and articles related to the Wikipedia community. [50] [51] A wide range of editors contribute articles and other pieces. [8]
The publication was founded in January 2005 by Wikipedia administrator and later Chair of the Wikimedia Foundation Board of Trustees, Michael Snow. [8] [46] [52] Originally titled The Wikipedia Signpost , it was later shortened to simply The Signpost . [46] [53] The newspaper reports on Wikipedia events including Arbitration Committee rulings, [54] Wikimedia Foundation issues, [55] and other Wikipedia-related projects . [56] Snow continued to contribute as a writer to The Signpost until his appointment to the Board of Trustees of the Wikimedia Foundation in February 2008. [57]
Investigative journalism by The Signpost in 2015 on changes to freedom of panorama copyright restrictions in Europe was covered by publications in multiple languages including German, [58] Italian, [59] Polish, [60] and Russian. [61] Wikipedia users Gamaliel and Go Phightins! became editors-in-chief of The Signpost in January 2015; prior editor-in-chief The ed17 noted that during his tenure the publication expanded its scope by including more reporting on the wider Wikimedia movement and English Wikipedia itself. [62] In a letter to readers upon the newspaper's tenth anniversary, the new co-editors-in-chief stressed the importance of maintaining independence from the Wikimedia Foundation in their reporting. [63]
The Signpost has been the subject of academic analysis in publications including Sociological Forum , [64] the social movements journal Interface , [65] and New Review of Academic Librarianship ; [66] and was consulted for data on Wikipedia by researchers from Los Alamos National Laboratory and Dartmouth College . [67] It has garnered generally positive reception from media publications including The New York Times , [68] The Register , [69] Nonprofit Quarterly , [70] and Heise Online . [71] The book Wikipedia: The Missing Manual called The Signpost essential reading for ambitious new Wikipedia editors. [72]
Other past and present community news publications include the " WikiWorld " web comic, the Wikipedia Weekly podcast, and newsletters of specific WikiProjects like The Bugle from WikiProject Military History and the monthly newsletter from The Guild of Copy Editors . There are also a number of publications from the Wikimedia Foundation and multilingual publications such as the Wikimedia Blog and This Month in Education .

See also

Footnotes
WebPage index: 00025
Spin (propaganda)
In public relations and politics , spin is a form of propaganda , achieved through providing a biased interpretation of an event or campaigning to persuade public opinion in favor or against some organization or public figure. While traditional public relations and advertising may also rely on altering the presentation of the facts, "spin" often implies the use of disingenuous , deceptive , and highly manipulative tactics. [1] Spin is typically applied to events or situations which are deemed to be unfavourable or potentially harmful to the popularity of a person, brand or product.
As such, a standard tactic used in "spinning" is to reframe, reposition, or otherwise modify the perception of an issue or event, to reduce any negative impact it might have on public opinion. For example, a company whose top-selling product is found to have a significant safety problem may "reframe" the issue by criticizing the safety of its main competitor's products or indeed by highlighting the risk associated with the entire product category. This might be done using a "catchy" slogan or sound bite that can help to persuade the public of the company's biased point of view . This tactic could enable the company to defocus the public's attention on the negative aspects of its product.
As it takes experience and training to "spin" an issue, spinning is typically a service provided by paid media advisors and media consultants . The largest and most powerful companies may have in-house employees and sophisticated units with expertise in spinning issues. While spin is often considered to be a private sector tactic, in the 1990s and 2000s, some politicians and political staff have been accused by their opponents of using deceptive "spin" tactics to manipulate public opinion or deceive the public. Spin approaches used by some political teams include "burying" potentially negative new information by releasing it at the end of the workday on the last day before a long weekend; selectively cherry-picking quotes from previous speeches made by their employer or an opposing politician to give the impression that she or he advocates a certain position; and purposely leaking misinformation about an opposing politician or candidate that casts her or him in a negative light.

Terminology
The term has its origin in the old American expression "to spin a yarn". In the 18th and 19th century, sailors were known for using their spare time on board ship to make thread or string (yarn). Sailors were also well known for telling incredible tales about their exploits when they were back on shore. When someone fooled you, it was said that "he spun me an amazing yarn". Yarn also became a synonym for " tall tale " - "What a yarn!" means "what a made-up story."
Because of the frequent association between spin and press conferences (especially government press conferences), the room in which these conferences take place is sometimes described as a " spin room ". [2] Public relations advisors, pollsters and media consultants who develop deceptive or misleading messages may be referred to as " spin doctors " or " spinmeisters ".

History
Edward Bernays has been called the "Father of Public Relations". As Larry Tye describes in his book The Father of Spin: Edward L. Bernays and The Birth of Public Relations , Bernays was able to help tobacco and alcohol companies use techniques to make certain behaviors more socially acceptable in 20th-century United States. Tye claims that Bernays was proud of his work as a propagandist. [3] As information technology has increased dramatically since the end of the 20th century, commentators like Joe Trippi have advanced the theory that modern Internet activism spells the end for political spin. By providing immediate counterpoint to every point a "spin doctor" can come up with, this theory suggests, the omnipresence of the Internet in some societies will inevitably lead to a reduction in the effectiveness of spin. [4]

Techniques
The techniques of spin include:
For years businesses have used fake or misleading customer testimonials by editing/spinning customers to reflect a much more satisfied experience than was actually the case. In 2009 the Federal Trade Commission updated their laws to include measures to prohibit this type of "spinning" and have been enforcing these laws as of late. Additionally, over the past 5 to 6 years several companies have arisen that verify the authenticity of the testimonials businesses present on the marketing materials in an effort to convince one to become a customer.

Fictional individuals
As spin doctors feature heavily in politics, communications directors, PR aides, and propagandists feature heavily in American and European political dramas. Examples of these include Malcolm Tucker ( Peter Capaldi ) in the BBC comedy The Thick of It and the film In the Loop (patterned after real-life communications director Alastair Campbell ), Kasper in Borgen , and Toby Ziegler in The West Wing . American drama Scandal closely follows a Washington, DC crisis management firm headed by Olivia Pope ( Kerry Washington ), while BBC comedy Absolute Power was set in a Westminster public relations company. Outside of television, George Orwell used the character of Squealer in his allegorical novel Animal Farm to illustrate the dangers of political propaganda, and the role it played in propping up totalitarian regimes. [7]

See also
WebPage index: 00026
Editing
Editing is the process of selecting and preparing written , visual , audible , and film media used to convey information. The editing process can involve correction, condensation, organization, and many other modifications performed with an intention of producing a correct, consistent, accurate and complete work. [1]
The editing process often begins with the author's idea for the work itself, continuing as a collaboration between the author and the editor as the work is created. As such, editing can involve creative skills, human relations and a precise set of methods. [2] [3]
There are various editorial positions in publishing. Typically, one finds editorial assistants reporting to the senior-level editorial staff and directors who report to senior executive editors. Senior executive editors are responsible for developing a product for its final release. The smaller the publication, the more these roles overlap.
The top editor at many publications may be known as the chief editor , executive editor , or simply the editor. A frequent and highly regarded contributor to a magazine may acquire the title of editor-at-large or contributing editor . Mid-level newspaper editors often manage or help to manage sections, such as business, sports and features. In U.S. newspapers, the level below the top editor is usually the managing editor .
In the book publishing industry, editors may organize anthologies and other compilations, produce definitive editions of a classic author's works (scholarly editor), and organize and manage contributions to a multi-author book (symposium editor or volume editor). Obtaining manuscripts or recruiting authors is the role of an acquisitions editor or a commissioning editor in a publishing house. [4] Finding marketable ideas and presenting them to appropriate authors are the responsibilities of a sponsoring editor.
Copy editors correct spelling , grammar and align writings to house style . Changes to the publishing industry since the 1980s have resulted in nearly all copy editing of book manuscripts being outsourced to freelance copy editors. [4]
At newspapers and wire services , copy editors write headlines and work on more substantive issues, such as ensuring accuracy, fairness, and taste. In some positions, they design pages and select news stories for inclusion. At U.K. and Australian newspapers, the term is sub-editor . They may choose the layout of the publication and communicate with the printer. These editors may have the title of layout or design editor or (more so in the past) makeup editor .

Scholarly books and journals
Within the publishing environment, editors of scholarly books are of three main types, each with particular responsibilities:
In the case of multi-author edited volumes , before the manuscript is delivered to the publisher it has undergone substantive and linguistic editing by the volume's editor, who works independently of the publisher.
As for scholarly journals , where spontaneous submissions are more common than commissioned works, the position of journal editor or editor-in-chief replaces the acquisitions editor of the book publishing environment, while the roles of production editor and copy editor remain. However, another editor is sometimes involved in the creation of scholarly research articles. Called the authors' editor , this editor works with authors to get a manuscript fit for purpose before it is submitted to a scholarly journal for publication.
The primary difference between copy editing scholarly books and journals and other sorts of copy editing lies in applying the standards of the publisher to the copy. Most scholarly publishers have a preferred style that usually specifies a particular dictionary and style manual—for example, the Chicago Manual of Style , the MLA Style Manual or the APA Publication Manual in the US, or the New Hart's Rules in the U.K.

Technical editing
Technical editing involves reviewing text written on a technical topic, identifying usage errors and ensuring adherence to a style guide.
Technical editing may include the correction of grammatical mistakes, misspellings, mistyping, incorrect punctuation, inconsistencies in usage, poorly structured sentences, wrong scientific terms, wrong units and dimensions, inconsistency in significant figures, technical ambivalence, technical disambiguation, statements conflicting with general scientific knowledge, correction of synopsis, content, index, headings and subheadings, correcting data and chart presentation in a research paper or report, and correcting errors in citations.
Large companies dedicate experienced writers to the technical editing function. Organizations that cannot afford dedicated editors typically have experienced writers peer-edit text produced by less experienced colleagues.
It helps if the technical editor is familiar with the subject being edited. The "technical" knowledge that an editor gains over time while working on a particular product or technology does give the editor an edge over another who has just started editing content related to that product or technology. But essential general skills are attention to detail, the ability to sustain focus while working through lengthy pieces of text on complex topics, tact in dealing with writers, and excellent communication skills.

Editing services
Editing is a growing field of work in the service industry . Paid editing services may be provided by specialized editing firms or by self-employed ( freelance ) editors.
Editing firms may employ a team of in-house editors, rely on a network of individual contractors or both. [5] Such firms are able to handle editing in a wide range of topics and genres, depending on the skills of individual editors. The services provided by these editors may be varied and can include proofreading , copy editing , online editing , developmental editing , editing for search engine optimization (SEO), etc.
Self-employed editors work directly for clients (e.g., authors, publishers) or offer their services through editing firms, or both. They may specialize in a type of editing (e.g., copy editing) and in a particular subject area. Those who work directly for authors and develop professional relationships with them are called authors' editors .

See also
WebPage index: 00027
Paul Kennedy (host)
Paul Kennedy is a broadcast journalist who works at the Canadian Broadcasting Corporation . He is a veteran broadcaster and award-winning documentarist, and is best known for being the host of the program Ideas on CBC Radio One since 1999. In 1977, he researched and wrote his first documentary segment (on the subject of the fur trade ), titled The Fur Trade Revisited . [1] This was featured in an Ideas series entitled Red Man, White World.
As well as hosting Ideas , Kennedy has continued to do documentary work.

Education
Kennedy has a BA degree from Queen's University , Kingston, Ontario, Canada; a MLitt degree from the University of Edinburgh , Scotland; and done postgraduate work at the University of Toronto , where he studied with the media theoretician Marshall McLuhan . [1]

Awards
WebPage index: 00028
Spanish Wikipedia
The Spanish Wikipedia ( Spanish : Wikipedia en español ) is a Spanish-language edition of Wikipedia , a free, online encyclopedia . It has 1,335,986 articles. Started in May 2001, it reached 100,000 articles on March 8, 2006 and 1,000,000 articles on May 16, 2013. It is the 9th-largest Wikipedia as measured by the number of articles and has the 4th-largest number of edits.

History
In February 2002, Larry Sanger wrote an e-mail stating that Bomis was considering selling advertisements. Edgar Enyedy, a user on the Spanish Wikipedia, criticized the proposal. Jimmy Wales and Sanger responded by saying that they did not immediately plan to implement advertisements, [1] but Enyedy began establishing a fork . Enciclopedia Libre was established by February 26, 2002. Enyedy persuaded most of the Spanish Wikipedians into going to the fork. By the end of 2002 over 10,000 articles were posted on the new site, and the Spanish Wikipedia was inactive for the rest of the year. Andrew Lih wrote that "for a long time it seemed that Spanish Wikipeda [ sic ] would be the unfortunate runt left from the Spanish fork." [2] The general popularity of Wikipedia attracted new users to the Spanish Wikipedia who were unfamiliar with the fork and these users came by June 2003. [2] By the end of that year the Wikipedia had over 10,000 articles. The size of the Spanish Wikipedia overtook that of the fork in the northern hemisphere fall of 2004. [2]
Lih stated in 2009 that the concepts of advertising and forking were still sensitive issues for the Wikipedia community because "It took more than a year for the Spanish Wikipedia to get back on its feet again" after the fork had been initiated. [2]
After the spin-off, the Spanish Wikipedia had very little activity until the upgrade to the Phase III of the software, later renamed MediaWiki , when the number of new users started to increase again. [ citation needed ] Both projects continue to co-exist, but the Spanish Wikipedia is by far the more active of the two. [3] [4]

Key dates

Size and users
It has the second largest number of users, after the English Wikipedia . [15] However, it is ranked eighth for number of articles, below other Wikipedias devoted to languages with smaller numbers of speakers, such as German , French , Cebuano , Dutch , Waray-Waray , Italian and Russian . In terms of quality, parameters such as article size (over 2 KB: 40%) show it as the second out of the ten largest Wikipedias after the German one. [16] As of October 2012, Spanish Wikipedia is the fourth Wikipedia in terms of the number of edits, [17] as well as the third Wikipedia by the number of page views. [18]
By country of origin, by September 2006, Spain was the main contributor to the Spanish Wikipedia (39.2% of edits). It is followed by Argentina (10.7%), Chile (8.8%), the Netherlands (8.4%), Mexico (7.0%), Venezuela (5.1%), Peru (3.5%), the United States (3.1%), Colombia (2.7%), Uruguay (1.3%) and Germany (1.1%). [19]
Among the countries where Spanish is an official language, Argentina , Chile , Mexico , Spain and Venezuela have established local chapters of the Wikimedia Foundation .

Usage in Spain
Following a study by Netsuus (online market analysis enterprises) on the use of Wikipedia in Spain, it was revealed that most users consult Spanish Wikipedia (97%) compared to Wikipedias in other regional languages (2.17% for Wikipedia in Catalan , 0.64% in Galician and 0.26% in Basque ). [20]

Differences from other Wikipedias

Evaluation and criticism
A comparative study by the Colegio Libre de Eméritos , made by Prof. Manuel Arias Maldonado ( University of Malaga ) and published in 2010, compared some articles with those of the English and German Wikipedias . It concluded that the Spanish version of Wikipedia was the least reliable of the three. It found it to be more cumbersome and imprecise than the German and English Wikipedias, stated that it often lacked reliable sources, including much unreferenced data, and found it to be too dependent on online references. [23]
During Wikimania 2009 , free-software activist Richard Stallman criticized the Spanish Wikipedia for restricting links to the Rebelion.org left-wing web site and allegedly banning users who had complained about what had happened. Participants in the Spanish Wikipedia responded that Rebelion.org is primarily a news aggregator , that links to aggregators should be replaced with links to original publishers whenever possible, and that they considered the issue to be one of spam . [24]
According to a 2013 Oxford University study, five of the ten most disputed pages on the Spanish Wikipedia were football (soccer) clubs, including Club América , FC Barcelona , Athletic Bilbao , Alianza Lima , and Newell's Old Boys . [25]
WebPage index: 00029
Madrid
WebPage index: 00030
Stop Online Piracy Act
The Stop Online Piracy Act ( SOPA ) was a controversial United States bill introduced by U.S. Representative Lamar S. Smith (R-TX) to expand the ability of U.S. law enforcement to combat online copyright infringement and online trafficking in counterfeit goods . Provisions included the requesting of court orders to bar advertising networks and payment facilities from conducting business with infringing websites, and web search engines from linking to the websites, and court orders requiring Internet service providers to block access to the websites. The proposed law would have expanded existing criminal laws to include unauthorized streaming of copyrighted content, imposing a maximum penalty of five years in prison.
Proponents of the legislation said it would protect the intellectual-property market and corresponding industry, jobs and revenue, and was necessary to bolster enforcement of copyright laws, especially against foreign-owned and operated websites. Claiming flaws in present laws that do not cover foreign-owned and operated websites, and citing examples of active promotion of rogue websites by U.S. search engines, proponents asserted that stronger enforcement tools were needed. The bill received strong, bipartisan support in the House of Representatives and the Senate. It also received support from the following organizations: Fraternal Order of Police, the National Governors Association, The National Conference of Legislatures, the U.S. Conference of Mayors, The National Association of Attorneys General, the Chamber of Commerce, the Better Business Bureau, the AFL–CIO and 22 trade unions, the National Consumers League, and over a hundred associations representing industries throughout the economy which claim that they are being harmed by online piracy . [2]
Opponents claimed that the proposed legislation threatened free speech and innovation, and enabled law enforcement to block access to entire Internet domains due to infringing content posted on a single blog or webpage. They also claimed that SOPA would bypass the "safe harbor" protections from liability presently afforded to websites by the Digital Millennium Copyright Act . Some library associations also claimed that the legislation's emphasis on stronger copyright enforcement would expose libraries to prosecution. Other opponents claimed that requiring search engines to delete domain names violated the First Amendment and could begin a worldwide arms race of unprecedented Internet censorship .
On January 18, 2012, the English Wikipedia , Google , and an estimated 7,000 other smaller websites coordinated a service blackout, [3] in protest against the bill. Wikipedia said more than 162 million people viewed its banner. [4] Other protests against SOPA and PIPA included petition drives, with Google stating it collected over seven million signatures, boycotts of companies and organizations that support the legislation, and an opposition rally held in New York City.
In response to the protest actions, the Recording Industry Association of America (RIAA) stated, "It's a dangerous and troubling development when the platforms that serve as gateways to information intentionally skew the facts to incite their users and arm them with misinformation", [5] and "it's very difficult to counter the misinformation when the disseminators also own the platform." [6]
Access to websites of several pro-SOPA organizations and companies such as RIAA, CBS.com, and others was impeded or blocked with denial-of-service attacks which started on January 19, 2012. Self-proclaimed members of the " hacktivist " group Anonymous claimed responsibility and stated the attacks were a protest of both SOPA and the United States Department of Justice's shutdown of Megaupload on that same day. [7]
Some opponents of the bill support the Online Protection and Enforcement of Digital Trade Act (OPEN) as an alternative. [8] [9] On January 20, 2012, House Judiciary Committee Chairman Smith postponed plans to draft the bill: "The committee remains committed to finding a solution to the problem of online piracy that protects American intellectual property and innovation ... The House Judiciary Committee will postpone consideration of the legislation until there is wider agreement on a solution." [10]

Overview
Bill 3261 or H.R. 3261 , was a proposed law that was introduced in the United States House of Representatives on October 26, 2011, by House Judiciary Committee Chair Representative Lamar S. Smith ( R - TX ) and a bipartisan group of 12 initial co-sponsors. [11] Presented to the House Judiciary Committee , it builds on the similar PRO-IP Act of 2008 and the corresponding Senate bill, the PROTECT IP Act (PIPA). [12] [13]
The originally proposed bill would allow the United States Department of Justice , as well as copyright holders, to seek court orders against websites outside U.S. jurisdiction accused of enabling or facilitating copyright infringement [ clarification needed ] . A court order requested by the DOJ could include barring online advertising networks and payment facilitators from conducting business with websites found to infringe on federal criminal intellectual-property laws, barring search engines from linking to such sites, and requiring Internet service providers to block access to such sites. [14] [15]
The bill establishes a two-step process for intellectual property-rights holders to seek relief if they have been harmed by a site dedicated to infringement. The rights holder must first notify, in writing, related payment facilitators and ad networks of the identity of the website, who, in turn, must then forward that notification and suspend services to that identified website, unless that site provides a counter notification explaining how it is not in violation. The rights holder can then sue for limited injunctive relief against the site operator, if such a counter notification is provided, or if the payment or advertising services fail to suspend service in the absence of a counter notification. [15]
The second section covers penalties for streaming video and for selling counterfeit drugs, military materials, or consumer goods. The bill would increase penalties and expand copyright offenses to include unauthorized streaming of copyrighted content and other intellectual-property offenses. The bill would criminalize unauthorized streaming of copyrighted content if they knowingly misrepresent the sites activity, with a maximum penalty of five years in prison for ten such infringements within six months. The copyrighted content can be removed, and infringements can lead to the site being shut down. [15] In July 2013, the Department of Commerce's Internet Policy Task Force issued a report endorsing "[a]dopting the same range of penalties for criminal streaming of copyrighted works to the public as now exists for criminal reproduction and distribution." [16]
The bill provides immunity from liability to the ad and payment networks that comply with this Act or that take voluntary action to sever ties to such sites. Any copyright holder who knowingly misrepresents that a website is involved in copyright infringement would be liable for damages. [14]
Supporters include the Motion Picture Association of America , pharmaceuticals makers, media businesses, and the United States Chamber of Commerce . They state it protects the intellectual-property market and corresponding industry, jobs and revenue, and is necessary to bolster enforcement of copyright laws, especially against foreign websites. [17] They cite examples such as Google's $500 million settlement with the Department of Justice for its role in a scheme to target U.S. consumers with ads to illegally import prescription drugs from Canadian pharmacies. [18]
Opponents state that it violates the First Amendment , [19] is Internet censorship , [20] will cripple the Internet, [21] and will threaten whistle-blowing and other free speech actions. [19] [22]
In October, 2011, co-sponsor Representative Bob Goodlatte (R-VA), chairman of the House Judiciary Committee 's Intellectual Property sub-panel , told The Hill that SOPA is a rewrite of the Senate's bill that addresses some tech-industry concerns, noting that under the House version of the legislation copyright holders won't be able to directly sue intermediaries such as search engines to block infringing websites and would instead need a court's approval before taking action against third parties. [23]
On December 12, 2011 a revised version of the bill was tabled. Titled the "Manager's Amendment", it contained a number of changes in response to criticism of the original. [24] As part of the revisions, the definition of sites that might be subject to enforcement was narrowed: the amendment limited such actions to sites that are designed or operated with the intent to promote copyright infringement, and it now only applies to non-US sites. [25] [26] [27]

Goals

Protecting intellectual property of content creators
According to Rep. Goodlatte, "Intellectual property is one of America's chief job creators and competitive advantages in the global marketplace, yet American inventors, authors, and entrepreneurs have been forced to stand by and watch as their works are stolen by foreign infringers beyond the reach of current U.S. laws. This legislation will update the laws to ensure that the economic incentives our Framers enshrined in the Constitution over 220 years ago—to encourage new writings, research, products and services— remain effective in the 21st century's global marketplace, which will create more American jobs." [28]
Rights holders see intermediaries—the companies who host, link to, and provide e-commerce around the content—as the only accessible defendants. [29]
Sponsor Rep. John Conyers (D-MI) said, "Millions of American jobs hang in the balance, and our efforts to protect America's intellectual property are critical to our economy's long-term success." [28] Smith added, "The Stop Online Piracy Act helps stop the flow of revenue to rogue websites and ensures that the profits from American innovations go to American innovators." [28]
The Motion Picture Association of America (MPAA) representative who testified before the committee said that the motion picture and film industry supported two million jobs and 95,000 small businesses. [30]

Protection against counterfeit drugs
Pfizer spokesman John Clark testified that patients could not always detect cleverly forged websites selling drugs that were either mis-branded or simply counterfeit. [31]
RxRights, a consumer-advocacy group, issued a statement saying that Clark failed "to acknowledge that there are Canadian and other international pharmacies that do disclose where they are located, require a valid doctor's prescription and sell safe, brand-name medications produced by the same leading manufacturers as prescription medications sold in the U.S." [32] They had earlier said that SOPA "fails to distinguish between counterfeit and genuine pharmacies" and would prevent American patients from ordering their medications from Canadian pharmacies online. [33]
Bill sponsor Smith accused Google of obstructing the bill, citing its $500 million settlement with the DOJ on charges that it allowed ads from Canadian pharmacies, leading to illegal imports of prescription drugs. [18] Shipment of prescription drugs from foreign pharmacies to customers in the US typically violates the Federal Food, Drug and Cosmetic Act and the Controlled Substances Act . [34]

Impact on online freedom of speech
Mentioned on the Texas Insider, President Obama "will not support legislation that reduces freedom of expression", said interviewer Jay Carney. [35]
On TIME ' s Techland blog , Jerry Brito wrote, "Imagine if the U.K. created a blacklist of American newspapers that its courts found violated celebrities' privacy? Or what if France blocked American sites it believed contained hate speech?" [36] Similarly, the Center for Democracy and Technology warned, "If SOPA and PIPA are enacted, the US government must be prepared for other governments to follow suit, in service to whatever social policies they believe are important—whether restricting hate speech, insults to public officials, or political dissent." [37]
Laurence H. Tribe , a Harvard University professor of constitutional law , released an open letter on the web stating that SOPA would "undermine the openness and free exchange of information at the heart of the Internet. And it would violate the First Amendment ". [19] [38]
The AFL–CIO 's Paul Almeida, arguing in favor of SOPA, has stated that free speech was not a relevant consideration, because "Freedom of speech is not the same as lawlessness on the Internet. There is no inconsistency between protecting an open Internet and safeguarding intellectual property. Protecting intellectual property is not the same as censorship; the First Amendment does not protect stealing goods off trucks." [39]

Autocratic countries
According to the Electronic Frontier Foundation , proxy servers , such as those used during the Arab Spring , can also be used to thwart copyright enforcement and therefore may be regulated by the act. [40]
John Palfrey , co-director of the Berkman Center for Internet & Society , expressed disagreement with the use of his research findings to support SOPA. He wrote that "SOPA would make many DNS circumvention tools illegal", which could put "dissident communities" in autocratic countries "at much greater risk than they already are". He added, "The single biggest funder of circumvention tools has been and remains the U.S. government, precisely because of the role the tools play in online activism. It would be highly counter-productive for the U.S. government to both fund and outlaw the same set of tools." [41]
Marvin Ammori has stated the bill might make The Tor Project illegal. Originally sponsored by the U.S. Naval Research Laboratory , [42] the Tor Project creates encryption technology used by dissidents in repressive regimes (that consequently outlaw it). Ammori says that the U.S. Supreme Court case of Lamont v. Postmaster General 381 U.S. 301 (1965) makes it clear that Americans have the First Amendment right to read and listen to such foreign dissident free speech, even if those foreigners themselves lack an equivalent free speech right (for example, under their constitution or through Optional Protocols under the United Nations International Covenant on Civil and Political Rights ). [43]

Impact on websites

Websites that host user content
Opponents have warned that SOPA could possibly have a negative impact on online communities. Journalist Rebecca MacKinnon argued in an op-ed that making companies liable for users' actions could have a chilling effect on user-generated sites such as YouTube. "The intention is not the same as China's Great Firewall , a nationwide system of Web censorship, but the practical effect could be similar", Mackinnon stated. [44] The Electronic Frontier Foundation (EFF) warned that websites Etsy , Flickr and Vimeo all seemed likely to shut down if the bill becomes law. [45] Policy analysts for New America Foundation say this legislation would enable law enforcement to take down an entire domain due to something posted on a single blog, arguing, "an entire largely innocent online community could be punished for the actions of a tiny minority". [46]
Additional concerns include the possible impact on common Internet functions such as links from one site to another or accessing data from the cloud. EFF claimed the bill would ban linking to sites deemed offending, even in search results [47] and on services such as Twitter. [48] Christian Dawson, Chief Operating Officer (COO) of Virginia-based hosting company ServInt , predicted that the legislation would lead to many cloud computing and Web hosting services moving out of the US to avoid lawsuits. [49] Even without SOPA, the U.S. Immigration and Customs Enforcement agency (ICE) has already launched extradition proceedings against Richard O'Dwyer in the UK. O'Dwyer hosted the TVShack.net website which had links to material elsewhere and did not host any files. ICE has stated that it intends to pursue websites even if their only connection to the USA is a .com or .net web domain. [50]
The Electronic Frontier Foundation has stated that the requirement that any site must self-police user generated content would impose significant liability costs and explains "why venture capitalists have said en masse they won't invest in online startups if PIPA and SOPA pass". [51] [52]
Proponents of the bill countered these claims, arguing that filtering is already common. Michael O'Leary of the MPAA testified on November 16 that the act's effect on business would be more minimal, noting that at least 16 countries already block websites, and that the Internet still functions in those countries. [53] MPAA Chairman Chris Dodd noted that Google figured out how to block sites when China requested it. [54] Some ISPs in Denmark, Finland, Ireland and Italy blocked The Pirate Bay after courts ruled in favor of music and film industry litigation, and a coalition of film and record companies has threatened to sue British Telecom if it does not follow suit. [55] Maria Pallante of the United States Copyright Office said that Congress has updated the Copyright Act before and should again, or "the U.S. copyright system will ultimately fail". Asked for clarification, she said that the US currently lacks jurisdiction over websites in other countries. [53]

Weakening of "safe harbor" protections
The 1998 Digital Millennium Copyright Act (DMCA) includes the Online Copyright Infringement Liability Limitation Act , that provides a "safe harbor" for websites that host content. Under that provision, copyright owners who felt that a site was hosting infringing content are required to request the site to remove the infringing material within a certain amount of time. [56] [57] [58] SOPA would bypass this "safe harbor" provision by placing the responsibility for detecting and policing infringement onto the site itself, and allowing judges to block access to websites "dedicated to theft of U.S. property". [59]
According to critics of the bill such as the Center for Democracy and Technology and the Electronic Frontier Foundation , the bill's wording is vague enough that a single complaint about a site could be enough to block it, with the burden of proof resting on the site. A provision in the bill states that any site would be blocked that "is taking, or has taken deliberate actions to avoid confirming a high probability of the use of the U.S.-directed site to carry out acts that constitute a violation". Critics have read this to mean that a site must actively monitor its content and identify violations to avoid blocking, rather than relying on others to notify it of such violations. [45] [60]
Law professor Jason Mazzone wrote, "Damages are also not available to the site owner unless a claimant 'knowingly materially' misrepresented that the law covers the targeted site, a difficult legal test to meet. The owner of the site can issue a counter-notice to restore payment processing and advertising but services need not comply with the counter-notice." [61]
Goodlatte stated, "We're open to working with them on language to narrow [the bill's provisions], but I think it is unrealistic to think we're going to continue to rely on the DMCA notice-and-takedown provision. Anybody who is involved in providing services on the Internet would be expected to do some things. But we are very open to tweaking the language to ensure we don't impose extraordinary burdens on legitimate companies as long as they aren't the primary purveyors [of pirated content]." [62] [63]
O'Leary submitted written testimony in favor of the bill that expressed guarded support of current DMCA provisions. "Where these sites are legitimate and make good faith efforts to respond to our requests, this model works with varying degrees of effectiveness", O'Leary wrote. "It does not, however, always work quickly, and it is not perfect, but it works." [30]

Web-related businesses
An analysis in the information technology magazine eWeek stated, "The language of SOPA is so broad, the rules so unconnected to the reality of Internet technology and the penalties so disconnected from the alleged crimes that this bill could effectively kill e-commerce or even normal Internet use. The bill also has grave implications for existing U.S., foreign and international laws and is sure to spend decades in court challenges." [64]
Art Bordsky of advocacy group Public Knowledge similarly stated, "The definitions written in the bill are so broad that any US consumer who uses a website overseas immediately gives the US jurisdiction the power to potentially take action against it." [65]
On October 28, 2011, the EFF called the bill a "massive piece of job-killing Internet regulation", and said, "This bill cannot be fixed; it must be killed." [66]
Gary Shapiro, CEO of the Consumer Electronics Association , spoke out strongly against the bill, stating, "The bill attempts a radical restructuring of the laws governing the Internet", and that "It would undo the legal safe harbors that have allowed a world-leading Internet industry to flourish over the last decade. It would expose legitimate American businesses and innovators to broad and open-ended liability. The result will be more lawsuits, decreased venture capital investment, and fewer new jobs." [67]
Lukas Biewald , founder of CrowdFlower , stated, "It'll have a stifling effect on venture capital... No one would invest because of the legal liability." [68]
Booz & Company on November 16 published a Google-funded study finding that almost all of the 200 venture capitalists and angel investors interviewed would stop funding digital media intermediaries if the bill became law. More than 80 percent said they would rather invest in a risky, weak economy with the current laws than a strong economy with the proposed law in effect. If legal ambiguities were removed and good faith provisions in place, investing would increase by nearly 115 percent. [69]
As reported by David Carr of The New York Times in an article critical of SOPA and PIPA, Google, Facebook, Twitter and other companies sent a joint letter to Congress, stating "We support the bills' stated goals – providing additional enforcement tools to combat foreign 'rogue' Web sites that are dedicated to copyright infringement or counterfeiting. However, the bills as drafted would expose law-abiding U.S. Internet and technology companies to new uncertain liabilities, private rights of action and technology mandates that would require monitoring of Web sites. We are concerned that these measures pose a serious risk to our industry's continued track record of innovation and job creation, as well as to our nation's cybersecurity." [38] [70] Smith responded, saying, the article "unfairly criticizes the Stop Online Piracy Act", and, "does not point to any language in the bill to back up the claims. SOPA targets only foreign Web sites that are primarily dedicated to illegal and infringing activity. Domestic Web sites, like blogs, are not covered by this legislation." Smith also said that Carr incorrectly framed the debate as between the entertainment industry and high-tech companies, noting support by more than "120 groups and associations across diverse industries, including the United States Chamber of Commerce ". [71]

Users uploading illegal content
Lateef Mtima, director of the Institute for Intellectual Property and Social Justice at Howard University School of Law , expressed concern that users who upload copyrighted content to sites could potentially be held criminally liable themselves, saying, "Perhaps the most dangerous aspect of the bill is that the conduct it would criminalize is so poorly defined. While on its face the bill seems to attempt to distinguish between commercial and non-commercial conduct, purportedly criminalizing the former and permitting the latter, in actuality the bill not only fails to accomplish this but, because of its lack of concrete definitions, it potentially criminalizes conduct that is currently permitted under the law." [72]
An aide to Rep. Smith said, "This bill does not make it a felony for a person to post a video on YouTube of their children singing to a copyrighted song. The bill specifically targets websites dedicated to illegal or infringing activity. Sites that host user content—like YouTube, Facebook, and Twitter—have nothing to be concerned about under this legislation." [72]

Internal networks
A paper by the Center for Democracy and Technology claimed that the bill "targets an entire website even if only a small portion hosts or links to some infringing content". [57]
According to A. M. Reilly of Industry Leaders Magazine , under SOPA, culpability for distributing copyright material is extended to those who aid the initial poster of the material. For companies that use virtual private networks (VPN) to create a network that appears to be internal but is spread across various offices and employees' homes, any of these offsite locations that initiate sharing of copyright material could put the entire VPN and hosting company at risk of violation. [73]
Answering similar criticism in a CNET editorial, Recording Industry Association of America (RIAA) head Cary Sherman wrote, "Actually, it's quite the opposite. By focusing on specific sites rather than entire domains, action can be targeted against only the illegal subdomain or Internet protocol address rather than taking action against the entire domain." [74]

Impact on web-browsing software
The Electronic Frontier Foundation expressed concern that free and open source software ( FLOSS ) projects found to be aiding online piracy could experience serious problems under SOPA. [75] Of special concern was the web browser Firefox , [40] which has an optional extension, MAFIAAFire Redirector , that redirects users to a new location for domains that were seized by the U.S. government. [76] In May 2011, Mozilla refused a request by the United States Department of Homeland Security to remove MAFIAAFire from its website, questioning whether the software had ever been declared illegal. [77] [78]

Potential effectiveness
Edward J. Black, president and CEO of the Computer & Communications Industry Association , wrote in the Huffington Post that "Ironically, it would do little to stop actual pirate websites, which could simply reappear hours later under a different name, if their numeric web addresses aren't public even sooner. Anyone who knows or has that web address would still be able to reach the offending website." [79]
An editorial in the San Jose Mercury-News stated, "Imagine the resources required to parse through the millions of Google and Facebook offerings every day looking for pirates who, if found, can just toss up another site in no time." [80]
John Palfrey of the Berkman Center for Internet & Society commented, "DNS filtering is by necessity either overbroad or underbroad; it either blocks too much or too little. Content on the Internet changes its place and nature rapidly, and DNS filtering is ineffective when it comes to keeping up with it." [41]
SOPA has largely been declared unconstitutional by the majority of Internet users. However, there are potential positive effects that could arise from passing the bill. A great number of jobs and industries are dependent on intellectual property and many people could benefit from better control and enforcement of their IP rights. The bill is supported by many media and film production companies, as well as renowned brand names like Nike who could see great financial benefits from having their copyrighted materials better protected. The implementation of SOPA or a similar policy could even potentially turn stock price declines of companies like Zynga and Netflix around. Producers of Internet content would benefit from SOPA in that it makes targeting copyright violators easier and less costly. SOPA also encourages ISPs and website owners to be proactive and make sure that their sites, products and services are not engaging in or facilitating high levels of copyright infringement – i.e. that their success does not depend on violating the rights of those who hold copyrighted material. SOPA may also be beneficial for preventing abuse of safe harbors. Some provisions within the bill would allow the US Attorney General to completely prohibit US internet users and servers from conducting business with sites that infringe upon IP rights, incentivizing careful self-monitoring. It essentially aims to encourage safer transactions and fair returns to the creators and owners of valuable IP. Those who do comply to IP legislation are currently at a competitive disadvantage, but bills like SOPA can reduce this disadvantage particularly against foreign sites. [ unbalanced opinion ] [81]

Technical issues

Deep-packet inspection and privacy
According to Markham Erickson, head of NetCoalition, which opposes SOPA, the section of the bill that would allow judges to order internet service providers to block access to infringing websites to customers located in the United States would also allow the checking of those customers' IP address , a method known as IP address blocking . Erickson has expressed concerns that such an order might require those providers to engage in " deep packet inspection ", which involves analyzing all of the content being transmitted to and from the user, raising new privacy concerns. [82] [83]
Policy analysts for New America Foundation say this legislation would "instigate a data obfuscation arms race" whereby by increasingly invasive practices would be required to monitor users' web traffic resulting in a "counterproductive cat-and-mouse game of censorship and circumvention [that] would drive savvy scofflaws to darknets while increasing surveillance of less technically proficient Internet users". [46]

Domain Name System
The Domain Name System (DNS) servers, sometimes likened to a telephone directory , translate browser requests for domain names into the IP address assigned to that computer or network. The original bill requires these servers to stop referring requests for infringing domains to their assigned IP addresses. DNS is robust by design against failure and requires that a lack of response is met by inquiries to other DNS servers. [84]
Andrew Lee, CEO of ESET North America, objected that since the bill would require internet service providers to filter DNS queries for the sites, this would undermine the integrity of the Domain Name System. [85]
According to David Ulevitch , the San Francisco-based head of OpenDNS , the passage of SOPA could cause Americans to switch to DNS providers located in other countries who offer encrypted links, and may cause U.S. providers, such as OpenDNS itself, to move to other countries, such as the Cayman Islands . [86]
In November 2011, an anonymous top-level domain , .bit , was launched outside of ICANN control, as a response to the perceived threat from SOPA, although its effectiveness (as well as the effectiveness of other alternative DNS roots ) remains unknown. [87]
On January 12, 2012, House sponsor Lamar Smith announced that provisions related to DNS redirection would be pulled from the bill. [88] [89] [90]

Internet security
A white paper by several internet security experts, including Steve Crocker and Dan Kaminsky , wrote, "From an operational standpoint, a resolution failure from a nameserver subject to a court order and from a hacked nameserver would be indistinguishable. Users running secure applications have a need to distinguish between policy-based failures and failures caused, for example, by the presence of an attack or a hostile network, or else downgrade attacks would likely be prolific." [91]

Domain Name System Security Extensions
Stewart Baker , former first Assistant Secretary for Policy at the Department of Homeland Security and former General Counsel of the National Security Agency , stated that SOPA would do "great damage to Internet security" [84] by undermining Domain Name System Security Extensions (DNSSEC), a proposed security upgrade for DNS, since a browser must treat all redirects the same, and must continue to search until it finds a DNS server (possibly overseas) providing untampered results. [84] On December 14, 2011 he wrote that SOPA was "badly in need of a knockout punch" [84] due to its impact on security and DNS:
DNSSEC is a set of protocols developed by the Internet Engineering Task Force (IETF) for ensuring internet security. A white paper by the Brookings Institution noted, "The DNS system is based on trust", adding that DNSSEC was developed to prevent malicious redirection of DNS traffic, and that "other forms of redirection will break the assurances from this security tool". [92]
On November 17, Sandia National Laboratories , a research agency of the U.S. Department of Energy , released a technical assessment of the DNS filtering provisions in the House and Senate bills, in response to Representative Zoe Lofgren's (D-CA) request. The assessment stated that the proposed DNS filtering would be unlikely to be effective, would negatively impact internet security, and would delay full implementation of DNSSEC. [93] [94]
On November 18, House Cybersecurity Subcommittee chair Dan Lungren stated that he had "very serious concerns" about SOPA's impact on DNSSEC, adding, "we don't have enough information, and if this is a serious problem as was suggested by some of the technical experts that got in touch with me, we have to address it". [95]

Transparency in enforcement
Brooklyn Law School professor Jason Mazzone warned, "Much of what will happen under SOPA will occur out of the public eye and without the possibility of holding anyone accountable. For when copyright law is made and enforced privately, it is hard for the public to know the shape that the law takes and harder still to complain about its operation." [61]

Supporters

Legislators
The Stop Online Piracy Act was introduced by Representative Lamar Smith (R-TX) and was initially co-sponsored by Howard Berman (D-CA), Marsha Blackburn (R-TN), Mary Bono Mack (R-CA), Steve Chabot (R-OH), John Conyers (D-MI), Ted Deutch (D-FL), Elton Gallegly (R-CA), Bob Goodlatte (R-VA), Timothy Griffin (R-AR), Dennis A. Ross (R-FL), Adam Schiff (D-CA) and Lee Terry (R-NE). As of January 16, 2012, there were 31 sponsors. [96]

Companies and organizations
The legislation has broad support from organizations that rely on copyright, including the Motion Picture Association of America , the Recording Industry Association of America , Entertainment Software Association , Macmillan US , Viacom , and various other companies and unions in the cable, movie, and music industries. Supporters also include trademark-dependent companies such as Nike , L'Oréal , and Acushnet Company . [97] [98]
Both the AFL–CIO and the U.S. Chamber of Commerce support H.R. 3261, and many trade unions and industry groups large and small, have also publicly praised the legislation. In a joint statement, the American Federation of Musicians (AFM), American Federation of Television and Radio Artists (AFTRA), Directors Guild of America (DGA), International Alliance of Theatrical Stage Employees, Moving Picture Technicians, Artists and Allied Crafts of the United States, Its Territories and Canada (IATSE), International Brotherhood of Teamsters (IBT), and Screen Actors Guild (SAG) all showed support for SOPA. Smaller trade organizations, such as A2IM, which represents independent musicians, have also backed the bill. [99]
In June 2011, former Bill Clinton press secretary Mike McCurry and former George W. Bush advisor Mark McKinnon , business partners in Public Strategies, Inc., started a campaign which echoed McCurry's earlier work in the network neutrality legislative fight. McCurry represented SOPA/PIPA in Politico as a way to combat theft on-line, [100] drawing a favorable comment from the MPAA. [101] On the 15th, McCurry and Arts + Labs co-chair McKinnon sponsored the "CREATE – A Forum on Creativity, Commerce, Copyright, Counterfeiting and Policy" conference with members of Congress, artists and information-business executives. [102]
On September 22, 2011, a letter signed by over 350 businesses and organizations—including NBCUniversal , Pfizer , Ford Motor Company , Revlon , NBA , and Macmillan US —was sent to Congress encouraging the passage of the legislation. [97] [98] Fightonlinetheft.com, a website of The Coalition Against Counterfeiting and Piracy (a project of the United States Chamber of Commerce Global Intellectual Property Center , [103] ) cites a long list of supporters including these and the Fraternal Order of Police , the National Governors Association , the U.S. Conference of Mayors , the National Association of Attorneys General , the Better Business Bureau , and the National Consumers League . [2] [104]
On November 22 the CEO of the Business Software Alliance (BSA) said, "valid and important questions have been raised about the bill". He said that definitions and remedies needed to be tightened and narrowed, but "BSA stands ready to work with Chairman Smith and his colleagues on the Judiciary Committee to resolve these issues". [105] [106]
On December 5, the Information Technology and Innovation Foundation , a non-partisan non-profit, published an article that blasted critics of SOPA and defended the bill. The report called opponents' claims about DNS filtering "inaccurate", their warnings against censorship as "unfounded" and recommended that the legislation be revised and passed into law. [107]
On December 22, Go Daddy , the world's largest domain name registrar, stated that it supported SOPA. [108] Go Daddy then rescinded its support, its CEO saying, "Fighting online piracy is of the utmost importance, which is why Go Daddy has been working to help craft revisions to this legislation—but we can clearly do better. It's very important that all Internet stakeholders work together on this. Getting it right is worth the wait. Go Daddy will support it when and if the Internet community supports it." [109]
In January 2012, the Entertainment Software Association announced support for SOPA, [110] although some association members expressed opposition. [111] Creative America , a group representing television networks, movie studios, and entertainment unions, produced a "fact vs. fiction" flyer that aimed to correct misperceptions about rogue sites legislation. [112]

Others
Professor and Intellectual Property rights lawyer, Hillel I. Parness, a Partner of Robins, Kaplan, Miller & Ciresi [113] has reviewed the bill, stating in a legal analysis that "There's a court involved here." In regards to "safe harbors", he stated the safe harbor provisions created by the DMCA in 1998 would still apply. "I think the proponents of the bill would say, what we're looking at today is a very different kind of Internet. The fact that the courts have said that entities like YouTube can be passive when it comes to copyright infringement, and just wait for notices rather than having to take any affirmative action, is also frustrating to them", he said. Regarding censorship concerns, he explained that none of the criminal copyright statutes in the bill were new, and therefore, "if there was a risk of abuse, that risk has always been there. And I have confidence in the structure of our court system, that the prosecutors and the courts are held to certain standards that should not allow a statute such as this to be manipulated in that way." [114]
Constitutional law expert Floyd Abrams , on behalf of the American Federation of Television and Radio Artists (AFTRA), the Directors Guild of America (DGA), the International Alliance of Theatrical and Stage Employees (IATSE), the Screen Actors Guild (SAG), the Motion Picture Association of America (MPAA) and others, [115] reviewed the proposed legislation and concluded, "The notion that adopting legislation to combat the theft of intellectual property on the Internet threatens freedom of expression and would facilitate, as one member of the House of Representatives recently put it, 'the end of the Internet as we know it,' is thus insupportable. Copyright violations have never been protected by the First Amendment and have been routinely punished wherever they occur; including the Internet. This proposed legislation is not inconsistent with the First Amendment; it would protect creators of speech, as Congress has done since this Nation was founded, by combating its theft." [116]

White House position
On January 14, 2012, the Obama administration responded to a petition against the bill, stating that while it would not support legislation with provisions that could lead to Internet censorship , squelching of innovation, or reduced Internet security, it encouraged "all sides to work together to pass sound legislation this year that provides prosecutors and rights holders new legal tools to combat online piracy originating beyond U.S. borders while staying true to the principles outlined above in this response." [117] [118] [119] [120] More than 100,000 people petitioned the White House in protest. [121] Three officials from the Obama administration articulated the White House's position on proposed anti-piracy legislation, balancing the need for strong antipiracy measures while respecting both freedom of expression and the way information and ideas are shared on the Internet. "While we believe that online piracy by foreign websites is a serious problem that requires a serious legislative response, we will not support legislation that reduces freedom of expression, increases cybersecurity risk, or undermines the dynamic, innovative global Internet." [122]

Opposition

Legislators
House Minority Leader Nancy Pelosi (D-CA) expressed opposition to the bill, as well as Representatives Darrell Issa (R-CA) and presidential candidate Ron Paul (R-TX), who joined nine Democrats to sign a letter to other House members warning that the bill would cause "an explosion of innovation-killing lawsuits and litigation". [123] "Issa said the legislation is beyond repair and must be rewritten from scratch", reported The Hill . [124] Issa and Lofgren announced plans for legislation offering "a copyright enforcement process modeled after the U.S. International Trade Commission 's (ITC) patent infringement investigations". [49] Politico referred to support as an "election liability" for legislators. [125] Subsequently, proponents began hinting that key provisions might be deferred with opponents stating this was inadequate. [126] [127] Representative Jared Polis (D-CO) has been known to lobby against SOPA in the game League of Legends , also making a post [128] in the official game message boards. [129]

Companies and organizations
Opponents include Google , Yahoo! , YouTube , Facebook , Twitter , AOL , LinkedIn , eBay , Mozilla Corporation , Mojang , Riot Games , [130] [131] Epic Games , Reddit , [132] Wikipedia [133] and the Wikimedia Foundation , [134] in addition to human rights organizations such as Reporters Without Borders , [135] the Electronic Frontier Foundation (EFF), the ACLU , and Human Rights Watch . [136]
Kaspersky Lab , a major computer security company, demonstrated its opposition to SOPA and "decided to discontinue its membership in the BSA ". [137]
On December 13, 2011, Julian Sanchez of the libertarian think tank Cato Institute came out in strong opposition to the bill saying that while the amended version "trims or softens a few of the most egregious provisions of the original proposal... the fundamental problem with SOPA has never been these details; it's the core idea. The core idea is still to create an Internet blacklist..." [138]
The Library Copyright Alliance (including the American Library Association ) objected to the broadened definition of "willful infringement" and the introduction of felony penalties for noncommercial streaming infringement, stating that these changes could encourage criminal prosecution of libraries. [139] A Harvard law professor's analysis said that this provision was written so broadly that it could make mainstream musicians felons for uploading covers of other people's music to sites like YouTube . [140]
On November 22, Mike Masnick of Techdirt called SOPA "toxic" [126] and published a detailed criticism [141] of the ideas underlying the bill, writing that "one could argue that the entire Internet enables or facilitates infringement", and saying that a list of sites compiled by the entertainment industry included the personal site of one of their own artists, 50 Cent , and legitimate internet companies. The article questioned the effect of the bill on $2 trillion in GDP and 3.1 million jobs, with a host of consequential problems on investment, liability and innovation. [142] Paul Graham , the founder of venture capital company Y Combinator opposed the bill, and banned all SOPA-supporting companies from their "demo day" events. "If these companies are so clueless about technology that they think SOPA is a good idea", he asks, "how could they be good investors?" [143] Prominent pro-democracy movement, Avaaz.org started a petition in protest over SOPA and so far has got over 3.4 million signatures worldwide. [144]
The Center for Democracy and Technology maintains a list of SOPA and PIPA opponents consisting of the editorial boards of The New York Times , [38] [145] the Los Angeles Times , 34 other organizations and hundreds of prominent individuals. [146]
Zynga Game Network , creator of Facebook games Texas HoldEm Poker and FarmVille , wrote to the sponsors of both bills highlighting concerns over the effect on "the DMCA's safe harbor provisions ... [which] ... have been a cornerstone of the U.S. Technology and industry's growth and success", and opposing the bill due to its impact on "innovation and dynamism". [147]

Others
Computer scientist Vint Cerf , one of the founders of the Internet, now Google vice president, wrote to Smith, saying "Requiring search engines to delete a domain name begins a worldwide arms race of unprecedented 'censorship' of the Web", in a letter published on CNet. [148] [149]
On December 15, 2011, a second hearing was scheduled to amend and vote on SOPA. Many opponents remained firm even after Smith proposed a 71-page amendment to the bill to address concerns. NetCoalition, which works with Google, Twitter, eBay and Facebook, appreciated that Smith was listening, but says it nonetheless could not support the amendment. Issa stated that Smith's amendment, "retains the fundamental flaws of its predecessor by blocking Americans' ability to access websites, imposing costly regulation on Web companies and giving Attorney General Eric Holder 's Department of Justice broad new powers to police the Internet". [150]
In December 2011, screenwriter and comics writer Steve Niles spoke out against SOPA, commenting, "I know folks are scared to speak out because a lot of us work for these companies, but we have to fight. Too much is at stake." [151] [152]
In January 2012, novelist, screenwriter and comics writer Peter David directed his ire at the intellectual property pirates whose activities he felt provoked the creation of SOPA. While expressing opposition to SOPA because of his view that the then-current language of the bill would go too far in its restriction of free expression, and would probably be scaled down, David argued that content pirates, such as the websites that had posted his novels online in their entirety for free downloads, as well as users who supported or took advantage of these activities, could have prevented SOPA by respecting copyright laws. [153]
Twenty one artists signed an open letter to Congress urging them to exercise extreme caution, including Comedian Aziz Ansari , The Lonely Island music parody band, MGMT , OK Go , Jason Mraz and Trent Reznor of Nine Inch Nails . The letter reads, "As creative professionals, we experience copyright infringement on a very personal level. Commercial piracy is deeply unfair and pervasive leaks of unreleased films and music regularly interfere with the integrity of our creations. We are grateful for the measures policymakers have enacted to protect our works. [...] We fear that the broad new enforcement powers provided under SOPA and PIPA could be easily abused against legitimate services like those upon which we depend. These bills would allow entire websites to be blocked without due process, causing collateral damage to the legitimate users of the same services - artists and creators like us who would be censored as a result." [154] Filmmaker Michael Moore also shut down his websites during the week of protest, [155] while other celebrities, including Ashton Kutcher , Alec Baldwin , and rapper B.o.B expressed their opposition via Twitter . [156] [157] The Daily Show ' s Jon Stewart stated that SOPA will "break the Internet". [158]
According to an NYT report (February 8, 2012), Art Brodsky of Public Knowledge said, "The movie business is fond of throwing out numbers about how many millions of dollars are at risk and how many thousands of jobs are lost ... We don't think it correlates to the state of the industry." The report also noted that "some in the internet world, including Tim O'Reilly , ... go so far as to question whether illegitimate downloading and sharing is such a bad thing. In fact, some say that it could even be a boon to artists and other creators." Tim O'Reilly is quoted as saying, "The losses due to piracy are far outweighed by the benefits of the free flow of information, which makes the world richer, and develops new markets for legitimate content ... Most of the people who are downloading unauthorized copies of O'Reilly books would never have paid us for them anyway." [159]

International response
Organizations in the international civil and human rights community expressed concerns that SOPA would cause the United States to lose its position as a global leader in supporting a free and open Internet for public good. [160]
On November 18, 2011, the European Parliament adopted by a large majority a resolution that "stresses the need to protect the integrity of the global Internet and freedom of communication by refraining from unilateral measures to revoke IP addresses or domain names". [161] [162]
Private individuals are petitioning the Foreign and Commonwealth Office , asking for the British government to condemn the bill. [163]
Vice-President of the European Commission and European Commissioner for Digital Agenda Neelie Kroes said she is "Glad [the] tide is turning on SOPA", explaining rather than having a "bad legislation" there "should be safeguarding benefits of open net". "Speeding is illegal too but you don't put speed bumps on the motorway", she said. [164]
Nonetheless, Ireland may have a law similar to SOPA passed soon - and "without Parliamentary vote". The Irish law is entitled, " S.I. No. 337/2011 — European Communities (Electronic Communications Networks and Services) (Universal Service and Users' Rights) Regulations 2011 ". [165] [166]

Protest actions
On November 16, 2011, Tumblr , Mozilla, Techdirt, the Center for Democracy and Technology were among many Internet companies that protested by participating in American Censorship Day . They displayed black banners over their site logos with the words "STOP CENSORSHIP". [167]
Google linked an online petition to its site, and says it collected more than 7 million signatures from the United States. [168]
Markham Erickson, executive director of NetCoalition, told Fox News that "a number of companies have had discussions about [blacking out services]" [169] and discussion of the option spread to other media outlets. [170]
In January 2012, Reddit announced plans to black out its site for twelve hours on January 18, as company co-founder Alexis Ohanian announced he was going to testify to Congress. "He's of the firm position that SOPA could potentially 'obliterate' the entire tech industry", Paul Tassi wrote in Forbes . Tassi also opined that Google and Facebook would have to join the blackout to reach a sufficiently broad audience. [171] Other prominent sites that planned to participate in the January 18 blackout were Cheezburger Sites, Mojang , [172] Major League Gaming , [173] Boing Boing , [174] BoardGameGeek , xkcd , [175] SMBC [176] and The Oatmeal . [177]
Wider protests were considered and in some cases committed to by major internet sites, with high-profile bodies such as Google, Facebook, Twitter, Yahoo, Amazon , AOL , Reddit, Mozilla, LinkedIn , IAC , eBay, PayPal, WordPress and Wikimedia being widely named as "considering" or committed to an "unprecedented" internet blackout on January 18, 2012. [178] [179] [180] [181] On January 17 a Republican aide on Capitol Hill said that the protests were making their mark, with SOPA having already become "a dirty word beyond anything you can imagine". [182]
A series of pickets against the bill were held at the U.S. Embassy in Moscow. Two picketers were arrested. [183]
On January 21, 2012 RT news reported, "Bill Killed: SOPA death celebrated as Congress recalls anti-piracy acts". The Electronic Frontier Foundation , a rights advocacy non-profit group opposing the bill, said the protests were the biggest in Internet history, with over 115 thousand sites altering their webpages. [184]
SOPA supporters complained that the bill was being misrepresented amidst the protests. RIAA spokesman Jonathan Lamy said, "It's a dangerous and troubling development when the platforms that serve as gateways to information intentionally skew the facts to incite their users and arm them with misinformation", [5] a sentiment echoed by RIAA CEO Cary Sherman who said "it's very difficult to counter the misinformation when the disseminators also own the platform". [6] At the American Constitution Society 's 2012 National Convention, the Democratic Party 's chief counsel to the United States House Judiciary Subcommittee on Courts, Intellectual Property and the Internet said that the protests were "orchestrated by misinformation by a few actors," adding that "activism is welcome on the Hill, but... There's this thing called 'mob rule', and it's not always right." [185]

Wikipedia blackout
The English Wikipedia blackout occurred for 24 hours on January 18–19, 2012. In place of articles , (with the exception of those for SOPA and PIPA themselves) the site showed only a message in protest of SOPA and PIPA asking visitors to " Imagine a world without free knowledge. " It is estimated in excess of 160 million people saw the banner. [168] A month earlier, Wikipedia co-founder Jimmy Wales initiated discussion with editors regarding a potential knowledge blackout , a protest inspired by a successful campaign by the Italian-language Wikipedia to block the Italian DDL intercettazioni bill, terms of which could have infringed the encyclopedia's editorial independence. Editors and others [186] mulled interrupting service for one or more days as in the Italian protest, or alternatively presenting site visitors with a blanked page directing them to further information before permitting them to complete searches. [187] [188] On January 16, the Wikimedia Foundation announced that the English-language Wikipedia would be blacked out for 24 hours on January 18. [189]
The Daily Mail estimated that 7,000 smaller websites either joined in the blackout for the day or posted some kind of protest at the proposed legislation. [3]
SOPA's sponsor in the House, Chairman Smith, called Wikipedia's blackout a "publicity stunt" saying: "It is ironic that a website dedicated to providing information is spreading misinformation about the Stop Online Piracy Act." Smith went on to insist that SOPA "will not harm Wikipedia, domestic blogs or social networking sites". [190]

Megaupload shutdown and protest
On January 19, 2012, Megaupload , a Hong Kong–based company providing file sharing services, was shut down by the US Department of Justice and the Federal Bureau of Investigation . [191] Barrett Brown, described as a spokesperson for the group Anonymous by the state-run [192] news outlet RT , said the timing of the Megaupload raid "couldn't have come at a worse time in terms of the government's standpoint". [7] Some commentators and observers have asserted that the FBI shut down of Megaupload proves that SOPA and PIPA are unnecessary. [193] [194]

Legislative history
The House Judiciary Committee held hearings on November 16 and December 15, 2011. The Committee was scheduled to continue debate in January 2012, [195] but on January 17 Chairman Smith said that "Due to the Republican and Democratic retreats taking place over the next two weeks, markup of the Stop Online Piracy Act is expected to resume in February." [196] However, in the wake of online protests held on January 18, 2012, Rep. Lamar Smith has stated, "The House Judiciary Committee will postpone consideration of the legislation until there is wider agreement on a solution", [10] and Sen. Reid announced that the PIPA test vote scheduled for January 24 would also be postponed. [10] [197] [198]

November 16 House Judiciary Committee hearing
At the House Judiciary Committee hearing, there was concern among some observers that the set of speakers who testified lacked technical expertise. Technology news site CNET reported "One by one, each witness—including a lobbyist for the Motion Picture Association of America—said they weren't qualified to discuss... DNSSEC." [95] Adam Thierer, a senior research fellow at the Mercatus Center , similarly said, "The techno-ignorance of Congress was on full display. Member after member admitted that they really didn't have any idea what impact SOPA's regulatory provisions would have on the DNS, online security, or much of anything else." [199]
Lofgren stated, "We have no technical expertise on this panel today." She also criticized the tone of the hearing, saying, "It hasn't generally been the policy of this committee to dismiss the views of those we are going to regulate. Impugning the motives of the critics instead of the substance is a mistake." [200]
Lungren told Politico's Morning Tech that he had "very serious concerns" about SOPA's impact on DNSSEC, adding "we don't have enough information, and if this is a serious problem as was suggested by some of the technical experts that got in touch with me, we have to address it. I can't afford to let that go by without dealing with it." [201]
Gary Shapiro, CEO of the Consumer Electronics Association , stated, "The significant potential harms of this bill are reflected by the extraordinary coalition arrayed against it. Concerns about SOPA have been raised by Tea Partiers , progressives, computer scientists, human rights advocates, venture capitalists, law professors, independent musicians, and many more. Unfortunately, these voices were not heard at today's hearing." [67]
An editorial in Fortune wrote, "This is just another case of Congress doing the bidding of powerful lobbyists—in this case, Hollywood and the music industry, among others. It would be downright mundane if the legislation weren't so draconian and the rhetoric surrounding it weren't so transparently pandering." [202]

December 15 markup of the bill
Since its introduction, a number of opponents to the bill have expressed concerns. The bill was presented for markup by the House Judiciary Committee on December 15.
An aide to Smith stated that "He is open to changes but only legitimate changes. Some site[s] are totally capable of filtering illegal content, but they won't and are instead profiting from the traffic of illegal content." [203]

Markup outcome
After the first day of the hearing, more than 20 amendments had been rejected, including one by Darrell Issa which would have stripped provisions targeting search engines and Internet providers. PC World reported that the 22–12 vote on the amendment could foreshadow strong support for the bill by the committee. [204]
The Committee adjourned on the second day agreeing to continue debate early in 2012. [195] [205] Smith announced a plan to remove the provision that requires Internet service providers to block access to certain foreign websites. [89] On January 15, 2012, Issa said he has received assurances from Rep. Eric Cantor that the bill would not come up for a vote until a consensus could be reached. [206]

MPAA's continuing efforts to enact SOPA principles
The 2014 Sony Pictures hack revealed that the MPAA has continued its efforts to enact SOPA-like blocking principles since the bill died in Congress. The emails indicated that the MPAA was actively exploring new strategies to implement SOPA-like regulations, such as using the All Writs Act to "allow [the MPAA] to obtain court orders requiring site blocking without first having to sue and prove the target ISPs are liable for copyright infringement." [207] The MPAA has also allied itself with National Association of Attorneys General president Jim Hood , who supports SOPA principles and has stated that "Google's not a government… they don't owe anyone a First Amendment right… [i]f you're an illegal site, you ought to clean up your act, instead of Google making money off it." [208] On November 27, 2013, Hood sent a letter to Google outlining his grievances. It was later revealed that much of the letter was drafted by the law firm representing the MPAA. [209]
On October 21, 2014, Hood issued a subpoena to Google for information about, among other items, its advertising partnerships and practices concerning illegal and sexual content. [210] Google requested an injunction to quash the subpoena from the United States District Court of the Southern District of Mississippi, Northern Division. Google was granted such an injunction on March 2, 2015. [211] The injunction also prevented Hood from bringing a charge against Google for making third-party content available to internet users. [211] Effectively, the injunction protected Google from having Hood's claims enforced until after the conclusion of the case. [211]
An MPAA spokesperson criticized Google's use of the First Amendment, accusing the company of using freedom of speech "as a shield for unlawful activities." [212] Leaders in the technology industry commended the federal court for issuing the injunction. [212] In addition, one of Google's head lawyers noted that "[w]e're pleased with the court's ruling, which recognizes that the MPAA's long-running campaign to censor the web — which started with SOPA — is contrary to federal law." [213]

See also
WebPage index: 00031
Page view
A page view ( PV ) or page impression is a request to load a single HTML file ( web page ) of an Internet site . [1] On the World Wide Web , a page request would result from a web surfer clicking on a link on another "page" pointing to the page in question.
A hit , which refers to a request for any file from a web server . There may, therefore, be many hits per page view since an HTML page can contain multiple files—images, CSS , etc. [2] On balance, page views refer to a number of pages viewed or clicked on the site during the given time. [3]
Page views may be counted as part of web analytics . For the owner of the site, this information can be useful to see if any change in the "page" (such as the information or the way it is presented) results in more visits. If there are any advertisements on the page, the publishers would also be interested in the number of page views to determine their expected revenue from the ads. For this reason, it is a term that is used widely for Internet marketing and advertising . [4]

Feature
The page impression has long been a measure of user activity on a website. However, the activity is not necessarily associated with loading a complete HTML page. Modern programming techniques can serve pages by other means that don't show as HTTP requests.

Advertisement
Since page views help estimate the popularity of sites, it helps determine their value for advertising revenue. The most common metric is CPM. It stands for 'Cost per thousand'(the M is the Roman numeral for 1,000) [5] and it is commonly used metrics to measure page views divided by the thousands, that is, cost per 1000 views, used for the ad rates and thus, the less CPM is, the better deal it offers to advertisers. [6] However, there has been a growing concern that CPM is not as trustworthy as it looks in the advertising market because, although, with CPM arrangement, everyone who visits a site makes publishers’ money, for an advertiser’s view, CPM is being challenged in comparison to CPC or CPA in terms of adverts’ efficiency because visiting does not mean clicking the ads. [7]

Measurement
The preferred way to count page views is using a website such as Google Analytics . They can measure the number of pages on any site and therefore, it helps people to receive a rough estimate of page views on web sites. [8] There are also many other page view measurement tools available including open source ones as well as licensed products.

Criticism and concerns
Despite a wide range of use of page view, it has come in for criticisms.

Manipulation
Page view can be manipulated or boosted for specific purposes. [9] For example, a recent incident, called 'page view fraud', compromised the accuracy of measurement of page view by boosting the page view. Perpetrators used a tool called 'a bot' to buy fake page-views for attention, recognition, and feedback, increasing the site's value. [10] As a result, some people already started building alternatives to measure audiences, such as "Ophan", saying that the page view is becoming passe. [11]

Humans vs. machines
Fake page views can reflect bots instead of humans. [12]

Wikipedia pageviews
Wikipedia provides tools that allow one to see how many people have visited a Wikipedia article during a given time period. Such have been used for tools that for instance display the most popular articles of the day. [13] Wikipedia pageviews have been used for stock market moves, [14] prediction of movie box office success, [15] spread of disease [16] [17] among other applications of datamining . Since search engines directly influence what is popular on Wikipedia such statistics may provide a more unfiltered and real–time view into what people are searching for on the Web [18] and societal interests. [19] For instance they can be used to gain insights into public anxiety and information seeking after or during events [20] or for the identification of concepts with significant increase of interest from the public. [21] A 2015 study examines the influence of reddit posts on Wikipedia pageviews. [22]

See also
WebPage index: 00032
Stigmergy
Stigmergy is a consensus social network mechanism of indirect coordination , through the environment, between agents or actions. [1] The principle is that the trace left in the environment by an action stimulates the performance of a next action, by the same or a different agent. In that way, subsequent actions tend to reinforce and build on each other, leading to the spontaneous emergence of coherent, apparently systematic activity. [2]
Stigmergy is a form of self-organization social network . It produces complex, seemingly intelligent structures, without need for any planning, control, or even direct communication between the agents. As such it supports efficient collaboration between extremely simple agents, who lack any memory, intelligence or even individual awareness of each other. [1] [3]

History
The term "stigmergy" was introduced by French biologist Pierre-Paul Grassé in 1959 to refer to termite behavior. He defined it as: "Stimulation of workers by the performance they have achieved." It is derived from the Greek words στίγμα stigma "mark, sign" and ἔργον ergon "work, action", and captures the notion that an agent’s actions leave signs in the environment, signs that it and other agents sense and that determine and incite their subsequent actions. [4] [5]
Later on, a distinction was made between the stigmergic phenomenon, which is specific to the guidance of additional work, and the more general, non-work specific incitation, for which the term sematectonic communication was coined [6] by E. O. Wilson , from the Greek words σῆμα sema "sign, token", and τέκτων tecton "craftsman, builder": "There is a need for a more general, somewhat less clumsy expression to denote the evocation of any form of behavior or physiological change by the evidences of work performed by other animals, including the special case of the guidance of additional work."
Stigmergy is now one of the key [7] concepts in the field of swarm intelligence .

Stigmergic behavior in lower organisms
Stigmergy was first observed in social insects . For example, ants exchange information by laying down pheromones (the trace) on their way back to the nest when they have found food. In that way, they collectively develop a complex network of trails, connecting the nest in the most efficient way to the different food sources. When ants come out of the nest searching for food, they are stimulated by the pheromone to follow the trail towards the food source. The network of trails functions as a shared external memory for the ant colony.
In computer science, this general method has been applied in a variety of techniques called ant colony optimization , which search for solutions to complex problems by depositing "virtual pheromones" along paths that appear promising.
Other eusocial creatures, such as termites , use pheromones to build their complex nests by following a simple decentralized rule set . Each insect scoops up a 'mudball' or similar material from its environment, invests the ball with pheromones, and deposits it on the ground, initially in a random spot. However, termites are attracted to their nestmates' pheromones and are therefore more likely to drop their own mudballs on top of their neighbors'. The larger the heap of mud becomes, the more attractive it is, and therefore the more mud will be added to it (positive feedback). Over time this leads to the construction of pillars, arches, tunnels and chambers. [8]
Stigmergy has even been observed in bacteria, various species of which differentiate into distinct cell types and which participate in group behaviors that are guided by sophisticated temporal and spatial control systems. [9] Spectacular examples of multicellular behavior can be found among the myxobacteria . Myxobacteria travel in swarms containing many cells kept together by intercellular molecular signals . Most myxobacteria are predatory: individuals benefit from aggregation as it allows accumulation of extracellular enzymes which are used to digest prey microorganisms. When nutrients are scarce, myxobacterial cells aggregate into fruiting bodies , within which the swarming cells transform themselves into dormant myxospores with thick cell walls. The fruiting process is thought to benefit myxobacteria by ensuring that cell growth is resumed with a group (swarm) of myxobacteria, rather than isolated cells. Similar life cycles have developed among the cellular slime molds . The best known of the myxobacteria, Myxococcus xanthus and Stigmatella aurantiaca , are studied in various laboratories as prokaryotic models of development. [10]

Analysis of human behavior
Stigmergy studied in eusocial creatures and physical systems, has been proposed as a model of analyzing some robotics systems, [11] multi- agent systems, communication in computer networks , and online communities .
On the Internet there are many collective projects where users interact only by modifying local parts of their shared virtual environment. Wikipedia is an example of this. [12] The massive structure of information available in a wiki , [13] or an open source software project such as the FreeBSD kernel [13] could be compared to a termite nest; one initial user leaves a seed of an idea (a mudball) which attracts other users who then build upon and modify this initial concept, eventually constructing an elaborate structure of connected thoughts. [14] [15]
In addition the concept of stigmergy has also been used to describe how cooperative work such as building design may be integrated. Designing a large contemporary building involves a large and diverse network of actors (e.g. architects, building engineers, static engineers, building services engineers). Their distributed activities may be partly integrated through practices of stigmergy. [16] [17]

Analysis of human social movements
The rise of open source software in the 21st century has disrupted the business models of some proprietary software providers, and open content projects like Wikipedia have threatened the business models of companies like Britannica . Researchers have studied collaborative open source projects, arguing they provide insights into the emergence of large-scale peer production and the growth of gift economy . [18]
Stigmergy also occurs with social movements, such as the arc from Wikileaks ’ cable release in Summer 2010 to the developments in global Occupy movement . [19] The Occupy movement itself operates stigmergically, with innovations developed by one node becoming part of the total movement’s common toolkit. [19]

Stigmergic society
The best way to think of a how a highly peaceful and harmonious society could emerge without a legal code is the concept of Stigmergy. [20] Heather Marsh , associated with the Occupy Movement , Wikileaks , and Anonymous , has proposed a new social system where competition as a driving force would be replaced with a more collaborative society. [21] This proposed society would not use representative democracy but new forms of governance generated by user groups and collaborative methods including stigmergy. [19] [22] [23] "With stigmergy, an initial idea is freely given, and the project is driven by the idea, not by a personality or group of personalities. No individual needs permission (competitive) or consensus (cooperative) to propose an idea or initiate a project." [19]
The Hong Kong Umbrella Movement in 2014 were quoted recommending stigmergy as a way forward. [24] [25]

See also
WebPage index: 00033
Wiki
A wiki ( i / ˈ w ɪ k i / WIK -ee ) is a website that provides collaborative modification of its content and structure directly from the web browser . In a typical wiki, text is written using a simplified markup language and often edited with the help of a rich-text editor . [1] A wiki is run using wiki software , otherwise known as a wiki engine. There are dozens of different wiki engines in use, both standalone and part of other software, such as bug tracking systems . Some wiki engines are open source , whereas others are proprietary. Some permit control over different functions (levels of access); for example, editing rights may permit changing, adding or removing material. Others may permit access without enforcing access control. Other rules may also be imposed to organize content. A wiki engine is a type of content management system , but it differs from most other such systems, including blog software , in that the content is created without any defined owner or leader, and wikis have little implicit structure, allowing structure to emerge according to the needs of the users. [2]
The online encyclopedia project Wikipedia is by far the most popular wiki-based website, and is one of the most widely viewed sites of any kind in the world, having been ranked in the top ten since 2007. [3] Wikipedia is not a single wiki but rather a collection of hundreds of wikis, one for each language. There are at least tens of thousands of other wikis in use, both public and private, including wikis functioning as knowledge management resources, notetaking tools, community websites and intranets . The English-language Wikipedia has the largest collection of articles; as of September 2016, it had over five million articles. Ward Cunningham , the developer of the first wiki software, WikiWikiWeb , originally described it as "the simplest online database that could possibly work". [4] " Wiki " (pronounced [ˈwiki] [note 1] ) is a Hawaiian word meaning "quick". [5] [6] [7]

Characteristics
Ward Cunningham and co-author Bo Leuf , in their book The Wiki Way: Quick Collaboration on the Web , described the essence of the Wiki concept as follows: [8]
A wiki enables communities of editors and contributors to write documents collaboratively. All that people require to contribute is a computer, Internet access, a web browser and a basic understanding of a simple markup language (e.g., HTML ). A single page in a wiki website is referred to as a "wiki page", while the entire collection of pages, which are usually well-interconnected by hyperlinks , is "the wiki". A wiki is essentially a database for creating, browsing, and searching through information. A wiki allows non-linear, evolving, complex and networked text, while also allowing for editor argument, debate and interaction regarding the content and formatting. [9] A defining characteristic of wiki technology is the ease with which pages can be created and updated. Generally, there is no review by a moderator or gatekeeper before modifications are accepted and thus lead to changes on the website. Many wikis are open to alteration by the general public without requiring registration of user accounts. Many edits can be made in real-time and appear almost instantly online. However, this feature facilitates abuse of the system. Private wiki servers require user authentication to edit pages, and sometimes even to read them. Maged N. Kamel Boulos , Cito Maramba and Steve Wheeler write that the open wikis produce a process of Social Darwinism . " 'Unfit' sentences and sections are ruthlessly culled, edited and replaced if they are not considered 'fit', which hopefully results in the evolution of a higher quality and more relevant page. While such openness may invite 'vandalism' and the posting of untrue information, this same openness also makes it possible to rapidly correct or restore a 'quality' wiki page." [10]

Editing
Some wikis have an "edit" button or link directly on the page being viewed, if the user has permission to edit the page. This leads to an "editing page" where participants structure and format wiki pages with a simplified markup language, sometimes known as wiki markup or wikitext. For example, starting lines of text with an asterisks creates a bulleted list . The style and syntax of wikitexts can vary greatly among wiki implementations, [ example needed ] some of which also allow HTML tags. Wikis favour plain-text editing, with fewer and simpler conventions than HTML, for indicating style and structure. Although limiting access to HTML and Cascading Style Sheets (CSS) of wikis limits user ability to alter the structure and formatting of wiki content, there are some benefits. Limited access to CSS promotes consistency in the look and feel, and having JavaScript disabled prevents a user from implementing code that may limit other users' access.
Wikis can make WYSIWYG editing available to users, usually by means of JavaScript control that translates graphically entered formatting instructions into the corresponding HTML tags or wikitext. In those implementations, the markup of a newly edited, marked-up version of the page is generated and submitted to the server transparently , shielding the user from this technical detail. An example of this is the VisualEditor on Wikipedia. However, WYSIWYG controls do not always provide all of the features available in wikitext, and some users prefer not to use a WYSIWYG editor. Hence, many of these sites offer some means to edit the wikitext directly.
Some wikis keep a record of changes made to wiki pages; often, every version of the page is stored. This means that authors can revert to an older version of the page, should it be necessary because a mistake has been made, such as the content accidentally being deleted, or the page has been vandalized to include offensive or malicious text or other content. Many implementations, like MediaWiki , allow users to supply an edit summary when they edit a page; this is a short piece of text summarizing the changes they have made (e.g., "corrected grammar" or "fixed formatting in table"). It is not inserted into the article's main text, but is stored along with that revision of the page (often in a log or "history" window), allowing users to explain what has been done and why, and enabling other users to see which changes have been made; this is similar to a log message when making changes to a revision-control system.

Navigation
Within the text of most pages, there are usually a large number of hypertext links to other pages within the wiki. This form of non-linear navigation is more "native" to a wiki than structured/formalized navigation schemes. Users can also create any number of index or table-of-contents pages, with hierarchical categorization or whatever form of organization they like. These may be challenging to maintain "by hand", as multiple authors and users may create and delete pages in an ad hoc , unorganized manner. Wikis can provide one or more ways to categorize or tag pages to support the maintenance of such index pages. Some wikis, including the original, have a backlink feature, which displays all pages that link to a given page. It is also typically possible in a wiki to create links to pages that do not yet exist, as a way to invite others to share what they know about a subject new to the wiki. Wiki users can typically "tag" pages with categories or keywords, to make it easier for other users to find the article. For example, a user creating a new article on cold weather cycling might "tag" this page under the categories of commuting, winter sports and bicycling. This would make it easier for other users to find the article.

Linking and creating pages
Links are created using a specific syntax, the so-called "link pattern". Originally, most wikis [ citation needed ] used CamelCase to name pages and create links. These are produced by capitalizing words in a phrase and removing the spaces between them (the word "CamelCase" is itself an example). While CamelCase makes linking easy, it also leads to links in a form that deviates from the standard spelling. To link to a page with a single-word title, one must abnormally capitalize one of the letters in the word (e.g. "WiKi" instead of "Wiki"). CamelCase-based wikis are instantly recognizable because they have many links with names such as "TableOfContents" and "BeginnerQuestions." It is possible for a wiki to render the visible anchor of such links "pretty" by reinserting spaces, and possibly also reverting to lower case. However, this reprocessing of the link to improve the readability of the anchor is limited by the loss of capitalization information caused by CamelCase reversal. For example, "RichardWagner" should be rendered as "Richard Wagner", whereas "PopularMusic" should be rendered as "popular music". There is no easy way to determine which capital letters should remain capitalized. As a result, many wikis now have "free linking" using brackets, and some disable CamelCase by default.

Searching
Most wikis offer at least a title search , and sometimes a full-text search . The scalability of the search depends on whether the wiki engine uses a database. Some wikis, such as PmWiki , use flat files . [11] MediaWiki's first versions used flat files, but it was rewritten by Lee Daniel Crocker in the early 2000s (decade) to be a database application. Indexed database access is necessary for high speed searches on large wikis. Alternatively, external search engines such as Google Search can sometimes be used on wikis with limited searching functions in order to obtain more precise results.

History
WikiWikiWeb was the first wiki. [12] Ward Cunningham started developing WikiWikiWeb in Portland, Oregon, in 1994, and installed it on the Internet domain c2.com on March 25, 1995. It was named by Cunningham, who remembered a Honolulu International Airport counter employee telling him to take the " Wiki Wiki Shuttle " bus that runs between the airport's terminals. According to Cunningham, "I chose wiki-wiki as an alliterative substitute for 'quick' and thereby avoided naming this stuff quick-web." [13] [14]
Cunningham was, in part, inspired by Apple's HyperCard , which he had used. Hypercard, however, was single-user. [15] Apple had designed a system allowing users to create virtual "card stacks" supporting links among the various cards. Cunningham developed Vannevar Bush 's ideas by allowing users to "comment on and change one another's text." [1] [16] Cunningham says his goals were to link together the experiences of multiple people to create a new literature to document programming patterns , and to harness people's natural desire to talk and tell stories with a technology that would feel comfortable to those not used to "authoring". [15]
Wikipedia became the most famous wiki site, entering the top ten most popular websites in 2007. In the early 2000s (decade), wikis were increasingly adopted in enterprise as collaborative software. Common uses included project communication, intranets, and documentation, initially for technical users. Some companies use wikis as their only collaborative software and as a replacement for static intranets, and some schools and universities use wikis to enhance group learning . There may be greater use of wikis behind firewalls than on the public Internet. On March 15, 2007, the word wiki was listed in the online Oxford English Dictionary . [17]

Alternative definitions
In the late 1990s and early 2000s, the word "wiki" was used to refer to both user-editable websites and the software that powers them; the latter definition is still occasionally in use. [2] Wiki inventor Ward Cunningham wrote in 2014 [18] that the word "wiki" should not be used to refer to a single website, but rather to a mass of user-editable pages and or sites, so that a single website is not "a wiki" but "an instance of wiki". He wrote that the concept of wiki federation, in which the same content can be hosted and edited in more than one location in a manner similar to distributed version control , meant that the concept of a single discrete "wiki" no longer made sense. [19]

Implementations
Wiki software is a type of collaborative software that runs a wiki system, allowing web pages to be created and edited using a common web browser. It may be implemented as a series of scripts behind an existing web server , or as a standalone application server that runs on one or more web servers. The content is stored in a file system , and changes to the content are stored in a relational database management system . A commonly implemented software package is MediaWiki , which runs Wikipedia . Alternatively, personal wikis run as a standalone application on a single computer. WikidPad is an example. One application, TiddlyWiki , simply makes use of an even single local HTML file with JavaScript inside.
Wikis can also be created on a " wiki farm ", where the server-side software is implemented by the wiki farm owner. PBwiki , Socialtext , and Wikia are popular examples of such services. Some wiki farms can also make private, password-protected wikis. Note that free wiki farms generally contain advertising on every page. For more information, see Comparison of wiki farms .

Trust and security

Controlling changes
Wikis are generally designed with the philosophy of making it easy to correct mistakes, rather than making it difficult to make them. Thus, while wikis are very open, they provide a means to verify the validity of recent additions to the body of pages. The most prominent, on almost every wiki, is the "Recent Changes" page—a specific list numbering recent edits, or a list of edits made within a given time frame. [20] Some wikis can filter the list to remove minor edits and edits made by automatic importing scripts (" bots "). [21] From the change log, other functions are accessible in most wikis: the revision history shows previous page versions and the diff feature highlights the changes between two revisions. Using the revision history, an editor can view and restore a previous version of the article. The diff feature can be used to decide whether or not this is necessary. A regular wiki user can view the diff of an edit listed on the "Recent Changes" page and, if it is an unacceptable edit, consult the history, restoring a previous revision; this process is more or less streamlined, depending on the wiki software used. [22]
In case unacceptable edits are missed on the "recent changes" page, some wiki engines provide additional content control. It can be monitored to ensure that a page, or a set of pages, keeps its quality. A person willing to maintain pages will be warned of modifications to the pages, allowing him or her to verify the validity of new editions quickly. [23] A watchlist is a common implementation of this. Some wikis also implement "patrolled revisions", in which editors with the requisite credentials can mark some edits as not vandalism. A "flagged revisions" system can prevent edits from going live until they have been reviewed. [24]

Trustworthiness and reliability of content
Critics of publicly editable wiki systems argue that these systems could be easily tampered with by malicious individuals ("vandals") or even by well-meaning but unskilled users who introduce errors into the content. While proponents argue that the community of users can catch malicious content and correct it. [1] Lars Aronsson , a data systems specialist, summarizes the controversy as follows: "Most people, when they first learn about the wiki concept, assume that a Web site that can be edited by anybody would soon be rendered useless by destructive input. It sounds like offering free spray cans next to a grey concrete wall. The only likely outcome would be ugly graffiti and simple tagging, and many artistic efforts would not be long lived. Still, it seems to work very well." [12] High editorial standards in medicine and health sciences articles, in which users typically use peer-reviewed journals or university textbooks as sources, have led to the idea of expert-moderated wikis. [25] Some wikis allow one to link to specific versions of articles, which has been useful to the scientific community, in that expert peer reviewers could analyse articles, improve them and provide links to the trusted version of that article. [26] Noveck points out that "participants are accredited by members of the wiki community, who have a vested interest in preserving the quality of the work product, on the basis of their ongoing participation." On controversial topics that have been subject to disruptive editing, a wiki may restrict editing to registered users. [27]

Security
The open philosophy of wiki – allowing anyone to edit content – does not ensure that every editor's intentions are well-mannered. For example, vandalism (changing wiki content to something offensive, adding nonsense or deliberately adding incorrect information, such as hoax information) can be a major problem. On larger wiki sites, such as those run by the Wikimedia Foundation , vandalism can go unnoticed for some period of time. Wikis, because of their open nature, are susceptible to intentional disruption, known as " trolling ". Wikis tend to take a soft-security [28] [ unreliable source ] approach to the problem of vandalism, making damage easy to undo rather than attempting to prevent damage. Larger wikis often employ sophisticated methods, such as bots that automatically identify and revert vandalism and JavaScript enhancements that show characters that have been added in each edit. In this way vandalism can be limited to just "minor vandalism" or "sneaky vandalism", where the characters added/eliminated are so few that bots do not identify them and users do not pay much attention to them. [29] [ unreliable source ] An example of a bot that reverts vandalism on Wikipedia is ClueBot NG. ClueBot NG can revert edits, often within minutes, if not seconds. The bot uses machine learning in lieu of heuristics . [30]
The amount of vandalism a wiki receives depends on how open the wiki is. For instance, some wikis allow unregistered users, identified by their IP addresses , to edit content, while others limit this function to just registered users. Most wikis allow anonymous editing without an account, [31] but give registered users additional editing functions; on most wikis, becoming a registered user is a short and simple process. Some wikis require an additional waiting period before gaining access to certain tools. For example, on the English Wikipedia , registered users can rename pages only if their account is at least four days old and has made at least ten edits. Other wikis such as the Portuguese Wikipedia use an editing requirement instead of a time requirement, granting extra tools after the user has made a certain number of edits to prove their trustworthiness and usefulness as an editor. Vandalism of Wikipedia is common (though policed and usually reverted) because it is extremely open, allowing anyone with a computer and Internet access to edit it, although this makes it grow rapidly. In contrast, Citizendium requires an editor's real name and short autobiography, affecting the growth of the wiki but sometimes helping stop vandalism.
Edit wars can also occur as users repetitively revert a page to the version they favor. In some cases, editors with opposing views of which content should appear or what formatting style should be used will change and re-change each other's edits. This results in the page being "unstable" from a general users' perspective, because each time a general user comes to the page, it may look different. Some wiki software allows an administrator to stop such edit wars by locking a page from further editing until a decision has been made on what version of the page would be most appropriate. [9] Some wikis are in a better position than others to control behavior due to governance structures existing outside the wiki. For instance, a college teacher can create incentives for students to behave themselves on a class wiki they administer by limiting editing to logged-in users and pointing out that all contributions can be traced back to the contributors. Bad behavior can then be dealt with in accordance with university policies. [11] The issue of wiki vandalism is debated. In some cases, when an editor deletes an entire article and replaces it with nonsense content, it may be a "test edit", made by the user as she or he is experimenting with the wiki system. Some editors may not realize that they have damaged the page, or if they do realize it, they may not know how to undo the mistake or restore the content.

Potential malware vector
Malware can also be problem for wikis, as users can add links to sites hosting malicious code. For example, a German Wikipedia article about the Blaster Worm was edited to include a hyperlink to a malicious website. Users of vulnerable Microsoft Windows systems who followed the link would be infected. [9] A countermeasure is the use of software that prevents users from saving an edit that contains a link to a site listed on a blacklist of malware sites. [32]

Communities

Applications
The English Wikipedia has the largest user base among wikis on the World Wide Web [33] and ranks in the top 10 among all Web sites in terms of traffic. [34] Other large wikis include the WikiWikiWeb , Memory Alpha , Wikivoyage and Susning.nu , a Swedish-language knowledge base. Medical and health-related wiki examples include Ganfyd , an online collaborative medical reference that is edited by medical professionals and invited non-medical experts. [10] Many wiki communities are private, particularly within enterprises . They are often used as internal documentation for in-house systems and applications. Some companies use wikis to allow customers to help produce software documentation. [35] A study of corporate wiki users found that they could be divided into "synthesizers" and "adders" of content. Synthesizers' frequency of contribution was affected more by their impact on other wiki users, while adders' contribution frequency was affected more by being able to accomplish their immediate work. [36] from a study of 1000s of wiki deployments,Jonathan Grudin concluded careful stakeholder analysis and education are crucial to successful wiki deployment. [37]
In 2005, the Gartner Group, noting the increasing popularity of wikis, estimated that they would become mainstream collaboration tools in at least 50% of companies by 2009. [38] [ needs update ] Wikis can be used for project management . [39] [40] [ unreliable source ] Wikis have also been used in the academic community for sharing and dissemination of information across institutional and international boundaries. [41] In those settings, they have been found useful for collaboration on grant writing , strategic planning , departmental documentation, and committee work. [42] In the mid-2000s (decade), the increasing trend among industries toward collaboration was placing a heavier impetus upon educators to make students proficient in collaborative work, inspiring even greater interest in wikis being used in the classroom. [9]
Wikis have found some use within the legal profession, and within government. Examples include the Central Intelligence Agency 's Intellipedia , designed to share and collect intelligence , dKospedia, which was used by the American Civil Liberties Union to assist with review of documents pertaining to internment of detainees in Guantánamo Bay ; [43] and the wiki of the United States Court of Appeals for the Seventh Circuit , used to post court rules and allow practitioners to comment and ask questions. The United States Patent and Trademark Office operates Peer-to-Patent , a wiki to allow the public to collaborate on finding prior art relevant to examination of pending patent applications. Queens , New York has used a wiki to allow citizens to collaborate on the design and planning of a local park. Cornell Law School founded a wiki-based legal dictionary called Wex, whose growth has been hampered by restrictions on who can edit. [27]

City wikis
A city wiki (or local wiki) is a wiki used as a knowledge base and social network for a specific geographical locale. [44] [45] [46] The term 'city wiki' or its foreign language equivalent (e.g. German 'Stadtwiki') is sometimes also used for wikis that cover not just a city, but a small town or an entire region. A city wiki contains information about specific instances of things, ideas, people and places. Much of this information might not be appropriate for encyclopedias such as Wikipedia (e.g., articles on every retail outlet in a town), but might be appropriate for a wiki with more localized content and viewers. A city wiki could also contain information about the following subjects, that may or may not be appropriate for a general knowledge wiki, such as:

WikiNodes
WikiNodes are pages on wikis that describe related wikis. They are usually organized as neighbors and delegates. A neighbor wiki is simply a wiki that may discuss similar content or may otherwise be of interest. A delegate wiki is a wiki that agrees to have certain content delegated to that wiki. [47] One way of finding a wiki on a specific subject is to follow the wiki-node network from wiki to wiki; another is to take a Wiki "bus tour", for example: Wikipedia's Tour Bus Stop .

Participants
The four basic types of users who participate in wikis are reader, author, wiki administrator and system administrator. The system administrator is responsible for installation and maintenance of the wiki engine and the container web server. The wiki administrator maintains wiki content and is provided additional functions pertaining to pages (e.g. page protection and deletion), and can adjust users' access rights by, for instance, blocking them from editing. [48]

Growth factors
A study of several hundred wikis showed that a relatively high number of administrators for a given content size is likely to reduce growth; [49] that access controls restricting editing to registered users tends to reduce growth; that a lack of such access controls tends to fuel new user registration; and that higher administration ratios (i.e. admins/user) have no significant effect on content or population growth. [50]

Conferences
Active conferences and meetings about wiki-related topics include:
Former wiki-related events include:

Rules
Wikis typically have a set of rules governing user behavior. Wikipedia, for instance, has a labyrinthine set of policies and guidelines summed up in its five pillars: Wikipedia is an encyclopedia; Wikipedia has a neutral point of view; Wikipedia is free content; Wikipedians should interact in a respectful and civil manner; and Wikipedia does not have firm rules. Many wikis have adopted a set of commandments. For instance, Conservapedia commands, among other things, that its editors use " B.C. " rather than " B.C.E. " when referring to years prior to C.E. 1 and refrain from "unproductive activity." [55] One teacher instituted a commandment for a class wiki, " Wiki unto others as you would have them wiki unto you ." [11]

Legal environment
Joint authorship of articles, in which different users participate in correcting, editing, and compiling the finished product, can also cause editors to become tenants in common of the copyright, making it impossible to republish without permission of all co-owners, some of whose identities may be unknown due to pseudonymous or anonymous editing. [9] However, where persons contribute to a collective work such as an encyclopedia, there is no joint ownership if the contributions are separate and distinguishable. [56] Despite most wikis' tracking of individual contributions, the action of contributing to a wiki page is still arguably one of jointly correcting, editing, or compiling, which would give rise to joint ownership. Some copyright issues can be alleviated through the use of an open content license. Version 2 of the GNU Free Documentation License includes a specific provision for wiki relicensing; Creative Commons licenses are also popular. When no license is specified, an implied license to read and add content to a wiki may be deemed to exist on the grounds of business necessity and the inherent nature of a wiki, although the legal basis for such an implied license may not exist in all circumstances. [ citation needed ]
Wikis and their users can be held liable for certain activities that occur on the wiki. If a wiki owner displays indifference and forgoes controls (such as banning copyright infringers) that he could have exercised to stop copyright infringement, he may be deemed to have authorized infringement, especially if the wiki is primarily used to infringe copyrights or obtains direct financial benefit, such as advertising revenue, from infringing activities. [9] In the United States, wikis may benefit from Section 230 of the Communications Decency Act , which protects sites that engage in " Good Samaritan " policing of harmful material, with no requirement on the quality or quantity of such self-policing. [57] However, it has also been argued that a wiki's enforcement of certain rules, such as anti-bias, verifiability, reliable sourcing, and no-original-research policies, could pose legal risks. [58] When defamation occurs on a wiki, theoretically all users of the wiki can be held liable, because any of them had the ability to remove or amend the defamatory material from the "publication." It remains to be seen whether wikis will be regarded as more akin to an internet service provider , which is generally not held liable due to its lack of control over publications' contents, than a publisher. [9] It has been recommended that trademark owners monitor what information is presented about their trademarks on wikis, since courts may use such content as evidence pertaining to public perceptions. Joshua Jarvis notes, "Once misinformation is identified, the trade mark owner can simply edit the entry." [59]

See also

Notes
WebPage index: 00034
Wikipedia Seigenthaler biography incident
In May 2005, an anonymous editor posted a hoax article in the online encyclopedia Wikipedia about journalist John Seigenthaler . [1] The article falsely stated that Seigenthaler had been a suspect in the assassinations of U.S. President John F. Kennedy and U.S. Attorney General Robert F. Kennedy . The then-78-year-old Seigenthaler, a friend and aide to Robert Kennedy, characterized the Wikipedia article about him as "Internet character assassination". [2]
The hoax was not discovered and corrected until September of that year, after which Seigenthaler wrote about his experience in USA Today . The incident raised questions about the reliability of Wikipedia and other websites with user-generated content that lack the legal accountability of traditional newspapers and published materials. [3] In a December 13 interview, [4] co-founder Jimmy Wales expressed his undiminished support for Wikipedia policy allowing articles to be edited by anonymous users – describing the participation of editors in China and Iran in terms of privacy issues – but announced plans to roll back their article creation privileges as part of a vandalism-control strategy: "...we've decided that we want to slow down...so starting in January we're preventing unregistered users from creating new pages, because so often those have to be deleted...". [4]

Hoax
The author of the hoax article was later identified as Brian Chase, an operations manager of Rush Delivery, a delivery service company in Nashville, Tennessee . [5] On May 26, 2005, Chase added a new article that contained, in its entirety, the following text:

Detection and correction
In September, Victor S. Johnson, Jr. , a friend of Seigenthaler's, discovered the article. [6] After Johnson alerted him to the article, Seigenthaler e-mailed his friends and colleagues about it. On September 23, 2005, colleague Eric Newton copied Seigenthaler's official biography from the Freedom Forum web site into Wikipedia. The following day, this biography was removed by a Wikipedia editor due to copyright violation , and was replaced with a short original biography. [7] Newton informed Seigenthaler of his action when he ran into Seigenthaler in November in New York at the Committee to Protect Journalists dinner.
In October 2005, Seigenthaler contacted the Chair of the Board of Trustees of the Wikimedia Foundation, Jimmy Wales , who hid affected versions of the article history from public view in the Wikipedia version logs, in effect removing them from all but Wikipedia administrators ' view. [8] In 2013, the hoax article was undeleted and archived to Wikipedia:List of hoaxes on Wikipedia . Some mirror websites not controlled by Wikipedia continued to display the older and inaccurate article for several weeks until the new version of the article was propagated to these other websites. [9]

Anonymous editor identified
Seigenthaler wrote an op-ed article describing the particulars of the incident, which appeared in USA Today , of which he had been the founding editorial director. [2] The article was published on November 29, 2005. In the article, he included a verbatim reposting of the false statements and called Wikipedia a "flawed and irresponsible research tool." An expanded version was published several days later in The Tennessean , a daily newspaper in Nashville, Tennessee, where Seigenthaler had served in various capacities from beat reporter to chairman. In the article, Seigenthaler detailed his own failed attempts to identify the anonymous person who posted the inaccurate biography. He reported that he had asked the poster's Internet service provider , BellSouth , to identify its user from the user's IP address . BellSouth refused to identify the user without a court order, suggesting that Seigenthaler file a John Doe lawsuit against the user, which Seigenthaler declined to do.
Daniel Brandt, a San Antonio activist who had started the anti-Wikipedia site "Wikipedia Watch" in response to objections he had to his eponymous article, looked up the IP address in Seigenthaler's article, and found that it related to "Rush Delivery", a company in Nashville. He contacted Seigenthaler and the media, and posted this information on his website. [10]
On December 9, Brian Chase admitted he had posted the false biography to Wikipedia because he believed Wikipedia to be "some sort of joke Web site." [11] After confessing, Chase was fired from his job at Rush Delivery. Seigenthaler received a hand-written apology [ clarification needed ] and spoke with Chase on the phone. Seigenthaler confirmed – as he had previously stated – that he would not file a lawsuit in relation to the incident, and urged Rush Delivery to rehire Chase, which it did. Seigenthaler commented: "I'm glad this aspect of it is over." He stated that he was concerned that "every biography on Wikipedia is going to be hit by this stuff – think what they'd do to Tom DeLay and Hillary Clinton , to mention two. My fear is that we're going to get government regulation of the Internet as a result." [12]

Reactions

Seigenthaler's public reaction
In his November 29, 2005, USA Today editorial, Seigenthaler criticized Congress for Section 230 of the Communications Decency Act , which protects ISPs and web sites from being held legally responsible for content posted by their customers and users: [2]
On December 5, 2005, Seigenthaler and Wales appeared jointly on CNN to discuss the matter. On December 6, 2005, the two were interviewed on National Public Radio 's Talk of the Nation radio program. Wales described a new policy that he had implemented in order to prevent unregistered users from creating new articles on the English-language Wikipedia, though their ability to edit existing articles was retained.
In the CNN interview, Seigenthaler also raised the spectre of increased government regulation of the Web:
In the December 6 joint NPR interview, Seigenthaler said that he did not want to have anything to do with Wikipedia because he disapproved of its basic assumptions. In an article Seigenthaler wrote for USA Today in late 2005, he said, "I am interested in letting many people know that Wikipedia is a flawed and irresponsible research tool." [2] He also pointed out that the false information had been online for over four months before he was aware of it, and that he had not been able to edit the article to correct it. After speaking with Wikipedia co-founder, Jimmy Wales, Seigenthaler said: "My 'biography' was posted May 26. On May 29, one of Wales' volunteers 'edited' it only by correcting the misspelling of the word 'early.' For four months, Wikipedia depicted me as a suspected assassin before I erased it from the website's history Oct. 5. The falsehoods remained on Answers.com and Reference.com for three more weeks." [2] Editing Wikipedia, he suggested, would lend it his sanction or approval, and he stated his belief that editing the article was not enough and instead he wanted to expose "incurable flaws" in the Wikipedia process and ethos.
On December 9, Seigenthaler appeared on C-SPAN 's Washington Journal with Brian Lamb hosting. He said he was concerned that other pranksters would try to spoof members of Congress or other powerful figures in government, which may then prompt a backlash and turn back First Amendment rights on the Web.
In the June 2007 issue of Reason magazine, Seigenthaler also expressed concern about the lack of transparency underlined by Wales' removal of the hoax pages from the article's history page. He has also stated that many of the comments left by users in the edit summaries are things he would not want his nine-year-old grandson to see. [13]

Wikimedia Foundation reaction
In an interview with BusinessWeek on December 13, 2005, Wales discussed the reasons the hoax had gone undetected and steps being taken to address them. [4] He stated that one problem was that Wikipedia's use had grown faster than its self-monitoring system could comfortably handle, and that therefore new page creation would be deliberately restricted to account-holders only, addressing one of Seigenthaler's main criticisms.
He also gave his opinion that encyclopedias as a whole (whether print or online) were not usually appropriate for primary sources and should not be relied upon as authoritative (as some were doing), but that nonetheless Wikipedia was more reliable as "background reading" on subjects than most online sources. He stated that Wikipedia was a "work in progress". [4]
A variety of changes were also made to Wikipedia's software and working practices, to address some of the issues arising. A new policy, ' biographies of living persons ', was created on December 17, 2005; editorial restrictions, including reference requirements, were introduced on the creation of new Wikipedia articles; and new tracking categories for the biographies of living people were implemented. [14]
The Foundation added a new level of "oversight" features to the MediaWiki software, [15] accessible as of May 16, 2012 to around 37 experienced editors and Wikimedia staff members nominated by either Wales or the Arbitration Committee . This originally allowed for specific historical versions to be hidden from everyone (including Oversight editors), which then become unable to be viewed by anyone except developers via manual intervention, though the feature was later changed so that other Oversighters could view these revisions to monitor the tool's use. Currently such procedures are standardized by the 'Office actions' policy which states: "Sometimes the Wikimedia Foundation has to delete, protect or blank a page without going through the normal site/community process(es). These edits are temporary measures to prevent legal trouble or personal harm and should not be undone by any user." [16]

Other reactions
In reaction to the controversy, The New York Times business editor Larry Ingrassia sent out a memo to his entire staff commenting on the reliability of Wikipedia and writing, "We shouldn't be using it to check any information that goes into the newspaper." [17] Several other publications commented on the incident, often criticizing Wikipedia and its open editing model as unreliable, citing the Seigenthaler incident as evidence.
The scientific journal Nature conducted a study comparing the accuracy of Wikipedia and the Encyclopædia Britannica in 42 hard sciences related articles in December 2005. The Wikipedia articles studied were found to contain four serious errors and 162 factual errors, omissions or misleading statements, while the Encyclopædia Britannica also contained four serious errors and 123 factual errors, omissions or misleading statements. [18] Referring to the Seigenthaler incident and several other controversies, the authors wrote that the study "suggests that such high-profile examples are the exception rather than the rule."

See also
WebPage index: 00035
60 Minutes
60 Minutes is an American newsmagazine television program broadcast on the CBS television network. Debuting in 1968, the program was created by Don Hewitt , who chose to set it apart from other news programs by using a unique style of reporter-centered investigation. In 2002, 60 Minutes was ranked #6 on TV Guide's 50 Greatest TV Shows of All Time [3] and in 2013, it was ranked #24 on TV Guide's 60 Best Series of All Time. [4] The New York Times has called it "one of the most esteemed news magazines on American television". [5]

Broadcast history

Early years
The program employed a magazine format, similar to that of the Canadian program W5 , which had premiered two years earlier. It pioneered many of the most important investigative journalism procedures and techniques, including re-editing interviews, hidden cameras, and " gotcha journalism " visits to the home or office of an investigative subject. [7] Similar programs sprang up in Australia and Canada during the 1970s, as well as on local television news. [7]
Initially, 60 Minutes aired as a bi-weekly show hosted by Harry Reasoner and Mike Wallace , debuting on September 24, 1968, and alternating weeks with other CBS News productions on Tuesday evenings at 10:00 p.m. Eastern Time . The first edition, described by Reasoner in the opening as a "kind of a magazine for television," featured the following segments:
The first "magazine-cover" chroma key was a photo of two helmeted policemen (for the Clark interview segment). Wallace and Reasoner sat in chairs on opposite sides of the set, which had a cream-colored backdrop; the more famous black backdrop (which is still used as of 2015 [update] ) did not appear until the following year. The logo was in Helvetica type with the word "Minutes" spelled in all lower-case letters; the logo most associated with the show (rendered in Eurostile type with "Minutes" spelled in uppercase) did not appear until about 1974. Further, to extend the magazine motif, the producers added a "Vol. xx, No. xx" to the title display on the chroma key; modeled after the volume and issue number identifications featured in print magazines, this was used until about 1971. The trademark stopwatch, however, did not appear on the inaugural broadcast; it would not debut until several episodes later. Alpo dog food was the sole sponsor of the first program. [2]
Don Hewitt, who had been a producer of the CBS Evening News with Walter Cronkite , sought out Wallace as a stylistic contrast to Reasoner. [8] According to one historian of the show, the idea of the format was to make the hosts the reporters, to always feature stories that were of national importance but focused upon individuals involved with, or in conflict with, those issues, and to limit the reports' airtime to around 13 minutes. [8] However, the initial season was troubled by lack of network confidence, as the program did not garner ratings much higher than that of other CBS News documentaries. As a rule, during that era, news programming during prime time lost money; networks mainly scheduled public affairs programs in prime time in order to bolster the prestige of their news departments, and thus boost ratings for the regular evening newscasts, which were seen by far more people than documentaries and the like. 60 Minutes struggled under that stigma during its first three years.
Changes to 60 Minutes came fairly early in the program's history. When Reasoner left CBS to co-anchor ABC 's evening newscast (he would return to CBS and 60 Minutes in 1978), Morley Safer joined the team in 1970, and he took over Reasoner's duties of reporting less aggressive stories. However, when Richard Nixon began targeting press access and reporting, even Safer, formerly the CBS News bureau chief in Saigon and London , began to do "hard" investigative reports, and during the 1970–71 season alone 60 Minutes reported on cluster bombs , the South Vietnamese Army , draft dodgers , Nigeria , the Middle East, and Northern Ireland . [9]

Effects from the Prime Time Access Rule
By 1971, the Federal Communications Commission (FCC) introduced the Prime Time Access Rule , which freed local network affiliates in the top 50 markets (in practice, the entire network) to take a half-hour of prime time from the networks on Mondays through Saturdays and one full hour on Sundays. Because nearly all affiliates found production costs for the FCC's intended goal of increased public affairs programming very high and the ratings (and by association, advertising revenues) low, making it mostly unprofitable, the FCC created an exception for network-authored news and public affairs shows. After a six-month hiatus in late 1971, CBS found a prime place for 60 Minutes in a portion of that displaced time, 6:00 to 7:00 p.m. (Eastern; 5:00 to 6:00 Central Time on Sundays, in January 1972. [9]
This proved somewhat less than satisfactory, however, because in order to accommodate CBS ' telecasts of late afternoon National Football League (NFL) football games, 60 Minutes went on hiatus during the fall from 1972 to 1975 (and the summer of 1972). This took place because football telecasts were protected contractually from interruptions in the wake of the infamous " Heidi Bowl " incident on NBC in November 1968. Despite the irregular scheduling, the program's hard-hitting reports attracted a steadily growing audience, particularly during the waning days of the Vietnam War and the gripping events of the Watergate scandal ; at that time, few if any other major network news shows did in-depth investigative reporting to the degree carried out by 60 Minutes. Eventually, during the summers of 1973 through 1975, CBS did allow the program back onto the prime time schedule proper, on Fridays in 1973 and Sundays the two years thereafter, as a replacement for programs aired during the regular television season.
It was only when the FCC returned an hour to the networks on Sundays (for children's/family or news programming), which had been taken away from them four years earlier, in a 1975 amendment to the Access Rule that CBS finally found a viable permanent timeslot for 60 Minutes. When a family-oriented drama, Three for the Road , ended after a 12-week run in the fall, the newsmagazine took its place at 7:00 p.m. Eastern Time (6:00 Central) on December 7. It has aired at that time since, for 40 years as of 2015 [update] , making 60 Minutes not only the longest-running prime time program currently in production, but also the television program (excluding daily programs such as evening newscasts or morning news-talk shows) broadcasting for the longest length of time at a single time period each week in U.S. television history. [ citation needed ]
This move, and the addition of then- White House correspondent Dan Rather to the reporting team, made the program into a strong ratings hit and, eventually, a general cultural phenomenon. This was no less than a stunning reversal of the historically poor ratings performances of documentary programs on network television. By 1976, 60 Minutes became the top-rated program on Sunday nights in the U.S. By 1979, it had achieved the #1 spot among all television programs in the Nielsen ratings , unheard of before for a news broadcast in prime time. This success translated into great profits for CBS; advertising rates went from $17,000 per 30-second spot in 1975 to $175,000 in 1982. [10]
The program sometimes does not start until after 7:00 p.m. Eastern, due largely to CBS' live broadcast of NFL games. At the conclusion of an NFL game, 60 Minutes will air in its entirety. However, on the West Coast (and all of the Mountain Time Zone ), because the actual end of the live games is much earlier in the afternoon in comparison to the Eastern and Central time zones, 60 Minutes is always able to start at its normal start time of 7:00 p.m. Pacific Time , leaving affiliates free to broadcast local news, the CBS Evening News , and other local or syndicated programming leading up to 60 Minutes . The program's success has also led CBS Sports to schedule events (such as the Masters Tournament and daytime games of the NCAA Men's Basketball Tournament ) leading into 60 Minutes and the rest of the network's primetime lineup, thus (again, except on the West Coast) pre-empting the Sunday editions of the CBS Evening News and affiliates' local newscasts.
With complaints of late starts because of late NFL games, starting in the 2012-13 season, CBS officially changed the start time of 60 Minutes to 7:30 p.m. Eastern time on Sundays when the network is scheduled to air an NFL doubleheader (there are nine during the NFL season – eight during the first 16 weeks of the season, and the final week). [11]

Pre-emptions since 1978
The program has rarely been pre-empted since 1978. Two notable pre-emptions occurred in 1976 and 1977, to make room for the annual telecast of The Wizard of Oz , which had recently returned to CBS after having been shown on NBC for eight years. However, CBS would, in later years, schedule the film so that it would no longer pre-empt 60 Minutes . Another exception is on years when CBS airs the Super Bowl or since 2003, alternating years where the AFC Championship Game has the 6:30 p.m. Eastern start time, which is played into prime-time and followed by a special lead-out program. [ citation needed ]
On September 22, 2013, CBS chose to pre-empt 60 Minutes as a result of carrying the 65th Primetime Emmy Awards after an NFL doubleheader. [12]

Radio broadcast and Internet distribution
60 Minutes is also simulcast on several CBS Radio stations ( such as KYW in Philadelphia, WCBS in New York City , KNX in Los Angeles , WBBM in Chicago , WWJ in Detroit and KCBS in San Francisco ) when it airs locally on their sister CBS Television Network affiliate; even in the Central and Eastern time zones, the show is aired at the top of the hour at 7 p.m./6 p.m Central (barring local sports play-by-play pre-emptions and breaking news coverage) no matter how long the show is delayed on CBS Television, resulting in radio listeners often hearing the show on those stations ahead of the television broadcast. An audio version of each broadcast without advertising began to be distributed via podcast and the iTunes Store , starting with the September 23, 2007 broadcast. [13] Video from 60 Minutes (including full episodes) is also made available for streaming several hours after the program's initial broadcast on CBSNews.com and CBS Interactive property CNET TV .

Format
60 Minutes consists of three long-form news stories, without superimposed graphics. There is a commercial break between two stories. Each story is introduced from a set with a backdrop resembling pages from a magazine story on the same topic. The program undertakes its own investigations and follows up on investigations instigated by national newspapers and other sources. Unlike its most famous competitor 20/20 as well as traditional local and national news programs, the 60 Minutes journalists never share the screen with (or speak to) other 60 Minutes journalists on camera at any time. This creates a strong psychological sense of intimacy between the journalist and the television viewer.

Reporting tone
60 Minutes blends the probing journalism of the seminal 1950s CBS series See It Now with Edward R. Murrow (a show for which Hewitt served as the director for its first few years) and the personality profiles of another Murrow program, Person to Person . In Hewitt's own words, 60 Minutes blends "higher Murrow" and "lower Murrow". [14]

"Point/Counterpoint" segment
For most of the 1970s, the program included Point/Counterpoint , in which a liberal and a conservative commentator debated a particular issue. This segment originally featured James J. Kilpatrick representing the conservative side and Nicholas von Hoffman for the liberal, with Shana Alexander taking over for von Hoffman after he departed in 1974. The segment was an innovation that caught the public imagination as a live version of competing editorials. Point/Counterpoint was also lampooned by the NBC comedy series Saturday Night Live , which featured Jane Curtin and Dan Aykroyd as debaters, with Aykroyd typically beginning his remarks with, "Jane, you ignorant slut" and Curtin with "Dan, you pompous ass"; in the 1980 film Airplane! , in which the faux Kilpatrick argues in favor of the plane crashing; and in the earlier sketch comedy film, The Kentucky Fried Movie , where the segment was called "Count/Pointercount".
A similar concept was revived briefly in March 2003, this time featuring Bob Dole and Bill Clinton , former opponents in the 1996 presidential election . The pair agreed to do ten segments, called "Clinton/Dole" and "Dole/Clinton" in alternating weeks, but did not continue into the 2003–04 fall television season. Reports indicated that the segments were considered too gentlemanly, in the style of the earlier "Point/Counterpoint", and lacked the feistiness of Crossfire . [15]

Andy Rooney segment
From 1978 to 2011, the program usually ended with a (usually light-hearted and humorous) commentary by Andy Rooney expounding on topics of wildly varying import, ranging from international politics, to economics, and to personal philosophy on everyday life. One recurring topic was measuring the amount of coffee in coffee cans. [16]
Rooney's pieces, particularly one in which he referred to actor Mel Gibson as a "wacko", on occasion led to complaints from viewers. Rooney published several books documenting his contributions to the program, including Years Of Minutes and A Few Minutes With Andy Rooney . Rooney retired from 60 Minutes , delivering his final commentary on October 2, 2011; it was his 1,097th commentary over his 34-year career on the program. He died one month later, on November 4, 2011. The November 13, 2011, edition of 60 Minutes featured an hour-long tribute to Rooney and his career, and included a rebroadcast of his final commentary segment.

Opening sequence
The opening sequence features a 60 Minutes "magazine cover" with the show's trademark, an Aristo stopwatch , intercut with preview clips of the episode's stories. The sequence ends with each of the current correspondents and hosts introducing themselves. The last host who appears (currently Scott Pelley ) then currently says, "Those stories tonight on 60 Minutes ". When Rooney was a prominent fixture, the final line was "Those stories and Andy Rooney, tonight on 60 Minutes ". Before that, and whenever Rooney did not appear, the final line was "Those stories and more, tonight on 60 Minutes ".
60 Minutes was the first, and remains the only, regularly scheduled program in the U.S. to never have used theme music . [ citation needed ] The only "theme" is the ticking of the stopwatch, which counts off each of the broadcast's titular 60 minutes, starting from zero at the beginning of each show. It is seen during the opening title sequence, before each commercial break, and at the tail-end of the closing credits, and each time it appears it displays (within reasonable accuracy) the elapsed time of the episode to that point.
On October 29, 2006, the opening sequence changed from a black background, which had been used for over a decade, to white. Also, the gray background for the Aristo stopwatch in the "cover" changed to red, the color for the title text changed to white, and the stopwatch itself changed from the diagonal position it had been oriented in for 31 years to an upright position. [ citation needed ]

Web content
Videos and transcripts of 60 Minutes editions, as well as clips that were not included in the broadcast are available on the program's website. In September 2010, the program launched a website called "60 Minutes Overtime", in which stories broadcast on-air are discussed in further detail. [17]

iPad content
CBS Interactive released a mobile app in 2013, "60 Minutes for iPad", which allows users to watch 60 Minutes on iPad devices and access some of the show's archival footage.

Correspondents and hosts

Current correspondents and commentators

Former correspondents and hosts

Commentators
Commentators for 60 Minutes have included:
† = Deceased

Ratings and recognition

Nielsen ratings
Based on ratings , 60 Minutes is the most successful program in U.S. television history, since it was moved into its present timeslot in 1975. For five of its seasons it has been that year's top program, a feat matched by the sitcoms All in the Family and The Cosby Show , and surpassed only by the reality competition series American Idol , which had been the #1 show for eight consecutive seasons from the 2003–04 television season up to the 2010–11 season. 60 Minutes was a top ten show for 23 seasons in a row (1977–2000), an unsurpassed record. [23]
60 Minutes first broke into the Nielsen Top 20 during the 1976–77 season. The following season, it was the fourth-most-watched program, and by 1979–80, it was the number one show. [23] During the 21st century, it remains among the top 20 programs in the Nielsen ratings, and the highest-rated news magazine. [24]
The November 16, 2008, edition, featuring an interview with President-Elect Barack Obama , earned a total viewership of 25.1 million viewers. [25]
The October 6, 2013, edition (which was delayed by 44 minutes that evening due to a Denver Broncos - Dallas Cowboys NFL game) drew 17.94 million viewers; retaining 63% of the 28.32 million viewers of its lead-in, and making it the most watched 60 Minutes broadcast since December 16, 2012. [26] [27]
The December 1, 2013, edition (delayed 50 minutes due to a Broncos- Kansas City Chiefs game) was watched by 18.09 million viewers, retaining 66% of its NFL lead-in (which earned 28.11 million viewers during the 7:00 p.m. hour). [28]

Recognition

Emmy Awards
As of October 1, 2013, 60 Minutes had won a total of 106 Emmy Awards , [23] a record unsurpassed by any other primetime program on U.S. television. [23] [29]

Peabody Awards
The program has won 20 Peabody Awards for segments including "All in the Family", an investigation into abuses by government and military contractors; "The CIA's Cocaine", which uncovered CIA involvement in drug smuggling; "Friendly Fire", a report on incidents of friendly fire in the Gulf War ; "The Duke Rape Case", an investigation into accusations of rape at an off campus lacrosse team party in 2006; and "The Killings in Haditha", an investigation into the killing of Iraqi civilians by U.S. Marines. [30]

Other awards
The show received an Investigative Reporter and Editor medal for their segment "The Osprey", documenting a Marine cover-up of deadly flaws in the V-22 Osprey aircraft. [ citation needed ]

Impact on innocent victims
In 1983, a report by Morley Safer, "Lenell Geter's in Jail", helped exonerate a Texas man who was wrongly convicted and imprisoned for armed robbery. [31]

Longest-running primetime show
60 Minutes currently holds the record for the longest continuously running program of any genre scheduled during American network prime time; it has aired at 7:00 p.m. Eastern Time on Sundays since December 7, 1975 (although since 1998, it is officially scheduled for 7:30 p.m. Eastern Time on Sundays where a CBS affiliate has a late NFL game).
The longer-running Meet the Press has also aired in prime time, however it has been a daytime program for most of its history. The Walt Disney anthology television series , which premiered in 1954, and the Hallmark Hall of Fame , which has aired since 1951, have aired longer than 60 Minutes , but none of them has aired in prime time continually, as 60 Minutes has done. [ citation needed ]

Controversies
The show has been praised for landmark journalism and received many awards. However, it has also become embroiled in some controversy, including (in order of appearance):

Unintended acceleration
On November 23, 1986, 60 Minutes aired a segment greenlit by Hewitt, concerning the Audi 5000 automobile, a popular German luxury car. The story covered a supposed problem of "unintended acceleration" when the brake pedal was pushed, with emotional interviews with six people who sued Audi (unsuccessfully) after they crashed their cars, including one woman whose 6-year-old boy had been killed. In the 60 Minutes segment footage was shown of an Audi 5000 with the accelerator "moving down on its own", accelerating the car. It later emerged that an expert witness employed by one of the plaintiffs modified the accelerator with a concealed device, causing the "unintended acceleration". [32] Independent investigators concluded that this "unintended acceleration" was most likely due to driver error, where the driver let their foot slip off the brake and onto the accelerator. Tests by Audi and independent journalists showed that even with the throttle wide open , the car would simply stall if the brakes were actually being used. [33]
The incident devastated Audi sales in the United States, which did not rebound for 15 years. The initial incidents which prompted the report were found by the National Highway Traffic Safety Administration and Transport Canada to have been attributable to operator error, where car owners had depressed the accelerator pedal instead of the brake pedal. CBS issued a partial retraction, without acknowledging the test results of involved government agencies. [34] Years later, Dateline NBC , a rival to 60 Minutes , was found guilty of similar tactics regarding the fuel tank integrity of General Motors pickup trucks . [35]

Alar
In February 1989, 60 Minutes aired a report by the Natural Resources Defense Council claiming that the use of daminozide (Alar) on apples presented an unacceptably high health risk to consumers. Apple sales dropped and CBS was sued unsuccessfully by apple growers. [36] Alar was subsequently banned for use on food crops in the U.S. by the Environmental Protection Agency (EPA).

Werner Erhard
On March 3, 1991, 60 Minutes broadcast " Werner Erhard ," which dealt with controversies involving Erhard's personal and business life. One year after the 60 Minutes piece aired, Erhard filed a lawsuit against CBS, claiming that the broadcast contained several "false, misleading and defamatory" statements about himself. One month after filing the lawsuit, Erhard filed for dismissal. [37] Erhard later told Larry King in an interview that he dropped the suit after receiving legal advice telling him that in order to win it, he had to prove not only that CBS knew the allegations were false but also that CBS acted with malice . [38] Because of factual inaccuracies, the segment was later removed by CBS from its archives, with a disclaimer: "This segment has been deleted at the request of CBS News for legal or copyright reasons." [39]

Brown & Williamson
In 1995, former Brown & Williamson Vice President for Research and Development Jeffrey Wigand provided information to 60 Minutes producer Lowell Bergman that B&W had systematically hidden the health risks of their cigarettes (see transcription ). Furthermore, it was alleged that B&W had introduced foreign agents (such as fiberglass and ammonia ) with the intent of enhancing the effect of nicotine . Bergman began to produce a piece based upon the information, but ran into opposition from Don Hewitt who, along with CBS lawyers, feared a billion dollar lawsuit from Brown and Williamson for tortious interference for encouraging Wigand to violate his non-disclosure agreement . A number of people at CBS would benefit from a sale of CBS to Westinghouse Electric Corporation , including the head of CBS lawyers and CBS News. Also, because of the interview, the son of CBS President Laurence Tisch (who also controlled Lorillard Tobacco ) was among the people from the big tobacco companies at risk of being caught having committed perjury. Due to Hewitt's hesitation, The Wall Street Journal instead broke Wigand's story. The 60 Minutes piece was eventually aired with substantially altered content and minus some of the most damning evidence against B&W. The exposé of the incident was published in an article in Vanity Fair by Marie Brenner , entitled "The Man Who Knew Too Much". [40]
The New York Times wrote that "the traditions of Edward R. Murrow and "60 Minutes" itself were diluted in the process," [41] though the newspaper revised the quote slightly, suggesting that 60 Minutes and CBS had "betrayed the legacy of Edward R. Murrow". The incident was turned into a seven-times Oscar -nominated feature film entitled The Insider , directed by Michael Mann and starring Russell Crowe as Wigand, Al Pacino as Bergman, and Christopher Plummer as Mike Wallace. Wallace denounced the portrayal of him as inaccurate to his stance on the issue. [42]

U.S. Customs Service
60 Minutes alleged in 1997 that agents of the U.S. Customs Service ignored drug trafficking across the Mexico–United States border at San Diego . [43] The only evidence was a memorandum apparently written by Rudy Camacho, who was the head of the San Diego branch office. Based on this memo, CBS alleged that Camacho had allowed trucks belonging to a particular firm to cross the border unimpeded. Mike Horner, a former Customs Service employee, had passed the memos on to 60 Minutes , and even provided a copy with an official stamp. Camacho was not consulted about the piece, and his career was devastated in the immediate term as his own department placed suspicion on him. In the end, it turned out that Horner had forged the documents as an act of revenge for his treatment within the Customs Service. Camacho sued CBS and settled for an undisclosed amount of money in damages. Hewitt was forced to issue an on-air retraction. [44]

Kennewick Man
A legal battle between archaeologists and the Umatilla tribe over the remains of a skeleton, nicknamed Kennewick Man , was reported by 60 Minutes on October 25, 1998, to which the Umatilla tribe reacted negatively. The tribe considered the segment heavily biased in favor of the scientists, cutting out important arguments, such as explanations of Native American Graves Protection and Repatriation Act . [45] The report focused heavily on the racial politics of the controversy and also added inflammatory arguments, such as questioning the legitimacy of Native American sovereignty [46] – much of the racial focus of the segment was later reported to have been either unfounded and/or misinterpreted. [47]

Timothy McVeigh
On March 12, 2000, 60 Minutes aired an interview with Oklahoma City bomber Timothy McVeigh . At the time, McVeigh had already been convicted and sentenced to death for the April 1995 bombing of the Alfred P. Murrah Federal Building and subsequent deaths of 168 people. On the program, McVeigh was given the opportunity to vent against the government. [48] Following the program, a federal policy called the Special Confinement Unit Media Policy was enacted prohibiting face-to-face interviews with death row inmates. [49] A federal inmate challenged the policy in Hammer v. Ashcroft , under which the U.S. Court of Appeals for the Seventh Circuit upheld the prison policy. In March 2010, the United States Supreme Court declined to hear an appeal in the case, and the policy limiting media access to death row inmates remains in place. CBS refuses to show the entire interview, and has stated no reasons. [50]

Viacom/CBS cross-promotion
In recent years, the program has been accused of promoting books, films, and interviews with celebrities who are published or promoted by sister businesses of media conglomerate Viacom (which owned CBS from 2000 to 2005, and is now owned by National Amusements , which is also the parent of CBS) and publisher Simon & Schuster (which remains a part of CBS Corporation after the 2005 CBS/Viacom split), without disclosing the journalistic conflict-of-interest to viewers. [51]

Killian documents controversy
The Killian documents controversy (also referred to as Memogate or Rathergate [ citation needed ] ) involved six documents critical of President George W. Bush 's service in the Texas Air National Guard in 1972–73. Four of these documents were presented as authentic in a 60 Minutes Wednesday broadcast aired by CBS on September 8, 2004, less than two months before the 2004 Presidential Election , but it was later found that CBS had failed to authenticate the documents. Subsequently, several typewriter and typography experts concluded the documents are forgeries, as have some media sources. No forensic document examiners or typography experts authenticated the documents, which may not be possible without original documents. The provider of the documents, Lt. Col. Bill Burkett, claimed to have burned the originals after faxing copies to CBS. [ citation needed ] The whole incident was turned into a feature-length film entitled Truth .

"The Internet Is Infected" episode and the false hacker photo
A segment aired on the March 29, 2009, edition of 60 Minutes , "The Internet Is Infected", featured an interview with Don Jackson, a data protection professional for SecureWorks . Jackson himself declares in the program that: "A part of my job is to know the enemy". However, during the interview, Jackson showed a photo of Finnish upper-level comprehensive school pupils and misidentified them as Russian hackers. [52] In the photo, one of the children is wearing a jacket with the Coat of Arms of Finland on it. Another one is wearing a cap which clearly has the logo of Karjala , a Finnish brand of beer, on it. The principal of the school in Taivalkoski confirmed that the photo was taken at the school about five years before the program was broadcast. [53]
The photo's exact origins are unknown, but it is widely known in Finland, having been originally posted to a Finnish social networking site, IRC-Galleria, in the early 2000s. It spread all over Finnish internet communities, and even originated a couple of patriotically titled (but intentionally misspelled) mock sites. [53] [54] 60 Minutes later issued a correction and on-air apology. [ when? ]

Benghazi report
Subsequent to the 2012 Benghazi attack , 60 Minutes aired report by correspondent Lara Logan on October 27, 2013, in which British military contractor, Dylan Davies, identified by CBS under the pseudonym "Morgan Jones," described racing to the Benghazi compound several hours after the main assault was over, scaling a 12-foot wall and knocking out a lone fighter with the butt of a rifle. He also claimed to have visited a Benghazi hospital earlier that night where he saw Ambassador Christopher Stevens' body.
In the days following the report, Davies' personal actions were challenged. [55] The FBI, which had interviewed Davies several times and considered him a credible source, [56] said the account Davies had given them was different than what he told 60 Minutes . Davies stood by his story, [57] but the inconsistency ultimately prompted 60 Minutes to conclude it was a mistake to include Davies in their report and a correction was issued. [58]
Following the correction, a journalistic review was conducted by Al Ortiz, CBS News' executive director of standards and practices. He determined that red flags about Davies' account were missed. [59] Davies had said to the program and written in his book that he told an alternative version of his actions to his employer, who he said had demanded that he stay inside his Benghazi villa as the attack unfolded. That alternative version was shared with US authorities and 60 Minutes was unable to prove the story Davies had told them was true. [60]
Davies' book, The Embassy House , was published two days after the 60 Minutes report, by Threshold Editions, part of the Simon and Schuster unit of CBS. It was pulled from shelves once 60 Minutes issued its correction. [61]

NSA report
On December 15, 2013, 60 Minutes aired a report on the National Security Agency (NSA) that was widely criticized [62] as false [63] and a "puff piece." [64] [65] The story was reported by John Miller , who once worked in the office of the Director of National Intelligence .

Tesla Automaker report
On March 30, 2014, 60 Minutes presented a story on the Tesla Model S luxury electric automobile in a segment, with Scott Pelley conducting an interview with CEO Elon Musk concerning the car brand as well as his SpaceX company. Within a day, the automotive blog site Jalopnik reported that the sounds accompanying footage of the car shown during the story were actually sounds from a traditional gasoline engine dubbed over the footage, when in reality the electric car is much quieter. [66] CBS released a statement explaining that the sound was the result of an audio editing error, and subsequently removed the noise from the online version of the piece. However, several news outlets, as well as Jalopnik itself, have expressed doubt over the authenticity of this explanation, noting the similar scandal involving Tesla Motors and The New York Times in 2013. [67] [68]

Spin-offs
The main 60 Minutes show has created a number of spin-offs over the years.

30 Minutes
30 Minutes was a newsmagazine aimed at children that was patterned after 60 Minutes , airing as the final program in CBS's Saturday morning lineup from 1978 to 1982. It was hosted by Christopher Glenn (who also served as the voice-over for the interstitial program In the News and was an anchor on the CBS Radio Network), along with Betsy Aaron (1978–1980) and Betty Ann Bowser (1980–1982).

60 Minutes More
60 Minutes More was a spin-off that ran for one season from 1996 to 1997. The episodes featured popular stories from the past that were expanded with updates on the original story. Each episode featured three of these segments. [69]

60 Minutes II
In 1999, a second edition of 60 Minutes was started in the U.S., called 60 Minutes II . This edition was later renamed 60 Minutes by CBS for the fall of 2004 in an effort to sell it as a high-quality program, since some had sarcastically referred to it as 60 Minutes, Jr. CBS News president Andrew Heyward said, "The Roman numeral II created some confusion on the part of the viewers and suggested a watered-down version". [70] However, a widely known controversy which came to be known as " Rathergate ", regarding a report that aired September 8, 2004, caused another name change. The program was retitled 60 Minutes Wednesday both to differentiate itself and to avoid tarnishing the Sunday edition, as the editions were editorially independent from one another. It reverted to its original Roman numeral title on July 8, 2005, when the program moved to Fridays in an 8:00 p.m. Eastern Time slot to finish its run. The show's final broadcast was on September 2, 2005.

60 Minutes on CNBC
In 2011, CNBC began airing a 60 Minutes spin-off of its own, called 60 Minutes on CNBC . Hosted by Lesley Stahl and Steve Kroft, it airs updated business-related reports seen on the original broadcasts and offers footage that were not included when the segments first aired.

60 Minutes Sports
CBS News began producing a sports-themed version of 60 Minutes for corporate sister and premium channel Showtime in January 2013. The program, titled 60 Minutes Sports , includes two original segments along with a classic interview from the show's archives. Personalities from CBS Sports join the 60 Minutes team in contributing. [71]

25th anniversary edition
For the 60 Minutes 25th anniversary in 1993, Charles Kuralt interviewed Don Hewitt, the active correspondents, some former correspondents, and revisited notable stories and celebrities.

International versions

Australia
The Australian version of 60 Minutes premiered on February 11, 1979. It still airs each Sunday night at 7:30 p.m. on the Nine Network and affiliates. Although Nine Network has the rights to the format, as of 2007, it does not have rights to stories from the U.S. program. Nevertheless, stories from the flagship 60 Minutes program in the U.S. often air on the Australian program by subleasing them from Network Ten . In 1980, 60 Minutes won a Logie Award for their investigation of lethal abuses at the Chelmsford psychiatric hospital in Sydney . [ citation needed ]

Germany
In the mid-1980s, an edited version (approx. 30 minutes in length) of the U.S. broadcast edition of 60 Minutes was shown for a time on West German television. This version retained the English-language soundtrack of the original, but also featured German subtitles.

New Zealand
The New Zealand version of 60 Minutes has aired on national television since 1989, when it was originally launched on TV3 . In 1992, the rights were acquired by TVNZ , who began broadcasting it in 1993. The network aired the program for nine years before dropping it in 2002 for its own program, entitled Sunday , which is currently the highest-rated current affairs show broadcast on New Zealand television, followed by 20/20 . 60 Minutes was broadcast by rival network TV3, before switching to the Sky Television owned Prime channel in 2013, when the contract changed hands.

Portugal
The original programs are shown in Portugal on SIC Notícias with introductory and closing remarks by journalist Mário Crespo .

Chile
The news program of National Broadcasting of Chile (TVN) , the public television network in that country, was named 60 Minutos ("60 Minutes") from 1975 to 1988, but the program had no accusations of any kind and no investigative reporting. [ citation needed ]

Other versions

See also
WebPage index: 00036
Anarchy
Anarchy is the condition of a society , entity, group of people, or a single person that rejects hierarchy . [1] The word originally meant leaderlessness , but in 1840 Pierre-Joseph Proudhon adopted the term in his treatise What Is Property? to refer to a new political philosophy : anarchism , which advocates stateless societies based on voluntary associations . In practical terms, anarchy can refer to the curtailment or abolition of traditional forms of government . It can also designate a nation (or anywhere on earth that is inhabited) that has no system of government or central rule.

Etymology
The word anarchy comes from the ancient Greek ἀναρχία ( anarchia ), which combines ἀ ( a ), "not, without" and ἀρχή ( arkhi ), "ruler, leader, authority." Thus, the term refers to a person or society "without rulers" or "without leaders". [2]

Political philosophy

Kant
The German philosopher Immanuel Kant treated anarchy in his Anthropology from a Pragmatic Point of View as consisting of "Law and Freedom without Force". Thus, for Kant, anarchy falls short of being a true civil state because the law is only an "empty recommendation" if force is not included to make this law efficacious ("legitimation", etymologically fancifully from "lex timere" = "fearing the law" [3] ). For there to be such a state, force must be included while law and freedom are maintained, a state which Kant calls a republic . [4] [5]
Kant identified four kinds of government:

Description
Anarchism as a political philosophy advocates self-governed societies based on voluntary institutions. These are often described as stateless societies , [6] [7] [8] [9] although several authors have defined them more specifically as institutions based on non- hierarchical free associations . [10] [11] [12] [13] Anarchism holds the state to be undesirable, unnecessary, or harmful. [14] [15] While anti-statism is central, [16] anarchism entails opposing authority or hierarchical organisation in the conduct of all human relations, including, but not limited to, the state system. [11] [17] [18] [19] [20] [21] [22] [23]
There are many types and traditions of anarchism, not all of which are mutually exclusive. [24] Anarchist schools of thought can differ fundamentally, supporting anything from extreme individualism to complete collectivism. [15] Strains of anarchism have been divided into the categories of social and individualist anarchism or similar dual classifications. [25] [26] Anarchism is often considered to be a radical left-wing ideology, [27] [28] and much of anarchist economics and anarchist legal philosophy reflect anti-statist interpretations of communism , collectivism , syndicalism or participatory economics . Some individualist anarchists are also socialists or communists while some anarcho-communists are also individualists [29] [30] or egoists . [31] [32]
Anarchism as a social movement has regularly endured fluctuations in popularity. The central tendency of anarchism as a mass social movement has been represented by anarcho-communism and anarcho-syndicalism , with individualist anarchism being primarily a literary phenomenon [33] which nevertheless did influence the bigger currents [34] and individualists also participated in large anarchist organizations. [35] [36] Some anarchists oppose all forms of aggression , supporting self-defense or non-violence ( anarcho-pacifism ), [37] [38] while others have supported the use of militant measures, including revolution and propaganda of the deed , on the path to an anarchist society. [39]
Since the 1890s, the term libertarianism has been used as a synonym for anarchism [40] [41] and was used almost exclusively in this sense until the 1950s in the United States. At this time, classical liberals in the United States began to describe themselves as libertarians, and it has since become necessary to distinguish their individualist and capitalist philosophy from socialist anarchism. Thus, the former is often referred to as right-wing libertarianism , or simply right-libertarianism , whereas the latter is described by the terms libertarian socialism , socialist libertarianism , left-libertarianism , and left-anarchism . [42] [43] Right-libertarians are divided into minarchists and anarcho-capitalists or voluntarists . Outside the English-speaking world , libertarianism generally retains its association with left-wing anarchism. [44]

Anthropology
Although most known societies are characterized by the presence of hierarchy or the state, anthropologists have studied many egalitarian stateless societies, including most nomadic hunter-gatherer societies [45] [46] and horticultural societies such as the Semai and the Piaroa . Many of these societies can be considered to be anarchic in the sense that they explicitly reject the idea of centralized political authority. [47]
The egalitarianism typical of human hunter-gatherers is interesting when viewed in an evolutionary context. One of humanity's two closest primate relatives, the chimpanzee , is anything but egalitarian, forming hierarchies that are dominated by alpha males. So great is the contrast with human hunter-gatherers that it is widely argued by palaeoanthropologists that resistance to being dominated was a key factor driving the development of human consciousness, language, kinship, and social organization. [48] [49] [50]
In Fragments of an Anarchist Anthropology anarchist anthropologist David Graeber attempts to outline areas of research that intellectuals might explore in creating a cohesive body of anarchist social theory . Graeber posits that anthropology is "particularly well positioned" as an academic discipline that can look at the gamut of human societies and organizations, to study, analyze and catalog alternative social and economic structures around the world, and most importantly, present these alternatives to the world. [51]
In Society Against the State Pierre Clastres examines stateless societies where certain cultural practices and attitudes avert the development of hierarchy and the state. He dismisses the notion that the state is the natural outcome of the evolution of human societies. [52]
In The Art of Not Being Governed James C. Scott studies Zomia , a vast stateless upland region on Southeast Asia. The hills of Zomia isolate it from the lowland states and create a refuge for people to escape to. Scott argues that the particular social and cultural characteristics of the hill people were adapted to escape capture by the lowland states and should not be viewed as relics of barbarism abandoned by civilization. [53]
Peter Leeson examines a variety of institutions of private law enforcement developed in anarchic situations by eighteenth century pirates, preliterate tribesmen, and Californian prison gangs. These groups all adapted different methods of private law enforcement to meet their specific needs and the particulars of their anarchic situation. [54]
Anarcho-primitivists base their critique of civilization partly on anthropological studies of nomadic hunter-gatherers, noting that the shift towards domestication has likely caused increases in disease, labor, inequality, warfare, and psychological disorders. [55] [56] [57] Authors such as John Zerzan have argued that negative stereotypes of primitive societies (e.g. that they are typically extremely violent or impoverished) are used to justify the values of modern industrial society and to move individuals further away from more natural and equitable conditions. [58] [59]

Examples of state-collapse anarchy

English Civil War (1642–1651)
Anarchy was one of the issues at the Putney Debates of 1647:
As people began to theorize about the English Civil War, "anarchy" came to be more sharply defined, albeit from differing political perspectives:

French Revolution (1789–1799)
Thomas Carlyle , Scottish essayist of the Victorian era known foremost for his widely influential work of history, The French Revolution , wrote that the French Revolution was a war against both aristocracy and anarchy:
Armand II , duke of Aiguillon came before the National Assembly in 1789 and shared his views on the anarchy:
Armand II was later exiled because he was viewed as being opposed to the revolution's violent tactics.
Professor Chris Bossche commented on the role of anarchy in the revolution:

Jamaica (1720)
Sir Nicholas Lawes , Governor of Jamaica , wrote to John Robinson , the Bishop of London , in 1720:
In the letter, Lawes goes on to complain that these "estated men now are like Jonah 's gourd " and details the humble origins of the " creolians " largely lacking an education and flouting the rules of church and state. In particular, he cites their refusal to abide by the Deficiency Act, which required slave owners to procure from England one white person for every 40 enslaved Africans , thereby hoping to expand their own estates and inhibit further English/ Irish immigration. Lawes describes the government as being "anarchical, but nearest to any form of Aristocracy ". "Must the King's good subjects at home who are as capable to begin plantations, as their Fathers, and themselves were, be excluded from their Liberty of settling Plantations in this noble Island, for ever and the King and Nation at home be deprived of so much riches, to make a few upstart Gentlemen Princes?" [65]

Russian Civil War (1917–1922)
During the Russian Civil War – which initially started as a confrontation between the Communists and Monarchists – on the territory of today's Ukraine , a new force emerged, namely the Anarchist Revolutionary Insurrectionary Army of Ukraine led by Nestor Makhno . The Ukrainian Anarchist during the Russian Civil War (also called the "Black Army") organized the Free Territory of Ukraine, an anarchist society , committed to resisting state authority, whether capitalist or communist . [66] [67] This project was cut short by the consolidation of Bolshevik power. Makhno was described by anarchist theorist Emma Goldman as "an extraordinary figure" leading a revolutionary peasants' movement. [68]
During 1918, most of Ukraine was controlled by the forces of the Central Powers , which were unpopular among the people. In March 1918, the young anarchist Makhno's forces and allied anarchist and guerrilla groups won victories against German, Austrian, and Ukrainian nationalist (the army of Symon Petlura ) forces, and units of the White Army , capturing a lot of German and Austro-Hungarian arms. These victories over much larger enemy forces established Makhno's reputation as a military tactician; he became known as Batko ('Father') to his admirers. [69]
At this point, the emphasis on military campaigns that Makhno had adopted in the previous year shifted to political concerns. The first Congress of the Confederation of Anarchists Groups , under the name of Nabat ("the Alarm Drum"), issued five main principles: rejection of all political parties, rejection of all forms of dictatorships (including the dictatorship of the proletariat , viewed by Makhnovists and many anarchists of the day as a term synonymous with the dictatorship of the Bolshevik communist party), negation of any concept of a central state, rejection of a so-called "transitional period" necessitating a temporary dictatorship of the proletariat, and self-management of all workers through free local workers' councils (soviets). While the Bolsheviks argued that their concept of dictatorship of the proletariat meant precisely "rule by workers' councils", the Makhnovist platform opposed the "temporary" Bolshevik measure of "party dictatorship". The Nabat was by no means a puppet of Mahkno and his supporters, from time to time criticizing the Black Army and its conduct in the war. [ citation needed ]
In 1918, after recruiting large numbers of Ukrainian peasants, as well as numbers of Jews, anarchists, naletchki , and recruits arriving from other countries, Makhno formed the Revolutionary Insurrectionary Army of Ukraine , otherwise known as the Anarchist Black Army. At its formation, the Black Army consisted of about 15,000 armed troops, including infantry and cavalry (both regular and irregular) brigades; artillery detachments were incorporated into each regiment. From November 1918 to June 1919, using the Black Army to secure its hold on power, the Makhnovists attempted to create an anarchist society in Ukraine, administered at the local level by autonomous peasants' and workers' councils. [ citation needed ]
Makhno called the Bolsheviks dictators and opposed the "Cheka [secret police]... and similar compulsory authoritative and disciplinary institutions" and called for "[f]reedom of speech, press, assembly, unions and the like". [70] The Bolsheviks accused the Makhnovists of imposing a formal government over the area they controlled , and also said that Makhnovists used forced conscription, committed summary executions, and had two military and counter-intelligence forces: the Razvedka and the Kommissiya Protivmakhnovskikh Del (patterned after the Cheka and the GRU ). [71] However, later historians have dismissed these claims as fraudulent propaganda. [72]
The Bolsheviks claimed that it would be impossible for a small, agricultural society to organize into an anarchist society so quickly. However, Eastern Ukraine had a large amount of coal mines, and was one of the most industrialised parts of the Russian Empire . [ citation needed ]

Spain (1936)
In 1919, the Confederación Nacional del Trabajo (CNT), the Spanish confederation of anarcho-syndicalist labor unions, had grown to 1 million members, and it became involved in many fights with the police and the fascists in Spain. On July 18, 1936, General Franco led the army to launch their fight against the government, but instead of an easy victory they faced significant obstacles. [73] They encountered resistance from the people, and the rebels were supported by military and the police. With the government in shambles, the workers and peasants took over the government of Spain and joined together to create a revolutionary militia to fight the fascists. [ citation needed ] The workers and peasants were fighting to start a revolution, not to help save their government. Spain's society was transposed by a social revolution. Every business was re-organized [ by whom? ] to have a company with no bosses; surprisingly profits increased by over half. Stalin wanted to send arms, but only on one condition: The party [ which? ] must be given government positions and the militias be "re-organized". On May 2, 1937, the CNT issued a warning:
On the next day after the warning was issued the CNT's central exchange was attacked and the militias prepared to quit, in front of Barcelona. There ensued a power struggle and confusion which led the workers to cease fire and to lay down their weapons. The "re-organized" Republican Army tried one last attempt to gain control. With over 70,000 casualties, and many people fleeing to France, General Franco's army entered Barcelona on January 26, 1939 to end the revolution. [73]

Albania (1997)
In 1997, Albania fell into a state of anarchy, mainly due to the heavy losses of money caused by the collapse of pyramid firms. As a result of the societal collapse, heavily armed criminals roamed freely with near total impunity. There were often 3–4 gangs per city, especially in the south, where the police did not have sufficient resources to deal with gang-related crime.

Somalia 1991–2006
Following the outbreak of the civil war in Somalia and the ensuing collapse of the central government, residents reverted to local forms of conflict resolution; either secular, traditional or Islamic law, with a provision for appeal of all sentences. The legal structure in the country was thus divided along three lines: civil law , religious law and customary law ( xeer ). [74]
While Somalia's formal judicial system was largely destroyed after the fall of the Siad Barre regime, it was later gradually rebuilt and administered under different regional governments, such as the autonomous Puntland and Somaliland macro-regions. In the case of the Transitional National Government and its successor the Transitional Federal Government , new interim judicial structures were formed through various international conferences.
Despite some significant political differences between them, all of these administrations shared similar legal structures, much of which were predicated on the judicial systems of previous Somali administrations. These similarities in civil law included: a) a charter which affirms the primacy of Muslim shari'a or religious law, although in practice shari'a is applied mainly to matters such as marriage, divorce, inheritance, and civil issues. The charter assured the independence of the judiciary , which in turn was protected by a judicial committee; b) a three-tier judicial system including a supreme court , a court of appeals , and courts of first instance (either divided between district and regional courts, or a single court per region); and c) the laws of the civilian government which were in effect prior to the military coup d'état that saw the Barre regime into power remain in forced until the laws are amended. [75]

Lists of ungoverned communities

Ungoverned communities

Anarchist communities
Anarchists have been involved in a wide variety of communities. While there are only a few instances of mass society "anarchies" that have come about from explicitly anarchist revolutions, there are also examples of intentional communities founded by anarchists.

See also
WebPage index: 00037
Anti-social behaviour
Anti-social behaviours are "age-inappropriate" [1] actions that harm or lack consideration for the well-being of others. [2] Many people also label behaviour which is deemed contrary to prevailing norms for social conduct as anti-social behaviour. [3] The term is especially used in British English . [4]
The American Psychiatric Association , in its Diagnostic and Statistical Manual of Mental Disorders , diagnoses persistent anti-social behaviour as antisocial personality disorder . [5] The World Health Organization includes it in the International Classification of Diseases as " dissocial personality disorder ". [6] A pattern of persistent anti-social behaviours can also be present in children and adolescents diagnosed with conduct problems, including conduct disorder or oppositional defiant disorder under the DSM-5 . [7]

Definition
There is a common error of the way the public use and interpret the word "anti-social" or "antisocial". The misinterpretation is when it is used in the context of meaning asocial instead of anti-social. (Someone say they are feeling antisocial in meaning that they are not feeling social at the time.) Asocial means to be not social, withdrawn from society [8] while anti-social relates to harmful acts or feelings.

Development
Intent and discrimination may determine both pro- and anti-social behaviour. Infants may act in seemingly anti-social ways and yet be generally accepted as too young to know the difference before the age of 4 or 5. [2] Berger states that parents should teach their children that "emotions need to be regulated, not depressed". [9] Studies have shown that in children between ages 13–14 who bully or show aggressive behavior towards others exhibits anti-social behaviors in their early adulthood. There are strong statistical relationships that shows this significant association between childhood aggressiveness and anti-social behaviors. Analyses saw that 20% of these children whom exhibits anti-social behaviors at later ages had court appearances and police contact as a result of their behavior. [10]
Many of the studies regarding the media's influence on anti-social behaviour have been deemed inconclusive. There has been a correlation found between the number of TV hours watched and amounts of aggressive behaviour. [11] A study was conducted that observed the effects of violent and non-violent films on Belgian and American male juvenile delinquents . The results stated that aggression increased in some measures due to the violent films, although only in those who were naturally high in aggression. [11] Violence, racism , sexism , and other anti-social acts are attributed to things such as genetic predisposition and violence in the home. [12] Some reviews have found strong correlations between aggression and the viewing of violent media, [13] while others find little evidence to support their case. [14] The only unanimously accepted truth regarding anti-social behaviour is that parental guidance carries an undoubtedly strong influence; providing children with brief negative evaluations of violent characters helps to reduce violent effects in the individual. [12]

Intervention and treatment
An individual's age at intervention is a strong predictor of the effectiveness of a given treatment. [7] The specific kinds of anti-social behaviours exhibited, as well as the magnitude of those behaviours also impact how effective a treatment is for an individual. [1]

Cognitive behavioural therapy
Cognitive behavioural therapy (CBT), is a highly effective, evidence-based therapy, in relation to anti-social behaviour. [15] This type of treatment focuses on changing how individuals think and act in social situations. Individuals with particularly aggressive anti-social behaviours tend to have maladaptive social cognitions, including hostile attribution bias , which lead to negative behavioural outcomes. [7] CBT has been found to be more effective for older children and less effective for younger children. [16] Problem-solving skills training (PSST) is a type of CBT that aims to recognize and correct how an individual thinks and consequently behaves in social environments. [1] This training provides steps to assist people in obtaining the skill to be able to evaluate potential solutions to problems occurring outside of therapy and learn how to create positive solutions to avoid physical aggression and resolve conflict. [17]

Behavioural parent training
Behavioural parent training (BPT) or parent management training (PMT), focuses on changing how parents interact with their children and equips them with ways to recognize and change their child's maladaptive behaviour in a variety of situations. BPT assumes that certain types of interactions between parents and children may reinforce a child's antisocial behaviours, therefore the aim of BPT is to teach the parent effective skills to better manage and communicate with their child. [1] BPT has been found to be most effective for younger children under the age of 12. [7] [1] Researchers credit the effectiveness of this treatment at younger ages due to the fact that younger children are more reliant on their parents. [7] BPT is used to treat children with conduct problems, but also for children with ADHD . [1]

Medication
In severe cases, medication will be administered to control behaviour, however it is not a suitable substitute for therapy. [18] Lithium carbonate has been proven to be effective medication for people with anti-social behaviour, reducing aggression, threatening behaviour, bullying, fighting and temper outbursts. [19]

In the UK
An anti-social behaviour order (ASBO) is a civil order made against a person who has been shown, on the balance of evidence, to have engaged in anti-social behaviour. The orders, introduced in the United Kingdom by Prime Minister Tony Blair in 1998, [20] were designed to criminalize minor incidents that would not have warranted prosecution before. [21]
The Crime and Disorder Act 1998 defines anti-social behaviour as acting in a manner that has "caused or was likely to cause harassment, alarm or distress to one or more persons not of the same household " as the perpetrator. There has been debate concerning the vagueness of this definition. [22]
In a survey conducted by University College London during May 2006, the UK was thought by respondents to be Europe's worst country for anti-social behaviour, with 76% believing Britain had a "big or moderate problem". [23]
Current legislation governing anti-social behaviour in the UK is the Anti-Social Behaviour, Crime and Policing Act 2014 which received Royal Assent in March 2014 and came into enforcement in October 2014. This replaces tools such as the ASBO with 6 streamlined tools designed to make it easier to act on anti-social behaviour. [24]

In Australia
Anti-social behaviour can have a negative effect and impact on Australian communities and their perception of safety. The Western Australia Police force define antisocial behaviour as any behaviour that annoys, irritates, disturbs or interferes with a persons’ ability to go about their lawful business. [25] In Australia, many different acts are classed as anti-social behaviour such as, misuse of public space, disregard for community safety, disregard for personal well-being, acts directed at people, graffiti , protests, liquor offences and drunk driving. [26] It has been found that it is very common for Australian adolescents to engage in different levels of anti-social behaviour.  A survey was conducted in 1996 in New South Wales , Australia, of 441, 234 secondary school students in years 7 to 12 about their involvement in anti-social activities. 38.6 percent reported intentionally damaging or destroying someone else's property, 22.8 percent admitted to received or selling stolen goods and close to 40 percent confessed to attacking someone with the idea of hurting them. [27] The Australian community are encouraged to report any behaviour of concern and play a vital role assisting police in reducing anti-social behaviour. One study conducted in 2016 established how perpetrators of anti-social behaviour may not actually intend to cause offense. The study examined anti-social behaviours (or microaggressions) within the LGBTIQ community on a university campus. The study established how many members felt that other people would often commit anti-social behaviours, however there was no explicit suggestion of any maliciousness behind these acts. Rather, it was just that the offenders were naive to impact of their behaviour. [28]
The Western Australia Police force uses a three step strategy to deal with antisocial behaviour.

See also
WebPage index: 00038
British Museum
The British Museum is dedicated to human history , art and culture , and is located in the Bloomsbury area of London . Its permanent collection, numbering some 8 million works, [4] is among the largest and most comprehensive in existence [4] and originates from all continents, illustrating and documenting the story of human culture from its beginnings to the present. [a]
The British Museum was established in 1753, largely based on the collections of the physician and scientist Sir Hans Sloane . The museum first opened to the public on 15 January 1759, in Montagu House , on the site of the current building. Its expansion over the following two and a half centuries was largely a result of an expanding British colonial footprint and has resulted in the creation of several branch institutions, the first being the British Museum of Natural History in South Kensington in 1881 (it is nowadays simply called the Natural History Museum).
In 1973, the British Library Act 1972 detached the library department from the British Museum, but it continued to host the now separated British Library in the same Reading Room and building as the museum until 1997. The museum is a non-departmental public body sponsored by the Department for Culture, Media and Sport , and as with all other national museums in the United Kingdom it charges no admission fee, except for loan exhibitions. [5]

History

Hans Sloane, founder of the British Museum
Although today principally a museum of cultural art objects and antiquities , the British Museum was founded as a "universal museum". Its foundations lie in the will of the Irish-born British physician and naturalist Sir Hans Sloane (1660–1753). During the course of his lifetime Sloane gathered an enviable collection of curiosities and, not wishing to see his collection broken up after death, he bequeathed it to King George II , for the nation, for a sum of £20,000. [6]
At that time, Sloane's collection consisted of around 71,000 objects of all kinds [7] including some 40,000 printed books, 7,000 manuscripts , extensive natural history specimens including 337 volumes of dried plants, prints and drawings including those by Albrecht Dürer and antiquities from Sudan , Egypt , Greece , Rome , the Ancient Near and Far East and the Americas . [8]

Foundation (1753)
On 7 June 1753, King George II gave his formal assent to the Act of Parliament which established the British Museum. [b] The British Museum Act 1753 also added two other libraries to the Sloane collection, namely the Cottonian Library , assembled by Sir Robert Cotton , dated back to Elizabethan times and the Harleian library , the collection of the Earls of Oxford . They were joined in 1757 by the "Old Royal Library", now the Royal manuscripts , assembled by various British monarchs . Together these four "foundation collections" included many of the most treasured books now in the British Library [10] including the Lindisfarne Gospels and the sole surviving copy of Beowulf . [c]
The British Museum was the first of a new kind of museum – national, belonging to neither church nor king, freely open to the public and aiming to collect everything. Sloane's collection, while including a vast miscellany of objects, tended to reflect his scientific interests. [11] The addition of the Cotton and Harley manuscripts introduced a literary and antiquarian element and meant that the British Museum now became both National Museum and library . [12]

Cabinet of curiosities (1753–78)
The body of trustees decided on a converted 17th-century mansion, Montagu House , as a location for the museum, which it bought from the Montagu family for £20,000. The Trustees rejected Buckingham House, on the site now occupied by Buckingham Palace , on the grounds of cost and the unsuitability of its location. [13] [d]
With the acquisition of Montagu House the first exhibition galleries and reading room for scholars opened on 15 January 1759. [14] In 1823, King George IV [15] gave the King's Library assembled by George III, and Parliament gave the right to a copy of every book published in the country, thereby ensuring that the Museum's library would expand indefinitely. During the few years after its foundation the British Museum received several further gifts, including the Thomason Collection of Civil War Tracts and David Garrick 's library of 1,000 printed plays. The predominance of natural history, books and manuscripts began to lessen when in 1772 the Museum acquired for £8,410 its first significant antiquities in Sir William Hamilton 's "first" collection of Greek vases . [16]

Indolence and energy (1778–1800)
From 1778, a display of objects from the South Seas brought back from the round-the-world voyages of Captain James Cook and the travels of other explorers fascinated visitors with a glimpse of previously unknown lands. The bequest of a collection of books, engraved gems , coins, prints and drawings by Clayton Mordaunt Cracherode in 1800 did much to raise the Museum's reputation; but Montagu House became increasingly crowded and decrepit and it was apparent that it would be unable to cope with further expansion. [17]
The museum's first notable addition towards its collection of antiquities, since its foundation, was by Sir William Hamilton (1730–1803), British Ambassador to Naples , who sold his collection of Greek and Roman artefacts to the museum in 1784 together with a number of other antiquities and natural history specimens. A list of donations to the Museum, dated 31 January 1784, refers to the Hamilton bequest of a "Colossal Foot of an Apollo in Marble". It was one of two antiquities of Hamilton's collection drawn for him by Francesco Progenie, a pupil of Pietro Fabris, who also contributed a number of drawings of Mount Vesuvius sent by Hamilton to the Royal Society in London.

Growth and change (1800–25)
In the early 19th century the foundations for the extensive collection of sculpture began to be laid and Greek, Roman and Egyptian artefacts dominated the antiquities displays. After the defeat of the French campaign in the Battle of the Nile , in 1801, the British Museum acquired more Egyptian sculptures and in 1802 King George III presented the Rosetta Stone – key to the deciphering of hieroglyphs. [18] Gifts and purchases from Henry Salt , British consul general in Egypt, beginning with the Colossal bust of Ramesses II in 1818, laid the foundations of the collection of Egyptian Monumental Sculpture. [19] Many Greek sculptures followed, notably the first purpose-built exhibition space, the Charles Towneley collection , much of it Roman Sculpture, in 1805. In 1806, Thomas Bruce, 7th Earl of Elgin , ambassador to the Ottoman Empire from 1799 to 1803 removed the large collection of marble sculptures from the Parthenon , on the Acropolis in Athens and transferred them to the UK. In 1816 these masterpieces of western art, were acquired by The British Museum by Act of Parliament and deposited in the museum thereafter. [20] The collections were supplemented by the Bassae frieze from Phigaleia , Greece in 1815. The Ancient Near Eastern collection also had its beginnings in 1825 with the purchase of Assyrian and Babylonian antiquities from the widow of Claudius James Rich . [21]
In 1802 a Buildings Committee was set-up to plan for expansion of the museum, and further highlighted by the donation in 1822 of the King's Library , personal library of King George III's, comprising 65,000 volumes, 19,000 pamphlets , maps, charts and topographical drawings . [22] The neoclassical architect, Sir Robert Smirke , was asked to draw up plans for an eastern extension to the Museum "... for the reception of the Royal Library , and a Picture Gallery over it ..." [23] and put forward plans for today's quadrangular building, much of which can be seen today. The dilapidated Old Montagu House was demolished and work on the King's Library Gallery began in 1823. The extension, the East Wing, was completed by 1831. However, following the founding of the National Gallery, London in 1824, [e] the proposed Picture Gallery was no longer needed, and the space on the upper floor was given over to the Natural history collections. [24]

The largest building site in Europe (1825–50)
The Museum became a construction site as Sir Robert Smirke 's grand neo-classical building gradually arose. The King's Library , on the ground floor of the East Wing, was handed over in 1827, and was described as one of the finest rooms in London. Although it was not fully open to the general public until 1857, special openings were arranged during The Great Exhibition of 1851. In spite of dirt and disruption the collections grew, outpacing the new building. [ citation needed ]
In 1840, the Museum became involved in its first overseas excavations , Charles Fellows 's expedition to Xanthos , in Asia Minor , whence came remains of the tombs of the rulers of ancient Lycia , among them the Nereid and Payava monuments. In 1857, Charles Newton was to discover the 4th-century BC Mausoleum of Halikarnassos , one of the Seven Wonders of the Ancient World . In the 1840s and 1850s the Museum supported excavations in Assyria by A.H. Layard and others at sites such as Nimrud and Nineveh . Of particular interest to curators was the eventual discovery of Ashurbanipal 's great library of cuneiform tablets , which helped to make the Museum a focus for Assyrian studies . [25]
Sir Thomas Grenville (1755–1846), a Trustee of The British Museum from 1830, assembled a library of 20,240 volumes, which he left to the Museum in his will. The books arrived in January 1847 in twenty-one horse-drawn vans. The only vacant space for this large library was a room originally intended for manuscripts, between the Front Entrance Hall and the Manuscript Saloon. The books remained here until the British Library moved to St Pancras in 1998.

Collecting from the wider world (1850–75)
The opening of the forecourt in 1852 marked the completion of Robert Smirke 's 1823 plan, but already adjustments were having to be made to cope with the unforeseen growth of the collections. Infill galleries were constructed for Assyrian sculptures and Sydney Smirke 's Round Reading Room , with space for a million books, opened in 1857. Because of continued pressure on space the decision was taken to move natural history to a new building in South Kensington , which would later become the British Museum of Natural History .
Roughly contemporary with the construction of the new building was the career of a man sometimes called the "second founder" of the British Museum, the Italian librarian Anthony Panizzi . Under his supervision, the British Museum Library (now part of the British Library ) quintupled in size and became a well-organised institution worthy of being called a national library, the largest library in the world after the National Library of Paris . [12] The quadrangle at the centre of Smirke's design proved to be a waste of valuable space and was filled at Panizzi's request by a circular Reading Room of cast iron, designed by Smirke's brother, Sydney Smirke. [26]
Until the mid-19th century, the Museum's collections were relatively circumscribed but, in 1851, with the appointment to the staff of Augustus Wollaston Franks to curate the collections, the Museum began for the first time to collect British and European medieval antiquities, prehistory , branching out into Asia and diversifying its holdings of ethnography . A real coup for the museum was the purchase in 1867, over French objections, of the Duke of Blacas 's wide-ranging and valuable collection of antiquities. Overseas excavations continued and John Turtle Wood discovered the remains of the 4th century BC Temple of Artemis at Ephesos , another Wonder of the Ancient World . [27]

Scholarship and legacies (1875–1900)
The natural history collections were an integral part of the British Museum until their removal to the new British Museum of Natural History in 1887, nowadays the Natural History Museum . With the departure and the completion of the new White Wing (fronting Montague Street) in 1884, more space was available for antiquities and ethnography and the library could further expand. This was a time of innovation as electric lighting was introduced in the Reading Room and exhibition galleries. [28]
The William Burges collection of armoury was bequeathed to the museum in 1881. In 1882, the Museum was involved in the establishment of the independent Egypt Exploration Fund (now Society) the first British body to carry out research in Egypt. A bequest from Miss Emma Turner in 1892 financed excavations in Cyprus. In 1897 the death of the great collector and curator, A.W. Franks , was followed by an immense bequest of 3,300 finger rings , 153 drinking vessels, 512 pieces of continental porcelain, 1,500 netsuke , 850 inro , over 30,000 bookplates and miscellaneous items of jewellery and plate, among them the Oxus Treasure . [29]
In 1898 Baron Ferdinand de Rothschild bequeathed the Waddesdon Bequest , the glittering contents from his New Smoking Room at Waddesdon Manor . This consisted of almost 300 pieces of objets d'art et de vertu which included exquisite examples of jewellery, plate, enamel, carvings, glass and maiolica , among them the Holy Thorn Reliquary , probably created in the 1390s in Paris for John, Duke of Berry . The collection was in the tradition of a schatzkammer or treasure house such as those formed by the Renaissance princes of Europe. [30] Baron Ferdinand's will was most specific, and failure to observe the terms would make it void, the collection should be
These terms are still observed, and the collection occupies room 45, although it will move to new quarters in 2015.

New century, new building (1900–25)
By the last years of the 19th century, The British Museum's collections had increased so much that the Museum building was no longer big enough for them. In 1895 the trustees purchased the 69 houses surrounding the Museum with the intention of demolishing them and building around the West, North and East sides of the Museum. The first stage was the construction of the northern wing beginning 1906.
All the while, the collections kept growing. Emil Torday collected in Central Africa, Aurel Stein in Central Asia, D.G. Hogarth , Leonard Woolley and T. E. Lawrence excavated at Carchemish . Around this time, the American collector and philanthropist J Pierpont Morgan donated a substantial number of objects to the museum, [31] including William Greenwell 's collection of prehistoric artefacts from across Europe which he had purchased for £10,000 in 1908. Morgan had also acquired a major part of Sir John Evans 's coin collection, which was later sold to the museum by his son John Pierpont Morgan Junior in 1915. In 1918, because of the threat of wartime bombing, some objects were evacuated to a Postal Tube Railway at Holborn, the National Library of Wales (Aberystwyth) and a country house near Malvern . On the return of antiquities from wartime storage in 1919 some objects were found to have deteriorated. A temporary conservation laboratory was set up in May 1920 and became a permanent department in 1931. It is today the oldest in continuous existence. [32] In 1923, the British Museum welcomed over one million visitors.

Disruption and reconstruction (1925–50)
New mezzanine floors were constructed and book stacks rebuilt in an attempt to cope with the flood of books. In 1931, the art dealer Sir Joseph Duveen offered funds to build a gallery for the Parthenon sculptures . Designed by the American architect John Russell Pope , it was completed in 1938. The appearance of the exhibition galleries began to change as dark Victorian reds gave way to modern pastel shades. [f] However, in August 1939, due to the imminence of war and the likelihood of air-raids the Parthenon Sculptures along with Museum's most valued collections were dispersed to secure basements, country house , Aldwych tube station , the National Library of Wales and a quarry. The evacuation was timely, for in 1940 the Duveen Gallery was severely damaged by bombing. [34] Meanwhile, prior to the war, the Nazis had sent a researcher to the British Museum for several years with the aim of "compiling an anti-Semitic history of Anglo-Jewry." [35] After the war, the Museum continued to collect from all countries and all centuries: among the most spectacular additions were the 2600 BC Mesopotamian treasure from Ur , discovered during Leonard Woolley 's 1922–34 excavations. Gold, silver and garnet grave goods from the Anglo-Saxon ship burial at Sutton Hoo (1939) and late Roman silver tableware from Mildenhall , Suffolk (1946). The immediate post-war years were taken up with the return of the collections from protection and the restoration of the museum after the Blitz . Work also began on restoring the damaged Duveen Gallery.

A new public face (1950–75)
In 1953, the Museum celebrated its bicentenary . Many changes followed: the first full-time in house designer and publications officer were appointed in 1964, A Friends organisation was set up in 1968, an Education Service established in 1970 and publishing house in 1973. In 1963, a new Act of Parliament introduced administrative reforms. It became easier to lend objects, the constitution of the Board of Trustees changed and the Natural History Museum became fully independent. By 1959 the Coins and Medals office suite, completely destroyed during the war, was rebuilt and re-opened, attention turned towards the gallery work with new tastes in design leading to the remodelling of Robert Smirke's Classical and Near Eastern galleries. [36] In 1962 the Duveen Gallery was finally restored and the Parthenon Sculptures were moved back into it, once again at the heart of the museum. [g]
By the 1970s the Museum was again expanding. More services for the public were introduced; visitor numbers soared, with the temporary exhibition "Treasures of Tutankhamun " in 1972, attracting 1,694,117 visitors, the most successful in British history. In the same year the Act of Parliament establishing the British Library was passed, separating the collection of manuscripts and printed books from the British Museum. This left the Museum with antiquities; coins, medals and paper money; prints & drawings; and ethnography . A pressing problem was finding space for additions to the library which now required an extra 1 1 ⁄ 4 miles of shelving each year. The Government suggested a site at St Pancras for the new British Library but the books did not leave the museum until 1997.

The Great Court emerges (1975–2000)
The departure of the British Library to a new site at St Pancras, finally achieved in 1998, provided the space needed for the books. It also created the opportunity to redevelop the vacant space in Robert Smirke's 19th-century central quadrangle into the Queen Elizabeth II Great Court – the largest covered square in Europe – which opened in 2000. The ethnography collections, which had been housed in the short-lived Museum of Mankind at 6 Burlington Gardens from 1970, were returned to new purpose-built galleries in the museum in 2000.
The Museum again readjusted its collecting policies as interest in "modern" objects: prints, drawings, medals and the decorative arts reawakened. Ethnographical fieldwork was carried out in places as diverse as New Guinea , Madagascar , Romania , Guatemala and Indonesia and there were excavations in the Near East , Egypt, Sudan and the UK. The Weston Gallery of Roman Britain, opened in 1997, displayed a number of recently discovered hoards which demonstrated the richness of what had been considered an unimportant part of the Roman Empire. The Museum turned increasingly towards private funds for buildings, acquisitions and other purposes. [38]

The British Museum today
Today the museum no longer houses collections of natural history , and the books and manuscripts it once held now form part of the independent British Library. The Museum nevertheless preserves its universality in its collections of artefacts representing the cultures of the world, ancient and modern. The original 1753 collection has grown to over thirteen million objects at the British Museum, 70 million at the Natural History Museum and 150 million at the British Library.
The Round Reading Room , which was designed by the architect Sydney Smirke , opened in 1857. For almost 150 years researchers came here to consult the Museum's vast library. The Reading Room closed in 1997 when the national library (the British Library) moved to a new building at St Pancras . Today it has been transformed into the Walter and Leonore Annenberg Centre.
With the bookstacks in the central courtyard of the museum empty, the process of demolition for Lord Foster 's glass-roofed Great Court could begin. The Great Court, opened in 2000, while undoubtedly improving circulation around the museum, was criticised for having a lack of exhibition space at a time when the museum was in serious financial difficulties and many galleries were closed to the public. At the same time the African collections that had been temporarily housed in 6 Burlington Gardens were given a new gallery in the North Wing funded by the Sainsbury family – with the donation valued at £25 million. [39]
As part of its very large website, the museum has the largest online database of objects in the collection of any museum in the world, with 2,000,000 individual object entries, 650,000 of them illustrated, online at the start of 2012. [40] There is also a "Highlights" database with longer entries on over 4,000 objects, and several specialised online research catalogues and online journals (all free to access). [41] In 2013 the museum's website received 19.5 millions visits, an increase of 47% from the previous year. [42]
In 2013 the museum received a record 6.7 million visitors, an increase of 20% from the previous year. [42] Popular exhibitions including "Life and Death in Pompeii and Herculaneum" and "Ice Age Art" are credited with helping fuel the increase in visitors. [43] Plans were announced in September 2014 to recreate the entire building along with all exhibits in the video game Minecraft in conjunction with members of the public. [44]

Governance
The British Museum is a non-departmental public body sponsored by the Department for Culture, Media and Sport through a three-year funding agreement. Its head is the Director . The British Museum was run from its inception by a 'Principal Librarian' (when the book collections were still part of the Museum), a role that was renamed 'Director and Principal Librarian' in 1898, and 'Director' in 1973 (on the separation of the British Library). [45]
A board of 25 trustees (with the Director as their accounting officer for the purposes of reporting to Government) is responsible for the general management and control of the Museum, in accordance with the British Museum Act 1963 and the Museums and Galleries Act 1992 . [46] Prior to the 1963 Act, it was chaired by the Archbishop of Canterbury , the Lord Chancellor and the Speaker of the House of Commons . The board was formed on the Museum's inception to hold its collections in trust for the nation without actually owning them themselves, and now fulfil a mainly advisory role. Trustee appointments are governed by the regulatory framework set out in the code of practice on public appointments issued by the Office of the Commissioner for Public Appointments. [47]

Senior management
On 29 September 2015, the Board of Trustees confirmed Hartwig Fischer as the director of the museum . He assumed his post on 4 April 2016. [48] [49]
Jonathan Williams is deputy director with responsibility for the Museum’s collection and research. [50] Christopher Yates is deputy director with responsibility for strategic planning, finance, human resources, information systems, governance, legal support, fundraising, and events. [51] Joanna Mackle is deputy director with responsibility for international engagement. [52] The post of deputy director with responsibility for the Museum's fabric and infrastructure is currently vacant. The post of deputy director with responsibility for exhibitions is also vacant. [53]

Building
The Greek Revival façade facing Great Russell Street is a characteristic building of Sir Robert Smirke , with 44 columns in the Ionic order 45 ft (14 m) high, closely based on those of the temple of Athena Polias at Priene in Asia Minor . The pediment over the main entrance is decorated by sculptures by Sir Richard Westmacott depicting The Progress of Civilisation , consisting of fifteen allegorical figures, installed in 1852.
The construction commenced around the courtyard with the East Wing ( The King's Library ) in 1823–1828, followed by the North Wing in 1833–1838, which originally housed among other galleries a reading room, now the Wellcome Gallery. Work was also progressing on the northern half of the West Wing (The Egyptian Sculpture Gallery) 1826–1831, with Montagu House demolished in 1842 to make room for the final part of the West Wing, completed in 1846, and the South Wing with its great colonnade, initiated in 1843 and completed in 1847, when the Front Hall and Great Staircase were opened to the public. [54] The Museum is faced with Portland stone , but the perimeter walls and other parts of the building were built using Haytor granite from Dartmoor in South Devon, transported via the unique Haytor Granite Tramway . [55]
In 1846 Robert Smirke was replaced as the Museum's architect by his brother Sydney Smirke , whose major addition was the Round Reading Room 1854–1857; at 140 feet (43 m) in diameter it was then the second widest dome in the world, the Pantheon in Rome being slightly wider.
The next major addition was the White Wing 1882–1884 added behind the eastern end of the South Front, the architect being Sir John Taylor .
In 1895, Parliament gave the Museum Trustees a loan of £200,000 to purchase from the Duke of Bedford all 69 houses which backed onto the Museum building in the five surrounding streets – Great Russell Street, Montague Street, Montague Place, Bedford Square and Bloomsbury Street. [56] The Trustees planned to demolish these houses and to build around the West, North and East sides of the Museum new galleries that would completely fill the block on which the Museum stands. The architect Sir John James Burnet was petitioned to put forward ambitious long-term plans to extend the building on all three sides. Most of the houses in Montague Place were knocked down a few years after the sale. Of this grand plan only the Edward VII galleries in the centre of the North Front were ever constructed, these were built 1906–14 to the design by J.J. Burnet, and opened by King George V and Queen Mary in 1914. They now house the Museum's collections of Prints and Drawings and Oriental Antiquities. There was not enough money to put up more new buildings, and so the houses in the other streets are nearly all still standing.
The Duveen Gallery, sited to the west of the Egyptian, Greek & Assyrian sculpture galleries, was designed to house the Elgin Marbles by the American Beaux-Arts architect John Russell Pope . Although completed in 1938, it was hit by a bomb in 1940 and remained semi-derelict for 22 years, before reopening in 1962. Other areas damaged during World War II bombing included: in September 1940 two unexploded bombs hit the Edward VII galleries, the King's Library received a direct hit from a high explosive bomb, incendiaries fell on the dome of the Round Reading Room but did little damage; on the night of 10 to 11 May 1941 several incendiaries fell on the south west corner of the Museum, destroying the book stack and 150,000 books in the courtyard and the galleries around the top of the Great Staircase – this damage was not fully repaired until the early 1960s. [57]
The Queen Elizabeth II Great Court is a covered square at the centre of the British Museum designed by the engineers Buro Happold and the architects Foster and Partners . [58] The Great Court opened in December 2000 and is the largest covered square in Europe. The roof is a glass and steel construction, built by an Austrian steelwork company, [59] with 1,656 uniquely shaped panes of glass. At the centre of the Great Court is the Reading Room vacated by the British Library, its functions now moved to St Pancras. The Reading Room is open to any member of the public who wishes to read there.
Today, the British Museum has grown to become one of the largest museums in the world, covering an area of over 92,000 m 2 (990,000 sq. ft). [4] [ not in citation given ] [60] In addition to 21,600 m 2 (232,000 sq. ft) [61] of on-site storage space, and 9,400 m 2 (101,000 sq. ft) [61] of external storage space. Altogether the British Museum showcases on public display less than 1% [61] of its entire collection, approximately 50,000 items. [62] There are nearly one hundred galleries open to the public, representing 2 miles (3.2 km) of exhibition space, although the less popular ones have restricted opening times. However, the lack of a large temporary exhibition space has led to the £135 million World Conservation and Exhibition Centre to provide one and to concentrate all the Museum's conservation facilities into one Conservation Centre. This project was announced in July 2007, with the architects Rogers Stirk Harbour and Partners . It was granted planning permission in December 2009 and was completed in time for the Viking exhibition in March 2014. [63] [64]
Blythe House in West Kensington is used by the Museum for off-site storage of small and medium-sized artefacts, and Franks House in East London is used for storage and work on the "Early Prehistory" – Palaeolithic and Mesolithic – and some other collections. [65]

Departments

Department of Ancient Egypt and Sudan
The British Museum houses the world's largest [h] and most comprehensive collection of Egyptian antiquities (with over 100,000 [66] pieces) outside the Egyptian Museum in Cairo . A collection of immense importance for its range and quality, it includes objects of all periods from virtually every site of importance in Egypt and the Sudan . Together, they illustrate every aspect of the cultures of the Nile Valley (including Nubia ), from the Predynastic Neolithic period (c. 10,000 BC ) through to the Coptic (Christian) times (12th century AD ), a time-span over 11,000 years.
Egyptian antiquities have formed part of the British Museum collection ever since its foundation in 1753 after receiving 160 Egyptian objects [67] from Sir Hans Sloane . After the defeat of the French forces under Napoleon at the Battle of the Nile in 1801, the Egyptian antiquities collected were confiscated by the British army and presented to the British Museum in 1803. These works, which included the famed Rosetta Stone , were the first important group of large sculptures to be acquired by the Museum. Thereafter, the UK appointed Henry Salt as consul in Egypt who amassed a huge collection of antiquities, some of which were assembled and transported with great ingenuity by the famous Italian explorer Giovanni Belzoni . Most of the antiquities Salt collected were purchased by the British Museum and the Musée du Louvre .
By 1866 the collection consisted of some 10,000 objects. Antiquities from excavations started to come to the museum in the latter part of the 19th century as a result of the work of the Egypt Exploration Fund under the efforts of E.A. Wallis Budge . Over the years more than 11,000 objects came from this source, including pieces from Amarna , Bubastis and Deir el-Bahari . Other organisations and individuals also excavated and donated objects to the British Museum, including Flinders Petrie 's Egypt Research Account and the British School of Archaeology in Egypt, as well as the Oxford University Expedition to Kawa and Faras in Sudan.
Active support by the museum for excavations in Egypt continued to result in important acquisitions throughout the 20th century until changes in antiquities laws in Egypt led to the suspension of policies allowing finds to be exported, although divisions still continue in Sudan. The British Museum conducted its own excavations in Egypt where it received divisions of finds, including Asyut (1907), Mostagedda and Matmar (1920s), Ashmunein (1980s) and sites in Sudan such as Soba , Kawa and the Northern Dongola Reach (1990s). The size of the Egyptian collections now stand at over 110,000 objects. [68]
In autumn 2001 the eight million objects forming the Museum's permanent collection were further expanded by the addition of six million objects from the Wendorf Collection of Egyptian and Sudanese Prehistory . [69] These were donated by Professor Fred Wendorf of Southern Methodist University in Texas , and comprise the entire collection of artefacts and environmental remains from his excavations at Prehistoric sites in the Sahara Desert between 1963 and 1997. Other fieldwork collections have recently come from Dietrich and Rosemarie Klemm ( University of Munich ) and William Adams ( University of Kentucky ).
The seven permanent Egyptian galleries at the British Museum, which include its largest exhibition space (Room 4, for monumental sculpture), can display only 4% of its Egyptian holdings. The second-floor galleries have a selection of the museum's collection of 140 mummies and coffins, the largest outside Cairo . A high proportion of the collection comes from tombs or contexts associated with the cult of the dead, and it is these pieces, in particular the mummies, that remain among the most eagerly sought after exhibits by visitors to the museum.
Key highlights of the collections include:
Predynastic and Early Dynastic period (c. 6000 BC – c. 2690 BC)
Old Kingdom (2690–2181 BC)
Middle Kingdom (2134–1690 BC)
New Kingdom (1549–1069 BC)
Third Intermediate Period (1069–664 BC)
Late Period (664–332 BC)
Ptolemaic dynasty (305–30 BC)
Roman Period (30 BC-641 AD)

Department of Greece and Rome
The British Museum has one of the world's largest and most comprehensive collections of antiquities from the Classical world , with over 100,000 objects. These mostly range in date from the beginning of the Greek Bronze Age (about 3200 BC) to the establishment of Christianity as the official religion of the Roman Empire, with the Edict of Milan under the reign of the Roman Emperor Constantine I in 313 AD. Archaeology was in its infancy during the nineteenth century and many pioneering individuals began excavating sites across the Classical world, chief among them for the museum were Charles Newton , John Turtle Wood , Robert Murdoch Smith and Charles Fellows .
The Greek objects originate from across the Ancient Greek world, from the mainland of Greece and the Aegean Islands, to neighbouring lands in Asia Minor and Egypt in the eastern Mediterranean and as far as the western lands of Magna Graecia that include Sicily and southern Italy. The Cycladic , Minoan and Mycenaean cultures are represented, and the Greek collection includes important sculpture from the Parthenon in Athens, as well as elements of two of the Seven Wonders of the Ancient World , the Mausoleum at Halicarnassus and the Temple of Artemis at Ephesos .
Beginning from the early Bronze Age , the department also houses one of the widest-ranging collections of Italic and Etruscan antiquities outside Italy, as well as extensive groups of material from Cyprus and non-Greek colonies in Lycia and Caria on Asia Minor. There is some material from the Roman Republic , but the collection's strength is in its comprehensive array of objects from across the Roman Empire , with the exception of Britain (which is the mainstay of the Department of Prehistory and Europe).
The collections of ancient jewellery and bronzes, Greek vases (many from graves in southern Italy that were once part of Sir William Hamilton 's and Chevalier Durand 's collections), Roman glass including the famous Cameo glass Portland Vase, Roman mosaics from Carthage and Utica in North Africa that were excavated by Nathan Davis , and silver hoards from Roman Gaul (some of which were bequeathed by the philanthropist and museum trustee Richard Payne Knight ), are particularly important. Cypriot antiquities are strong too and have benefited from the purchase of Sir Robert Hamilton Lang 's collection as well as the bequest of Emma Turner in 1892, which funded many excavations on the island. Roman sculptures (many of which are copies of Greek originals) are particularly well represented by the Townley collection as well as residual sculptures from the famous Farnese collection .
Objects from the Department of Greece and Rome are located throughout the museum, although many of the architectural monuments are to be found on the ground floor, with connecting galleries from Gallery 5 to Gallery 23. On the upper floor, there are galleries devoted to smaller material from ancient Italy, Greece, Cyprus and the Roman Empire.
Key highlights of the collections include:
Parthenon
Erechtheion
Temple of Athena Nike
Temple of Bassae
Mausoleum at Halicarnassus
Temple of Artemis in Ephesus
Knidos in Asia Minor
Xanthos in Asia Minor
Wider Collection
Prehistoric Greece and Italy (3300 BC – 8th century BC)
Etruscan (8th century BC – 1st century BC)
Ancient Greece (8th century BC – 4th century AD)
Ancient Rome (1st century BC – 4th century AD)

Department of the Middle East
With a collection numbering some 330,000 works, [71] the British Museum possesses the world's largest and most important collection of Mesopotamian antiquities outside Iraq . The collections represent the civilisations of the ancient Near East and its adjacent areas. These cover Mesopotamia , Persia , the Arabian Peninsula , Anatolia , the Caucasus , parts of Central Asia, Syria , the Holy Land and Phoenician settlements in the western Mediterranean from the prehistoric period and include objects from the beginning of Islam in the 7th century. A collection of immense importance, the holdings of Assyrian sculpture , Babylonian and Sumerian antiquities are among the most comprehensive in the world with entire suites of rooms panelled in alabaster Assyrian palace reliefs from Nimrud , Nineveh and Khorsabad . Outside the Middle East, this is the best collection, [72] and unaffected by recent terrorist destruction.
The first significant addition of Mesopotamian objects was from the collection of Claudius James Rich in 1825. The collection was later dramatically enlarged by the excavations of A. H. Layard at the Assyrian sites of Nimrud and Nineveh between 1845 and 1851. At Nimrud, Layard discovered the North-West Palace of Ashurnasirpal II , as well as three other palaces and various temples. He later uncovered the Palace of Sennacherib at Nineveh with 'no less than seventy-one halls'. As a result, a large numbers of Lamassu 's, palace reliefs, stelae , including the Black Obelisk of Shalmaneser III , were brought to the British Museum.
Layard's work was continued by his assistant, Hormuzd Rassam and in 1852–1854 he went on to discover the North Palace of Ashurbanipal at Nineveh with many magnificent reliefs, including the famous Lion Hunt of Ashurbanipal and Lachish reliefs . He also discovered the Royal Library of Ashurbanipal , a large collection of cuneiform tablets of enormous importance that today number around 130,000 pieces. W. K. Loftus excavated in Nimrud between 1850 and 1855 and found a remarkable hoard of ivories in the Burnt Palace. Between 1878 and 1882 Rassam greatly improved the Museum's holdings with exquisite objects including the Cyrus Cylinder from Babylon , the bronze gates from Balawat , important objects from Sippar , and a fine collection of Urartian bronzes from Toprakkale .
In the early 20th century excavations were carried out at Carchemish , Turkey by D. G. Hogarth and Leonard Woolley , the latter assisted by T. E. Lawrence . The Mesopotamian collections were greatly augmented by excavations in southern Iraq after the First World War . From Tell al-Ubaid came the bronze furnishings of a Sumerian temple, including life-sized lions and a panel featuring the lion-headed eagle Indugud found by H. R. Hall in 1919–24. Woolley went onto to excavate Ur between 1922 and 1934, discovering the 'Royal Cemeteries' of the 3rd millennium BC. Some of the masterpieces include the ' Standard of Ur ', the 'Ram in a Thicket', the ' Royal Game of Ur ', and two bull-headed lyres . The department also has three diorite statues of the ruler Gudea from the ancient state of Lagash and a series of limestone kudurru or boundary stones from different locations across ancient Mesopotamia .
Although the collections centre on Mesopotamia, most of the surrounding areas are well represented. The Achaemenid collection was enhanced with the addition of the Oxus Treasure in 1897 and objects excavated by the German scholar Ernst Herzfeld and the Hungarian-British explorer Sir Aurel Stein . Reliefs and sculptures from the site of Persepolis were donated by Sir Gore Ouseley in 1825 and the 5th Earl of Aberdeen in 1861. Moreover, the museum has been able to acquire one of the greatest assemblages of Achaemenid silverware in the world. The later Sasanian Empire is also well represented by ornate silver plates and cups, many representing ruling monarchs hunting lions and deer. Phoenician antiquities come from across the region, but the Tharros collection from Sardinia and the large number of Phoenician stelae from Carthage are outstanding. Another often overlooked highlight is Yemeni antiquities, the finest collection outside that country. Furthermore, the museum has a representative collection of Dilmun and Parthian material excavated from various burial mounds at the ancient sites of A'ali and Shakhura in Bahrain.
From the modern state of Syria come almost forty funerary busts from Palmyra and a group of stone reliefs from the excavations of Max von Oppenheim at Tell Halaf that was purchased in 1920. More material followed from the excavations of Max Mallowan at Chagar Bazar and Tell Brak in 1935–1938 and from Woolley at Alalakh in the years just before and after the Second World War . Mallowan returned with his wife Agatha Christie to carry out further digs at Nimrud in the postwar period which secured many important artefacts for the museum. The collection of Palestinian material was strengthened by the work of Kathleen Kenyon at Jericho in the 1950s and the acquisition in 1980 of around 17,000 objects found at Lachish by the Wellcome-Marston expedition of 1932–1938. Archaeological digs are still taking place where permitted in the Middle East, and, depending on the country, the museum continues to receive a share of the finds from sites such as Tell es Sa'idiyeh in Jordan.
The museum's collection of Islamic art , including archaeological material, numbers about 40,000 objects, [73] one of the largest of its kind in the world. As such, it contains a broad range of pottery, paintings, tiles, metalwork, glass, seals, and inscriptions from across the Islamic world, from Spain in the west to India in the east. It is particularly famous for its collection of Iznik ceramics (the largest in the world), a highlight of which is the mosque lamp from the Dome of the Rock , mediaeval metalwork such as the Vaso Vescovali with its depictions of the Zodiac , a fine selection of astrolabes , and Mughal paintings and precious artwork including a large jade terrapin made for the Emperor Jahangir . Thousands of objects were excavated after the war by professional archaeologists at Iranian sites such as Siraf by David Whitehouse and Alamut Castle by Peter Willey. The collection was augmented in 1983 by the Godman bequest of Iznik, Hispano-Moresque and early Iranian pottery. Artefacts from the Islamic world are on display in Gallery 34 of the museum.
A representative selection from the Department of Middle East, including the most important pieces, are on display in 13 galleries throughout the museum and total some 4,500 objects. A whole suite of rooms on the ground floor display the sculptured reliefs from the Assyrian palaces at Nineveh, Nimrud and Khorsabad, while 8 galleries on the upper floor hold smaller material from ancient sites across the Middle East . The remainder form the study collection which ranges in size from beads to large sculptures. They include approximately 130,000 cuneiform tablets from Mesopotamia. [74]
Key highlights of the collections include:
Nimrud :

Department of Prints and Drawings
The Department of Prints and Drawings holds the national collection of Western prints and drawings. It ranks as one of the largest and best print room collections in existence alongside the Albertina in Vienna, the Paris collections and the Hermitage . The holdings are easily accessible to the general public in the Study Room, unlike many such collections. [75] The department also has its own exhibition gallery in Room 90, where the displays and exhibitions change several times a year. [76]
Since its foundation in 1808, the prints and drawings collection has grown to international renown as one of the richest and most representative collections in the world. There are approximately 50,000 drawings and over two million prints. [76] The collection of drawings covers the period from the 14th century to the present, and includes many works of the highest quality by the leading artists of the European schools . The collection of prints covers the tradition of fine printmaking from its beginnings in the 15th century up to the present, with near complete holdings of most of the great names before the 19th century. Key benefactors to the department have been Clayton Mordaunt Cracherode , Richard Payne Knight , John Malcolm, Campbell Dodgson , César Mange de Hauke and Tomás Harris .
There are groups of drawings by Leonardo da Vinci , Raphael , Michelangelo , (including his only surviving full-scale cartoon ), Dürer (a collection of 138 drawings is one of the finest in existence), Peter Paul Rubens , Rembrandt , Claude and Watteau , and largely complete collections of the works of all the great printmakers including Dürer (99 engravings , 6 etchings and most of his 346 woodcuts ), Rembrandt and Goya . More than 30,000 British drawings and watercolours include important examples of work by Hogarth , Sandby , Turner , Girtin , Constable , Cotman , Cox , Gillray , Rowlandson and Cruikshank , as well as all the great Victorians . There are about a million British prints including more than 20,000 satires and outstanding collections of works by William Blake and Thomas Bewick . [ citation needed ] . The great eleven volume Catalogue of Political and Personal Satires Preserved in the Department of Prints and Drawings in the British Museum compiled between 1870 and 1954 is the definitive reference work for the study of British Satirical prints. Over 500,000 objects from the department are now on the online collection database, many with high quality images. [77] A 2011 donation of £1 million enabled the museum to acquire a complete set of Pablo Picasso 's Vollard Suite . [78]

Department of Prehistory and Europe
The Department of Prehistory and Europe was established in 1969 and is responsible for collections that cover a vast expanse of time and geography. It includes some of the earliest objects made by humans in east Africa over 2 million years ago, as well as Prehistoric and neolithic objects from other parts of the world; and the art and archaeology of Europe from the earliest times to the present day. Archeological excavation of prehistoric material took off and expanded considerably in the twentieth century and the department now has literally millions of objects from the Paleolithic and Mesolithic periods throughout the world, as well as from the Neolithic , Bronze Age and Iron age in Europe. Stone Age material from Africa has been donated by famous archaeologists such as Louis and Mary Leakey , and Gertrude Caton–Thompson . Paleolithic objects from the Sturge , Christy and Lartet collections include some of the earliest works of art from Europe. Many Bronze Age objects from across Europe were added during the nineteenth century, often from large collections built up by excavators and scholars such as Greenwell in Britain, Tobin and Cooke in Ireland, Lukis and de la Grancière in Brittany, Worsaae in Denmark, Siret at El Argar in Spain, and Klemm and Edelmann in Germany. A representative selection of Iron Age artefacts from Hallstatt were acquired as a result of the Evans / Lubbock excavations and from Giubiasco in Ticino through the Swiss National Museum .
In addition, the British Museum's collections covering the period AD 300 to 1100 are among the largest and most comprehensive in the world, extending from Spain to the Black Sea and from North Africa to Scandinavia ; a representative selection of these has recently been redisplayed in a newly refurbished gallery. Important collections include Latvian , Norwegian , Gotlandic and Merovingian material from Johann Karl Bähr , Alfred Heneage Cocks, Sir James Curle and Philippe Delamain respectively. However, the undoubted highlight from the early mediaeval period are the magnificent items from the Sutton Hoo royal grave, generously donated to the nation by the landowner Edith Pretty . The department includes the national collection of horology with one of the most wide-ranging assemblage of clocks, watches and other timepieces in Europe, with masterpieces from every period in the development of time-keeping. Choice horological pieces came from the Morgan and Ilbert collections. The department is also responsible for the curation of Romano-British objects – the museum has by far the most extensive such collection in Britain and one of the most representative regional collections in Europe outside Italy . It is particularly famous for the large number of late Roman silver treasures, many of which were found in East Anglia , the most important of which is the Mildenhall Treasure . The museum purchased many Roman-British objects from the antiquarian Charles Roach Smith in 1856. These quickly formed the nucleus of the collection.
Objects from the Department of Prehistory and Europe are mostly found on the upper floor of the museum, with a suite of galleries numbered from 38 to 51. Most of the collection is stored in its archive facilities, where it is available for research and study.
Key highlights of the collections include:
Stone Age (c. 3.4 million years BC – c. 2000 BC)
Bronze Age (c. 3300 BC – c. 600 BC)
Iron Age (c. 600 BC – c. 1st century AD)
Romano-British (43 AD – 410 AD)
Early Mediaeval (c. 4th century AD – c. 1000 AD)
Mediaeval (c. 1000 AD – c. 1500 AD)
Renaissance to Modern (c. 1500 AD – present)
The many hoards of treasure include those of Mildenhall , Esquiline , Carthage , First Cyprus , Lampsacus , Water Newton , Hoxne , and Vale of York , (4th–10th centuries AD)

Department of Asia
The scope of the Department of Asia is extremely broad; its collections of over 75,000 objects cover the material culture of the whole Asian continent (from East, South, Central and South-East Asia) and from the Neolithic up to the present day. Until recently, this department concentrated on collecting Oriental antiquities from urban or semi-urban societies across the Asian continent. Many of those objects were collected by colonial officers and explorers in former parts of the British Empire , especially the Indian subcontinent. Examples include the collections made by individuals such as Charles Stuart , James Prinsep , Charles Masson , Sir Alexander Cunningham , Sir Harold Deane and Sir John Marshall . A large number of Chinese antiquities were purchased from the Anglo-Greek banker George Eumorfopoulos in the 1930s. In the second half of the twentieth century, the museum greatly benefited from the bequest of the philanthropist PT Brooke Sewell, which allowed the department to purchase many objects and fill in gaps in the collection. [82] [83] [84]
In 2004, the ethnographic collections from Asia were transferred to the department. These reflect the diverse environment of the largest continent in the world and range from India to China, the Middle East to Japan. Much of the ethnographic material comes from objects originally owned by tribal cultures and hunter-gatherers , many of whose way of life has disappeared in the last century. Particularly valuable collections are from the Andaman and Nicobar Islands (much assembled by the British naval officer Maurice Portman ), Sri Lanka (especially through the colonial administrator Hugh Nevill ), Northern Thailand, south-west China, the Ainu of Hokaidu in Japan (chief among them the collection of the Scottish zoologist John Anderson ), Siberia and the islands of South-East Asia, especially Borneo. The latter benefited from the purchase in 1905 of the Sarawak collection put together by Dr Charles Hose , as well as from other colonial officers such as Edward A Jeffreys. In addition, a unique and valuable group of objects from Java, including shadow puppets and a gamelan musical set, was assembled by Sir Stamford Raffles .
The principal gallery devoted to Asian art in the museum is Gallery 33 with its comprehensive display of Chinese, Indian subcontinent and Southeast Asian objects. An adjacent gallery showcases the Amaravati sculptures and monuments. Other galleries on the upper floors are devoted to its Japanese, Korean, painting and calligraphy , and Chinese ceramics collections.
Key highlights of the collections include: [85]
East Asia
South Asia
South-east Asia

Department of Africa, Oceania and the Americas
The British Museum houses one of the world's most comprehensive collections of Ethnographic material from Africa, Oceania and the Americas, representing the cultures of indigenous peoples throughout the world. Over 350,000 objects [87] spanning thousands of years tells the history of mankind from three major continents and many rich and diverse cultures; the collecting of modern artefacts is ongoing. Many individuals have added to the department's collection over the years but those assembled by Henry Christy , Harry Beasley and William Oldman are outstanding. Objects from this department are mostly on display in several galleries on the ground and lower floors. Gallery 24 displays ethnographic from every continent while adjacent galleries focus on North America and Mexico . A long suite of rooms (Gallery 25) on the lower floor display African art. There are plans in place to develop permanent galleries for showcasing art from Oceania and South America.
Africa
The Sainsbury African Galleries display 600 objects from the greatest permanent collection of African arts and culture in the world. The three permanent galleries provide a substantial exhibition space for the Museum's African collection comprising over 200,000 objects. A curatorial scope that encompasses both archaeological and contemporary material, including both unique masterpieces of artistry and objects of everyday life. A great addition was material amassed by Sir Henry Wellcome , which was donated by the Wellcome Historical Medical Museum in 1954. Highlights of the African collection include objects found at megalithic circles in The Gambia, a dozen exquisite Afro-Portuguese ivories , a series of soapstone figures from the Kissi people in Sierra Leone and Liberia, Asante goldwork and regalia from Ghana including the Bowdich collection, the rare Akan Drum from the same region in west Africa, the Benin and Igbo-Ukwu bronze sculptures, the beautiful Bronze Head of Queen Idia , a magnificent brass head of a Yoruba ruler and quartz throne from Ife , a similar terracotta head from Iwinrin Grove near Ife, the Apapa Hoard from Lagos, southern Nigeria, an Ikom monolith from Cross River State, the Torday collection of central African sculpture, textiles and weaponry from the Kuba Kingdom including three royal figures , the unique Luzira Head from Uganda, processional crosses and other ecclesiastical and royal material from Gondar and Magdala , Ethiopia following the British Expedition to Abyssinia , excavated objects from Great Zimbabwe (that includes a unique soapstone, anthropomorphic figure) and satellite towns such as Mutare including a large hoard of Iron Age soapstone figures, a rare divining bowl from the Venda peoples and cave paintings and petroglyphs from South Africa .
Oceania
The British Museum's Oceanic collections originate from the vast area of the Pacific Ocean , stretching from Papua New Guinea to Easter Island, from New Zealand to Hawaii. The three main anthropological groups represented in the collection are Polynesia , Melanesia and Micronesia – Aboriginal art from Australia is considered separately in its own right. Metal working was not indigenous to Oceania before Europeans arrived, so many of the artefacts from the collection are made from stone, shell, bone and bamboo. Prehistoric objects from the region include a bird-shaped pestle and a group of stone mortars from Papua New Guinea . The British Museum is fortunate in having some of the earliest Oceanic and Pacific collections, many of which were put together by members of Cook 's and Vancouver 's expeditions or by colonial administrators such as Sir George Grey , Sir Frederick Broome and Arthur Gordon , before Western culture significantly impacted on indigenous cultures. The Wilson cabinet of curiosities from Palau is another example of pre-contact ware. The department has also benefited greatly from the legacy of pioneering anthropologists such as Bronisław Malinowski and Katherine Routledge . In addition, the Māori collection is the finest outside New Zealand with many intricately carved wooden and jade objects and the Aboriginal art collection is distinguished by its wide range of bark paintings , including two very early bark etchings collected by John Hunter Kerr . A poignant artefact is the wooden shield found near Botany Bay during Cook's first voyage in 1770. A particularly important group of objects was purchased from the London Missionary Society in 1911, that includes the unique statue of A'a from Rurutu Island, the rare idol from the isle of Mangareva and the Cook Islands deity figure . Other highlights include the huge Hawaiian statue of Kū-ka-ili-moku or god of war (one of three extant in the world) and the famous Easter Island statues Hoa Hakananai'a and Moai Hava .
Americas
The Americas collection mainly consists of 19th and 20th century items although the Paracas , Moche , Inca , Maya , Aztec , Taino and other early cultures are well represented. The Kayung totem pole , which was made in the late nineteenth century in the Queen Charlotte Islands , dominates the Great Court and provides a fitting introduction to this very wide-ranging collections that stretches from the very north of the North American continent where the Inuit population has lived for centuries, to the tip of South America where indigenous tribes have long thrived in Patagonia. Highlights of the collection include Aboriginal Canadian objects from Alaska and Canada collected by the 5th Earl of Lonsdale and the Marquis of Lorne , the Squier and Davis collection of prehistoric mound relics from North America, a selection of pottery vessels found in cliff-dwellings at Mesa Verde , a collection of turquoise Aztec mosaics from Mexico (the largest in Europe), important artefacts from Teotihuacan and Isla de Sacrificios , several rare pre-Columbian manuscripts including the Codex Zouche-Nuttall and Codex Waecker-Gotter , a spectacular series of Mayan lintels from Yaxchilan excavated by the British Mayanist Alfred Maudslay , a very high quality Mayan collection that includes sculptures from Copan , Tikal , Tulum , Pusilha , Naranjo and Nebaj (including the celebrated Fenton Vase ), a group of Zemi Figures from Vere, Jamaica , a number of prestigious pre-Columbian gold and votive objects from Colombia, ethnographic objects from across the Amazon region including the Schomburgk collection, two rare Tiwanaku pottery vessels from Lake Titicaca and important items from Tierra del Fuego donated by Commander Phillip Parker King .

Department of Coins and Medals
The British Museum is home to one of the world's finest numismatic collections, comprising about a million objects, including coins, medals, tokens and paper money. The collection spans the entire history of coinage from its origins in the 7th century BC to the present day and is representative of both the East and West . The Department of Coins and Medals was created in 1861 and celebrated its 150th anniversary in 2011. [88]

Department of Conservation and Scientific Research
This department was founded in 1920. Conservation has six specialist areas: ceramics & glass; metals; organic material (including textiles); stone, wall paintings and mosaics; Eastern pictorial art and Western pictorial art. The science department [89] has and continues to develop techniques to date artefacts, analyse and identify the materials used in their manufacture, to identify the place an artefact originated and the techniques used in their creation. The department also publishes its findings and discoveries.

Libraries and Archives
This department covers all levels of education, from casual visitors, schools, degree level and beyond. The Museum's various libraries hold in excess of 350,000 books, journals and pamphlets covering all areas of the museum's collection. Also the general Museum archives which date from its foundation in 1753 are overseen by this department; the individual departments have their own separate archives and libraries covering their various areas of responsibility, which can be consulted by the public on application. The Anthropology Library is especially large, with 120,000 volumes. [90] However, the Paul Hamlyn Library, which had become the central reference library of the British Museum and the only library there freely open to the general public, closed permanently in August 2011. [91] The website and online database of the collection also provide increasing amounts of information.

British Museum Press
The British Museum Press (BMP) is the publishing business and a division of the British Museum Company Ltd, a company and a charity (established in 1973) wholly owned by the Trustees of the British Museum. [92]
The BMP publishes both popular and scholarly illustrated books to accompany the exhibition programme and explore aspects of the general collection. Profits from their sales goes to support the British Museum. [92]
Scholarly titles are published in the Research Publications series, all of which are peer-reviewed . This series was started in 1978 and was originally called Occasional Papers. The series is designed to disseminate research on items in the collection. Between six and eight titles are published each year in this series. [93]

Controversy
It is a point of controversy whether museums should be allowed to possess artefacts taken from other countries, [ citation needed ] and the British Museum is a notable target for criticism. The Elgin Marbles , Benin Bronzes and the Rosetta Stone are among the most disputed objects in its collections, and organisations have been formed demanding the return of these artefacts to their native countries of Greece , Nigeria and Egypt respectively. Parthenon Marbles claimed by Greece were also claimed by UNESCO among others for restitution. From 1801 to 1812, Elgin's agents took about half of the surviving sculptures of the Parthenon, as well as sculptures from the Propylaea and Erechtheum.
In recent years, controversies pertaining to reparation of artefacts taken from the Old Summer Palace in Beijing during the Anglo-French invasion of China in 1860 have also begun to surface. [94] The ransacking and destruction of the Chinese palaces has led to unhealed historical wounds in Chinese culture. Victor Hugo condemned the French and British for their plundering. [95] The British Museum and the Victoria & Albert Museum, among others, have been asked since 2009 to open their archives for investigation by a team of Chinese investigators as a part of an international mission to document lost national treasures. However, there have been fears that the United Kingdom may be asked to return these treasures. [96] As of 2010 [update] , Neil MacGregor , the Director of the British Museum, said he hoped that both British and Chinese investigators would work together on the controversial collection, which continues to result in resentment in China. [97]
The British Museum has refused to return these artefacts, stating that the "restitutionist premise, that whatever was made in a country must return to an original geographical site, would empty both the British Museum and the other great museums of the world". [98] The Museum has also argued that the British Museum Act of 1963 legally prevents any object from leaving its collection once it has entered it. Nevertheless, it has returned items such as the Tasmanian Ashes after a 20-year-long battle with Australia. [99]
The British Museum continues to assert that it is an appropriate custodian and has an inalienable right to its disputed artefacts under British law .
In 2016, The British Museum moved its bag searches to marquees in the front courtyard and beside the rear entrance. This has been criticised by heritage groups as out-of-character with the historic building. The British Museum clarified that the change was purely logistical to save space in the main museum entrance and did not reflect any escalation in threat. [100]

Disputed items in the collection

Galleries
Department of Ancient Egypt and Sudan
Department of the Middle East
Department of Greece and Rome
Forgotten Empire Exhibition (October 2005 – January 2006)

See also

Notes
WebPage index: 00039
Aaron Swartz
Aaron Hillel Swartz (November 8, 1986 – January 11, 2013) was an American computer programmer, entrepreneur, writer, political organizer, and Internet hacktivist . He was involved in the development of the web feed format RSS [3] and the Markdown publishing format, [4] the organization Creative Commons , [5] the website framework web.py, [6] and the social news site Reddit , in which he became a partner after its merger with his company, Infogami. [i]
Swartz's work also focused on civic awareness and activism. [7] [8] He helped launch the Progressive Change Campaign Committee in 2009 to learn more about effective online activism . In 2010, he became a research fellow at Harvard University 's Safra Research Lab on Institutional Corruption, directed by Lawrence Lessig . [9] [10] He founded the online group Demand Progress , known for its campaign against the Stop Online Piracy Act .
On January 6, 2011, Swartz was arrested by MIT police on state breaking-and-entering charges, after connecting a computer to the MIT network in an unmarked and unlocked closet, and setting it to download academic journal articles systematically from JSTOR using a guest user account issued to him by MIT. [11] [12] Federal prosecutors later charged him with two counts of wire fraud and eleven violations of the Computer Fraud and Abuse Act , [13] carrying a cumulative maximum penalty of $1 million in fines, 35 years in prison, asset forfeiture , restitution , and supervised release . [14]
He committed suicide while under federal indictment for his alleged computer crimes . [15] Swartz declined a plea bargain under which he would have served six months in federal prison. Two days after the prosecution rejected a counter-offer by Swartz, he was found dead in his Brooklyn apartment, where he had hanged himself. [15] [16]
In June 2013, Swartz was inducted posthumously into the Internet Hall of Fame . [17] [18]

Life and works
Swartz was born in Highland Park, Illinois [2] [19] (a suburb of Chicago ), the eldest son of Jewish parents Susan and Robert Swartz and brother of Noah and Benjamin. [1] [20] His father had founded the software firm Mark Williams Company . Swartz immersed himself in the study of computers, programming, the Internet, and Internet culture . [21] He attended North Shore Country Day School , a small private school near Chicago, until 9th grade. [22] Swartz left high school in the 10th grade, and enrolled in courses at a Chicago area college. [23] [24]
At age 13, Swartz won an ArsDigita Prize , given to young people who create "useful, educational, and collaborative" noncommercial websites. [1] [25] [26] At age 14, he became a member of the working group that authored the RSS 1.0 web syndication specification .

Entrepreneurship
Swartz attended Stanford University . During his freshman year, Swartz applied to Y Combinator's very first Summer Founders Program proposing to work on a startup called Infogami designed as a flexible content management system to allow the creation of rich and visually interesting websites [27] or a form of wiki for structured data . After working on Infogami with co-founder Simon Carstensen over the summer of 2005, [28] Aaron opted not to return to Stanford, choosing instead to continue to develop and seek funding for Infogami. [27]
As part of his work on Infogami, Swartz created the web.py web application framework because he was unhappy with other available systems in the Python programming language . In early fall of 2005, Swartz worked with the founders of another nascent Y-Combinator firm Reddit , to rewrite their Lisp codebase using Python and web.py. Although Infogami's platform was abandoned after Not A Bug was acquired, Infogami's software was used to support the Internet Archive 's Open Library project and the web.py web framework was used as basis for many other projects by Swartz and many others. [6]
When Infogami failed to find further funding, Y-Combinator organizers suggested that Infogami merge with Reddit , [29] [30] which it did in November 2005 to form a new firm Not A Bug devoted to promoting both products. [29] [31] Although both projects initially struggled to gain traction, Reddit began to make large gains in popularity in 2005 and 2006.
In October 2006, based largely on the success of Reddit, Not A Bug was acquired by Condé Nast Publications , the owner of Wired magazine. [21] [32] Swartz moved with his company to San Francisco to work on Wired . [21] Swartz found office life uncongenial, and he ultimately left the company. [33]
In September 2007, Swartz joined with Infogami co-founder Simon Carstensen to launch a new firm Jottit in another attempt to create another markdown driven content management system in Python . [34]

Activism
In 2008, Swartz founded Watchdog.net, "the good government site with teeth," to aggregate and visualize data about politicians. [35] [36] In the same year, he wrote a widely circulated Guerilla Open Access Manifesto ; [37] [38] [39] [40] (see #Open Access below for details).
One of his more notorious works that supports activism is Deaddrop, now renamed to SecureDrop , a platform for secure communication between journalists and sources ( whistleblowers ) used at several news organizations, including ProPublica , The Intercept , The Guardian , and The Washington Post . [41] [42] [43] [44]

Progressive Change Campaign Committee
In 2009, wanting to learn about effective activism, Swartz helped launch the Progressive Change Campaign Committee . [45] He wrote on his blog, "I spend my days experimenting with new ways to get progressive policies enacted and progressive politicians elected." [46] Swartz led the first activism event of his career with the Progressive Change Campaign Committee, delivering thousands of "Honor Kennedy" petition signatures to Massachusetts legislators asking them to fulfill former Senator Ted Kennedy 's last wish by appointing a senator to vote for health care reform. [47]

Demand Progress
In 2010, [48] Swartz co-founded Demand Progress , [49] a political advocacy group that organizes people online to "take action by contacting Congress and other leaders, funding pressure tactics, and spreading the word" about civil liberties, government reform, and other issues. [50]
During academic year 2010–11, Swartz conducted research studies on political corruption as a Lab Fellow in Harvard University's Edmond J. Safra Research Lab on Institutional Corruption. [9] [10]
Author Cory Doctorow , in his novel, Homeland , "dr[ew] on advice from Swartz in setting out how his protagonist could use the information now available about voters to create a grass-roots anti-establishment political campaign." [51] In an afterword to the novel, Swartz wrote, "these [political hacktivist] tools can be used by anyone motivated and talented enough.... Now it's up to you to change the system. ... Let me know if I can help." [51]

Stop Online Piracy Act
Swartz was involved in the campaign to prevent passage of the Stop Online Piracy Act (SOPA), which sought to combat Internet copyright violations but was criticized on the basis that it would have made it easier for the U.S. government to shut down web sites accused of violating copyright and would have placed intolerable burdens on Internet providers. [52] Following the defeat of the bill, Swartz was the keynote speaker at the F2C:Freedom to Connect 2012 event in Washington, D.C., on May 21, 2012. His speech was titled "How We Stopped SOPA" and he informed the audience:
He added, "We won this fight because everyone made themselves the hero of their own story. Everyone took it as their job to save this crucial freedom." [53] [54] He was referring to a series of protests against the bill by numerous websites that was described by the Electronic Frontier Foundation as the biggest in Internet history, with over 115,000 sites altering their webpages. [55] Swartz also presented on this topic at an event organized by ThoughtWorks . [56]

Wikileaks
On December 27, 2010, Swartz filed a Freedom of Information Act (FOIA) request to learn about the treatment of Chelsea Manning , alleged source for WikiLeaks . [57] [58]

PACER
In 2008, Swartz downloaded about 2.7 million federal court documents stored in the PACER (Public Access to Court Electronic Records) database managed by the Administrative Office of the United States Courts . [59]
The Huffington Post characterized his actions this way: "Swartz downloaded public court documents from the PACER system in an effort to make them available outside of the expensive service. The move drew the attention of the FBI, which ultimately decided not to press charges as the documents were, in fact, public." [60]
PACER was charging 8 cents per page for information that Carl Malamud , who founded the nonprofit group Public.Resource.Org , contended should be free, because federal documents are not covered by copyright. [61] [62] The fees were "plowed back to the courts to finance technology, but the system [ran] a budget surplus of some $150 million, according to court reports," reported The New York Times . [61] PACER used technology that was "designed in the bygone days of screechy telephone modems ... put[ting] the nation's legal system behind a wall of cash and kludge." [61] Malamud appealed to fellow activists, urging them to visit one of 17 libraries conducting a free trial of the PACER system, download court documents, and send them to him for public distribution. [61]
After reading Malamud's call for action, [61] Swartz used a Perl computer script running on Amazon cloud servers to download the documents, using credentials belonging to a Sacramento library. [59] From September 4 to 20, 2008, it accessed documents and uploaded them to a cloud computing service. [62] He released the documents to Malamud's organization. [62]
On September 29, 2008, [61] the GPO suspended the free trial, "pending an evaluation" of the program. [61] [62] Swartz's actions were subsequently investigated by the FBI . [61] [62] The case was closed after two months with no charges filed. [62] Swartz learned the details of the investigation as a result of filing a FOIA request with the FBI and described their response as the "usual mess of confusions that shows the FBI's lack of sense of humor." [62] PACER still charges per page, but customers using Firefox have the option of saving the documents for free public access with a plug-in called RECAP . [63]
At a 2013 memorial for Swartz, Malamud recalled their work with PACER. They brought millions of U.S. District Court records out from behind PACER's "pay wall", he said, and found them full of privacy violations, including medical records and the names of minor children and confidential informants.
Malamud penned a more detailed account of his collaboration with Swartz on the Pacer project in an essay that appears on his website. [65]
Writing in Ars Technica , Timothy Lee, [66] who later made use of the documents obtained by Swartz as a co-creator of RECAP, offered some insight into discrepancies in reporting on just how much data Swartz had downloaded: "In a back-of-the-envelope calculation a few days before the offsite crawl was shut down, Swartz guessed he got around 25 percent of the documents in PACER. The New York Times similarly reported Swartz had downloaded "an estimated 20 percent of the entire database". Based on the facts that Swartz downloaded 2.7 million documents while PACER, at the time, contained 500 million, Lee concluded that Swartz downloaded less than one percent of the database. [59]

English Wikipedia
Swartz participated very actively as an editor at the English Wikipedia . In 2006, he ran unsuccessfully for the Wikimedia Foundation's Board of Trustees. [67]
In 2006, Swartz wrote an analysis of how Wikipedia articles are written, and concluded that the bulk of the actual content comes from tens of thousands of occasional contributors, or "outsiders", each of whom may not make many other contributions to the site, while a core group of 500 to 1,000 regular editors tend to correct spelling and other formatting errors. [68] According to Swartz: "the formatters aid the contributors, not the other way around." [68] [69] His conclusions, based on the analysis of edit histories of several randomly selected articles, contradicted the opinion of Wikipedia co-founder Jimmy Wales , who believed the core group of regular editors were providing most of the content while thousands of others contributed to formatting issues. Swartz came to his conclusions by counting the total number of characters added by an editor to a particular article—while Wales counted the total number of edits. [68]

Software developments

RDF/XML
In 2001, Swartz joined the RDF Core working group at the World Wide Web Consortium (W3C), [70] where he authored RFC 3870 , Application/RDF+XML Media Type Registration. The document described a new media type , " RDF/XML ", designed to support the Semantic Web . [71]

Markdown
Swartz was a major contributor to Markdown , [4] [72] a lightweight markup language for generating HTML, and author of its html2text translator. The syntax for Markdown was influenced by Swartz's earlier atx language (2002), [73] which today is primarily remembered for its syntax for specifying headers, known as atx-style headers: [74]
Markdown itself remains in widespread use.

Open Library
After his death, it was reported that around 2006, Swartz acquired the Library of Congress 's complete bibliographic dataset: the library charged fees to access this, but as a government document, it was not copyright-protected within the USA. By posting the data on OpenLibrary , Swartz made it freely available. [75] The Library of Congress project was met with approval by the Copyright Office. [76] Other sources [77] show that the file was donated to the Internet Archive from Plymouth State University 's library system, Scriblio. Regardless of the source, the file became the basis for the Open Library, with Swartz as chief designer.

Tor2web
In 2008, [78] Swartz worked with Virgil Griffith to design and implement Tor2web , an HTTP proxy for Tor-hidden services . The proxy was designed to provide easy access to Tor from a basic web browser . [79] [80]

DeadDrop
In 2011–2012, Swartz and Kevin Poulsen designed and implemented DeadDrop , a system that allows anonymous informants to send electronic documents without fear of disclosure. In May 2013, the first instance of the software was launched by The New Yorker under the name Strongbox . [81] [82] [83] The Freedom of the Press Foundation has since taken over development of the software, which has been renamed SecureDrop . [84]

JSTOR
According to state and federal authorities, Swartz used JSTOR , a digital repository , [85] to download a large number [ii] of academic journal articles through MIT's computer network over the course of a few weeks in late 2010 and early 2011. At the time, Swartz was a research fellow at Harvard University, which provided him with a JSTOR account. [13] Visitors to MIT's "open campus" were authorized to access JSTOR through its network. [86]
The authorities said Swartz downloaded the documents through a laptop connected to a networking switch in a controlled-access wiring closet at MIT. [12] [13] [87] [88] [89] The door to the closet was kept unlocked, according to press reports. [86] [90] [91] When discovered, a video camera was placed in the room to film Swartz and Swartz's computer was left untouched. Once video was captured of Swartz, the download was stopped and Swartz identified. Rather than pursue a civil lawsuit against him, in June 2011 it reached a settlement wherein he surrendered the downloaded data. [92] [93]

Response from JSTOR
On 25 September 2010, the IP Address 18.55.6.215, part of the MIT network, began sending hundreds of PDF download requests per minute, and was affecting the performance of the entire JSTOR site. [94] This prompted a block of the IP Address. In the morning, another IP Address, also from within the MIT network, began sending JSTOR more PDF download requests, resulting in a temporary full block on the firewall level of all MIT servers in the entire 18.0.0.0/8 range . An email was then sent to MIT, describing the situation:
From an email sent on 29 September 2010, one JSTOR employee wrote to MIT:
On 30 July 2013, JSTOR released 300 partially-redacted documents, which had been provided as incriminating evidence against Aaron Swartz. These documents were originally sent to the United States Attorney’s Office in response to subpoenas in the case United States v. Aaron Swartz. [96]
(The following images are all excerpts from the 3,461 page PDF document.)

Arrest and prosecution
On the night of January 6, 2011, Swartz was arrested near the Harvard campus by MIT police and a U.S. Secret Service agent. He was arraigned in Cambridge District Court on two state charges of breaking and entering with intent to commit a felony. [11] [12] [89] [103] [104]
On July 11, 2011, Swartz was indicted by a federal grand jury on charges of wire fraud , computer fraud , unlawfully obtaining information from a protected computer , and recklessly damaging a protected computer. [13] [105]
On November 17, 2011, Swartz was indicted by a Middlesex County Superior Court grand jury on state charges of breaking and entering with intent, grand larceny, and unauthorized access to a computer network. [106] [107] On December 16, 2011, state prosecutors filed a notice that they were dropping the two original charges; [12] the charges listed in the November 17, 2011, indictment were dropped on March 8, 2012. [108] According to a spokesperson for the Middlesex County prosecutor, the state charges were dropped to permit a federal prosecution headed by Stephen P. Heymann and supported by evidence provided by Secret Service agent Michael S. Pickett [109] to proceed unimpeded. [108]
On September 12, 2012, federal prosecutors filed a superseding indictment adding nine more felony counts, which increased Swartz's maximum criminal exposure to 50 years of imprisonment and $1 million in fines. [13] [110] [111] During plea negotiations with Swartz's attorneys, the prosecutors offered to recommend a sentence of six months in a low-security prison, if Swartz would plead guilty to 13 federal crimes. Swartz and his lead attorney rejected that deal, opting instead for a trial in which prosecutors would have been forced to justify their pursuit of Swartz. [112] [113]
The federal prosecution involved what was characterized by numerous critics such as former Nixon White House counsel John Dean as an " overcharging " 13-count indictment and "overzealous" prosecution for alleged computer crimes, brought by former U.S. Attorney for Massachusetts Carmen Ortiz . [114]
Swartz committed suicide on January 11, 2013. [115] After his death, federal prosecutors dropped the charges. [116] [117] On December 4, 2013, due to a Freedom of Information Act suit by the investigations editor of Wired magazine, several documents related to the case were released by the Secret Service , including a video of Swartz entering the MIT network closet. [118]

Death, funeral, and memorial gatherings

Death
On the evening of January 11, 2013, Swartz was found dead in his Brooklyn apartment by his partner, Taren Stinebrickner-Kauffman . [86] [119] [120] A spokeswoman for New York's Medical Examiner reported that he had hanged himself. [119] [120] [121] [122] No suicide note was found. [123] Swartz's family and his partner created a memorial website on which they issued a statement, saying: "He used his prodigious skills as a programmer and technologist not to enrich himself but to make the Internet and the world a fairer, better place." [20]
Days before Swartz's funeral, Lawrence Lessig eulogized his friend and sometime client in an essay, Prosecutor as Bully . He decried the disproportionality of Swartz's prosecution and said, "The question this government needs to answer is why it was so necessary that Aaron Swartz be labeled a 'felon'. For in the 18 months of negotiations, that was what he was not willing to accept." [124] Cory Doctorow wrote, "Aaron had an unbeatable combination of political insight, technical skill, and intelligence about people and issues. I think he could have revolutionized American (and worldwide) politics. His legacy may still yet do so." [125]

Funeral and memorial gatherings
Swartz's funeral services were held on January 15, 2013, at Central Avenue Synagogue in Highland Park , Illinois. Tim Berners-Lee , creator of the World Wide Web , delivered a eulogy. [126] [127] [128] [129] The same day, the Wall Street Journal published a story based in part on an interview with Stinebrickner-Kauffman. [130] She told the Journal that Swartz lacked the money to pay for a trial and "it was too hard for him to ... make that part of his life go public" by asking for help. He was also distressed, she said, because two of his friends had just been subpoenaed and because he no longer believed that MIT would try to stop the prosecution. [130]
Several memorials followed soon afterward. On January 19, hundreds attended a memorial at the Cooper Union , speakers at which included Stinebrickner-Kauffman, Open Source advocate Doc Searls , Creative Commons ' Glenn Otis Brown, journalist Quinn Norton , Roy Singham of ThoughtWorks , and David Segal of Demand Progress. [131] [132] [133] On January 24, there was a memorial at the Internet Archive with speakers including Stinebrickner-Kauffman, Alex Stamos, Brewster Kahle and Carl Malamud. [134] On February 4, a memorial was held in the Cannon House Office Building on Capitol Hill ; [135] [136] [137] [138] speakers at this memorial included Senator Ron Wyden and Representatives Darrell Issa , Alan Grayson and Jared Polis , [137] [138] and other lawmakers in attendance included Senator Elizabeth Warren and Representatives Zoe Lofgren and Jan Schakowsky . [137] [138] A memorial also took place on March 12 at the MIT Media Lab . [139]
Swartz's family recommended GiveWell for donations in his memory, an organization that Swartz admired, had collaborated with, and was the sole beneficiary of his will. [140] [141]

Aftermath

Family response and criticism
On January 12, 2013, Swartz's family and partner issued a statement, criticizing the prosecutors and MIT. [142] Speaking at his son's funeral on January 15, Robert Swartz said, "Aaron was killed by the government, and MIT betrayed all of its basic principles." [143]
Mitch Kapor posted the statement on Twitter . Tom Dolan , husband of U.S. Attorney for Massachusetts Carmen Ortiz , whose office prosecuted Swartz's case, replied with criticism of the Swartz family: "Truly incredible that in their own son's obit they blame others for his death and make no mention of the 6-month offer." [144] This comment triggered widespread criticism; Esquire writer Charlie Pierce replied, "the glibness with which her husband and her defenders toss off a ‘mere' six months in federal prison, low-security or not, is a further indication that something is seriously out of whack with the way our prosecutors think these days." [145]

In the press and the arts
The Huffington Post reported that "Ortiz has faced significant backlash for pursuing the case against Swartz, including a petition to the White House to have her fired." [146] Other news outlets reported similarly. [147] [148] [149]
Reuters news agency called Swartz "an online icon" who "help[ed] to make a virtual mountain of information freely available to the public, including an estimated 19 million pages of federal court documents." [150] The Associated Press (AP) reported that Swartz's case "highlights society's uncertain, evolving view of how to treat people who break into computer systems and share data not to enrich themselves, but to make it available to others," [52] and that JSTOR's lawyer, former U.S. Attorney for the Southern District of New York, Mary Jo White , had asked the lead prosecutor to drop the charges. [52]
As discussed by editor Hrag Vartanian in Hyperallergic , Brooklyn, NY muralist BAMN ("By Any Means Necessary") created a mural of Swartz. [151] "Swartz was an amazing human being who fought tirelessly for our right to a free and open Internet," the artist explained. "He was much more than just the ‘Reddit guy'."
In 2013, Kenneth Goldsmith dedicated his "Printing out the Internet" exhibition to Swartz. [152] [153]
Aaron Swartz's legacy has been reported as strengthening the "open access" to scholarship movement. In Illinois, his home state, Swartz's influence led state university faculties to adopt policies in favor of open access. [154]

The Internet’s Own Boy: The Story of Aaron Swartz
On January 11, 2014, marking the first anniversary of his death, a sneak preview was released from The Internet's Own Boy: The Story of Aaron Swartz , [155] a documentary about Swartz, the NSA and SOPA . [156] [157] The film was officially released at the January 2014 Sundance Film Festival . [158] Democracy Now! covered the release of the documentary, as well as Swartz's life and legal case, in a sprawling interview with director Brian Knappenberger , Swartz's father and brother, and his attorney. [159] The documentary is released under a Creative Commons License; [160] [161] it debuted in theaters and on-demand in June 2014. [162]
Mashable called the documentary "a powerful homage to Aaron Swartz". Its debut at Sundance received a standing ovation. Mashable printed, "With the help of experts, The Internet's Own Boy makes a clear argument: Swartz unjustly became a victim of the rights and freedoms for which he stood." [163] The Hollywood Reporter described it as a "heartbreaking" story of a "tech wunderkind persecuted by the US government", and a must-see "for anyone who knows enough to care about the way laws govern information transfer in the digital age". [164]

Killswitch
In October 2014, Killswitch , a film featuring Aaron Swartz, as well as Lawrence Lessig, Tim Wu , and Edward Snowden received its World Premiere at the Woodstock Film Festival , where it won the award for Best Editing. The film focuses on Swartz' integral role in the battle to control the Internet. [165] [166]
In February 2015, Killswitch was invited to screen at the Capitol Visitor's Center in Washington DC by Congressman Alan Grayson . The event was held on the eve of the Federal Communications Commission's historic decision on Net Neutrality . Congressman Grayson, Lawrence Lessig, and Free Press CEO Craig Aaron spoke about Swartz and his fight on behalf of a free and open Internet at the event. [167] [168]
Congressman Grayson states that Killswitch is "one of the most honest accounts of the battle to control the Internet – and access to information itself." [167] Richard von Busack of the Metro Silicon Valley , writes of Killswitch , "Some of the most lapidary use of found footage this side of The Atomic Café". [165] Fred Swegles of the Orange County Register , remarks, "Anyone who values unfettered access to online information is apt to be captivated by Killswitch , a gripping and fast-paced documentary." [166] Kathy Gill of GeekWire asserts that " Killswitch is much more than a dry recitation of technical history. Director Ali Akbarzadeh, producer Jeff Horn, and writer Chris Dollar created a human centered story. A large part of that connection comes from Lessig and his relationship with Swartz." [169]

Open Access
A long-time supporter of Open Access , Swartz wrote in his Guerilla Open Access Manifesto : [39]
Supporters of Swartz responded to news of his death with an effort called #PDFTribute [170] to promote Open Access. [171] [172] On January 12, Eva Vivalt, a development economist at the World Bank , began posting her academic articles online using the hashtag #pdftribute as a tribute to Swartz. [172] [173] [174] Scholars posted links to their works. [175]
Swartz's death prompted calls for more open access to scholarly data (e.g., open science data ). [176] [177]
The Think Computer Foundation and the Center for Information Technology Policy (CITP) at Princeton University announced scholarships awarded in memory of Aaron Swartz. [178]
In 2013, Swartz was posthumously awarded the American Library Association 's James Madison Award for being an "outspoken advocate for public participation in government and unrestricted access to peer-reviewed scholarly articles." [179] [180]
In March, the editor and editorial board of the Journal of Library Administration resigned en masse , citing a dispute with the journal's publisher, Routledge . [181] One board member wrote of a "crisis of conscience about publishing in a journal that was not open access" after the death of Aaron Swartz. [182] [183]
In 2002, Swartz had stated that when he died, he wanted all the contents of his hard drives made publicly available. [184] [185]

Hacks
On January 13, 2013, members of Anonymous hacked two websites on the MIT domain, replacing them with tributes to Swartz that called on members of the Internet community to use his death as a rallying point for the open access movement. The banner included a list of demands for improvements in the U.S. copyright system, along with Swartz's Guerilla Open Access Manifesto. [186]
On the night of January 18, 2013, MIT's e-mail system was taken out of action for ten hours. [187] On January 22, e-mail sent to MIT was redirected by hackers Aush0k and TibitXimer to the Korea Advanced Institute of Science & Technology . All other traffic to MIT was redirected to a computer at Harvard University that was publishing a statement headed "R.I.P Aaron Swartz," [188] with text from a 2009 posting by Swartz, [189] accompanied by a chiptunes version of The Star-Spangled Banner . MIT regained full control after about seven hours. [190]
In the early hours of January 26, 2013, the U.S. Sentencing Commission website, USSC.gov, was hacked by Anonymous. [191] [192] The home page was replaced with an embedded YouTube video, Anonymous Operation Last Resort . The video statement said Swartz "faced an impossible choice". [193] [194]
A hacker downloaded "hundreds of thousands" of scientific-journal articles from a Swiss publisher's website and republished them on the open Web in Swartz's honor a week before the first anniversary of his death. [195]

MIT and the Abelson investigation
MIT maintains an open-campus policy along with an "open network." [91] [196] Two days after Swartz's death, MIT President L. Rafael Reif commissioned professor Hal Abelson to lead an analysis of MIT's options and decisions relating to Swartz's "legal struggles." [197] [198] To help guide the fact-finding stage of the review, MIT created a website where community members could suggest questions and issues for the review to address. [199] [200]
Swartz's attorneys have requested that all pretrial discovery documents be made public, a move which MIT opposed. [201] Swartz allies have criticized MIT for its opposition to releasing the evidence without redactions. [202]
On July 26, 2013, the Abelson panel submitted a 182-page report to MIT president, L. Rafael Reif, who authorized its public release on July 30. [203] [204] [205] The panel reported that MIT had not supported charges against Swartz and cleared the institution of wrongdoing. However, its report also noted that despite MIT's advocacy for open access culture at the institutional level and beyond, the university never extended that support to Swartz. The report revealed, for example, that while MIT considered the possibility of issuing a public statement about its position on the case, it never materialized. [206]

Petition to the White House
After Swartz's death, more than 50,000 people signed an online petition [207] to the White House calling for the removal of Ortiz, "for overreach in the case of Aaron Swartz." [208] A similar petition [209] was submitted calling for prosecutor Stephen Heymann's firing. [210] [211]
In January 2015, two years after Swartz’s death, the White House declined both petitions. [212]

Congress
Several members of the U.S. House of Representatives — Republican Darrell Issa and Democrats Jared Polis and Zoe Lofgren — all on the House Judiciary Committee , have raised questions regarding the government's handling of the case. Calling the charges against him "ridiculous and trumped up," Polis said Swartz was a "martyr", whose death illustrated the need for Congress to limit the discretion of federal prosecutors. [213] Speaking at a memorial for Swartz on Capitol Hill , Issa said
Massachusetts Democratic Senator Elizabeth Warren issued a statement saying "[Aaron's] advocacy for Internet freedom, social justice, and Wall Street reform demonstrated ... the power of his ideas...." [214] In a letter to Attorney General Eric Holder , [215] Texas Republican Senator John Cornyn asked, "On what basis did the U.S. Attorney for the District of Massachusetts conclude that her office's conduct was ‘appropriate'?" and "Was the prosecution of Mr. Swartz in any way retaliation for his exercise of his rights as a citizen under the Freedom of Information Act?" [216] [217] [218]

Congressional investigations
Issa, who chairs the House Committee on Oversight and Government Reform , announced that he would investigate the Justice Department's actions in prosecuting Swartz. [213] In a statement to the Huffington Post , he praised Swartz's work toward "open government and free access to the people." Issa's investigation has garnered some bipartisan support. [214]
On January 28, 2013, Issa and ranking committee member Elijah Cummings published a letter to U.S. Attorney General Holder, questioning why federal prosecutors had filed the superseding indictment. [111] [219]
On February 20, WBUR reported that Ortiz was expected to testify at an upcoming Oversight Committee hearing about her office's handling of the Swartz case. [220]
On February 22, Associate Deputy Attorney General Steven Reich conducted a briefing for congressional staffers involved in the investigation. [221] [222] They were told that Swartz's Guerilla Open Access Manifesto played a role in prosecutorial decision-making. [38] [221] [222] Some are reported to have been left with the impression that prosecutors believed Swartz had to be convicted of a felony carrying at least a short prison sentence in order to justify having filed the case against him in the first place. [221] [222]
Excoriating the Department of Justice as the "Department of Vengeance", Stinebrickner-Kauffman told the Guardian that the DOJ had erred in relying on Swartz's Guerilla Open Access Manifesto as an accurate indication of his beliefs by 2010. "He was no longer a single issue activist," she said. "He was into lots of things, from healthcare, to climate change to money in politics." [38]
On March 6, Holder testified before the Senate Judiciary Committee that the case was "a good use of prosecutorial discretion." [223] Stinebrickner-Kauffman issued a statement in reply, repeating and amplifying her claims of prosecutorial misconduct. Public documents, she wrote, reveal that prosecutor Stephen Heymann "instructed the Secret Service to seize and hold evidence without a warrant... lied to the judge about that fact in written briefs... [and] withheld exculpatory evidence... for over a year," violating his legal and ethical obligations to turn it over. [224]
On March 22, Senator Al Franken wrote Holder a letter expressing concerns. Franken said, "charging a young man like Mr. Swartz with federal offenses punishable by over 35 years of federal imprisonment seems remarkably aggressive — particularly when it appears that one of the principal aggrieved parties ... did not support a criminal prosecution." [225]

Amendment to Computer Fraud and Abuse Act
In 2013, Rep. Zoe Lofgren (D-Calif.) introduced a bill, Aaron's Law ( H.R. 2454 , S. 1196 [226] ) to exclude terms of service violations from the 1986 Computer Fraud and Abuse Act and from the wire fraud statute. [227]
Lawrence Lessig wrote of the bill, "this is a critically important change.... The CFAA was the hook for the government's bullying.... This law would remove that hook. In a single line: no longer would it be a felony to breach a contract." [228] Professor Orin Kerr, a specialist in the nexus between computer law and criminal law, wrote that he had been arguing for precisely this sort of reform of the Act for years. [229] The ACLU , too, has called for reform of the CFAA to "remove the dangerously broad criminalization of online activity." [230] The EFF has mounted a campaign for these reforms. [231]
Lessig's inaugural Chair lecture as Furman Professor of Law and Leadership was entitled Aaron's Laws: Law and Justice in a Digital Age ; he dedicated the lecture to Swartz. [76] [232] [233] [234]
The Aaron's Law bill stalled in committee since May 2014, reportedly due to Oracle Corporation 's financial interests. [235]

Fair Access to Science and Technology Research Act
The Fair Access to Science and Technology Research Act (FASTR) is a bill that would mandate earlier public release of taxpayer-funded research. FASTR has been described as "The Other Aaron's Law." [236]
Senator Ron Wyden (D-Ore.) and Senator John Cornyn (R-Tex.) introduced the Senate version, in 2013 and again in 2015, while the bill was introduced to the House by Reps. Zoe Lofgren (D-Calif.), Mike Doyle (D-Pa.) and Kevin Yoder (R-Kans.). Senator Wyden wrote of the bill, "the FASTR act provides that access to taxpayer funded research should never be hidden behind a paywall." [237]
While the legislation has not passed as of October 2015 [update] , it has helped to prompt some motion toward more open access on the part of the US administration. Shortly after the bill's original introduction, the Office of Science and Technology Policy directed "each Federal agency with over $100 million in annual conduct of research and development expenditures to develop a plan to support increased public access to the results of research funded by the Federal Government." [238]

Commemorations
On August 3, 2013, Swartz was posthumously inducted into the Internet Hall of Fame . [17] [18] There was a hackathon held in Swartz' memory around the date of his birthday in 2013. [239] [240] Over the weekend of November 8–10, 2013, inspired by Swartz's work and life, a second annual hackathon was held in at least 16 cities around the world. [241] [242] [243] PreliminarHuby topics worked on at the 2013 Aaron Swartz Hackathon [244] were privacy and software tools, transparency, activism, access, legal fixes, and a low-cost book scanner. [245] In January 2014, Lawrence Lessig led a walk across New Hampshire in honor of Swartz, rallying for campaign finance reform. [246] [247]

Sci-Hub
Following Swartz's example Kazakh computer scientist and neuro-researcher Alexandra Elbakyan founded the website Sci-Hub . [248] Sci-Hub gives access to paywalled articles through its repository without paying, as of 2016 holding over 50 million articles. [248] [249] Elbakyan has frequently been compared to Swartz in her solid criticism of paywalls and her dedication to Sci-Hub which she says will not be brought down regardless of lawsuits. [250]

Publications

Notes
WebPage index: 00040
Sue Gardner
Sue Gardner (born May 11, 1967) [2] is a Canadian journalist . She was the executive director of the Wikimedia Foundation from December 2007 until May 2014, [3] and before that was the director of the Canadian Broadcasting Corporation's website and online news outlets.
In 2012, she was ranked as the 70th most powerful woman in the world by Forbes magazine. [4] In 2013, she joined the board of Global Voices . [5] In May 2015, the Tor Project announced that Gardner will be assisting the project with the development of their long-term organizational strategy. [6]

Early life
Gardner was born in Barbados . [1] She grew up in Port Hope, Ontario , Canada, the daughter of an Anglican minister and a school principal. [7] She received a degree in journalism from Ryerson University . [7]

Career

Journalism
Gardner began her career on Canadian Broadcasting Corporation (CBC) radio in 1990 on the program As It Happens , and worked for more than a decade as a producer, reporter and documentary-maker for CBC Radio current-affairs and for Newsworld International , focusing on pop culture and social issues. [8]
In March 2006, she succeeded Claude Galipeau as senior director of CBC.ca , the CBC website and Internet platform, building its staff from 35 to 160. [9] [10] [11]

Wikimedia
In May 2007, Gardner resigned from CBC, and shortly thereafter began consulting for the Wikimedia Foundation as a special advisor on operations and governance. [12] In December 2007, she was hired as the foundation's executive director. [13] Over the next two years, she oversaw growth of the staff including the addition of a fundraising team, and a move of the headquarters from St. Petersburg , Florida , to San Francisco , California . In October 2009, Gardner was named by The Huffington Post as one of ten "media game changers of the year" for the impact on new media of her work for Wikimedia. [14]
On March 27, 2013, Gardner announced she would be leaving her position at the Wikimedia Foundation. She stated that the Wikimedia Foundation is doing well now but that the Internet is not, and that she planned to help in that area going forward. [15] Gardner identified the "turning point" for her decision to move on as her involvement in the 2012 Wikipedia blackout protesting the Stop Online Piracy Act and the Protect Intellectual Property Act , protests that "started me thinking about the shape the Internet was taking and what role I could play in that." [16]
In 2013, Gardner received an honorary doctorate from Ryerson University, her alma mater . [17] [18]
It was announced on 1 May 2014 that Lila Tretikov would be replacing Gardner, and would take over as executive director of the Wikimedia Foundation on 1 June 2014. [3] [19] [20] [21]

Tor and First Look
Gardner has joined The Tor Project, Inc to develop a strategic plan, with support from First Look Media . [22] [23]
WebPage index: 00041
Swedish Wikipedia
The Swedish Wikipedia ( Swedish : svenska Wikipedia , also svenskspråkiga Wikipedia ) is the Swedish language edition of Wikipedia and was started on 23 May 2001. [1] It is currently the third largest Wikipedia by article-count with its 3,787,447 current articles, where a majority are generated by a bot
The administrators on the Swedish Wikipedia (currently 67) are elected for a fixed-term period of one year and have to be re-elected after that time. For active administrators not involved in controversies the re-election is often just a routine.

History
Originally, Swedish Wikipedia rivalled susning.nu , a wiki created by Lars Aronsson in 2001. Susning.nu was by 28 May 2003 the world's second largest wiki. Due to several controversies involving the authority of the founder, objections to Aronsson's decision to allow advertisement on the site, and the lack of proper tools to fight vandalism , several prolific Susning writers switched over to Swedish Wikipedia in 2002, and later more followed. [2] In April 2004, Susning.nu's editing features were closed down to all but a handful of users, which further increased the flow to Swedish Wikipedia. On 14 January 2005, Wikipedia's article count surpassed that of Susning.nu. [ citation needed ]
In March 2006, the Swedish newspaper Svenska Dagbladet published a comparative evaluation of Swedish Wikipedia, Susning.nu and the online version of Nationalencyklopedin . The evaluation was done by giving a selection of articles to independent subject matter experts for grading. While Nationalencyklopedin came out on top with respect to factuality and neutrality, Swedish Wikipedia received a good overall grade and came out on top with respect to being up to date and having a broad coverage, also including popular culture subjects. [3]
On 27 September 2012 it reached 500,000 articles. [4] On 15 June 2013 it reached 1,000,000 articles and rose from 8th to 5th place. [5] This meant that during 2012 and 2013 the number of articles on Swedish Wikipedia more than doubled. This is in large part due to a community project where bots were used in producing articles for all existing species of plants and animals. When finished, this project alone created more than a million articles, most short and sourced through available online databases on the subject. [6] To date, already about half of its articles were created by a single bot . [7]

Gallery

See also
WebPage index: 00042
Italian Wikipedia
The Italian Wikipedia ( Italian : Wikipedia in italiano ) is the Italian-language edition of Wikipedia . This edition was created on May 11, 2001 [1] and first edited on June 11, 2001. As of 26 May 2017 it has 1,359,154 articles and more than 1,511,739 registered accounts. [2] It is the 8th-largest Wikipedia by the number of articles (after the English , Swedish , German , Dutch , French , Cebuano , and Russian editions). [3]

History
As early as March 2001, Jimmy Wales , the creator and co-founder of the original English language Wikipedia , had proposed the creation of parallel Wikipedia projects in other languages. [4] The Italian language version was among the first ones to be created, in May 2001. The original URL was italian.wikipedia.com , while the standardized ISO 639 address it.wikipedia.com became active a few days later. [5] Afterwards, Wikipedia sites switched their domains from wikipedia.com to wikipedia.org . The very first pages (circa five hundred) were simply untranslated copies from the English-language Wikipedia; the first edits were made from 11 June 2001 onwards.
One of the earlier edits was an appeal to help Nupedia ; the first entries on the Italian Wikipedia were the pages on Dante Alighieri , Petrarch , Manzoni , and other Italian writers. The edits were not numerous, and the priority was initially given to helping Nupedia; the lemmas were just twenty or thirty, and there were about ten users. With the end of the Nupedia project, the situation began to improve for the Italian Wikipedia: users started to sign in, and the functions of administrators and semi-protection were implemented. This happened by 2004; the number of articles was now 56,000.
In August 2005 the Italian Wikipedia overtook the Spanish and Portuguese language editions, becoming the 8th largest edition by article count. The primary reason for the rapid leap from 56,000 to 64,000 articles was an automated bot which created stub articles on more than 8,000 municipalities of Spain in an operation dubbed " Comuni spagnoli ". [6] [7]
On September 8, 2005, the Italian Wikipedia overtook the Dutch Wikipedia and one day later, on September 9, it passed 100,000 articles. On September 11, it overtook the Swedish Wikipedia , becoming the fifth-largest language edition. Again, automated scripts contributed heavily to the growth. For instance, a bot created more than 35,000 articles on municipalities of France . [8] However, it was overtaken by the Polish edition on September 23, 2005.
In June 2006, Italian Wikipedia users independently created the Template:Bio (with "Bio" being a diminutive of biografia , " biography "). On 23 October, the Polish version surpassed the Italian Wikipedia by number of articles. As of 16 October 2006, the registered number of users was 100,000 (90 of which were administrators).
In 2007, the Italian Wikipedia adopted an Exemption Doctrin Policy , shared with other Wikipedias. In the same year, on 21 May, there were more than 300,000 entries. On 22 January 2008, the entries were 400,000; on 3 October, they were 500,000. The number of users had reached 250,000.
In 2009 the Italian Wikipedia was awarded the Premiolino , the oldest and most prestigious Italian journalism prize, in the new media category.
On June 22, 2010, it passed 700,000 articles ( Robie House – 700,000th article). On September 28, 2010, the Italian Wikipedia overtook the Polish Wikipedia, becoming the 4th largest edition, though in October 2010 the numbers on both Wikipedias were very close, and as of 2011 the Polish Wikipedia is in the lead again. [9] On May 12, 2011, it passed 800,000 articles. On the same day, it overtook the Polish Wikipedia. On March 12, 2012, it passed 900,000 articles. On January 22, 2013, it passed 1,000,000 articles.
In April 2016, the project had 2233 active editors who made at least five edits in that month.

2011 mass blanking protest
From October 4 to October 6, 2011, following a decision adopted by volunteers of the Italian Wikipedia community, a knowledge blackout was in place. During this time, all of the site's articles were hidden and the website was blocked by its administrators, as a protest against the DDL intercettazioni (Wiretapping Bill) [10] which was being debated at the time in the Chamber of Deputies of the Italian parliament . [11]
The controversy largely centered on paragraph 29 of the proposed bill. [12] According to a public statement by editors of the Italian Wikipedia: [12]
The bill allowed for a fine of between €9,500 and €12,000. [13]
This was the first time that a Wikipedia had blanked all its content to protest. [14] [15] [16] The Wikimedia Foundation officially supported the decision of the Italian Wikipedia by a statement released the same day. [11] As of 5 October 2011 [update] the manifesto, which replaced the Italian Wikipedia, had been viewed approximately 8 million times. [17] On October 6, 2011, the website content was restored, with a banner across the top of each page explaining the reason for the protest. [18]
On 18 January 2012, the English Wikipedia was shut down for 24 hours, following a decision by contributors to protest against two bills being examined by the Congress of the United States : the Stop Online Piracy Act and the Protect Intellectual Property Act . On that day, the Italian Wikipedia redirected users from its own main page to a black page expressing a message of support to the decision of the English encyclopedia. Users could then click to access the Italian encyclopedia's content normally.
On 10 July 2012, when the Russian Wikipedia was closed to protest State Duma ’s debating of amendments to the law "On information" ( Law Project No. 89417-6 ), the Italian Wikipedia displayed a site-wide banner supporting the protest. [19]
In November 2012, messages appeared on the Italian Wikipedia protesting the Italian Senate 's Bill #3491 , 3204 , 3.400 and especially 3.207 . [20]

Features
WebPage index: 00043
Portuguese Wikipedia
The Portuguese Wikipedia ( Portuguese : "Wikipédia em português" or "Wikipédia lusófona" ) is the Portuguese language edition of Wikipedia (written Wikipédia, in Portuguese), the free encyclopedia. It was started on 11 May 2001. [1] It is currently (July 2016) the thirteenth largest Wikipedia by article count , containing 969,220 articles.

History
From late 2004, the edition grew rapidly. During May 2005, it overtook both the Spanish and Italian language Wikipedias. By comparison, in May 2004 it was only the 17th Wikipedia by the number of articles.
Portuguese articles can contain variations of writing, as European Portuguese and Brazilian Portuguese have differences in vocabulary and usage. Articles can contain written characteristics of one or the other variant depending on who wrote the article.
The Portuguese Wikipedia community decided not to split a separate Brazilian Portuguese version off from the Portuguese Wikipedia. [2] In 2005, a proposal to fork Portuguese Wikipedia and create a Brazilian Portuguese ( pt-br ) version was voted down by the Wikimedia community. [3] In 2007 another one to create European Portuguese was rejected too by the Wikimedia community. [4] In 2009 another one to create in Brazilian Portuguese was rejected, but this time by language committee, according to new policies to create new Wikipedia editions, [5] with the following explanation: "Brazilian Portuguese is not a separate language.. this is a requirement." [6]
Beginning in January 2007, [7] the project experienced a decrease of the share of edits by unregistered users (from around 20 to around 15%) and an increase of the share of such edits being reverted, from about 15% to a peak of 25% in late 2008, [8] which suggests an increase of disruptive editing. In the same month, a JavaScript was added that forced all unregistered users to preview their edit before saving it. [9]
In December 2010, the Portuguese Wikipedia overtook the Dutch language Wikipedia in number of articles, but in the first quarter of 2011 it was surpassed by the Russian and Dutch language Wikipedias, ranking in the tenth position. It is currently (2016) the 14th Wikipedia version by number of articles.
In April 2016, the project had 1388 active editors who made at least five edits in that month.

Characteristics
The Portuguese language Wikipedia is different from the English one in a number of aspects.
WebPage index: 00044
Subdomain
WebPage index: 00045
American and British English spelling differences
Many of the differences between American and British English date back to a time when spelling standards had not yet developed. For instance, some spellings seen as "American" today were once commonly used in Britain and some spellings seen as "British" were once commonly used in the United States. A "British standard" began to emerge following the 1755 publication of Samuel Johnson 's A Dictionary of the English Language , and an "American standard" started following the work of Noah Webster and in particular his An American Dictionary of the English Language , first published in 1828. [1]
Webster's efforts at spelling reform were somewhat effective in his native country, resulting in certain well-known patterns of spelling differences between the American and British varieties of English . But English-language spelling reform has rarely been adopted otherwise, and thus modern English orthography varies somewhat between countries and is far from phonemic in any country.

Historical origins
In the early 18th century, English spelling was inconsistent. These differences became noticeable after the publishing of influential dictionaries . Today's British English spellings mostly follow Johnson's A Dictionary of the English Language (1755), while many American English spellings follow Webster's An American Dictionary of the English Language ("ADEL", "Webster's Dictionary", 1828). [2]
Webster was a proponent of English spelling reform for reasons both philological and nationalistic. In A Companion to the American Revolution (2008), John Algeo notes: "it is often assumed that characteristically American spellings were invented by Noah Webster. He was very influential in popularizing certain spellings in America, but he did not originate them. Rather […] he chose already existing options such as center, color and check for the simplicity, analogy or etymology". [3] William Shakespeare 's first folios, for example, used spellings like center and color as much as centre and colour . [4] [5] Webster did attempt to introduce some reformed spellings, as did the Simplified Spelling Board in the early 20th century, but most were not adopted. In Britain, the influence of those who preferred the Norman (or Anglo-French ) spellings of words proved to be decisive. Later spelling adjustments in the United Kingdom had little effect on today's American spellings and vice versa.
For the most part, the spelling systems of most Commonwealth countries and Ireland closely resemble the British system. In Canada , the spelling system can be said to follow both British and American forms, [6] and Canadians are somewhat more tolerant of foreign spellings when compared with other English-speaking nationalities. [7] Australian spelling has also strayed slightly from British spelling, with some American spellings incorporated as standard. [8] New Zealand spelling is almost identical to British spelling, except in the word fiord (instead of fjord ). There is also an increasing use of macrons in words that originated in Māori and an unambiguous preference for -ise endings (see below).

Latin-derived spellings

-our
Most words ending in an unstressed -our in British English (e.g., colour , flavour , behaviour , harbour , honour , humour , labour , neighbour , rumour , splendour ) end in -or in American English ( color , flavor , behavior , harbor , honor , humor , labor , neighbor , rumor , splendor ). Wherever the vowel is unreduced in pronunciation , e.g., contour , velour , paramour and troubadour the spelling is consistent everywhere.
Most words of this kind came from Latin, where the ending was spelled -or . They were first adopted into English from early Old French , and the ending was spelled -or or -ur . [9] After the Norman conquest of England , the ending became -our to match the Old French spelling. [10] The -our ending was not only used in new English borrowings, but was also applied to the earlier borrowings that had used -or . [9] However, -or was still sometimes found, [11] and the first three folios of Shakespeare 's plays used both spellings before they were standardised to -our in the Fourth Folio of 1685. [4] After the Renaissance , new borrowings from Latin were taken up with their original -or ending and many words once ending in -our (for example, chancellour and governour ) went back to -or . Many words of the -our/or group do not have a Latin counterpart; for example, armo(u)r , behavio(u)r , harbo(u)r , neighbo(u)r ; also arbo(u)r , meaning "shelter", though senses "tree" and "tool" are always arbor , a false cognate of the other word. Some 16th- and early 17th-century British scholars indeed insisted that -or be used for words from Latin (e.g., color ) [11] and -our for French loans; but in many cases the etymology was not clear, and therefore some scholars advocated -or only and others -our only. [12]
Webster's 1828 dictionary had only -or and is given much of the credit for the adoption of this form in the United States. By contrast, Johnson's 1755 dictionary used -our for all words still so spelled in Britain (like colour ), but also for words where the u has since been dropped: ambassadour , emperour , governour , perturbatour , inferiour , superiour ; errour , horrour , mirrour , tenour , terrour , tremour . Johnson, unlike Webster, was not an advocate of spelling reform, but chose the spelling best derived, as he saw it, from among the variations in his sources. He preferred French over Latin spellings because, as he put it, "the French generally supplied us". [13] English speakers who moved to America took these preferences with them, and H. L. Mencken notes that " honor appears in the 1776 Declaration of Independence , but it seems to have got there rather by accident than by design. In Jefferson 's original draft it is spelled honour ." [14] In Britain, examples of color , flavor , behavior , harbor , and neighbor rarely appear in Old Bailey court records from the 17th and 18th centuries, whereas there are thousands of examples of their -our counterparts. [15] One notable exception is honor . Honor and honour were equally frequent in Britain until the 17th century; [16] honor still is, in the UK, the usual spelling as a person's name and appears in Honor Oak , a district of London .

Derivatives and inflected forms
In derivatives and inflected forms of the -our/or words, British usage depends on the nature of the suffix used. The u is kept before English suffixes that are freely attachable to English words (for example in neighbourhood , humourless , and savoury ) and suffixes of Greek or Latin origin that have been adopted into English (for example in favourite , honourable , and behaviourism ). However, before Latin suffixes that are not freely attachable to English words, the u :
In American usage, derivatives and inflected forms are built by simply adding the suffix in all cases (for example, favorite , savory etc.) since the u is absent to begin with.

Exceptions
American usage, in most cases, keeps the u in the word glamour , which comes from Scots , not Latin or French. Glamor is sometimes used in imitation of the spelling reform of other -our words to -or . Nevertheless, the adjective glamorous often drops the first "u". Saviour is a somewhat common variant of savior in the US. The British spelling is very common for honour (and favour ) in the formal language of wedding invitations in the US. [17] The name of the Space Shuttle Endeavour has a u in it as the spacecraft was named after Captain James Cook 's ship, HMS Endeavour . The special car on Amtrak 's Coast Starlight train is known as the Pacific Parlour car, not Pacific Parlor . Proper names such as Pearl Harbor or Sydney Harbour are usually spelled according to their native-variety spelling vocabulary.
The name of the herb savory is thus spelled everywhere, although the related adjective savo(u)ry , like savo(u)r , has a u in the UK. Honor (the name) and arbor (the tool) have -or in Britain, as mentioned above. As a general noun, rigour / ˈ r ɪ ɡ ə / or / - ər / has a u in the UK; the medical term rigor (often / ˈ r aɪ ɡ ə / or / - ər / ) [18] does not, such as in rigor mortis , which is Latin. Derivations of rigour / rigor such as rigorous , however, are typically spelled without a u even in the UK. Words with the ending -irior , -erior or similar are spelled thus everywhere.
The word armour was once somewhat common in American usage but has disappeared from the current language.

Commonwealth usage
Commonwealth countries normally follow British usage. Canadian English most commonly uses the -our ending and -our- in derivatives and inflected forms. However, owing to the close historic, economic, and cultural relationship with the United States, -or endings are also sometimes used. Throughout the late 19th and early to mid-20th century, most Canadian newspapers chose to use the American usage of -or endings, originally to save time and money in the era of manual movable type . [19] However, in the 1990s, the majority of Canadian newspapers officially updated their spelling policies to the British usage of -our . This coincided with a renewed interest in Canadian English, and the release of the updated Gage Canadian Dictionary in 1997 and the first Oxford Canadian Dictionary in 1998. Historically, most libraries and educational institutions in Canada have supported the use of the Oxford English Dictionary rather the American Webster's Dictionary. Today, the use of a distinctive set of Canadian English spellings is viewed by many Canadians as one of the cultural uniquenesses of Canada (especially when compared to the United States).
In Australia, -or endings enjoyed some use throughout the 19th century and in the early 20th century. Like in Canada though, most major Australian newspapers have switched from " -or " endings to " -our " endings. The " -our " spelling is taught in schools nationwide as part of the Australian curriculum. The most notable countrywide use of the -or ending is for the Australian Labor Party , which was originally called "the Australian Labour Party" (name adopted in 1908), but was frequently referred to as both "Labour" and "Labor". The "Labor" was adopted from 1912 onward due to the influence of the American labor movement [20] and King O'Malley . Aside from that, -our is now almost universal in Australia. New Zealand English , while sharing some words and syntax with Australian English , follows British usage.

-re
In British English, some words from French, Latin or Greek end with a consonant followed by an unstressed -re (pronounced ( non-rhotic accent ) /ə(ɹ)/ or ( rhotic accent ) /ɚ/ ). In American English, most of these words have the ending -er . [21] [22] The difference is most common for words ending -bre or -tre : British spellings calibre , centre , fibre , goitre , litre , lustre , manoeuvre , meagre , metre , mitre , nitre , ochre , reconnoitre , sabre , saltpetre , sepulchre , sombre , spectre , theatre (see exceptions) and titre all have -er in American spelling.
In Britain, both -re and -er spellings were common before Johnson's dictionary was published. In Shakespeare's first folios, -er spellings are used the most. [5] Most English words that today use -er were spelled -re at one time. In American English, almost all of these have become -er , but in British English only some of them have. Words that were once spelled -re include chapter , December , disaster , enter , filter , letter , member , minister , monster , November , number , October , oyster , powder , proper , September , sober and tender . Words using the "-meter" suffix (from ancient Greek -μέτρον via post-Classical Latin meter ) have normally had the -er spelling from earliest use in English. Examples include thermometer and barometer .
The e preceding the r is kept in American-derived forms of nouns and verbs, for example, fibers , reconnoitered , centering , which are fibres , reconnoitred , and centring respectively in British English. Centring is an interesting example, since, according to the OED, it is a "word ... of 3 syllables (in careful pronunciation)" [23] (i.e., /ˈsɛntəɹɪŋ/ ), yet there is no vowel in the spelling corresponding to the second syllable ( /ə/ ). The three-syllable version is listed as only the American pronunciation of centering on the Oxford Dictionaries Online website. The e is dropped for other derivations, for example, central , fibrous , spectral . However, the existence of related words without e before the r is not proof for the existence of an -re British spelling: for example, entry and entrance come from enter , which has not been spelled entre for centuries. [24]
The difference relates only to root words; -er rather than -re is universal as a suffix for agentive ( reader , winner , user ) and comparative ( louder , nicer ) forms. One outcome is the British distinction of meter for a measuring instrument from metre for the unit of length . However, while " poetic metre " is often -re , pentameter , hexameter etc. are always -er . [25]

Exceptions
Many other words have -er in British English. These include Germanic words; such as anger , mother , timber and water and Romance words danger , quarter and river .
The ending -cre , as in acre , [26] lucre , massacre , and mediocre , is used in both British and American English to show that the c is pronounced /k/ rather than /s/ . The spellings ogre and euchre are also the same in both British and American English.
Theater is the prevailing American spelling used to refer to both the dramatic arts and buildings where stage performances and screenings of films take place (i.e., " movie theaters "); for example, a national newspaper such as The New York Times would use theater in its entertainment section. However, the spelling theatre appears in the names of many New York City theaters on Broadway [27] (cf. Broadway theatre ) and elsewhere in the United States. In 2003, the American National Theatre was referred to by The New York Times as the "American National Theater ", but the organization uses "re" in the spelling of its name. [28] [29] The John F. Kennedy Center for the Performing Arts in Washington D.C. has the more common American spelling theater in its references to The Eisenhower Theater, part of the Kennedy Center. [30] Some cinemas outside New York also use the theatre spelling. [31] (Note also that the word "theater" in American English is a place where stage performances and screenings of films take place, but in British English a "theatre" is where stage performances take place but not film screenings – these take place in a cinema.)
Some placenames in the United States use Centre in their names. Examples include the Stonebriar Centre mall, the cities of Rockville Centre and Centreville , Centre County and Centre College . Sometimes, these places were named before spelling changes but more often the spelling merely serves as an affectation.
For British accoutre , the American practice varies: the Merriam-Webster Dictionary prefers the -re spelling, [32] but The American Heritage Dictionary of the English Language prefers the -er spelling. [33]
More recent French loanwords keep the -re spelling in American English. These are not exceptions when a French-style pronunciation is used ( /ɹə/ rather than /ə(ɹ)/ or /ɚ/ ), as with double entendre , genre and oeuvre . However, the unstressed /ə(ɹ)/ and /ɚ/ pronunciation of an -er ending is used more (or less) often with some words, including cadre , macabre , maître d' , Notre Dame , piastre , and timbre .

Commonwealth usage
The -re endings are mostly standard throughout the Commonwealth. The -er spellings are recognized as minor variants in Canada, partly due to American influence, and are sometimes used in proper names (such as Toronto's controversially named Centerpoint Mall ). [34]

-ce
For advice / advise and device / devise , American English and British English both keep the noun–verb distinction both graphically and phonetically (where the pronunciation is -[s] for the noun and -[z] for the verb). For licence / license or practice / practise , British English also keeps the noun–verb distinction graphically (although phonetically the two words in each pair are homophones with -[s] pronunciation). On the other hand, American English uses license and practice for both nouns and verbs (with -[s] pronunciation in both cases too).
American English has kept the Anglo-French spelling for defense and offense , which are defence and offence in British English. Likewise, there are the American pretense and British pretence ; but derivatives such as defensive , offensive , and pretension are always thus spelled in both systems.
Australian [35] and Canadian usage generally follows British.

-xion
The spelling connexion is now rare in everyday British usage, its use lessening as knowledge of Latin lessens, [36] and it is not used at all in the US: the more common connection has become the standard worldwide. According to the Oxford English Dictionary the older spelling is more etymologically conservative, since the original Latin word had -xio- . The American usage comes from Webster , who abandoned -xion in favour of -ction by analogy with verbs like connect . [37] Connexion was still the house style of The Times of London until the 1980s and was still used by the British Post Office for its telephone services in the 1970s, but had by then been overtaken by connection in regular usage (for example, in more popular newspapers).
Complexion (which comes from complex ) is standard worldwide and complection is rare. [38] However, the adjective complected (as in "dark-complected"), although sometimes objected to, is standard in the US as an alternative to complexioned , [39] but is not used in this way in the UK, although there is a rare usage to mean complicated . [40]
In some cases, words with "old-fashioned" spellings are retained widely in the US for historical reasons (cf. connexionalism ).

Greek-derived spellings

-ise

Origin and recommendations
The -ize spelling is often incorrectly seen as an Americanism in Britain. [41] However, the Oxford English Dictionary (OED) recommends -ize and notes that the -ise spelling is from French: "The suffix…whatever the element to which it is added, is in its origin the Greek -ιζειν , Latin -izāre ; and, as the pronunciation is also with z , there is no reason why in English the special French spelling should be followed, in opposition to that which is at once etymological and phonetic." The OED lists the -ise form separately, as an alternative. [42]
Publications by Oxford University Press (OUP)—such as Henry Watson Fowler 's A Dictionary of Modern English Usage , Hart's Rules , [43] and The Oxford Guide to English Usage [44] —also recommend -ize . However, Robert Allan's Pocket Fowler's Modern English Usage considers either spelling to be acceptable anywhere but the US. [45] Also, Oxford University itself does not agree with the OUP, but advocates -ise instead of -ize in its staff style guide. [46]

Usage
American spelling avoids -ise endings in words like organize , realize and recognize . [47]
British spelling mostly uses -ise , while -ize is also used ( organise / organize , realise / realize , recognise / recognize ): [47] the ratio between -ise and -ize stood at 3:2 in the British National Corpus up to 2002. [48] The spelling -ise is more commonly used in UK mass media and newspapers, [47] including The Times (which switched conventions in 1992), [49] The Daily Telegraph and The Economist . Meanwhile, -ize is used in some British-based academic publications, such as Nature , the Biochemical Journal and The Times Literary Supplement . The dominant British English usage of -ise is preferred by Cambridge University Press . [45] The minority British English usage of -ize is known as Oxford spelling and is used in publications of the Oxford University Press, most notably the Oxford English Dictionary . It can be identified using the IETF language tag en-GB-oxendict (or, historically, by en-GB-oed ). [50]
In Canada, the -ize ending is more common, whereas in Ireland, India, Australia and New Zealand -ise spellings strongly prevail: the -ise form is preferred in Australian English at a ratio of about 3:1 according to the Macquarie Dictionary .
The same applies to derivatives and inflections such as colonisation / colonization , or modernisation / modernization
Worldwide, -ize endings prevail in scientific writing and are commonly used by many international organizations, such as the United Nations Organizations (such as the World Health Organization and the International Civil Aviation Organization ) and the International Organization for Standardization (but not by the Organisation for Economic Co-operation and Development ). The European Union 's style guides require the usage of - ise . [51] Proofreaders at the EU's Publications Office ensure consistent spelling in official publications such as the Official Journal (where legislation and other official documents are published), but the -ize spelling may be found in other documents.

Exceptions
Some verbs ending in -ize or -ise do not come from Greek - ιζειν , and their endings are therefore not interchangeable:
Some words spelled with -ize in American English are not used in British English , etc., e.g., the verb burglarize , regularly formed on the noun burglar , where the equivalent in British, and other versions of, English is the back-formation burgle and not burglarise . [56]

-yse
The ending -yse is British and -yze is American. Thus, in British English analyse , catalyse , hydrolyse and paralyse , but in American English analyze , catalyze , hydrolyze and paralyze .
Analyse seems to have been the more common spelling in 17th- and 18th-century English, but many of the great dictionaries of that time – John Kersey 's of 1702, Nathan Bailey 's of 1721 and Samuel Johnson 's of 1755 – prefer analyze . In Canada, -yze prevails, just as in the US. In South Africa, Australia and New Zealand, -yse stands alone.
English verbs ending in -lyse or -lyze are not similar to the Greek verb, which is λύω lúō ("I release"). Instead they come from the noun form λύσις lysis with the -ise or -ize suffix. For example, analyse comes from French analyser , formed by haplology from the French analysiser , [57] which would be spelled analysise or analysize in English.
Hart's Rules for Compositors and Readers at the University Press, Oxford states: "In verbs such as analyse, catalyse, paralyse, -lys- is part of the Greek stem (corresponding to the element -lusis ) and not a suffix like -ize . The spelling -yze is therefore etymologically incorrect, and must not be used, unless American printing style is being followed." [43]

-ogue
British and other Commonwealth English uses the ending -logue and -gogue while American English commonly uses the ending -log and -gog for words like analog(ue) , catalog(ue) , dialog(ue) , monolog(ue) , homolog(ue) , etc. The -gue spelling, as in catalogue , is used in the US, but catalog is more common. Additionally, in American English, dialogue is an extremely common spelling compared to dialog , although both are treated as acceptable ways to spell the word. [58] (thus the inflected forms, cataloged and cataloging vs. catalogued and cataloguing ). Synagogue is seldom used without -ue .
In Australia, analog is standard for the adjective, [ citation needed ] but both analogue and analog are current for the noun; in all other cases the -gue endings strongly prevail, [59] for example monologue , except for such expressions as dialog box in computing, [60] which are also used in the UK. In Australia, analog is used in its technical and electronic sense, as in analog electronics . [8] In Canada and New Zealand, analogue is used, but analog has some currency as a technical term [61] (e.g., in electronics, as in "analog electronics" as opposed to "digital electronics" and some video-game consoles might have an analog stick ). The -ue is absent worldwide in related words like analogy , analogous , and analogist .
Both British and American English use the spelling -gue with a silent -ue for certain words that are not part of the -ogue set, such as tongue (cf. tong ), plague , vague , and league. In addition, when the -ue is not silent, as in the words argue, ague and segue, all varieties of English use -gue.

ae
Many words that are written with ae/æ or oe/œ in British English are written with just an e in American English. The sounds in question are /iː/ or /ɛ/ (or, unstressed, /i/ or / ᵻ / ). Examples (with non-American letter in bold ): a eon , an a emia , an a esthesia , c a ecum , c a esium , c o eliac , diarrh o ea , encyclop a edia , f a eces , f o etal , gyn a ecology , h a emoglobin , h a emophilia , leuk a emia , o esophagus , o estrogen , orthop a edic , pal a eontology , p a ediatric . Oenology is acceptable in American English but is deemed a minor variant of enology , whereas although archeology and ameba exist in American English, the British versions archaeology and amoeba are more common. The chemical haem (named as a shortening of h a emoglobin ) is spelled heme in American English, to avoid confusion with hem .
Words that can be spelled either way in American English include a esthetics and arch a eology (which usually prevail over esthetics and archeology ), [62] as well as pal a estra , for which the simplified form palestra is described by Merriam-Webster as "chiefly Brit[ish]." [63]
Words that can be spelled either way in British English include encyclop a edia , hom o eopathy , cham a eleon , medi a eval (a minor variant in both AmE and BrE [64] [65] [66] ), f o etid and f o etus . The spellings f o etus and f o etal are Britishisms based on a mistaken etymology. [67] The etymologically correct original spelling fetus reflects the Latin original and is the standard spelling in medical journals worldwide, [68] the Oxford English Dictionary notes that "In Latin manuscripts both fētus and foetus are used". [69]
The Ancient Greek diphthongs <αι> and <οι> were transliterated into Latin as <ae> and <oe>. The ligatures æ and œ were introduced when the sounds became monophthongs , and later applied to words not of Greek origin, in both Latin (for example, cœli ) and French (for example, œuvre ). In English, which has adopted words from all three languages, it is now usual to replace Æ/æ with Ae/ae and Œ/œ with Oe/oe . In many words, the digraph has been reduced to a lone e in all varieties of English: for example, o economics , pr a emium , and a enigma . [70] In others, it is kept in all varieties: for example, phoenix , and usually subpoena , [71] but Phenix in Virginia . This is especially true of names: Caesar , Oedipus , Phoebe , etc. There is no reduction of Latin -ae plurals (e.g., larv ae ); nor where the digraph <ae>/<oe> does not result from the Greek-style ligature: for example, maelstrom , toe . The British form aeroplane is an instance (compare other aero- words such as aerosol ). The now chiefly North American airplane is not a respelling but a recoining, modelled after airship and aircraft . The word airplane dates from 1907, [72] at which time the prefix aero- was trisyllabic, often written aëro- .

Commonwealth usage
In Canada, e is usually preferred over oe and often over ae , [ citation needed ] but oe and ae are sometimes found in the academic and scientific writing as well as government publications (for example the fee schedule of the Ontario Health Insurance Plan ). In Australia, encyclopedia and medieval are spelled with e rather than ae , as with American usage, and the Macquarie Dictionary also notes a growing tendency towards replacing ae and oe with e worldwide. [8] Elsewhere, the British usage prevails, but the spellings with just e are increasingly used. [73] Manoeuvre is the only spelling in Australia, and the most common one in Canada, where maneuver and manoeuver are also sometimes found. [74]

Doubled consonants

Doubled in British English
The final consonant of an English word is sometimes doubled in both American and British spelling when adding a suffix beginning with a vowel, for example strip/stripped , which prevents confusion with stripe/striped and shows the difference in pronunciation (see digraph ). Generally, this happens only when the word's final syllable is stressed and when it also ends with a lone vowel followed by a lone consonant. In British English, however, a final -l is often doubled even when the final syllable is unstressed. [75] This exception is no longer usual in American English, seemingly because of Noah Webster. [76] The -ll- spellings are nevertheless still deemed acceptable variants by both Merriam-Webster Collegiate and American Heritage dictionaries.
Among consonants other than l , practice varies for some words, such as where the final syllable has secondary stress or an unreduced vowel. In the United States, the spellings kidnaped and worshiped , which were introduced by the Chicago Tribune in the 1920s, [78] are common, but kidnapped and worshipped prevail. [79] [80] Kidnapped and worshipped are the only standard British spellings.
Miscellaneous:

Doubled in American English
Conversely, there are words where British writers prefer a single l and Americans a double l . In American usage, the spelling of words is usually not changed when they form the main part (not prefix or suffix) of other words, especially in newly formed words and in words whose main part is in common use. Words with this spelling difference include wil(l)ful , skil(l)ful , thral(l)dom , appal(l) , fulfil(l) , fulfil(l)ment , enrol(l)ment , instal(l)ment . These words have monosyllabic cognates always written with -ll : will , skill , thrall , pall , fill , roll , stall . Cases where a single l nevertheless occurs in both American and British English include null → annul , annulment ; till → until (although some prefer til to reflect the single l in until , sometimes using an apostrophe ( ’til ); this should be considered a hypercorrection as till predates the use of until ); and others where the connection is not clear or the monosyllabic cognate is not in common use in American English (e.g., null is used mainly as a technical term in law, mathematics, and computer science).
In the UK, a single l is generally preferred in distil(l) , instil(l) , enrol(l) , and enthral(l)ment , and enthral(l) , although ll was formerly used; [83] these are always spelled with ll in American usage. The former British spellings instal , fulness , and dulness are now quite rare. [84] The Scottish tolbooth is cognate with tollbooth , but it has a distinct meaning.
In both American and British usages, words normally spelled -ll usually drop the second l when used as prefixes or suffixes, for example full → useful , handful ; all → almighty , altogether ; well → welfare , welcome ; chill → chilblain .
Both the British fulfil and the American fulfill never use -ll- in the middle (i.e., * fullfill and * fullfil are incorrect). [85] [86]
Johnson wavered on this issue. His dictionary of 1755 lemmatizes distil and instill , downhil and uphill . [87]

Dropped "e"
British English sometimes keeps silent "e" when adding suffixes where American English does not. Generally speaking, British English drops it in only some cases in which it is needed to show pronunciation whereas American English only uses it where needed.
Both forms of English keep the silent "e" in the words dyeing , singeing , and swingeing [90] (in the sense of dye , singe , and swinge ), to distinguish from dying , singing , swinging (in the sense of die , sing , and swing ). In contrast, the verb bathe and the British verb bath both form bathing . Both forms of English vary for tinge and twinge ; both prefer cringing , hinging , lunging , syringing .

Hard and soft "c"
A "c" is generally soft when followed by an "e", "i", or "y". One word with a pronunciation that is an exception in British English, "sceptic", is spelled "skeptic" in American English. See "Miscellaneous spelling differences" below.

Past tense differences
In the UK, Ireland, Australia, New Zealand and Canada, it is more common to end some past tense verbs with a "t" as in learnt or dreamt rather than learned or dreamed . [95] However, such spellings are also found in American English.
Several verbs have different past tenses or past participles in American and British English:

Different spellings for different meanings
See also meter/metre , for which there is a British English distinction between these etymologically related forms with different meanings but the standard American spelling is "meter". The spelling used by the International Bureau of Weights and Measures is "metre". [105] This spelling is also the usual one for the unit of length in most English-speaking countries, but only the spelling "meter" is used in American English, and this is officially endorsed by the United States. [106]

Different spellings for different pronunciations
In a few cases, essentially the same word has a different spelling that reflects a different pronunciation.
As well as the miscellaneous cases listed in the following table, the past tenses of some irregular verbs differ in both spelling and pronunciation, as with smelt (UK) versus smelled (US) (see American and British English differences: Verb morphology ).

Miscellaneous spelling differences
In the table below, the main spellings are above the accepted alternative spellings.

Compounds and hyphens
British English often prefers hyphenated compounds, such as anti-smoking , whereas American English discourages the use of hyphens in compounds where there is no compelling reason, so antismoking is much more common. [ citation needed ] Many dictionaries do not point out such differences. Canadian and Australian usage is mixed, although Commonwealth writers generally hyphenate compounds of the form noun plus phrase (such as editor-in-chief ). [196] Commander-in-chief prevails in all forms of English.

Acronyms and abbreviations
Acronyms pronounced as words are often written in title case by Commonwealth writers, but usually as upper case by Americans: for example, Nasa / NASA or Unicef / UNICEF . [203] This does not apply to abbreviations that are pronounced as individual letters (referred to by some as " initialisms "), such as US, IBM , or PRC (the People's Republic of China), which are virtually always written as upper case. However, sometimes title case is still used in the UK, such as Pc ( Police Constable ). [204]
Contractions , where the final letter is present, are often written in British English without full stops/periods ( Mr , Mrs , Dr , St , Ave ). Abbreviations where the final letter is not present generally do take full stops/periods (such as vol. , etc. , i.e. , ed. ); British English shares this convention with the French: Mlle , Mme , Dr , Ste , but M. for Monsieur . In American and Canadian English, abbreviations like St. , Ave. , Mr. , Mrs. , Ms. , Dr. , and Jr. , always require full stops/periods. Some initials are usually upper case in the US but lower case in the UK: liter/litre and its compounds ("2 L or 25 mL" vs "2 l or 25 ml"); [205] [206] and ante meridiem and post meridiem ( 10 P.M. or 10 PM vs 10 p.m. or 10 pm ). [207] [208] [209] Both AM/PM and a.m./p.m. are acceptable in American English, though AM/PM is more common.

Punctuation
The use of quotation marks , also called inverted commas or speech marks, is complicated by the fact that there are two kinds: single quotation marks (') and double quotation marks ("). British usage, at one stage in the recent past, preferred single quotation marks for ordinary use, but double quotation marks are again now increasingly common; American usage has always preferred double quotation marks, as does Canadian, Australian, and New Zealand English. It is the practice to alternate the type of quotation marks used where there is a quotation within a quotation. [210]
The convention used to be, and in American English still is, to put full stops (periods) and commas inside the quotation marks, irrespective of the sense. British English has moved away from this style while American English has kept it. British style now prefers to punctuate according to the sense, in which punctuation marks only appear inside quotation marks if they were there in the original. Formal British English practice requires a full stop to be put inside the quotation marks if the quoted item is a full sentence that ends where the main sentence ends, but it is common to see the stop outside the ending quotation marks. [211]

See also

Notes
WebPage index: 00046
North America
North America is a continent entirely within the Northern Hemisphere and almost all within the Western Hemisphere . It can also be considered a northern subcontinent of the Americas . [2] [3] It is bordered to the north by the Arctic Ocean , to the east by the Atlantic Ocean , to the west and south by the Pacific Ocean , and to the southeast by South America and the Caribbean Sea .
North America covers an area of about 24,709,000 square kilometers (9,540,000 square miles), about 16.5% of the earth's land area and about 4.8% of its total surface. North America is the third largest continent by area, following Asia and Africa , [4] and the fourth by population after Asia, Africa, and Europe . [5]
In 2013, its population was estimated at nearly 565 million people in 23 independent states , or about 7.5% of the world's population, if nearby islands (most notably the Caribbean ) are included.
North America was reached by its first human populations during the last glacial period , via crossing the Bering land bridge approximately 40,000 to 17,000 years ago. The so-called Paleo-Indian period is taken to have lasted until about 10,000 years ago (the beginning of the Archaic or Meso-Indian period). The Classic stage spans roughly the 6th to 13th centuries. The Pre-Columbian era ended with the transatlantic migrations and the arrival of European settlers during the Age of Discovery and the Early Modern period . Present-day cultural and ethnic patterns reflect different kind of interactions between European colonists , indigenous peoples , African slaves and their descendants. European influences are strongest in the northern parts of the continent while indigenous and African influences are relatively stronger in the south. Because of the history of colonialism, most North Americans speak English, Spanish or French and societies and states commonly reflect Western traditions .

Name
The Americas are usually accepted as having been named after the Italian explorer Amerigo Vespucci by the German cartographers Martin Waldseemüller and Matthias Ringmann . [6] Vespucci, who explored South America between 1497 and 1502, was the first European to suggest that the Americas were not the East Indies , but a different landmass previously unknown by Europeans. In 1507, Waldseemüller produced a world map, in which he placed the word "America" on the continent of South America, in the middle of what is today Brazil. He explained the rationale for the name in the accompanying book Cosmographiae Introductio : [7]
For Waldseemüller, no one should object to the naming of the land after its discoverer. He used the Latinized version of Vespucci's name (Americus Vespucius), but in its feminine form "America", following the examples of "Europa", "Asia" and "Africa".
Later, other mapmakers extended the name America to the northern continent, In 1538, Gerard Mercator used America on his map of the world for all the Western Hemisphere. [8]
Some argue that the convention is to use the surname for naming discoveries except in the case of royalty and so a derivation from "Amerigo Vespucci" could be problematic. [9] Ricardo Palma (1949) proposed a derivation from the "Amerrique" mountains of Central America—Vespucci was the first to discover South America and the Amerrique mountains of Central America , which connected his discoveries to those of Christopher Columbus .
Alfred E. Hudd proposed a theory in 1908 that the continents are named after a Welsh merchant named Richard Amerike from Bristol, who is believed to have financed John Cabot 's voyage of discovery from England to Newfoundland in 1497. A minutely explored belief that has been advanced is that America was named for a Spanish sailor bearing the ancient Visigothic name of 'Amairick'. Another is that the name is rooted in a Native American language. [8]

Extent
The term North America maintains various definitions in accordance with location and context. In Canadian English , North America may be used to refer to the United States and Canada together. [10] Alternatively, usage sometimes includes Greenland [11] [12] [13] and Mexico (as in the North American Free Trade Agreement ), [12] [14] [15] [16] [17] as well as offshore islands. The UN geoscheme for "North America" separates Mexico from the United States and Canada, placing it instead within its designated "Central America" region, while also treating the islands of the Caribbean separately from the US/Canada definition—the UN's "North America" definition still includes the Canadian Arctic Archipelago and Greenland together with the US/Canada continental definition, with both insular entities being tectonically on the North American plate .
In France , Italy , Portugal , Spain , Romania , Greece , and the countries of Latin America, the cognates of North America usually designate a subcontinent of the Americas comprising Canada, the United States, and Mexico, and often Greenland, Saint Pierre et Miquelon, and Bermuda. [18] [19] [20] [21] [22]
North America has been historically referred to by other names. Spanish North America ( New Spain ) was often referred to as Northern America , and this was the first official name given to Mexico. [23]

Regions
Geographically the North American continent has many regions and subregions. These include cultural, economic, and geographic regions. Economic regions included those formed by trade blocs, such as the North American Trade Agreement bloc and Central American Trade Agreement. Linguistically and culturally, the continent could be divided into Anglo-America and Latin America. Anglo-America includes most of Northern America, Belize , and Caribbean islands with English-speaking populations (though sub-national entities, such as Louisiana and Quebec , are Francophone in composition).
The southern North American continent is composed of two regions. These are Central America and the Caribbean . [24] [25] The north of the continent maintains recognized regions as well. In contrast to the common definition of "North America", that which encompasses the whole continent, the term "North America" is also used to refer to Canada, Mexico, the United States, and Greenland. [11] [12] [13] [14] [26]
The term Northern America refers to the northern-most countries and territories of North America, Canada, the United States, Greenland, Bermuda, and St. Pierre and Miquelon. [27] [28] Although rarely used, [ citation needed ] the term Middle America —not to be confused with the Midwestern United States —groups the regions of Central America, the Caribbean, and Mexico. [29]
The largest countries of the continent, Canada and the United States, also contain well-defined and recognized regions. In the case of Canada these are the British Columbia Coast , Canadian Prairies , Central Canada, Atlantic Canada , and Northern Canada. These regions also contain many subregions. In the case of the United States – and in accordance with the US Census Bureau definitions – these regions are: New England , Mid-Atlantic , East North Central States , West North Central States , South Atlantic States , East South Central States , West South Central States , Mountain States , and Pacific States . Regions shared between both nations included the Great Lakes Region . Megalopolises have also formed between both nations in the case of the Pacific Northwest and the Great Lakes Megaregion .

Countries, territories, and dependencies

History

Geologic history
Laurentia is an ancient craton which forms the geologic core of North America; it formed between 1.5 and 1.0 billion years ago during the Proterozoic eon. [37] The Canadian Shield is the largest exposure of this craton. From the Late Paleozoic to Early Mesozoic eras, North America was joined with the other modern-day continents as part of the supercontinent Pangaea , with Eurasia to its east. One of the results of the formation of Pangaea was the Appalachian Mountains , which formed some 480 million years ago, making it among the oldest mountain ranges in the world. When Pangaea began to rift around 200 million years ago, North America became part of Laurasia , before it separated from Eurasia as its own continent during the mid- Cretaceous period. [38] The Rockies and other western mountain ranges began forming around this time from a period of mountain building called the Laramide orogeny , between 80 and 55 million years ago. The formation of the Isthmus of Panama that connected the continent to South America arguably occurred approximately 12 to 15 million years ago, [39] and the Great Lakes (as well as many other northern freshwater lakes and rivers) were carved by receding glaciers about 10,000 years ago.
North America is the source of much of what humanity knows about geologic time periods. [40] The geographic area that would later become the United States has been the source of more varieties of dinosaurs than any other modern country. [40] According to paleontologist Peter Dodson, this is primarily due to stratigraphy, climate and geography, human resources, and history. [40] Much of the Mesozoic Era is represented by exposed outcrops in the many arid regions of the continent. [40] The most significant Late Jurassic dinosaur-bearing fossil deposit in North America is the Morrison Formation of the western United States. [41]

Pre-Columbian
The indigenous peoples of North America have many creation myths by which they assert that they have been present on the land since its creation. [42] The specifics of Paleo-Indian migration to and throughout the Americas , including the exact dates and routes traveled, are subject to ongoing research and discussion. [43] The traditional theory has been that these early migrants moved into the Beringia land bridge between eastern Siberia and present-day Alaska around 25,000 to 11,000 years ago. [44] The few agreements achieved to date are the origin from Central Asia , with widespread habitation of the Americas during the end of the last glacial period , or more specifically what is known as the late glacial maximum , around 13,000 years before present. [45] Some genetic research indicated secondary waves of migration occurred after the initial Paleo-Indian colonization, [46] but prior to modern Inuit , Inupiat and Yupik expansions. [47]
Before contact with Europeans , the natives of North America were divided into many different polities, from small bands of a few families to large empires. They lived in several " culture areas ", which roughly correspond to geographic and biological zones and give a good indication of the main lifeway or occupation of the people who lived there (e.g., the bison hunters of the Great Plains , or the farmers of Mesoamerica ). Native groups can also be classified by their language family (e.g., Athapascan or Uto-Aztecan ). Peoples with similar languages did not always share the same material culture , nor were they always allies . Anthropologists think that the Inuit people of the high Arctic came to North America much later than other native groups, as evidenced by the disappearance of Dorset culture artifacts from the archaeological record , and their replacement by the Thule people .
During the thousands of years of native habitation on the continent, cultures changed and shifted. One of the oldest cultures yet found is the Clovis culture of modern New Mexico . Later cultures include the Mississippian culture and related Mound building cultures, found in the Mississippi river valley and the Pueblo culture of what is now the Four Corners . The more southern cultural groups of North America were responsible for the domestication of many common crops now used around the world, such as tomatoes and squash . Perhaps most importantly they domesticated one of the world's major staples, maize (corn).
The earliest verifiable instance of pre-Columbian trans-oceanic contact by any European culture with the landmasses that geologically constitute the "mainland" of modern North America has been dated to the end of the 10th century CE - this site, situated at the northernmost extent of the island named Newfoundland , is known as L'Anse aux Meadows , where unmistakable evidence of Norse settlement was uncovered in the early 1960s. [48]
As a result of the development of agriculture in the south, many important cultural advances were made there. For example, the Maya civilization developed a writing system , built huge pyramids and temples , had a complex calendar , and developed the concept of zero around 400 CE, a few hundred years after the Mesopotamians . [49] The Mayan culture was still present in southern Mexico and Guatemala when the Spanish explorers arrived, but political dominance in the area had shifted to the Aztec Empire whose capital city Tenochtitlan was located further north in the Valley of Mexico . The Aztecs were conquered in 1521 by Hernán Cortés . [50]

Colonial period
During the Age of Discovery , Europeans explored and staked claims to various parts of North America. Upon their arrival in the " New World ", the Native American population declined substantially , because of violent conflicts with the invaders and the introduction of European diseases to which the Native Americans lacked immunity. [51] Native culture changed drastically and their affiliation with political and cultural groups also changed. Several linguistic groups died out , and others changed quite quickly. The names and cultures that Europeans recorded were not necessarily the same as the names they had used a few generations before, or the ones in use today.
Britain, Spain , and France took over extensive territories in North America - and fought over them. In the late 18th century and beginning of the 19th, independence movements that sprung up across the continent, led to the creation of the modern countries in the area. The 13 British colonies on the North Atlantic coast declared independence in 1776, becoming the United States of America . Canada was formed from the unification of northern territories controlled by Britain and France. New Spain, a territory that stretched from modern-day southern US to Central America, declared independence in 1810, becoming the First Mexican Empire . In 1823 the former Captaincy General of Guatemala , then part of the Mexican Empire, became the first independent state in Central America, officially changing its name to the United Provinces of Central America .

Geography
North America occupies the northern portion of the landmass generally referred to as the New World, the Western Hemisphere , the Americas , or simply America (which, less commonly, is considered by some as a single continent [52] [53] [54] with North America a subcontinent ). [55] North America's only land connection to South America is at the Isthmus of Panama. The continent is delimited on the southeast by most geographers at the Darién watershed along the Colombia -Panama border, placing all of Panama within North America. [56] [57] [58] Alternatively, some geologists physiographically locate its southern limit at the Isthmus of Tehuantepec , Mexico, with Central America extending southeastward to South America from this point. [59] The Caribbean islands, or West Indies, are considered part of North America. [2] The continental coastline is long and irregular. The Gulf of Mexico is the largest body of water indenting the continent, followed by Hudson Bay . Others include the Gulf of Saint Lawrence and the Gulf of California .
Before the Central American isthmus formed, the region had been underwater. The islands of the West Indies delineate a submerged former land bridge , which had connected North and South America via what are now Florida and Venezuela .
There are numerous islands off the continent's coasts; principally, the Arctic Archipelago, the Bahamas , Turks & Caicos , the Greater and Lesser Antilles , the Aleutian Islands (some of which are in the Eastern Hemisphere proper), the Alexander Archipelago , the many thousand islands of the British Columbia Coast, and Newfoundland. Greenland, a self-governing Danish island, and the world's largest , is on the same tectonic plate (the North American Plate ) and is part of North America geographically. In a geologic sense, Bermuda is not part of the Americas, but an oceanic island which was formed on the fissure of the Mid-Atlantic Ridge over 100 million years ago. The nearest landmass to it is Cape Hatteras , North Carolina . However, Bermuda is often thought of as part of North America, especially given its historical, political and cultural ties to Virginia and other parts of the continent.
The vast majority of North America is on the North American Plate. Parts of western Mexico, including Baja California, and of California , including the cities of San Diego , Los Angeles , and Santa Cruz , lie on the eastern edge of the Pacific Plate , with the two plates meeting along the San Andreas fault . The southernmost portion of the continent and much of the West Indies lie on the Caribbean Plate , whereas the Juan de Fuca and Cocos plates border the North American Plate on its western frontier.
The continent can be divided into four great regions (each of which contains many subregions): the Great Plains stretching from the Gulf of Mexico to the Canadian Arctic ; the geologically young, mountainous west, including the Rocky Mountains , the Great Basin , California and Alaska ; the raised but relatively flat plateau of the Canadian Shield in the northeast; and the varied eastern region, which includes the Appalachian Mountains, the coastal plain along the Atlantic seaboard, and the Florida peninsula. Mexico, with its long plateaus and cordilleras , falls largely in the western region, although the eastern coastal plain does extend south along the Gulf.
The western mountains are split in the middle into the main range of the Rockies and the coast ranges in California, Oregon , Washington , and British Columbia , with the Great Basin—a lower area containing smaller ranges and low-lying deserts—in between. The highest peak is Denali in Alaska.
The United States Geographical Survey (USGS) states that the geographic center of North America is "6 miles [10 km] west of Balta, Pierce County, North Dakota " at about 48°10′N 100°10′W ﻿ / ﻿ 48.167°N 100.167°W ﻿ / 48.167; -100.167 , about 24 kilometres (15 mi) from Rugby, North Dakota . The USGS further states that "No marked or monumented point has been established by any government agency as the geographic center of either the 50 States, the conterminous United States, or the North American continent." Nonetheless, there is a 4.6-metre (15 ft) field stone obelisk in Rugby claiming to mark the center. The North American continental pole of inaccessibility is located 1,650 km (1,030 mi) from the nearest coastline, between Allen and Kyle , South Dakota at 43°22′N 101°58′W ﻿ / ﻿ 43.36°N 101.97°W ﻿ / 43.36; -101.97 ﻿ ( Pole of Inaccessibility North America ) . [60]

Geology

Canadian geology
Geologically, Canada is one of the oldest regions in the world, with more than half of the region consisting of precambrian rocks that have been above sea level since the beginning of the Palaeozoic era. [61] Canada's mineral resources are diverse and extensive. [61] Across the Canadian Shield and in the north there are large iron, nickel, zinc , copper, gold, lead, molybdenum , and uranium reserves. Large diamond concentrations have been recently developed in the Arctic, [62] making Canada one of the world's largest producers. Throughout the Shield there are many mining towns extracting these minerals. The largest, and best known, is Sudbury , Ontario. Sudbury is an exception to the normal process of forming minerals in the Shield since there is significant evidence that the Sudbury Basin is an ancient meteorite impact crater . The nearby, but less known Temagami Magnetic Anomaly has striking similarities to the Sudbury Basin. Its magnetic anomalies are very similar to the Sudbury Basin, and so it could be a second metal-rich impact crater. [63] The Shield is also covered by vast boreal forests that support an important logging industry.

United States geology
The lower 48 US states can be divided into roughly five physiographic provinces:
The geology of Alaska is typical of that of the cordillera, while the major islands of Hawaii consist of Neogene volcanics erupted over a hot spot .

Central American geology
Central America is geologically active with volcanic eruptions and earthquakes occurring from time to time. In 1976 Guatemala was hit by a major earthquake , killing 23,000 people; Managua, the capital of Nicaragua, was devastated by earthquakes in 1931 and 1972, the last one killing about 5,000 people; three earthquakes devastated El Salvador, one in 1986 and two in 2001; one earthquake devastated northern and central Costa Rica in 2009, killing at least 34 people; in Honduras a powerful earthquake killed seven people in 2009.
Volcanic eruptions are common in the region. In 1968 the Arenal Volcano , in Costa Rica, erupted and killed 87 people. Fertile soils from weathered volcanic lavas have made it possible to sustain dense populations in the agriculturally productive highland areas.
Central America has many mountain ranges ; the longest are the Sierra Madre de Chiapas , the Cordillera Isabelia , and the Cordillera de Talamanca . Between the mountain ranges lie fertile valleys that are suitable for the people; in fact, most of the population of Honduras, Costa Rica, and Guatemala live in valleys. Valleys are also suitable for the production of coffee, beans, and other crops.

Climate
North America is a very large continent which surpasses the Arctic Circle , and the Tropic of Cancer . Greenland, along with the Canadian shield , is tundra with average temperatures ranging from between 10 to 20 °C (50 to 68 °F), but central Greenland is composed of a very large ice sheet. This tundra radiates throughout Canada, but its border ends near the Rocky Mountains (but still contains Alaska) and at the end of the Canadian Shield, near the Great Lakes. Climate west of the Cascades is described as being a temperate weather with average precipitation 20 inches (510 mm). [64] Climate in coastal California is described to be Mediterranean, with average temperatures in cities like San Francisco ranging from between 57 to 70 °F (14 to 21 °C) over the course of the year. [65]
Stretching from the East Coast to eastern North Dakota, and stretching down to Kansas, is the continental-humid climate featuring hard seasons, with a large amount of annual precipitation, with places like New York City averaging 50 inches (1,300 mm). [66] Starting at the southern border of the continental-humid climate and stretching to the Gulf of Mexico (whilst encompassing the eastern half of Texas) is the subtropical climate. This area has the wettest cities in the contiguous U.S. with annual precipitation reaching 67 inches (1,700 mm) in Mobile, Alabama. [67] Stretching from the borders of the continental humid and subtropical climates, and going west to the Cascades Sierra Nevada, south to the southern tip of durango, north to the border with tundra climate, the steppe/desert climate is the driest climate in the U.S. [68]

Ecology

Demographics
Economically, Canada and the United States are the wealthiest and most developed nations in the continent, followed by Mexico, a newly industrialized country . [69] The countries of Central America and the Caribbean are at various levels of economic and human development. For example, small Caribbean island-nations, such as Barbados, Trinidad and Tobago, and Antigua and Barbuda, have a higher GDP (PPP) per capita than Mexico due to their smaller populations. Panama and Costa Rica have a significantly higher Human Development Index and GDP than the rest of the Central American nations. [70] Additionally, despite Greenland's vast resources in oil and minerals, much of them remain untapped, and the island is economically dependent on fishing, tourism, and subsidies from Denmark. Nevertheless, the island is highly developed. [71]
Demographically, North America is ethnically diverse. Its three main groups are Caucasians , Mestizos and Blacks . [ citation needed ] There is a significant minority of Indigenous Americans and Asians among other less numerous groups. [ citation needed ]

Languages
The dominant languages in North America are English, Spanish, and French. Danish is prevalent in Greenland alongside Greenlandic , and Dutch is spoken side by side local languages in the Dutch Caribbean . The term Anglo-America is used to refer to the anglophone countries of the Americas: namely Canada (where English and French are co-official) and the United States, but also sometimes Belize and parts of the tropics, especially the Commonwealth Caribbean . Latin America refers to the other areas of the Americas (generally south of the United States) where the Romance languages , derived from Latin , of Spanish and Portuguese (but French speaking countries are not usually included) predominate: the other republics of Central America (but not always Belize), part of the Caribbean (not the Dutch-, English-, or French-speaking areas), Mexico, and most of South America (except Guyana , Suriname , French Guiana (France), and the Falkland Islands (UK)).
The French language has historically played a significant role in North America and now retains a distinctive presence in some regions. Canada is officially bilingual. French is the official language of the Province of Quebec, where 95% of the people speak it as either their first or second language, and it is co-official with English in the Province of New Brunswick . Other French-speaking locales include the Province of Ontario (the official language is English, but there are an estimated 600,000 Franco-Ontarians), the Province of Manitoba (co-official as de jure with English), the French West Indies and Saint-Pierre et Miquelon , as well as the US state of Louisiana, where French is also an official language. Haiti is included with this group based on historical association but Haitians speak both Creole and French. Similarly, French and French Antillean Creole is spoken in Saint Lucia and the Commonwealth of Dominica alongside English.

Religions
Christianity is the largest religion in the United States, Canada and Mexico according to a 2012 Pew Research Center survey, 77.4% of the population considered themselves Christians . [72] Christianity also is the predominant religion in the 23 dependent territories in North America . [73] The United States has the largest Christian population in the world, with nearly 247 million Christians (70%), although other countries have higher percentages of Christians among their populations. [74] Mexico has the world's second largest number of Catholics, surpassed only by Brazil . [75] A 2015 study estimates about 493,000 Christian believers from a Muslim background in North America, most of them belonging to some form of Protestantism. [76]
According to the same study religiously unaffiliated (include agnostic and atheist ) make up about 17.1% of the population of Canada and the United States. [77] No religion make up about 22.8% of the United States population, and 23.9% of Canada total population. [78]
Canada, the United States and Mexico host communities of both Jews (6 million or about 1.8%), [79] Buddhists (3.8 million or 1.1%) [80] and Muslims (3.4 million or 1.0%). [81] The biggest number of Jewish individuals can be found in the United States (5.4 million), [82] Canada (375,000) [83] and Mexico (67,476). [84] The United States host the largest Muslim population in North America with 2.7 million or 0.9%, [85] [86] While Canada host about one million Muslim or 3.2% of the population. [87] While in Mexico there were 3,700 Muslims in the country. [88] In 2012, U-T San Diego estimated U.S. practitioners of Buddhism at 1.2 million people, of whom 40% are living in Southern California . [89]
The predominant religion in Central America is Christianity (95.6%). [90] Beginning with the Spanish colonization of Central America in the 16th century, Roman Catholicism became the most popular religion in the region until the first half of the 20th century. Since the 1960s, there has been an increase in other Christian groups, particularly Protestantism , as well as other religious organizations, and individuals identifying themselves as having no religion. Also Christianity is the predominant religion in the Caribbean (84.7%). [90] Other religious groups in the region are Hinduism , Islam , Rastafari (in Jamaica), and Afro-American religions such as Santería and Vodou .

Populace
The most populous country in North America is the United States with 318.4 million persons. [91] The second largest country is Mexico with a population of 112,322,757. [92] Canada is the third most populous country with 32,623,490. [93] The majority of Caribbean island-nations have national populations under a million, though Cuba, Dominican Republic, Haiti, Puerto Rico (a territory of the United States), Jamaica, and Trinidad and Tobago each have populations higher than a million. [94] [95] [96] [97] [98] Despite Greenland's massive size (2,166,000 km² or 836,297 mi²), it has the world's lowest population density at 0.03 pop./km² (0.08 pop./mi²) for a small population of 55,984. [99]
While the United States, Canada, and Mexico maintain the largest populations, large city populations are not restricted to those nations. There are also large cities in the Caribbean. The largest cities in North America, by far, are Mexico City and New York. These cities are the only cities on the continent to exceed eight million, and two of three in the Americas. Next in size are Los Angeles, Toronto , [100] Chicago, Havana, Santo Domingo, and Montreal . Cities in the sunbelt regions of the United States, such as those in Southern California and Houston , Phoenix , Miami, Atlanta , and Las Vegas , are experiencing rapid growth. These causes included warm temperatures, retirement of Baby Boomers , large industry, and the influx of immigrants. Cities near the United States border, particularly in Mexico, are also experiencing large amounts of growth. Most notable is Tijuana , a city bordering San Diego that receives immigrants from all over Latin America and parts of Europe and Asia. Yet as cities grow in these warmer regions of North America, they are increasingly forced to deal with the major issue of water shortages . [101]
Eight of the top ten metropolitan areas are located in the United States . These metropolitan areas all have a population of above 5.5 million and include the New York City metropolitan area , Los Angeles metropolitan area , Chicago metropolitan area , and the Dallas–Fort Worth metroplex . [102] Whilst the majority of the largest metropolitan areas are within the United States, Mexico is host to the largest metropolitan area by population in North America: Greater Mexico City . [103] Canada also breaks into the top ten largest metropolitan areas with the Toronto metropolitan area having six million people. [104] The proximity of cities to each other on the Canada–United States border and Mexico–United States border has led to the rise of international metropolitan areas. These urban agglomerations are observed at their largest and most productive in Detroit–Windsor and San Diego–Tijuana and experience large commercial, economic, and cultural activity. The metropolitan areas are responsible for millions of dollars of trade dependent on international freight. In Detroit-Windsor the Border Transportation Partnership study in 2004 concluded US$13 billion was dependent on the Detroit–Windsor international border crossing while in San Diego-Tijuana freight at the Otay Mesa Port of Entry was valued at US$20 billion. [105] [106]
North America has also been witness to the growth of megapolitan areas . In the United States exists eleven megaregions that transcend international borders and comprise Canadian and Mexican metropolitan regions. These are the Arizona Sun Corridor , Cascadia, Florida, Front Range , Great Lakes Megaregion, Gulf Coast Megaregion , Northeast , Northern California , Piedmont Atlantic , Southern California, and the Texas Triangle . [107] Canada and Mexico are also the home of megaregions. These include the Quebec City – Windsor Corridor , Golden Horseshoe – both of which are considered part of the Great Lakes Megaregion – and megalopolis of Central Mexico . Traditionally the largest megaregion has been considered the Boston-Washington, D.C. Corridor, or the Northeast, as the region is one massive contiguous area. Yet megaregion criterion have allowed the Great Lakes Megalopolis to maintain status as the most populated region, being home to 53,768,125 people in 2000. [108]
The top ten largest North American metropolitan areas by population as of 2013, based on national census numbers from the United States and census estimates from Canada and Mexico.
‌ † 2011 Census figures.

Economy
Canada, Mexico, and the United States have significant and multifaceted economic systems. The United States has the largest economy of all three countries and in the world. [109] In 2014, the US had an estimated per capita gross domestic product (PPP) of $54,980, and is the most technologically developed economy of the three. [109] The United States' services sector comprises 76.7% of the country's GDP (estimated in 2010), industry comprises 22.2% and agriculture comprises 1.2%. [109]
Canada shows significant growth in the sectors of services, mining and manufacturing. [110] Canada's per capita GDP (PPP) was estimated at $44,656 and it had the 11th largest GDP (nominal) in 2014. [110] Canada's services sector comprises 78% of the country's GDP (estimated in 2010), industry comprises 20% and agriculture comprises 2%. [110] Mexico has a per capita GDP (PPP) of $16,111 and as of 2014 is the 15th largest GDP (nominal) in the world. [111] Being a newly industrialized country , [69] Mexico maintains both modern and outdated industrial and agricultural facilities and operations. [112] Its main sources of income are oil, industrial exports, manufactured goods, electronics, heavy industry, automobiles, construction, food, banking and financial services. [113]
The North American economy is well defined and structured in three main economic areas. [114] These areas are the North American Free Trade Agreement (NAFTA), Caribbean Community and Common Market (CARICOM), and the Central American Common Market (CACM). [114] Of these trade blocs, the United States takes part in two. In addition to the larger trade blocs there is the Canada-Costa Rica Free Trade Agreement among numerous other free trade relations, often between the larger, more developed countries and Central American and Caribbean countries.
The North America Free Trade Agreement (NAFTA) forms one of the four largest trade blocs in the world. [115] Its implementation in 1994 was designed for economic homogenization with hopes of eliminating barriers of trade and foreign investment between Canada, the United States and Mexico. [116] While Canada and the United States already conducted the largest bilateral trade relationship – and to present day still do – in the world and Canada - United States trade relations already allowed trade without national taxes and tariffs, [117] NAFTA allowed Mexico to experience a similar duty-free trade. The free trade agreement allowed for the elimination of tariffs that had previously been in place on United States-Mexico trade. Trade volume has steadily increased annually and in 2010, surface trade between the three NAFTA nations reached an all-time historical increase of 24.3% or US$791 billion. [118] The NAFTA trade bloc GDP (PPP) is the world's largest with US$17.617 trillion. [119] This is in part attributed to the fact that the economy of the United States is the world's largest national economy; the country had a nominal GDP of approximately $14.7 trillion in 2010. [120] The countries of NAFTA are also some of each other's largest trade partners. The United States is the largest trade partner of Canada and Mexico; [121] while Canada and Mexico are each other's third largest trade partners. [122] [123]
The Caribbean trade bloc – CARICOM – came into agreement in 1973 when it was signed by 15 Caribbean nations. As of 2000, CARICOM trade volume was US$96 billion. CARICOM also allowed for the creation of a common passport for associated nations. In the past decade the trade bloc focused largely on Free Trade Agreements and under the CARICOM Office of Trade Negotiations (OTN) free trade agreements have been signed into effect.
Integration of Central American economies occurred under the signing of the Central American Common Market agreement in 1961; this was the first attempt to engage the nations of this area into stronger financial cooperation. Recent implementation of the Central American Free Trade Agreement (CAFTA) has left the future of the CACM unclear. [124] The Central American Free Trade Agreement was signed by five Central American countries, the Dominican Republic, and the United States. The focal point of CAFTA is to create a free trade area similar to that of NAFTA. In addition to the United States, Canada also has relations in Central American trade blocs. Currently under proposal, the Canada – Central American Free Trade Agreement (CA4) would operate much the same as CAFTA with the United States does.
These nations also take part in inter-continental trade blocs. Mexico takes a part in the G3 Free Trade Agreement with Colombia and Venezuela and has a trade agreement with the EU. The United States has proposed and maintained trade agreements under the Transatlantic Free Trade Area between itself and the European Union ; the US-Middle East Free Trade Area between numerous Middle Eastern nations and itself; and the Trans-Pacific Strategic Economic Partnership between Southeast Asian nations, Australia, and New Zealand.

Transport
The Pan-American Highway route in the Americas is the portion of a network of roads nearly 48,000 km (30,000 mi) in length which travels through the mainland nations. No definitive length of the Pan-American Highway exists because the US and Canadian governments have never officially defined any specific routes as being part of the Pan-American Highway, and Mexico officially has many branches connecting to the US border. However, the total length of the portion from Mexico to the northern extremity of the highway is roughly 26,000 km (16,000 mi).
The First Transcontinental Railroad in the United States was built in the 1860s, linking the railroad network of the eastern US with California on the Pacific coast. Finished on 10 May 1869 at the famous Golden spike event at Promontory Summit, Utah , it created a nationwide mechanized transportation network that revolutionized the population and economy of the American West , catalyzing the transition from the wagon trains of previous decades to a modern transportation system. [125] Although an accomplishment, it achieved the status of first transcontinental railroad by connecting myriad eastern US railroads to the Pacific and was not the largest single railroad system in the world. The Canadian Grand Trunk Railway (GTR) had, by 1867, already accumulated more than 2,055 km (1,277 mi) of track by connecting Ontario with the Canadian Atlantic provinces west as far as Port Huron, Michigan , through Sarnia, Ontario .

Communications
A shared telephone system known as the North American Numbering Plan (NANP) which is an integrated telephone numbering plan of 24 countries and territories: the United States and its territories , Canada, Bermuda, and 17 Caribbean nations.

Culture
Canada and the United States were both former British colonies . There is frequent cultural interplay between the United States and English-speaking Canada. Greenland shares some cultural ties with the indigenous people of Canada but is considered Nordic and has strong Danish ties due to centuries of colonization by Denmark . Spanish-speaking North America shares a common past as former Spanish colonies . In Mexico and the Central American countries where civilizations like the Maya developed, indigenous people preserve traditions across modern boundaries. Central American and Spanish-speaking Caribbean nations have historically had more in common due to geographical proximity.
Northern Mexico, particularly in the cities of Monterrey , Tijuana, Ciudad Juárez , and Mexicali , is strongly influenced by the culture and way of life of the United States . Of the aforementioned cities, Monterrey has been regarded as the most Americanized city in North America. [126] Immigration to the United States and Canada remains a significant attribute of many nations close to the southern border of the US. The Anglophone Caribbean states have witnessed the decline of the British Empire and its influence on the region, and its replacement by the economic influence of Northern America. In the Anglophone Caribbean. This is partly due to the relatively small populations of the English-speaking Caribbean countries, and also because many of them now have more people living abroad than those remaining at home.

Sports
The following table shows the most prominent sports leagues in North America, in order of average revenue. [127] [128]

See also
Organizations and agreements:

Notes
WebPage index: 00047
Edwin Black
Edwin Black is a Jewish-American syndicated columnist and investigative journalist . He specializes in human rights , the historical interplay between economics and politics in the Middle East , petroleum policy, the abuses practiced by corporations, and the financial underpinnings of Nazi Germany .

Biography

Early years
Black is the son of Polish Jews who were survivors of the Holocaust. His mother, Ethel "Edjya" Katz, from Białystok , told of narrowly escaping death the Holocaust by escaping a boxcar en route to the Treblinka extermination camp as a 13-year old in August 1943. After escaping, she was shot. [1] Black's father described escaping his own murder by fleeing to the woods from a long march to an isolated "shooting pit" and subsequently fighting the Nazis as a Betar partisan . The pair had survived World War II by hiding in the forests of Poland for two years, emerging only after the end of the conflict and emigrating to the United States. [2]
Of his own origins, Black has written: "I was born in Chicago, raised in Jewish neighborhoods, and my parents never tried to speak of their experience again." [2]
In his book The Transfer Agreement Black notes that following in the beliefs of his parents he was from his earliest days a supporter of the State of Israel . [2] As a young man he spent time on a kibbutz , visited Israel on several other occasions, and gave earnest consideration to permanent residency there. [2]

Career
Black began working as a professional journalist while still in high school, later attending university where he further developed the craft. He also was a frequent freelance contributor to the four major Chicago newspapers of the day, the Tribune , the Daily News , the Sun-Times , and Chicago Today , as well as such weeklies as Chicago Reader and Chicago Magazine . [ citation needed ]
In 1978 Black interviewed the American Civil Liberties Union lawyer who represented members of the American Nazi Party which in an intended provocation had marched through the predominantly Jewish Chicago suburb of Skokie . [3] In preparing himself for that interview, Black's interest was piqued in the hidden history of relations between the government of Adolf Hitler and German-Jewish Zionists during the first years of the Nazi regime. Five years of research followed, ending in the 1984 publication of his first book, The Transfer Agreement: The Dramatic Story of the Pact Between the Third Reich and Jewish Palestine . [4]
In the early 1990s Black served as the editor-in-chief for OS/2 Professional magazine and OS/2 Week [5] [6] and reported on OS/2 users and technology.
Black's books have typically made use of networks of volunteer and professional researchers assembled for each project. Three years before completion of his 2001 book, IBM and the Holocaust , Black began to put together what would ultimately become a team of more than 100 researchers, translators, and assistants to work on discovery and analysis of primary source documents written in German, French, and Polish. [ citation needed ] In all, more than 20,000 documents from some 50 different libraries, archives, museums, and other collections were assembled and analyzed in the writing of the book. [7]
In the fall of 2012 it was reported that Plan B, a production company owned by actor Brad Pitt , had taken an option on a cinematic adaptation of Black's IBM and the Holocaust. [8] Marcus Hinchey , co-writer of the 2010 film All Good Things , was tapped for script-writing responsibilities. [8]
Black has written on topics beyond that of 1933-1945 German history, including books on the issue of oil dependence, the history of Iraq , and alternative energy . He is presently a contributor to the online magazine, The Cutting Edge. [ citation needed ]
Black has also occasionally written on the subject of film and television music , contributing opinion pieces and composer interviews to various print and online publications. [9] An aficionado of musical soundtracks , Black regularly credits specific works which have provided "musical inspiration that propelled the writing" in the introductory notes to each book. [10]

Selected book tours
In February and March 2014, Black embarked upon a "Parliamentary Tour" in which he appeared at four parliaments in a four-week period, including the House of Commons in London, the European Parliament in Brussels, the Israeli Knesset in Jerusalem, and the Foreign Affairs Committee of the United States House of Representatives in Washington D.C. [11]
In November and December 2014, he went on a 45-event "Human Rights Tour." In North Carolina, Black reportedly appeared nine times in three days speaking out against the persecution of Yazidis, Shia Muslims, and Christians in Iraq, racial injustice in America and its impact on the November elections, as well as environmental injustice arising out of oil addiction, journalistic ethics in covering human rights, bias against Jews in Israel, and a health care crisis in the Middle East. [12] At one of his November events, a lecture about his book Financing the Flames presented at Guilford College in Greensboro, North Carolina , some members of the audience associated with a group called Students for Justice in Palestine participated in an organized walk-out over his positions on the Mid-East conflict. [13]

Selected literary awards
Black's ten works of non-fiction have been translated into an array of non-English languages, including French , Polish , Hungarian , Dutch , German , Spanish , Japanese , Portuguese , and Hebrew . [14]

Selected human rights awards

Works

Books

Anthology contributions

Contributions to video and film documentaries

Footnotes

External links
Media related to Edwin Black at Wikimedia Commons
WebPage index: 00048
Plagiarism
Plagiarism is the "wrongful appropriation" and "stealing and publication" of another author 's "language, thoughts, ideas, or expressions" and the representation of them as one's own original work . [1] [2]
Plagiarism is considered academic dishonesty and a breach of journalistic ethics . It is subject to sanctions like penalties, suspension, and even expulsion . Recently, cases of 'extreme plagiarism' have been identified in academia. [3] The modern concept of plagiarism as immoral and originality as an ideal emerged in Europe in the 18th century, particularly with the Romantic movement .
Plagiarism is not in itself a crime , but can constitute copyright infringement . In academia and industry, it is a serious ethical offense. [4] [5] Plagiarism and copyright infringement overlap to a considerable extent, but they are not equivalent concepts, and many types of plagiarism do not constitute copyright infringement, which is defined by copyright law and may be adjudicated by courts. Plagiarism is not defined or punished by law, but rather by institutions (including professional associations, educational institutions, and commercial entities, such as publishing companies).

Etymology
In the 1st century, the use of the Latin word plagiarius (literally "kidnapper") to denote stealing someone else's work was pioneered by the Roman poet Martial , who complained that another poet had "kidnapped his verses". Plagiary , a derivative of plagiarus , was introduced into English in 1601 by dramatist Ben Jonson during the Jacobean Era to describe someone guilty of literary theft. [4] [6]
The derived form plagiarism was introduced into English around 1620. [7] The Latin plagiārius , "kidnapper", and plagium , "kidnapping", have the root plaga ("snare", "net"), based on the Indo-European root *-plak , "to weave" (seen for instance in Greek plekein , Bulgarian "плета" pleta , and Latin plectere , all meaning "to weave").

Legal aspects
Although plagiarism in some contexts is considered theft or stealing, the concept does not exist in a legal sense, although the use of someone elses work in order to gain academic credit may meet some legal definitions of fraud . [8] "Plagiarism" specifically is not mentioned in any current statute, either criminal or civil . [9] [5] Some cases may be treated as unfair competition or a violation of the doctrine of moral rights . [5] The increased availability of copyrighted material due to the development of information technology has furthered the debate as to whether copyright offences are criminal. [ citation needed ] In short, people are asked to use the guideline, "if you did not write it yourself, you must give credit". [10]
Plagiarism is not the same as copyright infringement . While both terms may apply to a particular act, they are different concepts, and false claims of authorship generally constitute plagiarism regardless of whether the material is protected by copyright. Copyright infringement is a violation of the rights of a copyright holder, when material whose use is restricted by copyright is used without consent. Plagiarism, in contrast, is concerned with the unearned increment to the plagiarizing author's reputation, or the obtaining of academic credit, that is achieved through false claims of authorship. Thus, plagiarism is considered a moral offense against the plagiarist's audience (for example, a reader, listener, or teacher).
Plagiarism is also considered a moral offense against anyone who has provided the plagiarist with a benefit in exchange for what is specifically supposed to be original content (for example, the plagiarist's publisher, employer, or teacher). In such cases, acts of plagiarism may sometimes also form part of a claim for breach of the plagiarist's contract, or, if done knowingly, for a civil wrong .

In academia and journalism
Within academia , plagiarism by students, professors, or researchers is considered academic dishonesty or academic fraud, and offenders are subject to academic censure, up to and including expulsion . Many institutions use plagiarism detection software to uncover potential plagiarism and to deter students from plagiarizing. Most universities address the issue of academic integrity by providing students with thorough orientations, required writing courses, and clearly articulated honor codes. Indeed, there is a virtually uniform understanding among college students that plagiarism is wrong. Nevertheless, each year students are brought before their institutions’ disciplinary boards on charges that they have misused sources in their schoolwork." [11] However, the practice of plagiarizing by use of sufficient word substitutions to elude detection software, known as rogeting , has rapidly evolved as students and unethical academics seek to stay ahead of detection software. [12] An extreme form of plagiarism, known as contract cheating involves students paying someone else, such as an essay mill , to do their work for them. [8]
In journalism , plagiarism is considered a breach of journalistic ethics , and reporters caught plagiarizing typically face disciplinary measures ranging from suspension to termination of employment. Some individuals caught plagiarizing in academic or journalistic contexts claim that they plagiarized unintentionally, by failing to include quotations or give the appropriate citation . While plagiarism in scholarship and journalism has a centuries-old history, the development of the Internet , where articles appear as electronic text, has made the physical act of copying the work of others much easier. [13]
Predicated upon an expected level of learning/comprehension having been achieved, all associated academic accreditation becomes seriously undermined if plagiarism is allowed to become the norm within academic submissions. [14]
For professors and researchers, plagiarism is punished by sanctions ranging from suspension to termination, along with the loss of credibility and perceived integrity. [15] [16] Charges of plagiarism against students and professors are typically heard by internal disciplinary committees, by which students and professors have agreed to be bound. [17] Plagiarism is a common reason for academic research papers to be retracted. [18]

Academia
No universally adopted definition of academic plagiarism exists; however, this section provides several definitions to exemplify the most common characteristics of academic plagiarism.
According to Bela Gipp [19] academic plagiarism encompasses:
The definition by B. Gipp is an abridged version of Teddi Fishman's definition of plagiarism, which proposed five elements characteristic of plagiarism. [20] According to T. Fishman, plagiarism occurs when someone:
Furthermore, plagiarism is defined differently among institutions of higher learning and universities:

Common forms of student plagiarism
According to "The Reality and Solution of College Plagiarism" [27] [ better source needed ] created by the Health Informatics department of the University of Illinois at Chicago there are 10 main forms of plagiarism that students commit:

Sanctions for student plagiarism
In the academic world, plagiarism by students is usually considered a very serious offense that can result in punishments such as a failing grade on the particular assignment, the entire course, or even being expelled from the institution. Generally, the punishment increases as a person enters higher institutions of learning. The seriousness with which academic institutions address student plagiarism may be tempered by a recognition that students may not fully understand what plagiarism is. A 2015 study showed that students who were new to university study did not have a good understanding of even the basic requirements of how to attribute sources in written academic work, yet students were very confident that they understood what referencing and plagiarism are. [28] The same students also had a lenient view of how plagiarism should be penalised.
For cases of repeated plagiarism, or for cases in which a student commits severe plagiarism (e.g., purchasing an assignment), suspension or expulsion is likely. [29] There has been historic concern about inconsistencies in penalties administered for university student plagiarism, and a plagiarism tariff was devised in 2008 for UK higher education institutions in an attempt to encourage some standardization of approaches. [30]
However, to impose sanctions, plagiarism needs to be detected. It has been found that a significant share of (university) teachers do not use detection methods such as using text-matching software. [31] A few more try to detect plagiarism by reading term-papers specifically for plagiarism, while the latter method might be not very effective in detecting plagiarism – especially when plagiarism from unfamiliar sources needs to be detected. [31]

Criminal and negative behaviour by diploma mills
There are allegations that some diploma mills [ discuss ] take students' money for essays, then produce a low standard essay or close their websites without providing the purchased essay. Students then have little time to provide an essay before a deadline. Also diploma mills have allegedly blackmailed students demanding more money than was originally agreed and threatening to reveal plagiarism to the university unless more money is paid. Sorana Vieru of the NUS said, “We would urge those who are struggling to seek support through their unions and universities rather than looking to a quick fix, and be aware that using these websites could cost not only money but jeopardise their qualifications.” [32]

Plagiarism education
Given the serious consequences that plagiarism has for students, there has been a call for a greater emphasis on learning in order to help students avoid committing plagiarism. [33] This is especially important when students move to a new institution that may have a different view of the concept when compared with the view previously developed by the student. [34] Indeed, given the seriousness of plagiarism accusations for a student's future, the pedagogy of plagiarism education may need to be considered ahead of the pedagogy of the discipline being studied. [33] The need for plagiarism education extends to academic staff, who may not completely understand what is expected of their students or the consequences of misconduct. [35]

Factors influencing student´s decision to plagiarize
Several studies investigated factors that influence the decision to plagiarize. For example, a panel study with students from German universities found that academic procrastination predicts the frequency plagiarism conducted within six months followed the measurement of academic procrastination. [36] It has been argued that by plagiarizing students cope with the negative consequences that result from academic procrastination such as poor grades. Another study found that plagiarism is more frequent if students perceive plagiarism as beneficial and if they have the opportunity to plagiarize. [37] When students had expected higher sanctions and when they had internalized social norms that define plagiarism as very objectionable, plagiarism was less likely to occur.
Methods of preventing plagiarism
"Planning your paper:
Writing your paper:

Journalism
Since journalism relies on the public trust, a reporter's failure to honestly acknowledge their sources undercuts a newspaper or television news show's integrity and undermines its credibility. Journalists accused of plagiarism are often suspended from their reporting tasks while the charges are being investigated by the news organization. [39]

Self-plagiarism
The reuse of significant, identical, or nearly identical portions of one's own work without acknowledging that one is doing so or citing the original work is sometimes described as "self-plagiarism"; the term "recycling fraud" has been used. [40] Articles of this nature are often referred to as duplicate or multiple publication . In addition there can be a copyright issue if copyright of the prior work has been transferred to another entity. Typically, self-plagiarism is only considered a serious ethical issue in settings where someone asserts that a publication consists of new material, such as in publishing or factual documentation. [41] It does not apply to public-interest texts, such as social, professional, and cultural opinions usually published in newspapers and magazines.
In academic fields, self-plagiarism occurs when an author reuses portions of his own published and copyrighted work in subsequent publications, but without attributing the previous publication. [42] Identifying self-plagiarism is often difficult because limited reuse of material is accepted both legally (as fair use ) and ethically. [43]

The concept
The term "self-plagiarism" has been challenged as being self-contradictory, an oxymoron , [44] and on other grounds. [45]
For example, Stephanie J. Bird [46] argues that self-plagiarism is a misnomer, since by definition plagiarism concerns the use of others' material.
However, the phrase is used to refer to specific forms of putatively unethical publication. Bird identifies the ethical issues of "self-plagiarism" as those of "dual or redundant publication." She also notes that in an educational context, "self-plagiarism" refers to the case of a student who resubmits "the same essay for credit in two different courses." As David B. Resnik clarifies, "Self-plagiarism involves dishonesty but not intellectual theft." [47]
According to Patrick M. Scanlon [48]

Codes of ethics
Some academic journals have codes of ethics that specifically refer to self-plagiarism. For example, the Journal of International Business Studies . [49] Some professional organizations like the Association for Computing Machinery (ACM) have created policies that deal specifically with self-plagiarism. [50] Other organizations do not make specific reference to self-plagiarism such as the American Political Science Association (APSA). The organization published a code of ethics that describes plagiarism as "...deliberate appropriation of the works of others represented as one's own." It does not make any reference to self-plagiarism. It does say that when a thesis or dissertation is published "in whole or in part", the author is "not ordinarily under an ethical obligation to acknowledge its origins." [51] The American Society for Public Administration (ASPA) also published a code of ethics that says its members are committed to: "Ensure that others receive credit for their work and contributions," but it makes no reference to self-plagiarism. [52]

Factors that justify reuse
Pamela Samuelson , in 1994, identified several factors she says excuse reuse of one's previously published work, that make it not self-plagiarism. [43] She relates each of these factors specifically to the ethical issue of self-plagiarism, as distinct from the legal issue of fair use of copyright, which she deals with separately. Among other factors that may excuse reuse of previously published material Samuelson lists the following:
Samuelson states she has relied on the "different audience" rationale when attempting to bridge interdisciplinary communities. She refers to writing for different legal and technical communities, saying: "there are often paragraphs or sequences of paragraphs that can be bodily lifted from one article to the other. And, in truth, I lift them." She refers to her own practice of converting "a technical article into a law review article with relatively few changes—adding footnotes and one substantive section" for a different audience. [43]
Samuelson describes misrepresentation as the basis of self-plagiarism. [43] She also states "Although it seems not to have been raised in any of the self-plagiarism cases, copyrights law's fair use defense would likely provide a shield against many potential publisher claims of copyright infringement against authors who reused portions of their previous works." [43]

Organizational publications
Plagiarism is presumably not an issue when organizations issue collective unsigned works since they do not assign credit for originality to particular people. For example, the American Historical Association 's "Statement on Standards of Professional Conduct" (2005) regarding textbooks and reference books states that, since textbooks and encyclopedias are summaries of other scholars' work, they are not bound by the same exacting standards of attribution as original research and may be allowed a greater "extent of dependence" on other works. [53] However, even such a book does not make use of words, phrases, or paragraphs from another text or follow too closely the other text's arrangement and organization, and the authors of such texts are also expected to "acknowledge the sources of recent or distinctive findings and interpretations, those not yet a part of the common understanding of the profession." [53]

In the arts

The history of the arts
Through all of the history of literature and of the arts in general, works of art are for a large part repetitions of the tradition ; to the entire history of artistic creativity belong plagiarism, literary theft, appropriation , incorporation, retelling, rewriting, recapitulation, revision, reprise, thematic variation , ironic retake, parody , imitation, stylistic theft, pastiches , collages , and deliberate assemblages . [54] [55] [9] [56] [57] [58] There is no rigorous and precise distinction between practices like imitation, stylistic plagiarism, copy , replica and forgery . [54] [59] [60] [61] These appropriation procedures are the main axis of a literate culture, in which the tradition of the canonic past is being constantly rewritten. [58]
Ruth Graham quotes T.S. Eliot —"Immature poets imitate; mature poets steal. Bad poets deface what they take."—she notes that despite the "taboo" of plagiarism, the ill-will and embarrassment it causes in the modern context, readers seem to often forgive the past excesses of historic literary offenders. [62]

Praisings of artistic plagiarism
A passage of Laurence Sterne 's 1767 Tristram Shandy , condemns plagiarism by resorting to plagiarism. [63] Oliver Goldsmith commented:

In other contexts

On the Internet
Free online tools are becoming available to help identify plagiarism, [65] [66] and there are a range of approaches that attempt to limit online copying, such as disabling right clicking and placing warning banners regarding copyrights on web pages. Instances of plagiarism that involve copyright violation may be addressed by the rightful content owners sending a DMCA removal notice to the offending site-owner, or to the ISP that is hosting the offending site. The term "content scraping" has arisen to describe the copying and pasting of information from websites [67] and blogs. [68]

See also
WebPage index: 00049
Utility
In economics , utility is a measure of preferences over some set of goods (including services: something that satisfies human wants ); it represents satisfaction experienced by the consumer of a good . The concept is an important underpinning of rational choice theory in economics and game theory : since one cannot directly measure benefit, satisfaction or happiness from a good or service, economists instead have devised ways of representing and measuring utility in terms of measurable economic choices. Economists have attempted to perfect highly abstract methods of comparing utilities by observing and calculating economic choices; in the simplest sense, economists consider utility to be revealed in people's willingness to pay different amounts for different goods.

Applications
Utility is usually applied by economists in such constructs as the indifference curve , which plot the combination of commodities that an individual or a society would accept to maintain a given level of satisfaction. Utility and indifference curves are used by economists to understand the underpinnings of demand curves , which are half of the supply and demand analysis that is used to analyze the workings of goods markets.
Individual utility and social utility can be construed as the value of a utility function and a social welfare function respectively. When coupled with production or commodity constraints, under some assumptions these functions can be used to analyze Pareto efficiency , such as illustrated by Edgeworth boxes in contract curves . Such efficiency is a central concept in welfare economics .
In finance , utility is applied to generate an individual's price for an asset called the indifference price . Utility functions are also related to risk measures , with the most common example being the entropic risk measure .

Revealed preference
It was recognized that utility could not be measured or observed directly, so instead economists devised a way to infer underlying relative utilities from observed choice. These 'revealed preferences', as they were named by Paul Samuelson , were revealed e.g. in people's willingness to pay:

Functions
There has been some controversy over the question whether the utility of a commodity can be measured or not. At one time, it was assumed that the consumer was able to say exactly how much utility he got from the commodity. The economists who made this assumption belonged to the 'cardinalist school' of economics. Today utility functions , expressing utility as a function of the amounts of the various goods consumed, are treated as either cardinal or ordinal , depending on whether they are or are not interpreted as providing more information than simply the rank ordering of preferences over bundles of goods, such as information on the strength of preferences.

Cardinal
When cardinal utility is used, the magnitude of utility differences is treated as an ethically or behaviorally significant quantity. For example, suppose a cup of orange juice has utility of 120 utils, a cup of tea has a utility of 80 utils, and a cup of water has a utility of 40 utils. With cardinal utility, it can be concluded that the cup of orange juice is better than the cup of tea by exactly the same amount by which the cup of tea is better than the cup of water. One cannot conclude, however, that the cup of tea is two thirds as good as the cup of juice, because this conclusion would depend not only on magnitudes of utility differences, but also on the "zero" of utility. For example, if the "zero" of utility was located at -40, then a cup of orange juice would be 160 utils more than zero, a cup of tea 120 utils more than zero.
Neoclassical economics has largely retreated from using cardinal utility functions as the basis of economic behavior. A notable exception is in the context of analyzing choice under conditions of risk (see below ).
Sometimes cardinal utility is used to aggregate utilities across persons, to create a social welfare function .

Ordinal
When ordinal utilities are used, differences in utils (values taken on by the utility function) are treated as ethically or behaviorally meaningless: the utility index encodes a full behavioral ordering between members of a choice set, but tells nothing about the related strength of preferences . In the above example, it would only be possible to say that juice is preferred to tea to water, but no more.
Ordinal utility functions are unique up to increasing monotone transformations. For example, if a function u ( x ) {\displaystyle u(x)} is taken as ordinal, it is equivalent to the function u ( x ) 3 {\displaystyle u(x)^{3}} , because taking the 3rd power is an increasing monotone transformation . This means that the ordinal preference induced by these functions is the same. In contrast, cardinal utilities are unique only up to increasing linear transformations, so if u ( x ) {\displaystyle u(x)} is taken as cardinal, it is not equivalent to u ( x ) 3 {\displaystyle u(x)^{3}} .

Preferences
Although preferences are the conventional foundation of microeconomics , it is often convenient to represent preferences with a utility function and analyze human behavior indirectly with utility functions. Let X be the consumption set , the set of all mutually-exclusive baskets the consumer could conceivably consume. The consumer's utility function u : X → R {\displaystyle u\colon X\to \mathbb {R} } ranks each package in the consumption set. If the consumer strictly prefers x to y or is indifferent between them, then u ( x ) ≥ u ( y ) {\displaystyle u(x)\geq u(y)} .
For example, suppose a consumer's consumption set is X = {nothing, 1 apple,1 orange, 1 apple and 1 orange, 2 apples, 2 oranges}, and its utility function is u (nothing) = 0, u (1 apple) = 1, u (1 orange) = 2, u (1 apple and 1 orange) = 4, u (2 apples) = 2 and u (2 oranges) = 3. Then this consumer prefers 1 orange to 1 apple, but prefers one of each to 2 oranges.
In micro-economic models, there are usually a finite set of L commodities, and a consumer may consume an arbitrary amount of each commodity. This gives a consumption set of R + L {\displaystyle \mathbb {R} _{+}^{L}} , and each package x ∈ R + L {\displaystyle x\in \mathbb {R} _{+}^{L}} is a vector containing the amounts of each commodity. In the previous example, we might say there are two commodities: apples and oranges. If we say apples is the first commodity, and oranges the second, then the consumption set X = R + 2 {\displaystyle X=\mathbb {R} _{+}^{2}} and u (0, 0) = 0, u (1, 0) = 1, u (0, 1) = 2, u (1, 1) = 4, u (2, 0) = 2, u (0, 2) = 3 as before. Note that for u to be a utility function on X , it must be defined for every package in X .
A utility function u : X → R {\displaystyle u\colon X\to \mathbb {R} } represents a preference relation ⪯ {\displaystyle \preceq } on X iff for every x , y ∈ X {\displaystyle x,y\in X} , u ( x ) ≤ u ( y ) {\displaystyle u(x)\leq u(y)} implies x ⪯ y {\displaystyle x\preceq y} . If u represents ⪯ {\displaystyle \preceq } , then this implies ⪯ {\displaystyle \preceq } is complete and transitive, and hence rational.

Examples
In order to simplify calculations, various alternative assumptions have been made concerning details of human preferences, and these imply various alternative utility functions such as:
Most utility functions used in modeling or theory are well-behaved. They are usually monotonic and quasi-concave. However, it is possible for preferences not to be representable by a utility function. An example is lexicographic preferences which are not continuous and cannot be represented by a continuous utility function. [2]

Expected
The expected utility theory deals with the analysis of choices among risky projects with multiple (possibly multidimensional) outcomes.
The St. Petersburg paradox was first proposed by Nicholas Bernoulli in 1713 and solved by Daniel Bernoulli in 1738. D. Bernoulli argued that the paradox could be resolved if decision-makers displayed risk aversion and argued for a logarithmic cardinal utility function.
The first important use of the expected utility theory was that of John von Neumann and Oskar Morgenstern , who used the assumption of expected utility maximization in their formulation of game theory .

von Neumann–Morgenstern
Von Neumann and Morgenstern addressed situations in which the outcomes of choices are not known with certainty, but have probabilities attached to them.
A notation for a lottery is as follows: if options A and B have probability p and 1 − p in the lottery, we write it as a linear combination:
More generally, for a lottery with many possible options:
where ∑ i p i = 1 {\displaystyle \sum _{i}p_{i}=1} .
By making some reasonable assumptions about the way choices behave, von Neumann and Morgenstern showed that if an agent can choose between the lotteries, then this agent has a utility function such that the desirability of an arbitrary lottery can be calculated as a linear combination of the utilities of its parts, with the weights being their probabilities of occurring.
This is called the expected utility theorem . The required assumptions are four axioms about the properties of the agent's preference relation over 'simple lotteries', which are lotteries with just two options. Writing B ⪯ A {\displaystyle B\preceq A} to mean 'A is weakly preferred to B' ('A is preferred at least as much as B'), the axioms are:
Axioms 3 and 4 enable us to decide about the relative utilities of two assets or lotteries.
In more formal language: A von Neumann–Morgenstern utility function is a function from choices to the real numbers:
which assigns a real number to every outcome in a way that captures the agent's preferences over simple lotteries. Under the four assumptions mentioned above, the agent will prefer a lottery L 2 {\displaystyle L_{2}} to a lottery L 1 {\displaystyle L_{1}} if and only if, for the utility function characterizing that agent, the expected utility of L 2 {\displaystyle L_{2}} is greater than the expected utility of L 1 {\displaystyle L_{1}} :
Repeating in category language: u {\displaystyle u} is a morphism between the category of preferences with uncertainty and the category of reals as an additive group.
Of all the axioms, independence is the most often discarded. A variety of generalized expected utility theories have arisen, most of which drop or relax the independence axiom.

As probability of success
Castagnoli and LiCalzi and Bordley and LiCalzi (2000) provided another interpretation for Von Neumann and Morgenstern's theory. Specifically for any utility function, there exists a hypothetical reference lottery with the expected utility of an arbitrary lottery being its probability of performing no worse than the reference lottery. Suppose success is defined as getting an outcome no worse than the outcome of the reference lottery. Then this mathematical equivalence means that maximizing expected utility is equivalent to maximizing the probability of success. In many contexts, this makes the concept of utility easier to justify and to apply. For example, a firm's utility might be the probability of meeting uncertain future customer expectations. [3] [4] [5] [6]

Indirect
An indirect utility function gives the optimal attainable value of a given utility function, which depends on the prices of the goods and the income or wealth level that the individual possesses.

Money
One use of the indirect utility concept is the notion of the utility of money. The (indirect) utility function for money is a nonlinear function that is bounded and asymmetric about the origin. The utility function is concave in the positive region, reflecting the phenomenon of diminishing marginal utility . The boundedness reflects the fact that beyond a certain point money ceases being useful at all, as the size of any economy at any point in time is itself bounded. The asymmetry about the origin reflects the fact that gaining and losing money can have radically different implications both for individuals and businesses. The non-linearity of the utility function for money has profound implications in decision making processes: in situations where outcomes of choices influence utility through gains or losses of money, which are the norm in most business settings, the optimal choice for a given decision depends on the possible outcomes of all other decisions in the same time-period. [7]

Discussion and criticism
Cambridge economist Joan Robinson famously criticized utility for being a circular concept: "Utility is the quality in commodities that makes individuals want to buy them, and the fact that individuals want to buy commodities shows that they have utility" [8] :48 Robinson also pointed out that because the theory assumes that preferences are fixed this means that utility is not a testable assumption. This is so because if we take changes in peoples' behavior in relation to a change in prices or a change in the underlying budget constraint we can never be sure to what extent the change in behavior was due to the change in price or budget constraint and how much was due to a change in preferences. [9] This criticism is similar to that of the philosopher Hans Albert who argued that the ceteris paribus conditions on which the marginalist theory of demand rested rendered the theory itself an empty tautology and completely closed to experimental testing. [10] In essence, demand and supply curve (theoretical line of quantity of a product which would have been offered or requested for given price) is purely ontological and could never been demonstrated empirically.
Another criticism comes from the assertion that neither cardinal nor ordinal utility is empirically observable in the real world. In the case of cardinal utility it is impossible to measure the level of satisfaction "quantitatively" when someone consumes or purchases an apple. In case of ordinal utility, it is impossible to determine what choices were made when someone purchases, for example, an orange. Any act would involve preference over a vast set of choices (such as apple, orange juice, other vegetable, vitamin C tablets, exercise, not purchasing, etc.). [11] [12]
Other questions of what arguments ought to enter into a utility function are difficult to answer, yet seem necessary to understanding utility. Whether people gain utility from coherence of wants, beliefs or a sense of duty is key to understanding their behavior in the utility organon. [13] Likewise, choosing between alternatives is itself a process of determining what to consider as alternatives, a question of choice within uncertainty. [14]
An evolutionary psychology perspective is that utility may be better viewed as due to preferences that maximized evolutionary fitness in the ancestral environment but not necessarily in the current one. [15]

See also
WebPage index: 00050
Katherine Maher
WebPage index: 00051
Primary source
In the study of history as an academic discipline, a primary source (also called original source or evidence ) is an artifact, a document, diary, manuscript , autobiography, a recording, or any other source of information that was created at the time under study. It serves as an original source of information about the topic. Similar definitions can be used in library science , and other areas of scholarship, although different fields have somewhat different definitions. In journalism , a primary source can be a person with direct knowledge of a situation, or a document written by such a person [ citation needed ] .
Primary sources are distinguished from secondary sources , which cite, comment on, or build upon primary sources. Generally, accounts written after the fact with the benefit (and possible distortions) of hindsight are secondary. [1] A secondary source may also be a primary source depending on how it is used. [2] For example, a memoir would be considered a primary source in research concerning its author or about his or her friends characterized within it, but the same memoir would be a secondary source if it were used to examine the culture in which its author lived. "Primary" and "secondary" should be understood as relative terms, with sources categorized according to specific historical contexts and what is being studied. [3] :118–246 [4]

The significance of source classification

History
In scholarly writing, an important objective of classifying sources is to determine their independence and reliability. [4] In contexts such as historical writing, it is almost always advisable to use primary sources and that "if none are available, it is only with great caution that [the author] may proceed to make use of secondary sources." [5] Sreedharan believes that primary sources have the most direct connection to the past and that they "speak for themselves" in ways that cannot be captured through the filter of secondary sources. [6]

Other fields
In scholarly writing, the objective of classifying sources is to determine the independence and reliability of sources. [4] Though the terms primary source and secondary source originated in historiography [ citation needed ] as a way to trace the history of historical ideas, they have been applied to many other fields. For example, these ideas may be used to trace the history of scientific theories, literary elements and other information that is passed from one author to another.
In scientific literature , a primary source is the original publication of a scientist's new data, results and theories. In political history , primary sources are documents such as official reports, speeches, pamphlets, posters, or letters by participants, official election returns and eyewitness accounts. In the history of ideas or intellectual history , the main primary sources are books, essays and letters written by intellectuals; these intellectuals may include historians, whose books and essays are therefore considered primary sources for the intellectual historian, though they are secondary sources in their own topical fields. In religious history , the primary sources are religious texts and descriptions of religious ceremonies and rituals . [7]
A study of cultural history could include fictional sources such as novels or plays. In a broader sense primary sources also include artifacts like photographs, newsreels, coins, paintings or buildings created at the time. Historians may also take archaeological artifacts and oral reports and interviews into consideration. Written sources may be divided into three types. [8]
In historiography, when the study of history is subject to historical scrutiny, a secondary source becomes a primary source. For a biography of a historian, that historian's publications would be primary sources. Documentary films can be considered a secondary source or primary source, depending on how much the filmmaker modifies the original sources. [9]
The Lafayette College Library, provides a synopsis of primary sources in several areas of study:

Finding primary sources
Although many primary sources remain in private hands, others are located in archives , libraries , museums , historical societies , and special collections . These can be public or private. Some are affiliated with universities and colleges, while others are government entities. Materials relating to one area might be spread over a large number of different institutions. These can be distant from the original source of the document. For example, the Huntington Library in California houses a large number of documents from the United Kingdom.
In the US, digital copies of primary sources can be retrieved from a number of places. The Library of Congress maintains several digital collections where they can be retrieved. Some examples are American Memory and Chronicling America . The National Archives and Records Administration also has digital collections in Digital Vaults . The Digital Public Library of America searches across the digitized primary source collections of many libraries, archives, and museums. The Internet Archive also has primary source materials in many formats.
In the UK, the National Archives provides a consolidated search of its own catalogue and a wide variety of other archives listed on the Access to Archives index. Digital copies of various classes of documents at the National Archives (including wills) are available from DocumentsOnline. Most of the available documents relate to England and Wales. Some digital copies of primary sources are available from the National Archives of Scotland . Many County Record Offices collections are included in Access to Archives, while others have their own on-line catalogues. Many County Record Offices will supply digital copies of documents.
In other regions, Europeana has digitized materials from across Europe while the World Digital Library and Flickr Commons have items from all over the world. Trove has primary sources from Australia.
Most primary source materials are not digitized and may only be represented online with a record or finding aid . Both digitized and not digitized materials can be found through catalogs such as WorldCat , the Library of Congress catalog , the National Archives catalog , and so on.

Using primary sources
History as an academic discipline is based on primary sources, as evaluated by the community of scholars, who report their findings in books, articles and papers. Arthur Marwick says "Primary sources are absolutely fundamental to history." [11] Ideally, a historian will use all available primary sources that were created by the people involved at the time being studied. In practice some sources have been destroyed, while others are not available for research. Perhaps the only eyewitness reports of an event may be memoirs , autobiographies, or oral interviews taken years later. Sometimes the only evidence relating to an event or person in the distant past was written or copied decades or centuries later. Manuscripts that are sources for classical texts can be copies of documents, or fragments of copies of documents. This is a common problem in classical studies , where sometimes only a summary of a book or letter has survived. Potential difficulties with primary sources have the result that history is usually taught in schools using secondary sources.
Historians studying the modern period with the intention of publishing an academic article prefer to go back to available primary sources and to seek new (in other words, forgotten or lost) ones. Primary sources, whether accurate or not, offer new input into historical questions and most modern history revolves around heavy use of archives and special collections for the purpose of finding useful primary sources. A work on history is not likely to be taken seriously as scholarship if it only cites secondary sources, as it does not indicate that original research has been done. [3]
However, primary sources – particularly those from before the 20th century – may have hidden challenges. "Primary sources, in fact, are usually fragmentary, ambiguous and very difficult to analyse and interpret." [11] Obsolete meanings of familiar words and social context are among the traps that await the newcomer to historical studies. For this reason, the interpretation of primary texts is typically taught as part of an advanced college or postgraduate history course, although advanced self-study or informal training is also possible.
The following questions are asked about primary sources:

Strengths and weaknesses
In many fields and contexts, such as historical writing, it is almost always advisable to use primary sources if possible, and "if none are available, it is only with great caution that [the author] may proceed to make use of secondary sources." [5] In addition, primary sources avoid the problem inherent in secondary sources in which each new author may distort and put a new spin on the findings of prior cited authors. [12]
However, a primary source is not necessarily more of an authority or better than a secondary source. There can be bias and tacit unconscious views which twist historical information.
The errors may be corrected in secondary sources, which are often subjected to peer review , can be well documented, and are often written by historians working in institutions where methodological accuracy is important to the future of the author's career and reputation. Historians consider the accuracy and objectiveness of the primary sources that they are using and historians subject both primary and secondary sources to a high level of scrutiny. A primary source such as a journal entry (or the online version, a blog), at best, may only reflect one individual's opinion on events, which may or may not be truthful, accurate, or complete.
Participants and eyewitnesses may misunderstand events or distort their reports, deliberately or not, to enhance their own image or importance. Such effects can increase over time, as people create a narrative that may not be accurate. [14] For any source, primary or secondary, it is important for the researcher to evaluate the amount and direction of bias. [15] As an example, a government report may be an accurate and unbiased description of events, but it may be censored or altered for propaganda or cover-up purposes. The facts can be distorted to present the opposing sides in a negative light. Barristers are taught that evidence in a court case may be truthful but may still be distorted to support or oppose the position of one of the parties.

Classifying sources
Many sources can be considered either primary or secondary, depending on the context in which they are examined. [4] Moreover, the distinction between primary and secondary sources is subjective and contextual, [16] so that precise definitions are difficult to make. [17] A book review, when it contains the opinion of the reviewer about the book rather than a summary of the book, becomes a primary source. [18] [19]
If a historical text discusses old documents to derive a new historical conclusion, it is considered to be a primary source for the new conclusion. Examples in which a source can be both primary and secondary include an obituary [20] or a survey of several volumes of a journal counting the frequency of articles on a certain topic. [20]
Whether a source is regarded as primary or secondary in a given context may change, depending upon the present state of knowledge within the field. [21] For example, if a document refers to the contents of a previous but undiscovered letter, that document may be considered "primary", since it is the closest known thing to an original source; but if the letter is later found, it may then be considered "secondary" [22]
In some instances, the reason for identifying a text as the "primary source" may devolve from the fact that no copy of the original source material exists, or that it is the oldest extant source for the information cited. [23]

Forgeries
Historians must occasionally contend with forged documents that purport to be primary sources. These forgeries have usually been constructed with a fraudulent purpose, such as promulgating legal rights, supporting false pedigrees, or promoting particular interpretations of historic events. The investigation of documents to determine their authenticity is called diplomatics .
For centuries, Popes used the forged Donation of Constantine to bolster the Papacy's secular power. Among the earliest forgeries are false Anglo-Saxon charters , a number of 11th- and 12th-century forgeries produced by monasteries and abbeys to support a claim to land where the original document had been lost or never existed. One particularly unusual forgery of a primary source was perpetrated by Sir Edward Dering , who placed false monumental brasses in a parish church . [24] In 1986, Hugh Trevor-Roper "authenticated" the Hitler Diaries , which were later proved to be forgeries. Recently, forged documents have been placed within the UK National Archives in the hope of establishing a false provenance . [25] [26] However, historians dealing with recent centuries rarely encounter forgeries of any importance. [3] :22–25

See also
WebPage index: 00052
American Library Association
The American Library Association ( ALA ) is a nonprofit organization based in the United States that promotes libraries and library education internationally. It is the oldest and largest library association in the world, [4] with more than 62,000 members. [5]

History
Founded by Justin Winsor , Charles Ammi Cutter , Samuel S. Green , James L. Whitney, Melvil Dewey (Melvil Dui), Fred B. Perkins, Charles Evans , and Thomas W. Bicknell in 1876 in Philadelphia and chartered [6] in 1879 in Massachusetts , its head office is now in Chicago .
During the Centennial Exposition in Philadelphia in 1876, 103 librarians, 90 men and 13 women, responded to a call for a "Convention of Librarians" to be held October 4–6 at the Historical Society of Pennsylvania. At the end of the meeting, according to Ed Holley in his essay "ALA at 100," "the register was passed around for all to sign who wished to become charter members," making October 6, 1876, to be ALA's birthday. In attendance were 90 men and 13 women, among them Justin Winsor (Boston Public, Harvard), William Frederick Poole (Chicago Public, Newberry), Charles Ammi Cutter (Boston Athenaeum), Melvil Dewey, and Richard Rogers Bowker. Attendees came from as far west as Chicago and from England. [7] The aim of the Association, in that resolution, was "to enable librarians to do their present work more easily and at less expense." [8] The Association has worked throughout its history to define, extend, protect and advocate for equity of access to information. [9]
Library activists in the 1930s pressured the American Library Association to be more responsive to issues put forth by young members involved with issues such as peace, segregation, library unions and intellectual freedom. In 1931, the Junior Members Round Table (JMRT) was formed to provide a voice for the younger members of the ALA, but much of what they had to say resurfaced in the social responsibility movement to come years later. [10] During this period, the first Library Bill of Rights (LBR) was drafted by Forrest Spaulding to set a standard against censorship and was adopted by the ALA in 1939. This has been recognized as the moment defining modern librarianship as a profession committed to intellectual freedom and the right to read over government dictates. [11] The ALA formed the Staff Organization's Round Table in 1936 and the Library Unions Round Table in 1940.
The ALA appointed a committee to study censorship and recommend policy after the banning of The Grapes of Wrath and the implementation of the LBR. The committee reported in 1940 that intellectual freedom and professionalism were linked and recommended a permanent committee – Committee on Intellectual Freedom. [12] The ALA made revisions to strengthen the LBR in June 1948, approved the Statement on Labeling in 1951 to discourage labeling material as subversive, and adopted the Freedom to Read Statement and the Overseas Library Statement in 1953. [12]
In 1961, the ALA took a stand regarding service to African Americans and others, advocating for equal library service for all. An amendment was passed to the LBR in 1961 that made clear that an individual's library use should not be denied or abridged because of race, religion, national origin, or political views. Some communities decided to close their doors rather than desegregate. [13] In 1963, the ALA commissioned a study, Access to Public Libraries , which found direct and indirect discrimination in American libraries. [14]
In 1967 some librarians protested against a pro- Vietnam War speech given by General Maxwell D. Taylor at the annual ALA conference in San Francisco; the former president of Sarah Lawrence College , Harold Taylor, spoke to the Middle-Atlantic Regional Library Conference about socially responsible professionalism; and less than one year later a group of librarians proposed that the ALA schedule a new round table program discussion on the social responsibilities of librarians at its next annual conference in Kansas City . This group called themselves the Organizing Committee for the ALA Round Table on Social Responsibilities of Libraries. This group drew in many other under-represented groups in the ALA who lacked power, including the Congress for Change in 1969. [15] This formation of the committee was approved in 1969 and would change its name to the Social Responsibilities Round Table (SRRT) in 1971). After its inception, the Round Table of Social Responsibilities began to press ALA leadership to address issues such as library unions, working conditions, wages, and intellectual freedom. The Freedom to Read Foundation was created by ALA's Executive Board in 1969. [16] The Black Caucus of the ALA and the Office for Literacy and Outreach were set up in 1970. [17]
In June 1990, the ALA approved “Policy on Library Services to the Poor” and in 1996 the Task Force on Hunger Homelessness, and Poverty was formed to resurrect and promote the ALA guidelines on library services to the poor. [18]
In 2014 Courtney Young, the president of the association, commented on the background and implications of a racist joke author Daniel Handler made as African-American writer Jacqueline Woodson received a National Book Award for Brown Girl Dreaming . "His comments were inappropriate and fell far short of the association's commitment to diversity," said Young. "Handler's remarks come at a time when the publishing world has little diversity. Works from authors and illustrators of color make up less than 8 percent of children’s titles produced in 2013. The ALA hopes this regrettable incident will be used to open a dialogue on the need for diversity in the publishing industry, particularly in regards to books for young people." [19]
The ALA Archives, including historical documents, non-current records, and digital records, are currently held at the University of Illinois Urbana-Champaign archives. [20]

Membership
ALA membership is open to any person or organization, though most of its members are libraries or librarians. Most members live and work in the United States, with international members comprising 3.5% of total membership. [21]

Governing structure
The ALA is governed by an elected council and an executive board. Since 2002, Keith Michael Fiels has been the ALA executive director (CEO). [22] Policies and programs are administered by various committees and round tables. One of the organization's most visible tasks is overseen by the Office for Accreditation, which formally reviews and authorizes American and Canadian academic institutions that offer degree programs in library and information science . The ALA's current President is Julie B. Todaro (2016-2017). Notable past presidents of the ALA include Theresa Elmendorf , its first female president (1911–1912), [23] Clara Stanton Jones , its first African-American president (she served as acting president from April 11 to July 22 in 1976 and then president from July 22, 1976 to 1977 [24] [25] ), Loriene Roy , its first Native American president (2007–2008), [26] [27] Michael Gorman (2005-2007), and Roberta A. Stevens. [28] (See List of presidents of the American Library Association .)

Activities
The official purpose of the association is "to promote library service and librarianship." Members may join one or more of eleven membership divisions that deal with specialized topics such as academic, school, or public libraries, technical or reference services, and library administration. Members may also join any of seventeen round tables that are grouped around more specific interests and issues than the broader set of ALA divisions.

Divisions

Notable offices

Notable sub-organizations
In 1970, the ALA founded the first lesbian , gay , bisexual and transgender professional organization, called the "Task Force on Gay Liberation", now known as the Gay, Lesbian, Bisexual, and Transgender Round Table or GLBT Round Table. [30] [31] Barbara Gittings became its coordinator in 1971. In the early 1970s, the Task Force on Gay Liberation campaigned to have books about the gay liberation movement at the Library of Congress reclassified from HQ 71–471 (“Abnormal Sexual Relations, Including Sexual Crimes”). In 1972, after receiving a letter requesting the reclassification, the Library of Congress agreed to make the shift, reclassifying those books into a newly created category, HQ 76.5 (“Homosexuality, Lesbianism—Gay Liberation Movement, Homophile Movement”). In 1971 the GLBTRT created the first award for GLBT books, the Stonewall Book Award, which celebrates books of exceptional merit that relate to LGBT issues. Patience and Sarah by Alma Routsong (pen name Isabel Miller) was the first winner. In 1992, American Libraries published a photo of the GLBTRT (then called the Gay and Lesbian Task Force) on the cover of its July/August issue, drawing both criticism and praise from the library world. Some commenters called the cover “in poor taste” and accused American Libraries of “glorifying homosexuality,” while others were supportive of the move. Christine Williams, who wrote an essay about the controversy surrounding the cover, concluded that in the mid-90s, the library world was “not an especially welcoming place to gays and lesbians." In 2010, the GLBTRT announced a new committee, the Over the Rainbow Committee. This committee annually compiles a bibliography of books that show the GLBT community in a favorable light and reflects the interests of adults. The bibliographies provide guidance to libraries in the selection of positive GLBT materials.
On July 23, 1976, the Committee on the Status of Women in Librarianship was established as a Council Committee of the ALA on recommendation of the Ad Hoc Committee with the same name (which had been appointed by the President of the ALA in December 1975) and of the Committee on Organization. The Committee on the Status of Women in Librarianship works to "officially represent the diversity of women's interest within ALA and to ensure that the Association considers the rights of the majority (women) in the library field; to promote and initiate the collection, analysis, dissemination, and coordination of information on the status of women in librarianship; to coordinate the activities of ALA units which consider questions of special relevance for women; to identify lags, gaps, and possible discrimination in resources and programs relating to women; in cooperation with other ALA units, to help develop and evaluate tools, guidelines, and programs designed to enhance the opportunities and the image of women in the library profession, thus raising the level of consciousness concerning women; to establish contacts with committees on women within other professional groups and to officially represent ALA concerns at interdisciplinary meetings on women's equality; and to provide Council and Membership with reports needed for establishment of policies and actions related to the status of women in librarianship; and to monitor ALA units to ensure consideration of the rights of women." [32] [33] In 1979 the Committee on the Status of Women in Librarianship received the Bailey K. Howard - World Book Encyclopedia - ALA Goal Award to develop a profile of ALA personal members, known as the COSWL Study. In 1980 the Committee on the Status of Women in Librarianship was awarded the J. Morris Jones - World Book Encyclopedia - ALA Goals Award with the OLPR Advisory Committee to undertake a special project on equal pay for work of equal value. [33]

Affiliates

National outreach
The ALA is affiliated with regional, state, and student chapters (SCALA) across the country. It organizes conferences, participates in library standards development, and publishes a number of books and periodicals. The ALA publishes the magazines American Libraries and Booklist . Along with other organizations, it sponsors the annual Banned Books Week the last week of September. Young Adult Library Services Association ( YALSA ) also sponsors Teen Read Week , the third week of each October, and Teen Tech Week , the second week of each March. In addition, the ALA helps to promote diversity in the library profession with various outreach activities, including the Spectrum Scholarship program, which awards academic scholarships to minority library students each year. [35] National Library Week, the second week of each April, is a national observance sponsored by the ALA since 1958. [36] Libraries across the country celebrate library resources, library champions and promote public outreach.

Awards
The ALA annually confers numerous book and media awards, primarily through its children's and young adult divisions (others are the Dartmouth Medal , Coretta Scott King Awards , Schneider Book Awards, and Stonewall Book Award ).
The children's division ALSC administers the Caldecott Medal , Newbery Medal , Batchelder Award , Belpré Awards , Geisel Award , and Sibert Medal , all annual book awards; [37] the Odyssey Award for best audiobook (joint with YALSA), and the (U.S.) Carnegie Medal and for best video. There are also two ALSC lifetime recognitions, the Wilder Medal and the Arbuthnot Lecture .
The young-adult division YALSA administers the Margaret Edwards Award for significant and lasting contribution to YA literature, a lifetime recognition of one author annually, and some annual awards that recognize particular works: the Michael L. Printz Award for a YA book judged on literary merit alone, the William C. Morris Award for an author's first YA book, the new "YALSA Award for Excellence in Nonfiction for Young Adults", and the " Alex Award " list of ten adult books having special appeal for teens. Jointly with the children's division ALSC there is the Odyssey Award for excellence in audiobook production. [38]
The award for YA nonfiction was inaugurated in 2012, defined by ages 12 to 18 and publication year November 2010 to October 2011. The first winner was The Notorious Benedict Arnold: A True Story of Adventure, Heroism & Treachery by Steve Sheinkin (Roaring Brook Press, November 2010) and four other finalists were named. [39] [40]
Beside the Alex Awards, ALA disseminates some annual lists of "Notable" and "Best" books and other media.
The annual awards roster includes the John Cotton Dana Award for excellence in library public relations.
In 2000, the Office for Literacy and Outreach Services (OLOS) launched the Jean E. Coleman Library Outreach Lecture in tribute to the work of the first OLOS director, Dr. Jean E. Coleman. Barbara J. Ford gave the inaugural lecture, "Libraries, Literacy, Outreach and the Digital Divide."
Since 2006, the ALA has selected a class of Emerging Leaders , typically comprising about 100 librarians and library school students. This minor distinction is a form of organizational outreach to new librarians. The Emerging Leaders are allocated to project groups tasked with developing solutions to specified problems within ALA divisions. The class meets at the ALA Midwinter and Annual Meetings, commonly January and June. Project teams may present posters of their completed projects at the Annual. [41]

Conferences
The ALA and its divisions hold numerous conferences throughout the year. The two largest conferences are the annual conference and the midwinter meeting. The latter is typically held in January and focused on internal business, while the annual conference is typically held in June and focused on exhibits and presentations. The ALA annual conference is notable for being one of the largest professional conferences in existence, typically drawing over 25,000 attendees. [42]

Political positions
The ALA advocates positions on United States political issues that it believes are related to libraries and librarianship. For court cases that touch on issues about which the organization holds positions, the ALA often files amici curiae briefs, voluntarily offering information on some aspect of the case to assist the court in deciding a matter before it. The ALA has an office in Washington, D.C. , that lobbies Congress on issues relating to libraries, information and communication. It also provides materials to libraries that may include information on how to apply for grants, how to comply with the law, and how to oppose a law. [43]

Intellectual freedom
The primary documented expressions of the ALA's intellectual freedom principles are the Freedom to Read Statement [44] and the Library Bill of Rights ; the Library Bill of Rights urges libraries to "challenge censorship in the fulfillment of their responsibility to provide information and enlightenment." [45] The ALA Code of Ethics also calls on librarians to "uphold the principles of intellectual freedom and resist all efforts to censor library resources." [46]
The ALA maintains an Office for Intellectual Freedom (OIF) headed by Barbara M. Jones, former University Librarian for Wesleyan University and internationally known intellectual freedom advocate and author. [47] She is the second director of the Office for Intellectual Freedom, succeeding Judith Krug , who headed the office for four decades. OIF is charged with "implementing ALA policies concerning the concept of intellectual freedom ," [48] that the ALA defines as "the right of every individual to both seek and receive information from all points of view without restriction. It provides for free access to all expressions of ideas through which any and all sides of a question, cause or movement may be explored." [49] Its goal is "to educate librarians and the general public about the nature and importance of intellectual freedom in libraries." [48] The OIF compiles lists of challenged books as reported in the media and submitted to them by librarians across the country. [50]
In 1950, the Intellectual Freedom Committee, the forerunner of the OIF, investigated the termination of Ruth W. Brown as librarian of the Bartlesville Public Library, a position she held in the Oklahoma town for 30 years. Brown's termination was based on the false allegation that she was a communist and that she had as part of the library's serials collection two left wing publications, The New Republic and The Nation . The ALA support for her and the subsequent legal case was the first such investigation undertaken by the ALA or one of its state chapters. [51]
In 1999, radio personality Laura Schlessinger campaigned publicly against the ALA's intellectual freedom policy, specifically in regard to the ALA's refusal to remove a link on its web site to a specific sex-education site for teens. [52] Sharon Priestly said, however, that Schlessinger "distorted and misrepresented the ALA stand to make it sound like the ALA was saying porno for 'children' is O.K." [53]
In 2002, the ALA filed suit with library users and the ACLU against the United States Children's Internet Protection Act (CIPA), which required libraries receiving federal E-rate discounts for Internet access to install a "technology protection measure" to prevent children from accessing "visual depictions that are obscene, child pornography, or harmful to minors." [54] At trial, the federal district court struck down the law as unconstitutional. [55] The government appealed this decision, and on June 23, 2003, the Supreme Court of the United States upheld the law as constitutional as a condition imposed on institutions in exchange for government funding. In upholding the law, the Supreme Court, adopting the interpretation urged by the U.S. Solicitor General at oral argument, made it clear that the constitutionality of CIPA would be upheld only "if, as the Government represents, a librarian will unblock filtered material or disable the Internet software filter without significant delay on an adult user's request." [56]

Privacy

1970s
The Federal Bureau of Investigation attempted to use librarians as possible informants in the conspiracy case of the Harrisburg Seven in 1971. The Harrisburg Seven, made up of religious anti-war activists, were primarily accused of conspiring to kidnap National Security Advisor Henry Kissinger . The supposed leader of the group, Philip Berrigan , was serving time at the Lewisburg penitentiary. The FBI sought "to use library surveillance and librarian informants" at Bucknell University as evidence of the Harrisburg Seven's "characters and intentions." [57] Boyd Douglas became one such informant for the FBI: he was a prisoner at the same penitentiary with a work-release position at the library. Boyd presented himself as an anti-war activist and offered to smuggle letters he collected while at work to Philip Berrigan at the prison.
The FBI also attempted to use Zoia Horn , a librarian at the Bucknell library, and interviewed other library workers. The FBI met with Horn in her home to debrief her, but Horn refused to answer their questions. She refused to testify, even after she was given immunity from self-incrimination. [58] Horn stated, "To me it stands on: Freedom of thought" and that the government "spying in homes, in libraries and universities inhibits and destroys this freedom." [59] Zoia Horn was charged with contempt of the court and served 20 days in jail. She was "the first librarian who spent time in jail for a value of our profession" according to Judith Krug of the American Library Association's Office for Intellectual Freedom. [60] Horn continued to fight for intellectual freedom in libraries and beyond. The Intellectual Freedom Committee of the California Library Association now awards the Zoia Horn Intellectual Freedom Award in honor of those who make contributions to intellectual freedom. [61]
In the 1970s, United States Department of the Treasury agents also pressured public libraries across the country to "release circulation records recording the names and identifying information of people who checked out books on bomb making." [57] The ALA believed this to be an "unconscionable and unconstitutional invasion of library patrons' privacy." [57]
As a result of these two situations and many others, the ALA affirmed the confidential status of all records which held patron names in a Policy on the Confidentiality of Library Records . The ALA also released the ALA Statement on Professional Ethics in 1975 which advocated for the protection of the “confidential relationship" between a library user and a library. [57]

1980s
The FBI tried to use surveillance in library settings as part of its Library Awareness Program of the 1980s; it aimed to use librarians "as partners in surveillance." The program was known to the FBI as "The Development of Counterintelligence Among Librarians," indicating that the FBI believed that librarians might be supportive in its counterintelligence investigations. The FBI attempted to profile "Russian or Slavic-sounding last names" of library patrons to look for possible "national security threats." The FBI wanted libraries to help it trace "the reading habits of patrons with those names." [57]
The ALA responded by writing to the FBI director. The Intellectual Freedom Committee also created "an advisory statement to warn libraries" of the Library Awareness Program, including ways to help librarians "avoid breaking their ethical obligations if faced with FBI surveillance." [62]

USA PATRIOT Act
In 2003, the ALA passed a resolution opposing the USA PATRIOT Act , which called sections of the law "a present danger to the constitutional rights and privacy rights of library users". [63] Since then, the ALA and its members have sought to change the law by working with members of Congress and educating their communities and the press about the law's potential to violate the privacy rights of library users. ALA has also participated as an amicus curiae in lawsuits filed by individuals challenging the constitutionality of the USA PATRIOT Act, including a lawsuit filed by four Connecticut librarians after the library consortium they managed was served with a national security letter seeking information about library users. [64] After several months of litigation, the lawsuit was dismissed when the FBI decided to withdraw the National Security Letter. [65] In 2007 the "Connecticut Four" were honored by the ALA with the Paul Howard Award for Courage for their challenge to the National Security Letter and gag order provision of the USA PATRIOT Act. [66]
In 2006, the ALA sold humorous "radical militant librarian" buttons for librarians to wear in support of the ALA's stances on intellectual freedom, privacy, and civil liberties. [67] Inspiration for the button’s design came from documents obtained from the FBI by the Electronic Privacy Information Center (EPIC) through a Freedom of Information Act (FOIA) request. The request revealed a series of e-mails in which FBI agents complained about the "radical, militant librarians" while criticizing the reluctance of FBI management to use the secret warrants authorized under Section 215 of the USA PATRIOT Act. [68]

Copyright
The ALA "supports efforts to amend the Digital Millennium Copyright Act (DMCA) and urges the courts to restore the balance in copyright law, ensure fair use and protect and extend the public domain". [69] It supports changing copyright law to eliminate damages when using orphan works without permission; [70] is wary of digital rights management ; and, in ALA v. FCC [71] , successfully sued the Federal Communications Commission to prevent regulation that would enforce next-generation digital televisions to contain rights-management hardware. It has joined the Information Access Alliance to promote open access to research. [72] The Copyright Advisory Network of the Association's Office for Information Technology Policy provides copyright resources to libraries and the communities they serve. The ALA is a member of the Library Copyright Alliance , along with the Association of Research Libraries and the Association of College and Research Libraries, which provides a unified voice for over 300,000 information professionals in the United States. [73]

ALA-Accredited Programs in Library and Information Studies
ALA-Accredited programs can be found at schools in the U.S., Puerto Rico, and Canada. Theses programs offer degrees with names such as Master of Library Science (MLS), Master of Arts, Master of Librarianship, Master of Library and Information Studies (MLIS), and Master of Science. To be accredited, the program must undergo an external review and meet the Standards for Accreditation of Master’s Programs in Library and Information Studies. The ALA website provides a directory directory in database form of ALA-Accredited programs. There are currently 59 accredited programs, and two that are candidates seeking accreditation.

See also
WebPage index: 00053
James Heilman
James M. " Doc James " Heilman is a Canadian emergency room physician , Wikipedian , and advocate for the improvement of Wikipedia's health-related content . He encourages other clinicians to contribute to the online encyclopaedia. [2] [3]
He is an active contributor to WikiProject Medicine , is a volunteer Wikipedia administrator , was the president of Wikimedia Canada between 2010 and 2013, and founded and was formerly the president of Wiki Project Med Foundation. [4] [5] [6] [7] [8] He is also the founder of WikiProject Medicine's Medicine Translation Task Force. [9] In June 2015, he was elected to the Wikimedia Foundation Board of Trustees , a position which he held until he was removed on December 28, 2015. [10] [11] [12]
Heilman is a clinical assistant professor at the department of emergency medicine at the University of British Columbia , [13] [14] and the head of the department of emergency medicine at East Kootenay Regional Hospital in Cranbrook, British Columbia , where he lives. [1] [2] He often works the night shift in the emergency room at East Kootenay Regional Hospital. [14]

Early life and education
Heilman was born and raised in rural Saskatchewan . [15] He graduated from the University of Saskatchewan in 2000 with a Bachelor of Science in anatomy, and he subsequently earned his medical degree there in 2003. [2] He then completed his residency in British Columbia. [15]

Medical career
Heilman worked at Moose Jaw Union Hospital , a hospital in Moose Jaw , Saskatchewan, until 2010, when he began working at East Kootenay Regional Hospital, [2] [16] where, in October 2012, he was appointed head of the department of emergency medicine . [2] In 2014, he told the Cranbrook Daily Townsman that the emergency department at East Kootenay saw an average of 22,000 patients each year. [17] In 2016, he told the Globe and Mail that he had seen patients who had experienced chest pains for over half a day before going to the hospital. Of these patients, he said, "“They’re like, ‘It’s just indigestion. It’s just indigestion. It’s just indigestion. And when they arrive, [it turns out] they’ve had a massive heart attack. That occurs not that infrequently." [18]

Research
As of May 2014, Heilman was working on a study with Samir Grover , of the University of Toronto , which would assign medical students to take a test using either Wikipedia or medical textbooks to determine which is more accurate. [19] Later that year, Heilman co-authored a version of the Wikipedia article for dengue fever in the peer-reviewed journal Open Medicine . [20] Heilman also worked on a study with Microsoft which found that in the three countries where the Ebola outbreak had the largest impact, Wikipedia was the most popular source for information about the disease. [21] In 2015, Heilman and Andrew West published a study which found that the number of Wikipedia editors who focused on editing medical articles decreased by 40 percent from 2008 to 2013. [22] These results, together with other detailed analyses about the production and consumption of medical content on Wikipedia, were published by the Journal of Medical Internet Research in 2015. [23]

Wikipedia and Wikimedia activities
Since the beginning of his activity as a contributor to medicine-related Wikipedia articles in 2008, Heilman has been promoting the improvement of medical content by encouraging fellow physicians to take part. [2] He became interested in editing Wikipedia on a slow night shift, when he looked up the article on obesity and found that it contained many errors. "I realized that I could fix it. I made a huge number of edits and improved the quality a great deal. I sort of became hooked from there," he told the Hamilton Spectator in 2011. [3]
Heilman takes part in an initiative through Wiki Project Med Foundation with Translators Without Borders , working to improve and translate English Wikipedia medical articles of top importance into minority languages. [24] [25] [26] The Wiki Project Med Foundation has started a collaboration with the University of California, San Francisco as a recruit for scientifically literate editors, by giving students college credit for improving medicine-related Wikipedia pages. [27] In 2014, the Wiki Project Med Foundation also partnered with the Cochrane Collaboration , with the goal of improving the reliability and accuracy of information on Wikipedia. With regard to this partnership, Heilman said, "The way Wikipedia works is that all content is to stand entirely on the references that are listed. If the best quality sources are used to write Wikipedia there's a good chance that Wikipedia will contain the best quality information." [28]
Heilman spoke at Wikimania 2014 , where he said that 93% of medical students use Wikipedia, and argued that "fixing the internet" is now a critical task for anyone who cares about healthcare. [29]

Ebola contributions
By reviewing and correcting medical content in the manner promoted by Heilman (and with many of his contributions), in Wikipedia articles like that about Ebola , Wikipedia has become a source of information to the general public, thus being regarded among respected sites run by the World Health Organization [30] and the Centers for Disease Control and Prevention , [31] covering the topic. [4] [32] Heilman reduced the time he spent working in the emergency room so he could spend more time updating this page. [33] In 2014, he told the Cranbrook Daily Townsman that with respect to Wikipedia's coverage of Ebola, “The big thing is emphasizing what we know, making sure that minor concerns don’t get blown out of proportion." [34] He also said that, despite rumours to the contrary, there was no evidence that the disease had become airborne, and that ebola had caused far fewer deaths than other conditions such as malaria and gastroenteritis . [34]

Rorschach test images
In 2009, Heilman, who was then a resident of Moose Jaw, Saskatchewan , [35] added public domain images of the ink blots used in the Rorschach test to the Wikipedia article on the subject, and concerned psychologists said that this could invalidate the tests. [16] [36] [37] Some psychologists stated the test had "already lost its popularity and usefulness." [37] In an interview with The New York Times , Heilman stated that he added the entire set because a debate about a single image seemed absurd and psychologists' fears were unfounded. [38] Appearing on Canada AM on July 31, 2009, Heilman also said that "This information [i.e. the inkblots] is encyclopedic. This is what people expect to see when they see this page." [39] In August 2009, two Canadian psychologists filed complaints about Heilman to his local doctors' organization; Heilman called the complaints "intimidation tactics". [40] In September 2009, the College of Psychologists of British Columbia urged the Saskatchewan College of Physicians and Surgeons to launch an investigation into Heilman's posting of the images. Heilman told CTV News that "The psychological community is trying to exclude everybody outside their field from taking part in discussions related to what they do. And personally, I think that's bad science." [41] An extensive debate ensued on Wikipedia, and the images were kept. [38]

Textbook plagiarism
In 2012, Heilman noticed that the book Understanding and Management of Special Child in Pediatric Dentistry , published by Jaypee Brothers , contained a long passage about HIV that was plagiarized from Wikipedia's article on the subject. [24] This led to the book being withdrawn by the publisher. [42] In October 2014, when Heilman was reading a copy of the Oxford Textbook of Zoonoses (published by Oxford University Press ), he noticed that the book's section on Ebola was very similar to the Wikipedia page on that subject. [22] Originally he suspected that a Wikipedia editor had copied from the textbook when writing the article. [22] However, he later noticed that the part of the Wikipedia article that resembled the part of the textbook had been written in 2006 and 2010, while the textbook had not been published until 2011. [22] Christian Purdy, an Oxford University Press spokesperson, acknowledged that some of the text in the textbook had been copied but described it as an “inadvertent omission of an appropriate attribution" rather than plagiarism. [22]

Tenure on the Wikimedia Foundation Board of Trustees
In June 2015, Heilman was elected to the Wikimedia Foundation Board of Trustees . [10] In December 2015, the Board removed Heilman from his position as a Trustee, a decision that generated controversy amongst members of the Wikipedia community. [11] [43] [44] A statement released by the board after Heilman was removed stated that he lacked the confidence of his fellow trustees. Heilman himself later said that he "was given the option of resigning [by the Board] over the last few weeks. As a community elected member I see my mandate as coming from the community which elected me and thus declined to do so. I saw such a move as letting down those who elected me." [45] Heilman subsequently pointed out that while on the Board, he had pushed for greater transparency regarding the Wikimedia Foundation's controversial Knowledge Engine project and its financing, [46] and indicated that his attempts to make public the Knight Foundation grant for the engine had been a factor in his dismissal. [47]

Other
In 2012, Heilman was one of two Wikimedia contributors sued by Internet Brands for shifting freely licensed content and volunteer editors from the for-profit site Wikitravel to the non-profit site Wikivoyage . The Wikimedia Foundation defended Heilman's actions in the lawsuit, citing volunteer freedom of choice. [48] [49] In February 2013 the parties settled their litigation. [50] In 2014, Heilman criticized a study which concluded that 9 out of 10 Wikipedia medical articles contained errors. [6] [51] In 2015, the Atlantic ran a piece about conflict-of-interest editing on Wikipedia which detailed Heilman's efforts to counteract edits made by employees of Medtronic to the Wikipedia page for percutaneous vertebroplasty . [22]

Personal life
Heilman enjoys running ultramarathons and adventure racing , [16] [52] and he and his girlfriend ran the Gobi March in 2008. [53] He has also run the Marathon des Sables , the Adventure Racing World Championships , [15] and the Saskatchewan Marathon . [54]

Wikipedia-related publications
WebPage index: 00054
James M. McPherson
James M. "Jim" McPherson (born October 11, 1936) is an American Civil War historian , and is the George Henry Davis '86 Professor Emeritus of United States History at Princeton University . He received the 1989 Pulitzer Prize for Battle Cry of Freedom: The Civil War Era . McPherson was the president of the American Historical Association in 2003, and is a member of the editorial board of Encyclopædia Britannica .

Early life and education
Born in Valley City , North Dakota , McPherson graduated from St. Peter High School, and he received his Bachelor of Arts at Gustavus Adolphus College ( St. Peter , Minnesota ) in 1958 (from which he graduated magna cum laude ), and his Ph.D. at Johns Hopkins University in 1963 where he studied under C. Vann Woodward . [1]

Career
McPherson's works include The Struggle for Equality , awarded the Anisfield-Wolf Award in 1965. In 1988, he published his Pulitzer-winning book, Battle Cry of Freedom . And in 1998 another book, For Cause and Comrades: Why Men Fought in the Civil War , received the Lincoln Prize . [2] In 2002, he published both a scholarly book, Crossroads of Freedom: Antietam 1862, and a history of the American Civil War for children, Fields of Fury .
McPherson published This Mighty Scourge in 2007, a series of essays about the American Civil War. One essay describes the huge difficulty of negotiation when regime change is a war aim on either side of a conflict. "For at least the past two centuries, nations have usually found it harder to end a war than to start one. Americans learned that bitter lesson in Vietnam , and apparently having forgotten it, we're forced to learn it all over again in Iraq." One of McPherson's examples is the American Civil War, in which both the Union and the Confederacy sought regime change. It took four years to end the war. [3]
In 2009, he was the co-winner of the Lincoln Prize for Tried by War: Abraham Lincoln as Commander in Chief . [5]
McPherson was named the 2000 Jefferson Lecturer in the humanities by the National Endowment for the Humanities . [1] [6] [7] In making the announcement of McPherson's selection, NEH Chairman William R. Ferris said:
In 2007, he was awarded the $100,000 Pritzker Military Library Literature Award for lifetime achievement in military history and was the first recipient of the prize. [9] He was elected a Fellow of the American Academy of Arts and Sciences in 2009. [10]

Personal life
Currently, McPherson resides in Princeton , New Jersey . He is married to Patricia and they have one child. [1]

Political activism
McPherson is known for his outspokenness on contemporary issues and for his activism, such as his work on behalf of the preservation of Civil War battlefields . As president in 1993-1994 of Protect Historic America , he lobbied against the construction of a Disney theme park near Manassas battlefield . [11] He has also served on the boards of the Civil War Trust as well as the Association for the Preservation of Civil War Sites , a predecessor to the Civil War Trust. From 1990 to 1993, he sat on the Civil War Sites Advisory Commission . [12]
Along with several other historians, McPherson signed a May 2009 petition asking U.S. President Barack Obama not to lay a wreath at the Confederate Monument Memorial at Arlington National Cemetery . The petition stated:
Obama put the wreath on the monument anyway, winning the praise of the Sons of Confederate Veterans . [14]

Filmography

See also
WebPage index: 00055
Thomas Jefferson University
Thomas Jefferson University is a private health sciences university in Center City , Philadelphia , Pennsylvania , United States. The university consists of six constituent colleges and schools, Sidney Kimmel Medical College, Jefferson College of Biomedical Sciences, Jefferson College of Health Professions, Jefferson College of Nursing, Jefferson College of Pharmacy, and Jefferson College of Population Health. In 2017, the Sidney Kimmel Medical College was ranked by U.S. News & World Report as 53rd among research institutions in the US and 51st among primary care institutions. [4]

History
Although today Thomas Jefferson University includes many different graduate programs, it began as a medical school. During the early 19th century, several attempts to create a second medical school in Philadelphia had been stymied, largely due to the efforts of University of Pennsylvania School of Medicine alumni. [1] [5] In an attempt to circumvent that opposition, a group of Philadelphia physicians led by Dr. George McClellan sent a letter to the trustees of Jefferson College in Canonsburg, Pennsylvania (now Washington & Jefferson College ) in 1824, asking the College to establish a medical department in Philadelphia. [6] The trustees agreed, establishing the Medical Department of Jefferson College in Philadelphia in 1825. [1] [6] In response to a second request, the Pennsylvania General Assembly granted an expansion of Jefferson College's charter in 1826, endorsing the creation of the new department and allowing it to grant medical degrees . [1] [6] [7] An additional 10 Jefferson College trustees were appointed to supervise the new facility from Philadelphia, owing to the difficulty of managing a medical department on the other side of the state. [6] Two years later, this second board was granted authority to manage the Medical Department, while the Jefferson College trustees maintained veto power for major decisions. [6]
The first class was graduated in 1826, receiving their degrees only after the disposition of a lawsuit seeking to close the school. [6] The first classes were held in the Tivoli Theater on Prune Street in Philadelphia, which had the first medical clinic attached to a medical school. [8] Owing to the teaching philosophy of Dr. McClellan, classes focused on clinical practice. [8] In 1828, the Medical Department moved to the Ely Building, which allowed for a large lecture space and the "Pit," a 700-seat amphitheater to allow students to view surgeries. [8] This building had an attached hospital, the second such medical school/hospital arrangement in the nation, servicing 441 inpatients and 4,659 outpatients in its first year of operation. [8] The relationship with Jefferson College survived until 1838, when the Medical Department received a separate charter, allowing it operate separately as the Jefferson Medical College. [7] [9] At this time, all instructors, including McClellan, were vacated from the school and the trustees hired all new individuals to teach. This has been considered the time at which the school came to be considered a "legitimate" medical school. [1] [10]
In 1841, Jefferson Medical College hired what would be dubbed "The Faculty of '41," an influential collection of professors including Charles Delucena Meigs and Mütter Museum founder Thomas Dent Mütter . This collection of professors would institute numerous impactful changes to Jefferson — including Jefferson was providing patient beds over a shop at 10th and Sansom Streets in 1844 — and the staff would remain unchanged for fifteen years. [11]
A 125-bed hospital, one of the first in the nation affiliated with a medical school, opened in 1877, and a school for nurses began in 1891. The Medical College became Thomas Jefferson University on July 1, 1969. As an academic health care center, Jefferson is currently involved in education, medical research, and patient care. Jefferson Medical College is the 9th oldest American medical school that is in existence today. [12]
On June 17, 2014 Sidney Kimmel donated $110 million to Jefferson Medical College, prompting the announcement that Jefferson Medical College would be renamed Sidney Kimmel Medical College [13]

Affiliations
The University is affiliated with Thomas Jefferson University Hospitals (TJUH)—including Thomas Jefferson University Hospital , Jefferson Hospital for Neuroscience , and Methodist Hospital (Philadelphia) .
Thomas Jefferson University is also the primary academic affiliate of the Jefferson Health System. Jefferson Health System was founded in 1995 when Thomas Jefferson University Hospital and the Main Line Health System signed an agreement establishing a new, nonprofit, corporate entity known as the Jefferson Health System. The agreement brought together the Thomas Jefferson University Hospitals, Inc. and Main Line Health under one corporate parent. Since then, other established networks have joined Jefferson Health System as founding members, which at one point included the Albert Einstein Healthcare Network , [14] Frankford Health Care System (now Aria Health ), [15] [16] Main Line Health and Magee Rehabilitation Hospital .
On June 20, 2013 the board of directors for both organizations announced that Dr. Stephen Klasko would assume the role of President and CEO for both Thomas Jefferson University and the TJUH System in an effort to unify the clinical and educational missions on campus. In March 2014, the Jefferson Health System was dissolved "in order for (TJUH) to move forward" and "be nimble and agile, but also not be constrained by a corporate relationship that in some respects put some limits on what we could do," according to Stephen K. Klasko, Jefferson's President and Chief Executive of both Thomas Jefferson University and the parent Thomas Jefferson University Hospitals Inc. [17]

The Gross Clinic
In January 2007, the University sold Thomas Eakins ' painting The Gross Clinic , which depicts a surgery that took place at the school, for $68 million, to the Pennsylvania Academy of the Fine Arts , in association with the Philadelphia Museum of Art . [18] A reproduction hangs in its place at Jefferson University.

See also
WebPage index: 00056
Muhammad
Muhammad [n 1] ( Arabic : محمد ‎‎; pronounced [muħammad] ; [n 2] c. 570 CE – 8 June 632 CE) [2] is the prophet of Islam and widely identified as its founder by non-Muslims. [3] [4] According to Islamic doctrine , he was God's Messenger ( rasūl Allāh ) sent to confirm the essential teachings of monotheism preached previously by Adam , Abraham , Moses , Jesus , and other prophets . [4] [5] [6] [7] He is viewed as the final prophet of God in primary branches of Islam , though some modern denominations diverge from this belief. [n 3] Muhammad united Arabia into a single Muslim polity and ensured that his teachings, practices, and the Quran , formed the basis of Islamic religious belief.
Born approximately 570 CE ( Year of the Elephant ) in the Arabian city of Mecca , Muhammad was orphaned at an early age; he was raised under the care of his paternal uncle Abu Talib . Periodically, he would seclude himself in a mountain cave named Hira for several nights of prayer; later, at age 40, he reported being visited by Gabriel in the cave, [8] [9] where he stated he received his first revelation from God. Three years later, in 610, [10] Muhammad started preaching these revelations publicly, [11] proclaiming that " God is One ", that complete "surrender" (lit. islām ) to him is the right course of action ( dīn ), [12] and that he was a prophet and messenger of God, similar to the other prophets in Islam . [13] [14] [15]
Muhammad gained few early followers , and met hostility from some Meccan tribes . To escape persecution, Muhammad sent some followers to Abyssinia before he and his followers migrated from Mecca to Medina (then known as Yathrib) in the year 622. This event, the Hijra , marks the beginning of the Islamic calendar , also known as the Hijri Calendar. In Medina, Muhammad united the tribes under the Constitution of Medina . In December 629, after eight years of intermittent conflict with Meccan tribes, Muhammad gathered an army of 10,000 Muslim converts and marched on the city of Mecca . The attack went largely uncontested and Muhammad seized the city with little bloodshed. In 632, a few months after returning from the Farewell Pilgrimage , he fell ill and died. Before his death, most of the Arabian Peninsula had converted to Islam . [16] [17]
The revelations (each known as Ayah , lit. "Sign [of God]"), which Muhammad reported receiving until his death, form the verses of the Quran, regarded by Muslims as the "Word of God" and around which the religion is based. Besides the Quran, Muhammad's teachings and practices ( sunnah ), found in the Hadith and sira literature, are also upheld by Muslims and used as sources of Islamic law (see Sharia ).

Names and appellations in the Quran
The name Muhammad ( / m ʊ ˈ h æ m ə d , - ˈ h ɑː m ə d / ) [18] means "praiseworthy" and appears four times in the Quran. [19] The Quran addresses Muhammad in the second person by various appellations ; prophet , messenger , servant of God (' abd ), announcer ( bashir ) [ Quran 2:119 ] , witness ( shahid ), [ Quran 33:45 ] bearer of good tidings ( mubashshir ), warner ( nathir ), [ Quran 11:2 ] reminder ( mudhakkir ), [ Quran 88:21 ] one who calls [unto God] ( dā‘ī ), [ Quran 12:108 ] light personified ( noor ) [ Quran 05:15 ] , and the light-giving lamp ( siraj munir ) [ Quran 33:46 ] . Muhammad is sometimes addressed by designations deriving from his state at the time of the address: thus he is referred to as the enwrapped ( al-muzzammil ) in Quran 73:1 and the shrouded ( al-muddaththir ) in Quran 74:1 . [20] In Sura Al-Ahzab 33:40 God singles out Muhammad as the " Seal of the Prophets ", or the last of the prophets. [21] The Quran also refers to Muhammad as Aḥmad "more praiseworthy" ( Arabic : أحمد ‎‎, Sura As-Saff 61:6 ). [22]
The name Abū al-Qāsim Muḥammad ibn ʿAbd Allāh ibn ʿAbd al-Muṭṭalib ibn Hāshim, [23] begins with the kunya [24] Abū, which corresponds to the English, father of . [25]

Sources

Quran
The Quran is the central religious text of Islam . Muslims believe it represents the words of God revealed by the archangel Gabriel to Muhammad. [26] [27] [28] The Quran, however, provides minimal assistance for Muhammad's chronological biography; most Quranic verses do not provide significant historical context. [29] [30]

Early biographies
Important sources regarding Muhammad's life may be found in the historic works by writers of the 2nd and 3rd centuries of the Muslim era (AH – 8th and 9th century CE). [31] These include traditional Muslim biographies of Muhammad, which provide additional information about Muhammad's life. [32]
The earliest surviving written sira (biographies of Muhammad and quotes attributed to him) is Ibn Ishaq 's Life of God's Messenger written c. 767 CE (150 AH). Although the work was lost, this sira was used verbatim at great length by Ibn Hisham and Al-Tabari . [33] [34] Another early history source is the history of Muhammad's campaigns by al-Waqidi (death 207 of Muslim era), and the work of his secretary Ibn Sa'd al-Baghdadi (death 230 of Muslim era). [31]
Many scholars accept these early biographies as authentic, though their accuracy is unascertainable. [33] Recent studies have led scholars to distinguish between traditions touching legal matters and purely historical events. In the legal group, traditions could have been subject to invention while historic events, aside from exceptional cases, may have been only subject to "tendential shaping". [35]

Hadith
Other important sources include the hadith collections, accounts of the verbal and physical teachings and traditions of Muhammad. Hadiths were compiled several generations after his death by followers including Muhammad al-Bukhari , Muslim ibn al-Hajjaj , Muhammad ibn Isa at-Tirmidhi , Abd ar-Rahman al-Nasai , Abu Dawood , Ibn Majah , Malik bin Anas , al-Daraqutni . [36] [37]
Some Western academics cautiously view the hadith collections as accurate historical sources. [36] Scholars such as Madelung do not reject the narrations which have been compiled in later periods, but judge them in the context of history and on the basis of their compatibility with the events and figures. [38] Muslim scholars on the other hand typically place a greater emphasis on the hadith literature instead of the biographical literature, since hadiths maintain a verifiable chain of transmission ( isnad ); the lack of such a chain for the biographical literature makes it less verifiable in their eyes. [39]

Pre-Islamic Arabia
The Arabian Peninsula was largely arid and volcanic, making agriculture difficult except near oases or springs. The landscape was dotted with towns and cities; two of the most prominent being Mecca and Medina . Medina was a large flourishing agricultural settlement, while Mecca was an important financial center for many surrounding tribes. [40] Communal life was essential for survival in the desert conditions, supporting indigenous tribes against the harsh environment and lifestyle. Tribal affiliation, whether based on kinship or alliances, was an important source of social cohesion. [41] Indigenous Arabs were either nomadic or sedentary , the former constantly travelling from one place to another seeking water and pasture for their flocks, while the latter settled and focused on trade and agriculture. Nomadic survival also depended on raiding caravans or oases; nomads did not view this as a crime. [42] [43]
In pre-Islamic Arabia, gods or goddesses were viewed as protectors of individual tribes, their spirits being associated with sacred trees, stones , springs and wells. As well as being the site of an annual pilgrimage, the Kaaba shrine in Mecca housed 360 idols of tribal patron deities. Three goddesses were associated with Allah as his daughters: Allāt , Manāt and al-‘Uzzá . Monotheistic communities existed in Arabia, including Christians and Jews . [44] Hanifs – native pre-Islamic Arabs who "professed a rigid monotheism" [45] – are also sometimes listed alongside Jews and Christians in pre-Islamic Arabia, although their historicity is disputed among scholars. [46] [47] According to Muslim tradition, Muhammad himself was a Hanif and one of the descendants of Ishmael , son of Abraham . [48]
The second half of the sixth century was a period of political disorder in Arabia and communication routes were no longer secure. [49] Religious divisions were an important cause of the crisis. [50] Judaism became the dominant religion in Yemen while Christianity took root in the Persian Gulf area. [50] In line with broader trends of the ancient world, the region witnessed a decline in the practice of polytheistic cults and a growing interest in a more spiritual form of religion. [50] While many were reluctant to convert to a foreign faith, those faiths provided intellectual and spiritual reference points. [50]
During the early years of Muhammad's life, the Quraysh tribe he belonged to became a dominant force in western Arabia. [51] They formed the cult association of hums , which tied members of many tribes in western Arabia to the Kaaba and reinforced the prestige of the Meccan sanctuary. [52] To counter the effects of anarchy, Quraysh upheld the institution of sacred months during which all violence was forbidden, and it was possible to participate in pilgrimages and fairs without danger. [52] Thus, although the association of hums was primarily religious, it also had important economic consequences for the city. [52]

Life

In Mecca
Muhammad was born in Mecca and lived there for roughly the first 52 years of his life (c. 570–622). This period is generally divided into two phases, before and after declaring his prophetic visions.

Childhood and early life
Abū al-Qāsim Muḥammad ibn ʿAbd Allāh ibn ʿAbd al-Muṭṭalib ibn Hāshim, [23] was born about the year 570 [8] and his birthday is believed to be in the month of Rabi' al-awwal . [57] He belonged to the Banu Hashim clan, part of the Quraysh tribe , and was one of Mecca 's prominent families, although it appears less prosperous during Muhammad's early lifetime. [15] [58] Tradition places the year of Muhammad's birth as corresponding with the Year of the Elephant , which is named after the failed destruction of Mecca that year by the Abraha , Yemen's king, who supplemented his army with elephants. [59] [60] [61] Alternatively some 20th century scholars have suggested different years, such as 568 or 569. [62]
Muhammad's father, Abdullah , died almost six months before he was born. [64] According to Islamic tradition, soon after birth he was sent to live with a Bedouin family in the desert, as desert life was considered healthier for infants; some western scholars reject this tradition's historicity. [65] Muhammad stayed with his foster-mother, Halimah bint Abi Dhuayb , and her husband until he was two years old. At the age of six, Muhammad lost his biological mother Amina to illness and became an orphan. [65] [66] For the next two years, until he was eight years old, Muhammad was under the guardianship of his paternal grandfather Abd al-Muttalib , of the Banu Hashim clan until his death. He then came under the care of his uncle Abu Talib , the new leader of the Banu Hashim. [62] According to Islamic historian William Montgomery Watt there was a general disregard by guardians in taking care of weaker members of the tribes in Mecca during the 6th century, "Muhammad's guardians saw that he did not starve to death, but it was hard for them to do more for him, especially as the fortunes of the clan of Hashim seem to have been declining at that time." [67]
In his teens, Muhammad accompanied his uncle on Syrian trading journeys to gain experience in commercial trade. [67] Islamic tradition states that when Muhammad was either nine or twelve while accompanying the Meccans' caravan to Syria, he met a Christian monk or hermit named Bahira who is said to have foreseen Muhammad's career as a prophet of God. [68]
Little is known of Muhammad during his later youth, available information is fragmented, making it difficult to separate history from legend. [67] It is known that he became a merchant and "was involved in trade between the Indian Ocean and the Mediterranean Sea ." [69] Due to his upright character he acquired the nickname " al-Amin " (Arabic: الامين), meaning "faithful, trustworthy" and "al-Sadiq" meaning "truthful" [70] and was sought out as an impartial arbitrator. [9] [15] [71] His reputation attracted a proposal in 595 from Khadijah , a 40-year-old widow. Muhammad consented to the marriage, which by all accounts was a happy one. [69]
Several years later, according to a narration collected by historian Ibn Ishaq , Muhammad was involved with a well-known story about setting the Black Stone in place in the wall of the Kaaba in 605 CE. The Black Stone, a sacred object, was removed during renovations to the Kaaba. The Meccan leaders could not agree which clan should return the Black Stone to its place. They decided to ask the next man who comes through the gate to make that decision; that man was the 35-year-old Muhammad. This event happened five years before the first revelation by Gabriel to him. He asked for a cloth and laid the Black Stone in its center. The clan leaders held the corners of the cloth and together carried the Black Stone to the right spot, then Muhammad laid the stone, satisfying the honour of all. [72] [73]

Beginnings of the Quran
Muhammad began to pray alone in a cave named Hira on Mount Jabal al-Nour , near Mecca for several weeks every year. [74] [75] Islamic tradition holds that during one of his visits to that cave, in the year 610 the angel Gabriel appeared to him and commanded Muhammad to recite verses that would be included in the Quran. [76] Consensus exists that the first Quranic words revealed were the beginning of Surah 96:1 . [77] Muhammad was deeply distressed upon receiving his first revelations. After returning home, Muhammad was consoled and reassured by Khadijah and her Christian cousin, Waraqah ibn Nawfal . [78] He also feared that others would dismiss his claims as being possessed. [43] Shi'a tradition states Muhammad was not surprised or frightened at Gabriel's appearance; rather he welcomed the angel, as if he was expected. [79] The initial revelation was followed by a three-year pause (a period known as fatra ) during which Muhammad felt depressed and further gave himself to prayers and spiritual practices . [77] When the revelations resumed he was reassured and commanded to begin preaching: "Thy Guardian-Lord hath not forsaken thee, nor is He displeased." [80] [81] [82]
Sahih Bukhari narrates Muhammad describing his revelations as "sometimes it is (revealed) like the ringing of a bell". Aisha reported, "I saw the Prophet being inspired Divinely on a very cold day and noticed the sweat dropping from his forehead (as the Inspiration was over)". [83] According to Welch these descriptions may be considered genuine, since they are unlikely to have been forged by later Muslims. [15] Muhammad was confident that he could distinguish his own thoughts from these messages. [84] According to the Quran, one of the main roles of Muhammad is to warn the unbelievers of their eschatological punishment (Quran 38:70 , Quran 6:19 ). Occasionally the Quran did not explicitly refer to Judgment day but provided examples from the history of extinct communities and warns Muhammad's contemporaries of similar calamities (Quran 41:13–16 ). [20] Muhammad did not only warn those who rejected God's revelation, but also dispensed good news for those who abandoned evil, listening to the divine words and serving God. [85] Muhammad's mission also involves preaching monotheism: The Quran commands Muhammad to proclaim and praise the name of his Lord and instructs him not to worship idols or associate other deities with God. [20]
The key themes of the early Quranic verses included the responsibility of man towards his creator; the resurrection of the dead, God's final judgment followed by vivid descriptions of the tortures in Hell and pleasures in Paradise, and the signs of God in all aspects of life. Religious duties required of the believers at this time were few: belief in God, asking for forgiveness of sins, offering frequent prayers, assisting others particularly those in need, rejecting cheating and the love of wealth (considered to be significant in the commercial life of Mecca), being chaste and not killing newborn girls. [15]

Opposition
According to Muslim tradition, Muhammad's wife Khadija was the first to believe he was a prophet. [86] She was followed by Muhammad's ten-year-old cousin Ali ibn Abi Talib , close friend Abu Bakr , and adopted son Zaid . [86] Around 613, Muhammad began to preach to the public (Quran 26:214 ). [11] [87] Most Meccans ignored and mocked him, though a few became his followers. There were three main groups of early converts to Islam: younger brothers and sons of great merchants; people who had fallen out of the first rank in their tribe or failed to attain it; and the weak, mostly unprotected foreigners. [88]
According to Ibn Saad, opposition in Mecca started when Muhammad delivered verses that condemned idol worship and the polytheism practiced by the Meccan forefathers. [89] However, the Quranic exegesis maintains that it began as Muhammad started public preaching. [90] As his followers increased, Muhammad became a threat to the local tribes and rulers of the city, whose wealth rested upon the Ka'aba, the focal point of Meccan religious life that Muhammad threatened to overthrow. Muhammad's denunciation of the Meccan traditional religion was especially offensive to his own tribe, the Quraysh , as they were the guardians of the Ka'aba. [88] Powerful merchants attempted to convince Muhammad to abandon his preaching; he was offered admission to the inner circle of merchants, as well as an advantageous marriage. He refused both of these offers. [88]
Tradition records at great length the persecution and ill-treatment towards Muhammad and his followers. [15] Sumayyah bint Khabbab , a slave of a prominent Meccan leader Abu Jahl , is famous as the first martyr of Islam; killed with a spear by her master when she refused to give up her faith. Bilal , another Muslim slave, was tortured by Umayyah ibn Khalaf who placed a heavy rock on his chest to force his conversion. [91] [92]
In 615, some of Muhammad's followers emigrated to the Ethiopian Aksumite Empire and founded a small colony under the protection of the Christian Ethiopian emperor Aṣḥama ibn Abjar . [15] Ibn Sa'ad mentions two separate migrations. According to him, most of the Muslims returned to Mecca prior to Hijra , while a second group rejoined them in Medina. Ibn Hisham and Tabari , however, only talk about one migration to Ethiopia. These accounts agree that Meccan persecution played a major role in Muḥammad's decision to suggest that a number of his followers seek refuge among the Christians in Abyssinia. According to the famous letter of ʿUrwa preserved in al-Tabari, the majority of Muslims returned to their native town as Islam gained strength and high ranking Meccans, such as Umar and Hamzah converted. [ citation needed ]
However, there is a completely different story on the reason why the Muslims returned from Ethiopia to Mecca. According to this account – initially mentioned by Al-Waqidi then rehashed by Ibn Sa'ad and Tabari , but not by Ibn Hisham and not by Ibn Ishaq [93] – Muhammad, desperately hoping for an accommodation with his tribe, pronounced a verse acknowledging the existence of three Meccan goddesses considered to be the daughters of Allah. Muhammad retracted the verses the next day at the behest of Gabriel, claiming that the verses were whispered by the devil himself. Instead, a ridicule of these gods was offered. [94] [n 4] [n 5] This episode known as "The Story of the Cranes" (translation: قصة الغرانيق , transliteration : Qissat al Gharaneeq ) is also known as " Satanic Verses ". According to the story this led to a general reconciliation between Muḥammad and the Meccans, and the Abyssinia Muslims began to return home. When they arrived Gabriel had informed Muḥammad the two verses were not part of the revelation, but had been inserted by Satan. Notable scholars at the time argued against the historic authenticity of these verses and the story itself on various grounds. [95] [96] [n 6] Al-Waqidi was severely criticized by Islamic scholars such as Malik ibn Anas , al-Shafi’i , Ahmad ibn Hanbal , Al-Nasa’i , al-Bukhari , Abu Dawood , Al-Nawawi and others as a liar and forgerer. [97] [98] [99] [100] Later, the incident received some acceptance among certain groups, though strong objections to it continued onwards past the 10th century. The objections continued until rejection of these verses and the story itself eventually became the only acceptable orthodox Muslim position. [101]
In 617, the leaders of Makhzum and Banu Abd-Shams , two important Quraysh clans, declared a public boycott against Banu Hashim , their commercial rival, to pressure it into withdrawing its protection of Muhammad. The boycott lasted three years but eventually collapsed as it failed in its objective. [102] [103] During this, Muhammad was only able to preach during the holy pilgrimage months in which all hostilities between Arabs was suspended.

Isra and Mi'raj
Islamic tradition states that in 620, Muhammad experienced the Isra and Mi'raj , a miraculous night-long journey said to have occurred with the angel Gabriel . At the journey's beginning, the Isra , he is said to have travelled from Mecca on a winged steed ( Buraq ) to "the farthest mosque" (in Arabic: masjid al-aqsa ). Later, during the Mi'raj , Muhammad is said to have toured heaven and hell , and spoke with earlier prophets, such as Abraham , Moses , and Jesus . [105] Ibn Ishaq , author of the first biography of Muhammad , presents the event as a spiritual experience; later historians, such as Al-Tabari and Ibn Kathir , present it as a physical journey. [105]
Some western scholars [ who? ] hold that the Isra and Mi'raj journey traveled through the heavens from the sacred enclosure at Mecca to the celestial al-Baytu l-Maʿmur (heavenly prototype of the Kaaba); later traditions indicate Muhammad's journey as having been from Mecca to Jerusalem. [106] [ page needed ]

Last years in Mecca before Hijra
Muhammad's wife Khadijah and uncle Abu Talib both died in 619, the year thus being known as the " year of sorrow ". With the death of Abu Talib, leadership of the Banu Hashim clan passed to Abu Lahab, a tenacious enemy of Muhammad. Soon afterwards, Abu Lahab withdrew the clan's protection over Muhammad. This placed Muhammad in danger; the withdrawal of clan protection implied that blood revenge for his killing would not be exacted. Muhammad then visited Ta'if , another important city in Arabia, and tried to find a protector, but his effort failed and further brought him into physical danger. [15] [103] Muhammad was forced to return to Mecca. A Meccan man named Mut'im ibn Adi (and the protection of the tribe of Banu Nawfal ) made it possible for him to safely re-enter his native city. [15] [103]
Many people visited Mecca on business or as pilgrims to the Kaaba . Muhammad took this opportunity to look for a new home for himself and his followers. After several unsuccessful negotiations, he found hope with some men from Yathrib (later called Medina). [15] The Arab population of Yathrib were familiar with monotheism and were prepared for the appearance of a prophet because a Jewish community existed there. [15] They also hoped, by the means of Muhammad and the new faith, to gain supremacy over Mecca; the Yathrib were jealous of its importance as the place of pilgrimage. Converts to Islam came from nearly all Arab tribes in Medina; by June of the subsequent year, seventy-five Muslims came to Mecca for pilgrimage and to meet Muhammad. Meeting him secretly by night, the group made what is known as the " Second Pledge of al-`Aqaba ", or, in Orientalists' view, the " Pledge of War ". [108] Following the pledges at Aqabah, Muhammad encouraged his followers to emigrate to Yathrib . As with the migration to Abyssinia , the Quraysh attempted to stop the emigration. However, almost all Muslims managed to leave. [109]

Hijra
The Hijra is the migration of Muhammad and his followers from Mecca to Medina in 622 CE. In June 622, warned of a plot to assassinate him, Muhammad secretly slipped out of Mecca and moved his followers to Medina, [110] 450 kilometres (280 miles) north of Mecca. [111]

Migration to Medina
A delegation, consisting of the representatives of the twelve important clans of Medina, invited Muhammad to serve as chief arbitrator for the entire community; due to his status as a neutral outsider. [112] [113] There was fighting in Yathrib: primarily the dispute involved its Arab and Jewish inhabitants, and was estimated to have lasted for around a hundred years before 620. [112] The recurring slaughters and disagreements over the resulting claims, especially after the Battle of Bu'ath in which all clans were involved, made it obvious to them that the tribal concept of blood-feud and an eye for an eye were no longer workable unless there was one man with authority to adjudicate in disputed cases. [112] The delegation from Medina pledged themselves and their fellow-citizens to accept Muhammad into their community and physically protect him as one of themselves. [15]
Muhammad instructed his followers to emigrate to Medina, until nearly all his followers left Mecca. Being alarmed at the departure, according to tradition, the Meccans plotted to assassinate Muhammad. With the help of Ali , Muhammad fooled the Meccans watching him, and secretly slipped away from the town with Abu Bakr. [114] By 622, Muhammad emigrated to Medina, a large agricultural oasis . Those who migrated from Mecca along with Muhammad became known as muhajirun (emigrants). [15]

Establishment of a new polity
Among the first things Muhammad did to ease the longstanding grievances among the tribes of Medina was to draft a document known as the Constitution of Medina , "establishing a kind of alliance or federation" among the eight Medinan tribes and Muslim emigrants from Mecca; this specified rights and duties of all citizens, and the relationship of the different communities in Medina (including the Muslim community to other communities, specifically the Jews and other " Peoples of the Book "). [112] [113] The community defined in the Constitution of Medina, Ummah , had a religious outlook, also shaped by practical considerations and substantially preserved the legal forms of the old Arab tribes. [15]
Several ordinances were proclaimed to win over the numerous and wealthy Jewish population. These were soon rescinded as the Jews insisted on preserving the entire Mosaic law, and did not recognize him as a prophet because he was not of the race of David. [ citation needed ]
The first group of converts to Islam in Medina were the clans without great leaders; these clans had been subjugated by hostile leaders from outside. [115] This was followed by the general acceptance of Islam by the pagan population of Medina, with some exceptions. According to Ibn Ishaq , this was influenced by the conversion of Sa'd ibn Mu'adh (a prominent Medinan leader) to Islam. [116] Medinans who converted to Islam and helped the Muslim emigrants find shelter became known as the ansar (supporters). [15] Then Muhammad instituted brotherhood between the emigrants and the supporters and he chose Ali as his own brother. [117]

Beginning of armed conflict
Following the emigration, the people of Mecca seized property of Muslim emigrants to Medina. [118] Armed conflict would later break out between the Meccan pagans and the Muslims. Muhammad delivered Quranic verses permitting Muslims to fight the Meccans (see sura Al-Hajj , Quran 22:39–40 ). [119] According to the traditional account, on 11 February 624, while praying in the Masjid al-Qiblatayn in Medina, Muhammad received revelations from God that he should be facing Mecca rather than Jerusalem during prayer. Muhammad adjusted to the new direction, and his companions praying with him followed his lead, beginning the tradition of facing Mecca during prayer. [120]
In March 624, Muhammad led some three hundred warriors in a raid on a Meccan merchant caravan. The Muslims set an ambush for the caravan at Badr. [121] Aware of the plan, the Meccan caravan eluded the Muslims. A Meccan force was sent to protect the caravan, and went on to confront the Muslims upon receiving word that the caravan was safe. The Battle of Badr commenced. [122] Though outnumbered more than three to one, the Muslims won the battle, killing at least forty-five Meccans with fourteen Muslims dead. They also succeeded in killing many Meccan leaders, including Abu Jahl . [123] Seventy prisoners had been acquired, many of whom were ransomed in return for wealth or freed. [124] [125] [126] Muhammad and his followers saw the victory as confirmation of their faith [15] and Muhammad ascribed the victory as assisted from an invisible host of angels. The Quranic verses of this period, unlike the Meccan verses, dealt with practical problems of government and issues like the distribution of spoils. [127]
The victory strengthened Muhammad's position in Medina and dispelled earlier doubts among his followers. [128] As a result, the opposition to him became less vocal. Pagans who had not yet converted were very bitter about the advance of Islam. Two pagans, Asma bint Marwan of the Aws Manat tribe and Abu 'Afak of the 'Amr b. 'Awf tribe, had composed verses taunting and insulting the Muslims. [129] They were killed by people belonging to their own or related clans, and Muhammad did not disapprove of the killings. [129] This report however is considered by some to be a fabrication. [130] Most members of those tribes converted to Islam, and little pagan opposition remained. [131]
Muhammad expelled from Medina the Banu Qaynuqa , one of three main Jewish tribes, [15] but some historians contend that the expulsion happened after Muhammad's death. [132] According to al-Waqidi , after Abd-Allah ibn Ubaiy spoke for them, Muhammad refrained from executing them and commanded that they be exiled from Medina. [133] Following the Battle of Badr, Muhammad also made mutual-aid alliances with a number of Bedouin tribes to protect his community from attacks from the northern part of Hejaz . [15]

Conflict with Mecca
The Meccans were eager to avenge their defeat. To maintain economic prosperity, the Meccans needed to restore their prestige, which had been reduced at Badr. [135] In the ensuing months, the Meccans sent ambush parties to Medina while Muhammad led expeditions against tribes allied with Mecca and sent raiders onto a Meccan caravan. [136] Abu Sufyan gathered an army of three thousand men and set out for an attack on Medina. [137]
A scout alerted Muhammad of the Meccan army's presence and numbers a day later. The next morning, at the Muslim conference of war, dispute arose over how best to repel the Meccans. Muhammad and many senior figures suggested it would be safer to fight within Medina and take advantage of the heavily fortified strongholds. Younger Muslims argued that the Meccans were destroying crops, and huddling in the strongholds would destroy Muslim prestige. Muhammad eventually conceded to the younger Muslims and readied the Muslim force for battle. Muhammad led his force outside to the mountain of Uhud (the location of the Meccans camp) and fought the Battle of Uhud on 23 March 625. [138] [139] Although the Muslim army had the advantage in early encounters, lack of discipline on the part of strategically placed archers led to a Muslim defeat; 75 Muslims were killed including Hamza , Muhammad's uncle who became one of the best known martyrs in the Muslim tradition . The Meccans did not pursue the Muslims, instead they marched back to Mecca declaring victory. The announcement is probably because Muhammad was wounded and thought dead. When they discovered that Muhammad lived, the Meccans did not return due to false information about new forces coming to his aid. The attack had failed to achieve their aim of completely destroying the Muslims. [140] [141] The Muslims buried the dead, and returned to Medina that evening. Questions accumulated about the reasons for the loss; Muhammad delivered Quranic verses 3:152 indicating that the defeat was twofold: partly a punishment for disobedience, partly a test for steadfastness. [142]
Abu Sufyan directed his effort towards another attack on Medina. He gained support from the nomadic tribes to the north and east of Medina; using propaganda about Muhammad's weakness, promises of booty, memories of Quraysh prestige and through bribery. [143] Muhammad's new policy was to prevent alliances against him. Whenever alliances against Medina were formed, he sent out expeditions to break them up. [143] Muhammad heard of men massing with hostile intentions against Medina, and reacted in a severe manner. [144] One example is the assassination of Ka'b ibn al-Ashraf , a chieftain of the Jewish tribe of Banu Nadir . Al-Ashraf went to Mecca and wrote poems that roused the Meccans' grief, anger and desire for revenge after the Battle of Badr. [145] [146] Around a year later, Muhammad expelled the Banu Nadir from Medina [147] forcing their emigration to Syria; he allowed them to take some possessions, as he was unable to subdue the Banu Nadir in their strongholds. The rest of their property was claimed by Muhammad in the name of God as it was not gained with bloodshed. Muhammad surprised various Arab tribes, individually, with overwhelming force, causing his enemies to unite to annihilate him. Muhammad's attempts to prevent a confederation against him were unsuccessful, though he was able to increase his own forces and stopped many potential tribes from joining his enemies. [148]

Siege of Medina
With the help of the exiled Banu Nadir , the Quraysh military leader Abu Sufyan mustered a force of 10,000 men. Muhammad prepared a force of about 3,000 men and adopted a form of defense unknown in Arabia at that time; the Muslims dug a trench wherever Medina lay open to cavalry attack. The idea is credited to a Persian convert to Islam, Salman the Persian . The siege of Medina began on 31 March 627 and lasted two weeks. [149] Abu Sufyan's troops were unprepared for the fortifications, and after an ineffectual siege, the coalition decided to return home. [150] The Quran discusses this battle in sura Al-Ahzab, in verses 33:9–27 . [90] During the battle, the Jewish tribe of Banu Qurayza , located to the south of Medina, entered into negotiations with Meccan forces to revolt against Muhammad. Although the Meccan forces were swayed by suggestions that Muhammad was sure to be overwhelmed, they desired reassurance in case the confederacy was unable to destroy him. No agreement was reached after prolonged negotiations, partly due to sabotage attempts by Muhammad's scouts. [151] After the coalition's retreat, the Muslims accused the Banu Qurayza of treachery and besieged them in their forts for 25 days. The Banu Qurayza eventually surrendered; according to Ibn Ishaq , all the men apart from a few converts to Islam were beheaded, while the women and children were enslaved. [152] [153] Walid N. Arafat and Barakat Ahmad have disputed the accuracy of Ibn Ishaq's narrative. [154] Arafat believes that Ibn Ishaq's Jewish sources, speaking over 100 years after the event, conflated this account with memories of earlier massacres in Jewish history; he notes that Ibn Ishaq was considered an unreliable historian by his contemporary Malik ibn Anas , and a transmitter of "odd tales" by the later Ibn Hajar . [155] Ahmad argues that only some of the tribe was killed, while some of the fighters were merely enslaved. [156] [157] Watt finds Arafat's arguments "not entirely convincing", while Meir J. Kister has contradicted [ clarification needed ] the arguments of Arafat and Ahmad. [158]
In the siege of Medina, the Meccans exerted the available strength to destroy the Muslim community. The failure resulted in a significant loss of prestige; their trade with Syria vanished. [159] Following the Battle of the Trench, Muhammad made two expeditions to the north, both ended without any fighting. [15] While returning from one of these journeys (or some years earlier according to other early accounts), an accusation of adultery was made against Aisha , Muhammad's wife. Aisha was exonerated from accusations when Muhammad announced he had received a revelation confirming Aisha's innocence and directing that charges of adultery be supported by four eyewitnesses (sura 24, An-Nur ). [160]

Truce of Hudaybiyyah
Although Muhammad had delivered Quranic verses commanding the Hajj , [162] the Muslims had not performed it due to Quraysh enmity. In the month of Shawwal 628, Muhammad ordered his followers to obtain sacrificial animals and to prepare for a pilgrimage ( umrah ) to Mecca, saying that God had promised him the fulfillment of this goal in a vision when he was shaving his head after completion of the Hajj. [163] Upon hearing of the approaching 1,400 Muslims, the Quraysh dispatched 200 cavalry to halt them. Muhammad evaded them by taking a more difficult route, enabling his followers to reach al-Hudaybiyya just outside Mecca. [164] According to Watt, although Muhammad's decision to make the pilgrimage was based on his dream, he was also demonstrating to the pagan Meccans that Islam did not threaten the prestige of the sanctuaries, that Islam was an Arabian religion. [164]
Negotiations commenced with emissaries travelling to and from Mecca. While these continued, rumors spread that one of the Muslim negotiators, Uthman bin al-Affan , had been killed by the Quraysh. Muhammad called upon the pilgrims to make a pledge not to flee (or to stick with Muhammad, whatever decision he made) if the situation descended into war with Mecca. This pledge became known as the "Pledge of Acceptance" ( Arabic : بيعة الرضوان , bay'at al-ridhwān ‎‎) or the " Pledge under the Tree ". News of Uthman's safety allowed for negotiations to continue, and a treaty scheduled to last ten years was eventually signed between the Muslims and Quraysh. [164] [165] The main points of the treaty included: cessation of hostilities, the deferral of Muhammad's pilgrimage to the following year, and agreement to send back any Meccan who emigrated to Medina without permission from their protector. [164]
Many Muslims were not satisfied with the treaty. However, the Quranic sura " Al-Fath " (The Victory) (Quran 48:1–29 ) assured them that the expedition must be considered a victorious one. [166] It was later that Muhammad's followers realized the benefit behind the treaty. These benefits included the requirement of the Meccans to identify Muhammad as an equal, cessation of military activity allowing Medina to gain strength, and the admiration of Meccans who were impressed by the pilgrimage rituals. [15]
After signing the truce, Muhammad assembled an expedition against the Jewish oasis of Khaybar , known as the Battle of Khaybar . This was possibly due to housing the Banu Nadir who were inciting hostilities against Muhammad, or to regain prestige from what appeared as the inconclusive result of the truce of Hudaybiyya. [137] [167] According to Muslim tradition, Muhammad also sent letters to many rulers, asking them to convert to Islam (the exact date is given variously in the sources). [15] [168] [169] He sent messengers (with letters) to Heraclius of the Byzantine Empire (the eastern Roman Empire), Khosrau of Persia , the chief of Yemen and to some others. [168] [169] In the years following the truce of Hudaybiyya, Muhammad directed his forces against the Arabs on Transjordanian Byzantine soil in the Battle of Mu'tah . [170]

Final years

Conquest of Mecca
The truce of Hudaybiyyah was enforced for two years. [171] [172] The tribe of Banu Khuza'a had good relations with Muhammad, whereas their enemies, the Banu Bakr , had allied with the Meccans. [171] [172] A clan of the Bakr made a night raid against the Khuza'a, killing a few of them. [171] [172] The Meccans helped the Banu Bakr with weapons and, according to some sources, a few Meccans also took part in the fighting. [171] After this event, Muhammad sent a message to Mecca with three conditions, asking them to accept one of them. These were: either the Meccans would pay blood money for the slain among the Khuza'ah tribe, they disavow themselves of the Banu Bakr, or they should declare the truce of Hudaybiyyah null. [173]
The Meccans replied that they accepted the last condition. [173] Soon they realized their mistake and sent Abu Sufyan to renew the Hudaybiyyah treaty, a request that was declined by Muhammad.
Muhammad began to prepare for a campaign. [174] In 630, Muhammad marched on Mecca with 10,000 Muslim converts. With minimal casualties, Muhammad seized control of Mecca. [175] He declared an amnesty for past offences, except for ten men and women who were "guilty of murder or other offences or had sparked off the war and disrupted the peace". [176] Some of these were later pardoned. [177] Most Meccans converted to Islam and Muhammad proceeded to destroy all the statues of Arabian gods in and around the Kaaba. [178] [179] According to reports collected by Ibn Ishaq and al-Azraqi , Muhammad personally spared paintings or frescos of Mary and Jesus, but other traditions suggest that all pictures were erased. [180] The Quran discusses the conquest of Mecca. [90] [181]

Conquest of Arabia
Following the conquest of Mecca, Muhammad was alarmed by a military threat from the confederate tribes of Hawazin who were raising an army twice Muhammad's size. The Banu Hawazin were old enemies of the Meccans. They were joined by the Banu Thaqif (inhabiting the city of Ta'if) who adopted an anti-Meccan policy due to the decline of the prestige of Meccans. [182] Muhammad defeated the Hawazin and Thaqif tribes in the Battle of Hunayn . [15]
In the same year, Muhammad organized an attack against northern Arabia because of their previous defeat at the Battle of Mu'tah and reports of hostility adopted against Muslims. With great difficulty he assembled thirty thousand men; half of whom on the second day returned with Abd-Allah ibn Ubayy , untroubled by the damning verses which Muhammad hurled at them. Although Muhammad did not engage with hostile forces at Tabuk, he received the submission of some local chiefs of the region. [15] [183]
He also ordered destruction of any remaining pagan idols in Eastern Arabia. The last city to hold out against the Muslims in Western Arabia was Taif . Muhammad refused to accept the city's surrender until they agreed to convert to Islam and allowed men to destroy the statue of their goddess Allat . [184] [185] [186]
A year after the Battle of Tabuk, the Banu Thaqif sent emissaries to surrender to Muhammad and adopt Islam. Many bedouins submitted to Muhammad to safeguard against his attacks and to benefit from the spoils of war. [15] However, the bedouins were alien to the system of Islam and wanted to maintain independence: namely their code of virtue and ancestral traditions. Muhammad required a military and political agreement according to which they "acknowledge the suzerainty of Medina, to refrain from attack on the Muslims and their allies, and to pay the Zakat , the Muslim religious levy." [187]

Farewell pilgrimage
In 632, at the end of the tenth year after migration to Medina, Muhammad completed his first true Islamic pilgrimage, setting precedence for the annual Great Pilgrimage, known as Hajj . [15] On the 9th of Dhu al-Hijjah Muhammad delivered his Farewell Sermon , at Mount Arafat east of Mecca. In this sermon, Muhammad advised his followers not to follow certain pre-Islamic customs. For instance, he said a white has no superiority over a black, nor a black has any superiority over a white except by piety and good action. [188] He abolished old blood feuds and disputes based on the former tribal system and asked for old pledges to be returned as implications of the creation of the new Islamic community. Commenting on the vulnerability of women in his society, Muhammad asked his male followers to "be good to women, for they are powerless captives ( awan ) in your households. You took them in God's trust, and legitimated your sexual relations with the Word of God, so come to your senses people, and hear my words ..." He told them that they were entitled to discipline their wives but should do so with kindness. He addressed the issue of inheritance by forbidding false claims of paternity or of a client relationship to the deceased, and forbade his followers to leave their wealth to a testamentary heir. He also upheld the sacredness of four lunar months in each year. [189] [190] According to Sunni tafsir , the following Quranic verse was delivered during this event: "Today I have perfected your religion, and completed my favours for you and chosen Islam as a religion for you" (Quran 5:3 ). [15] According to Shia tafsir, it refers to the appointment of Ali ibn Abi Talib at the pond of Khumm as Muhammad's successor , this occurring a few days later when Muslims were returning from Mecca to Medina. [191]

Death and tomb
A few months after the farewell pilgrimage, Muhammad fell ill and suffered for several days with fever, head pain, and weakness. He died on Monday, 8 June 632, in Medina, at the age of 62 or 63, in the house of his wife Aisha. [192] With his head resting on Aisha's lap, he asked her to dispose of his last worldly goods (seven coins), then spoke his final words:
Ar-Rafiq Al-A'la may be referring to God. [196] He was buried where he died in Aisha's house. [15] [197] [198] During the reign of the Umayyad caliph al-Walid I , al-Masjid an-Nabawi (the Mosque of the Prophet) was expanded to include the site of Muhammad's tomb. [199] The Green Dome above the tomb was built by the Mamluk sultan Al Mansur Qalawun in the 13th century, although the green color was added in the 16th century, under the reign of Ottoman sultan Suleiman the Magnificent . [200] Among tombs adjacent to that of Muhammad are those of his companions ( Sahabah ), the first two Muslim caliphs Abu Bakr and Umar , and an empty one that Muslims believe awaits Jesus . [198] [201] [202] When bin Saud took Medina in 1805, Muhammad's tomb was stripped of its gold and jewel ornaments. [203] Adherents to Wahhabism , bin Sauds' followers destroyed nearly every tomb dome in Medina in order to prevent their veneration, [203] and the one of Muhammad is said to have narrowly escaped. [204] Similar events took place in 1925 when the Saudi militias retook—and this time managed to keep—the city. [205] [206] [207] In the Wahhabi interpretation of Islam, burial is to take place in unmarked graves. [204] Although frowned upon by the Saudis, many pilgrims continue to practice a ziyarat —a ritual visit—to the tomb. [208] [209]

After Muhammad
Muhammad united several of the tribes of Arabia into a single Arab Muslim religious polity in the last years of his life. With Muhammad's death, disagreement broke out over who his successor would be. [17] Umar ibn al-Khattab , a prominent companion of Muhammad, nominated Abu Bakr , Muhammad's friend and collaborator. With additional support Abu Bakr was confirmed as the first caliph . This choice was disputed by some of Muhammad's companions, who held that Ali ibn Abi Talib, his cousin and son-in-law, had been designated the successor by Muhammad at Ghadir Khumm . Abu Bakr immediately moved to strike against the Byzantine (or Eastern Roman Empire ) forces because of the previous defeat, although he first had to put down a rebellion by Arab tribes in an event that Muslim historians later referred to as the Ridda wars , or "Wars of Apostasy". [210]
The pre-Islamic Middle East was dominated by the Byzantine and Sassanian empires. The Roman-Persian Wars between the two had devastated the region, making the empires unpopular amongst local tribes. Furthermore, in the lands that would be conquered by Muslims many Christians ( Nestorians , Monophysites , Jacobites and Copts ) were disaffected from the Eastern Orthodox Church which deemed them heretics. Within a decade Muslims conquered Mesopotamia , Byzantine Syria , Byzantine Egypt , [211] large parts of Persia , and established the Rashidun Caliphate .

Early social changes under Islam
According to William Montgomery Watt religion, for Muhammad, was not a private and individual matter but "the total response of his personality to the total situation in which he found himself. He was responding [not only]... to the religious and intellectual aspects of the situation but also to the economic, social, and political pressures to which contemporary Mecca was subject." [212] Bernard Lewis says there are two important political traditions in Islam – Muhammad as a statesman in Medina, and Muhammad as a rebel in Mecca. His view believed Islam as a great change, akin to a revolution, when introduced to new societies. [213]
Historians generally agree that Islamic social changes in areas such as social security , family structure, slavery and the rights of women and children improved on the status quo of Arab society. [213] [214] For example, according to Lewis, Islam "from the first denounced aristocratic privilege, rejected hierarchy, and adopted a formula of the career open to the talents". [ which? ] [213] Muhammad's message transformed society and moral orders of life in the Arabian Peninsula; society focused on the changes to perceived identity, world view , and the hierarchy of values. [215] [ page needed ] Economic reforms addressed the plight of the poor, which was becoming an issue in pre-Islamic Mecca. [216] The Quran requires payment of an alms tax ( zakat ) for the benefit of the poor; as Muhammad's power grew he demanded that tribes who wished to ally with him implement the zakat in particular. [217] [218]

Appearance
The description given in Muhammad al-Bukhari 's book Sahih al-Bukhari , in Chapter 61, Hadith 57 & Hadith 60, [219] [220] is depicted by two of his companions as:
The description given in Muhammad ibn Isa at-Tirmidhi 's book Shama'il al-Mustafa , attributed to Ali ibn Abi Talib and Hind ibn Abi Hala is as follows: [221] [222] [223]
The "seal of prophecy" between Muhammad's shoulders is generally described as having been a type of raised mole the size of a pigeon's egg. [222] Another description of Muhammad was provided by Umm Ma'bad, a woman he met on his journey to Medina: [224] [225]
Descriptions like these were often reproduced in calligraphic panels ( hilya or, in Turkish, hilye ), which in the 17th century developed into an art form of their own in the Ottoman Empire . [224]

Household
Muhammad's life is traditionally defined into two periods: pre-hijra (emigration) in Mecca (from 570 to 622), and post-hijra in Medina (from 622 until 632). Muhammad is said to have had thirteen wives in total (although two have ambiguous accounts, Rayhana bint Zayd and Maria al-Qibtiyya , as wife or concubine. [226] [227] ) Eleven of the thirteen marriages occurred after the migration to Medina .
At the age of 25, Muhammad married the wealthy Khadijah bint Khuwaylid who was 40 years old. [228] The marriage lasted for 25 years and was a happy one. [229] Muhammad did not enter into marriage with another woman during this marriage. [230] [231] After Khadija's death, Khawla bint Hakim suggested to Muhammad that he should marry Sawda bint Zama , a Muslim widow, or Aisha , daughter of Um Ruman and Abu Bakr of Mecca . Muhammad is said to have asked for arrangements to marry both. [160] Muhammad's marriages after the death of Khajida were contracted mostly for political or humanitarian reasons. The women were either widows of Muslims killed in battle and had been left without a protector, or belonged to important families or clans whom it was necessary to honor and strengthen alliances with. [232]
According to traditional sources Aisha was six or seven years old when betrothed to Muhammad, [160] [233] [234] with the marriage not being consummated until she had reached puberty at the age of nine or ten years old. [160] [233] [235] [236] [237] [238] [239] [240] [241] She was therefore a virgin at marriage. [233] Muslim authors who calculate Aisha's age based on other sources of information, such that available about her sister Asma about whom more is known, estimate that she was over thirteen and perhaps in her late teens at the time of her marriage. [242] [243] [244] [245] [246]
After migration to Medina, Muhammad (now in his fifties) married several more women.
Muhammad did household chores and helped with housework such as preparing food, sewing clothes, and repairing shoes. He is also said to have had accustomed his wives to dialogue; he listened to their advice, and the wives debated and even argued with him. [247] [248] [249]
Khadijah is said to have had four daughters with Muhammad ( Ruqayyah bint Muhammad , Umm Kulthum bint Muhammad , Zainab bint Muhammad , Fatimah Zahra ) and two sons ( Abd-Allah ibn Muhammad and Qasim ibn Muhammad , who both died in childhood). All but one of his daughters, Fatimah, died before him. [250] Some Shi'a scholars contend that Fatimah was Muhammad's only daughter. [251] Maria al-Qibtiyya bore him a son named Ibrahim ibn Muhammad , but the child died when he was two years old. [250]
Nine of Muhammad's wives survived him. [227] Aisha, who became known as Muhammad's favourite wife in Sunni tradition, survived him by decades and was instrumental in helping assemble the scattered sayings of Muhammad that form the Hadith literature for the Sunni branch of Islam. [160]
Muhammad's descendants through Fatimah are known as sharifs , syeds or sayyids . These are honorific titles in Arabic , sharif meaning 'noble' and sayed or sayyid meaning 'lord' or 'sir'. As Muhammad's only descendants, they are respected by both Sunni and Shi'a, though the Shi'a place much more emphasis and value on their distinction. [252]
Zayd ibn Harith was a slave that Muhammad bought, freed, and then adopted as his son. He also had a wetnurse . [253] According to a BBC summary, "the Prophet Muhammad did not try to abolish slavery, and bought, sold, captured, and owned slaves himself. But he insisted that slave owners treat their slaves well and stressed the virtue of freeing slaves. Muhammad treated slaves as human beings and clearly held some in the highest esteem". [254]

Legacy

Muslim views
Following the attestation to the oneness of God , the belief in Muhammad's prophethood is the main aspect of the Islamic faith . Every Muslim proclaims in Shahadah that "I testify that there is no god but God, and I testify that Muhammad is a Messenger of God". The Shahadah is the basic creed or tenet of Islam . Islamic belief is that ideally the Shahadah is the first words a newborn will hear; children are taught it immediately and it will be recited upon death. Muslims repeat the shahadah in the call to prayer ( adhan ) and the prayer itself. Non-Muslims wishing to convert to Islam are required to recite the creed. [255]
In Islamic belief, Muhammad is regarded as the last prophet sent by God [256] [257] [258] [259] [260] for the benefit of mankind. Quran 10:37 states that "...it (the Quran) is a confirmation of (revelations) that went before it, and a fuller explanation of the Book – wherein there is no doubt – from The Lord of the Worlds .". Similarly Quran 46:12 states "...And before this was the book of Moses, as a guide and a mercy. And this Book confirms (it)...", while 2:136 commands the believers of Islam to "Say: we believe in God and that which is revealed unto us, and that which was revealed unto Abraham and Ishmael and Isaac and Jacob and the tribes, and that which Moses and Jesus received, and which the prophets received from their Lord. We make no distinction between any of them, and unto Him we have surrendered."
Muslim tradition credits Muhammad with several miracles or supernatural events . [261] For example, many Muslim commentators and some Western scholars have interpreted the Surah 54:1–2 as referring to Muhammad splitting the Moon in view of the Quraysh when they began persecuting his followers. [262] [263] Western historian of Islam Denis Gril believes the Quran does not overtly describe Muhammad performing miracles , and the supreme miracle of Muhammad is identified with the Quran itself . [262]
According to Islamic tradition, Muhammad was attacked by the people of Ta'if and was badly injured. The tradition also describes an angel appearing to him and offering retribution against the assailants. It is said that Muhammad rejected the offer and prayed for the guidance of the people of Ta'if. [264]
The Sunnah represents actions and sayings of Muhammad (preserved in reports known as Hadith ), and covers a broad array of activities and beliefs ranging from religious rituals, personal hygiene, burial of the dead to the mystical questions involving the love between humans and God. The Sunnah is considered a model of emulation for pious Muslims and has to a great degree influenced the Muslim culture. The greeting that Muhammad taught Muslims to offer each other, "may peace be upon you" (Arabic: as-salamu `alaykum ) is used by Muslims throughout the world. Many details of major Islamic rituals such as daily prayers, the fasting and the annual pilgrimage are only found in the Sunnah and not the Quran. [265]
The Sunnah contributed much to the development of Islamic law, particularly from the end of the first Islamic century. [267] Muslim mystics, known as sufis , who were seeking for the inner meaning of the Quran and the inner nature of Muhammad, viewed the prophet of Islam not only as a prophet but also as a perfect human-being. All Sufi orders trace their chain of spiritual descent back to Muhammad. [268]
Muslims have traditionally expressed love and veneration for Muhammad. Stories of Muhammad's life, his intercession and of his miracles (particularly " Splitting of the moon ") have permeated popular Muslim thought and poetry . Among Arabic odes to Muhammad, Qasidat al-Burda ("Poem of the Mantle") by the Egyptian Sufi al-Busiri (1211–1294) is particularly well known, and widely held to possess a healing, spiritual power. [269] The Quran refers to Muhammad as "a mercy ( rahmat ) to the worlds" (Quran 21:107 ). [15] The association of rain with mercy in Oriental countries has led to imagining Muhammad as a rain cloud dispensing blessings and stretching over lands, reviving the dead hearts, just as rain revives the seemingly dead earth (see, for example, the Sindhi poem of Shah ʿAbd al-Latif). [15] Muhammad's birthday is celebrated as a major feast throughout the Islamic world , excluding Wahhabi -dominated Saudi Arabia where these public celebrations are discouraged. [270] When Muslims say or write the name of Muhammad, they usually follow it with Peace be upon him (Arabic: sallAllahu `alayhi wa sallam ). [271] In casual writing, this is sometimes abbreviated as PBUH or SAW; in printed matter, a small calligraphic rendition is commonly used (ﷺ).

 Islamic depictions
In line with the hadith prohibition against creating images of sentient living beings , which is particularly strictly observed with respect to God and Muhammad, Islamic religious art is focused on the word. [272] [273] Muslims generally avoid depictions of Muhammad , and mosques are decorated with calligraphy and Quranic inscriptions or geometrical designs, not images or sculptures. [272] [274] Today, the interdiction against images of Muhammad – designed to prevent worship of Muhammad, rather than God – is much more strictly observed in Sunni Islam (85%–90% of Muslims) and Ahmadiyya Islam (1%) than among Shias (10%–15%). [275] While both Sunnis and Shias have created images of Muhammad in the past, [276] Islamic depictions of Muhammad are rare. [272] They have, until recently [ when? ] , mostly been limited to the private and elite medium of the miniature, and since about 1500 most depictions show Muhammad with his face veiled, or symbolically represent him as a flame. [274] [277]
The earliest extant depictions come from 13th century Anatolian Seljuk and Ilkhanid Persian miniatures , typically in literary genres describing the life and deeds of Muhammad. [277] [278] During the Ilkhanid period, when Persia's Mongol rulers converted to Islam, competing Sunni and Shi'a groups used visual imagery, including images of Muhammad, to promote their particular interpretation of Islam's key events. [279] Influenced by the Buddhist tradition of representational religious art predating the Mongol elite's conversion, this innovation was unprecedented in the Islamic world, and accompanied by a "broader shift in Islamic artistic culture away from abstraction toward representation" in "mosques, on tapestries, silks, ceramics, and in glass and metalwork" besides books. [280] In the Persian lands, this tradition of realistic depictions lasted through the Timurid dynasty until the Safavids took power in the early 16th century. [279] The Safavaids, who made Shi'i Islam the state religion, initiated a departure from the traditional Ilkhanid and Timurid artistic style by covering Muhammad's face with a veil to obscure his features and at the same time represent his luminous essence. [281] Concomitantly, some of the unveiled images from earlier periods were defaced. [279] [282] [283] Later images were produced in Ottoman Turkey and elsewhere, but mosques were never decorated with images of Muhammad. [276] Illustrated accounts of the night journey ( mi'raj ) were particularly popular from the Ilkhanid period through the Safavid era. [284] During the 19th century, Iran saw a boom of printed and illustrated mi'raj books, with Muhammad's face veiled, aimed in particular at illiterates and children in the manner of graphic novels . Reproduced through lithography , these were essentially "printed manuscripts". [284] Today, millions of historical reproductions and modern images are available in some Muslim countries, especially Turkey and Iran, on posters, postcards, and even in coffee-table books, but are unknown in most other parts of the Islamic world, and when encountered by Muslims from other countries, they can cause considerable consternation and offense. [276] [277]

Medieval Christian views
The earliest documented Christian knowledge of Muhammad stems from Byzantine sources. They indicate that both Jews and Christians saw Muhammad as a false prophet . [285] Another Greek source for Muhammad is Theophanes the Confessor , a 9th-century writer. The earliest Syriac source is the 7th-century writer John bar Penkaye . [286]
According to Hossein Nasr , the earliest European literature often refers to Muhammad unfavorably. A few learned circles of Middle Ages Europe – primarily Latin-literate scholars – had access to fairly extensive biographical material about Muhammad. They interpreted the biography through a Christian religious filter; one that viewed Muhammad as a person who seduced the Saracens into his submission under religious guise. [15] Popular European literature of the time portrayed Muhammad as though he were worshipped by Muslims, similar to an idol or a heathen god. [15]
In later ages, Muhammad came to be seen as a schismatic: Brunetto Latini 's 13th century Li livres dou tresor represents him as a former monk and cardinal, [15] and Dante's Divine Comedy ( Inferno , Canto 28), written in the early 1300s, puts Muhammad and his son-in-law, Ali, in Hell "among the sowers of discord and the schismatics, being lacerated by devils again and again." [15]

Emergence of positive views in Europe
After the Reformation , Muhammad was often portrayed in a similar way. [15] [287] Guillaume Postel was among the first to present a more positive view of Muhammad. [15] Gottfried Leibniz praised Muhammad because "he did not deviate from the natural religion". [15] Henri de Boulainvilliers , in his Vie de Mahomed which was published posthumously in 1730, described Muhammad as a gifted political leader and a just lawmaker. [15] He presents him as a divinely inspired messenger whom God employed to confound the bickering Oriental Christians, to liberate the Orient from the despotic rule of the Romans and Persians , and to spread the knowledge of the unity of God from India to Spain. Voltaire had both a positive and negative opinion on Muhammad: in his play Le fanatisme, ou Mahomet le Prophète he vilifies Muhammad as a symbol of fanaticism, and in a published essay in 1748 he calls him "a sublime and hearty charlatan", but in his historical survey Essai sur les mœurs , he presents him as legislator and a conqueror and calls him an "enthusiast", not an imposter. Jean-Jacques Rousseau , in his Social Contract (1762), brushing aside hostile legends of Muhammad as a trickster and impostor, presents him as a sage legislator who wisely fused religious and political powers. Emmanuel Pastoret published in 1787 his Zoroaster, Confucius and Muhammad , in which he presents the lives of these three "great men", "the greatest legislators of the universe", and compares their careers as religious reformers and lawgivers. He rejects the common view that Muhammad is an impostor and argues that the Quran proffers "the most sublime truths of cult and morals"; it defines the unity of God with an "admirable concision." Pastoret writes that the common accusations of his immorality are unfounded: on the contrary, his law enjoins sobriety, generosity, and compassion on his followers: the "legislator of Arabia" was "a great man." [288] Napoleon Bonaparte admired Muhammad and Islam, [289] and described him as a model lawmaker and a great man. [290] [291] Thomas Carlyle in his book Heroes and Hero Worship and the Heroic in History (1840) describes Muhammad as "[a] silent great soul; [...] one of those who cannot but be in earnest". [292] Carlyle's interpretation has been widely cited by Muslim scholars as a demonstration that Western scholarship validates Muhammad's status as a great man in history. [293]

Views by modern historians
According to William Montgomery Watt and Richard Bell, recent writers generally dismiss the idea that Muhammad deliberately deceived his followers, arguing that Muhammad "was absolutely sincere and acted in complete good faith" [294] and Muhammad's readiness to endure hardship for his cause, with what seemed to be no rational basis for hope, shows his sincerity. [295] Watt says that sincerity does not directly imply correctness: In contemporary terms, Muhammad might have mistaken his subconscious for divine revelation. [296] Watt and Bernard Lewis argue that viewing Muhammad as a self-seeking impostor makes it impossible to understand Islam's development. [297] [298] Alford T. Welch holds that Muhammad was able to be so influential and successful because of his firm belief in his vocation. [15]

Other religious views
Bahá'ís venerate Muhammad as one of a number of prophets or " Manifestations of God ". He is thought to be the final manifestation, or seal of the Adamic cycle , but consider his teachings to have been superseded by those of Bahá'u'lláh , the founder of the Bahai faith, and the first of Manifestation of the current cycle. [299] [300]

Criticism
As early as the 7th century Muhammad was attacked by non-Muslim Arab contemporaries for preaching monotheism . In modern times, criticism has also dealt with Muhammad's sincerity in claiming to be a prophet , his morality, warfare, and his marriages .

Praise and veneration
Praise and veneration of Muhammad have been expressed throughout the life of Muhammad, where from an early age, he was referred to as al-Amin (faithful, trustworthy) and as-Sadiq (truthful). [301] Muslim scholars, thinkers, mystics and other religious scholars have expressed praise and veneration of Muhammad throughout history and it remains an integral part of the Islamic tradition. [302] [303] Topics of the praise and veneration of Muhammad include the personality, character, teachings, morality, conduct, actions, and way of life. [304]

See also

Notes
WebPage index: 00057
New York Public Library for the Performing Arts
The New York Public Library for the Performing Arts, Dorothy and Lewis B. Cullman Center , at 40 Lincoln Center Plaza, is located in Manhattan , New York City , at the Lincoln Center for the Performing Arts on the Upper West Side , between the Metropolitan Opera House and the Vivian Beaumont Theater . It houses one of the world's largest collections of materials relating to the performing arts. [1] [2] [3] It is one of the four research centers of the New York Public Library 's Research library system, and it is also one of the branch libraries.

History

Founding and original configuration
Originally the collections that formed The New York Public Library for the Performing Arts (hereafter LPA) were housed in two buildings. The Research collections on Dance, Music, and Theatre were located at the New York Public Library Main Branch , now named the Stephen A. Schwarzman Building, and the circulating music collection was located in the 58th Street Library.
A separate center to house performing arts was first proposed by Carleton Sprague Smith (chief of the Music Division) in a 1932 report to the library administration, "A Worthy Music Center for New York." [4] (At the time, dance materials and sound recordings were all part of the Music Division.) There were attempts to create partnerships with Rockefeller Center (under construction at the time), the Museum of Modern Art , and the Metropolitan Museum of Art (to which New York University wanted to join as a partner). During the late 1930s and early 1940s, the Music Division produced a program of concerts (based on the model of the Library of Congress concerts in Coolidge Auditorium ). These concerts were often held in conjunction with the Metropolitan Museum of Art and Juilliard School , and the program grew to include Lectures from New York University staff.
After Lincoln Center was incorporated in 1956, an early mention of a possible "library and museum of the performing arts" appeared in June 1957. [5] It was envisioned that a library-museum would serve to "interpret and illuminate the entire range of the performing arts." [6] By December of that year, the library had become an accepted component of Lincoln Center planning and fundraising. [7] Recalling his earlier reports, Smith produced a new report arguing for a move to Lincoln Center. Library administration officially approved of the move in June 1959. [8]
The building housing the library's research collections and the Vivian Beaumont Theater was the third building to be opened at Lincoln Center. [9] Original plans conceived the library as a separate building, but prohibitive costs necessitated a combination of the Library and the Theater. As built, the Theater forms the central core of the building, the 1st and 2nd floors occupying the southern and western sides, and the 3rd floor research collections providing a roof. Noted modernist architect Gordon Bunshaft , of the firm of Skidmore, Owings and Merrill (SOM) designed the interiors, and SOM consulted with Eero Saarinen and Associates (architect for the Vivian Beaumont Theater) on the exteriors. [10] The Claire Tow Theater (belonging to Lincoln Center Theater) was built on the roof of the Library and opened in June 2012.
The third floor, housing the research collections, opened to the public on July 19. [10] The entire library was opened to the public on November 30, 1965, the 4th building to open at Lincoln Center. [11] At its opening, it was called "Library and Museum of the Performing Arts." The Library's museum component was named the Shelby Collum Davis Museum in honor of an investment banker who contributed $1 million to Lincoln Center for museum purposes. [11]
At its opening, the Library's main lobby at the Lincoln Center Plaza entrance housed a bookstore, a film viewing area, and a listening area. The second floor included a children's performing arts collection as well as the Hecksher Oval, an enclosed space that could accommodate story-telling. Prior to the 2001 renovation, the children's collection was relocated to the Riverside Branch. The Hecksher Oval was removed as part of the renovation.
The Shelby Collum Davis Museum spaces included small and separate areas in the Dance, Music, Sound archive and Theater research divisions. Bigger galleries were the Vincent Astor Gallery on the 2nd floor, and galleries on the lower level and 2nd floor.

2001 renovation
From 1998 through 2001, the building was closed due to a $38 million renovation project designed by Polshek Partnership . (The renovation was unrelated to the Lincoln Center renovations which commenced shortly after 2001.) During this time, the research collections were serviced from the NYPL's Annex (at 10th avenue and 43rd street), and the circulating collections were housed at the Mid-Manhattan Library at 40th Street and Fifth Avenue. LPA reopened to the public on October 29, 2001 with its building newly named Dorothy and Lewis B. Cullman Center after a gift from the Cullmans (Dorothy was a trustee until she died; Lewis is still a trustee). [12]
During the renovation, the library was wired to enable installation of numerous computers on each floor. There are nearly 200 publicly accessible computers in the building. [13] Most are restricted to use of the library catalog and electronic databases or viewing the library's audiovisual material, but a few provide full Internet use. The renovation also created a Technology Training Room, with twelve desktop computers for users and one for a teacher, as well as a projection screen.
Upon the building's original opening in 1965, each research division had a separate reading room. The renovation removed these and consolidated public areas into a single unified public reading area, with separate rooms for the Theater on Film and Tape Archive (its screening room named for Lucille Lortel ) and Special Collections (its room named for Katharine Cornell and Guthrie McClintic ). Subsequently the Special Collections reading room was moved into a portion of the main reading area of the 3rd floor, while a screening room for the Reserve Film and Video Collection (originally part of the Donnell Media Center , but absorbed into the Collection in 2008) took its place. Meanwhile, gallery space for the museum was consolidated into two main gallery spaces with smaller areas for display of other items. The Donald and Mary Oenslager Gallery is located on the first floor, adjacent to the Lincoln Plaza entrance, while the Vincent Astor Gallery (formerly on the second floor) is now located on the lower level, adjacent to the Amsterdam Avenue entrance. A small area near the Lincoln Center Plaza entrance houses caricaturist Al Hirschfield 's desk and chair. The main corridor on the first floor is used for displaying photographs, posters, and other two-dimensional items. The third floor has numerous display cases highlighting rotating displays of thematic groupings of artifacts from the collections.
The renovation was not without detractors. Critic Joseph Horowitz criticized the third floor in particular. Where previously each division had its own reading room, the renovation united all public reading areas into one room, resulting in less intimacy and more noise. [14] Edmund Morris characterized the Special Collections reading room as "a charmless space...[which] exudes a dispirited air of neglect." [15]

Research collections
From its inception, LPA has had both a research component (funded mostly with private money) and a branch library component (funded with significant money from New York City, the remainder coming from private contributions).

Materials and formats
In addition to published works (for example, books, periodicals, and scores), the research divisions collect an enormous amount of unique material: Archival material (material that was created by or that once belonged to an individual or organization), text manuscripts , music manuscripts , typescripts, prompt books , posters , original set and costume designs , programs , and other ephemera are just some of the major categories of materials. The library's collection of sound recordings is in all formats that in themselves trace the history and development of sound recording.
The library has 500 thousand folders containing clippings on a variety of people and subjects pertaining to the performing arts. These clippings can sometimes provide a beginning to those at the initial stage of their research. The library also collects a variety of iconography in various forms: photographs , lithographs , engravings , drawings , and others. A recent internal report estimated that LPA holds approximately 4.5 million photographs, including the recently acquired collection of New York photographer Martha Swope, itself holding 1 million photographs.
Much of this non-book material was not initially in the online catalog. [16] Some materials are accessible through in-house card files and indexes. Policy since changed to bring as much of the material as possible into the main catalog,and by 2013, most of it was accessible in the catalog. Because of the enormous volume of material, some classes of it, such as the clipping files, has never been inventoried, although it is arranged in a retrievable manner with an alphabetical or chronological arrangement. Unlike most U.S. public libraries, the research collections stacks are located in non-public areas and are not available for browsing. Patrons must determine what they want to view, fill out call slips, and submit the slips to library staff. Library staff then retrieves the material for the patron.
The holdings of LPA are divided by subject into divisions, which contain a number of special centers.

Music Division
The Music Division, as a founding division of The New York Public Library, is the oldest of all the divisions at LPA. Its origins stem from the private library of banker Joseph William Drexel . Upon his death in 1888, his valuable library of 5,542 volumes and 766 pamphlets, known as the Drexel Collection , became part of the Lenox Library. The Astor Library also had an endowment that helped with the purchase of music. In 1895, upon the Lenox Library's consolidation with the Astor Library, the Music Division became one of the first subject divisions of The New York Public Library. [17] [18]
According to The New Grove Dictionary of Jazz , the library has particular strong manuscript holdings in jazz , These include 400 of Benny Goodman 's arrangements, and the arrangements made by Sy Oliver for musicians including Duke Ellington , Jimmie Lunceford , and Tommy Dorsey . It holds working scores of works by Ellington, and by Charles Mingus as well as extensive microlim copies of Mingus' manuscripts. [19]
Classical music manuscript holding include manuscripts by Bach, Johannes Brahms , Franz Liszt , Glinka , Handel, Haydn, Korngold Mozart, Paganini , Schubert and Schumann  ; [20]

Billy Rose Theatre Division
The Library has been collecting theatrical materials for years prior to 1931, when the executors of David Belasco 's estate offered the producer's holdings on the condition that a division be created. The Theatre Collection (as it was initially known) began on September 1, 1931. The division opened at Lincoln Center as the Theatre Collection. In 1979, it was renamed the Billy Rose Theatre Division, honoring a financial gift from the lyricist/producer's foundation. It is now the largest research division at the library, with holdings primarily on the theatre, and increasing on film, with some collections on the related subjects of vaudeville, magic, puppetry, and the circus. The Theater of Film and Tape Archive is administratively within the division.

Jerome Robbins Dance Division
The Jerome Robbins Dance Division began in 1944 under the auspices of Genevieve Oswald. [21] Originally dance materials were part of the Music Division (when it was known as the "Dance Collection"), but its growth necessitated hiring a full-time staff member in 1947. [22] Acquisitions were augmented by gifts of papers of Ted Shawn and Ruth St. Denis , Doris Humphrey , Charles Weidman , and Hanya Holm . With the gift of a collection of Walter Toscanini in honor of his deceased wife, Cia Fornaroli (a dancer), the Dance Collection became an internationally known repository. [22] Due to its subsequent growth and increasing importance, the collection was formally recognized as a separate division on January 1, 1964. [23]
One of the division's most significant resources is the Jerome Robbins Archive of the Recorded Moving Image. Endowed with a gift from Jerome Robbins, this archive collects and preserves moving images of dance, making them available to researchers. The Archive has received many gifts from dancers and choreographers and contains many privately made films and video. [24]
The Division's oral history program began formally in 1965. These oral histories are particularly valuable since they provide information, history and context not generally available in published sources. [25]

Reserve Film and Video
Though not technically a part of the Research divisions, the Reserve Film and Video Collection (formerly the Donnell Media Center) is serviced from the third floor. For film and video that must be viewed onsite, there is a screening room (large enough for classes) equipped with a 16 mm projector. There are also moviolas and Steenbeck equipment, permitting close frame-by-frame examination and analysis.

Rodgers and Hammerstein Archives of Recorded Sound
The origins of the Rodgers and Hammerstein Archives of Recorded Sound can be traced to a gift of 500 78 rpm records by Columbia Records in 1937 to the Music Division. Successive gifts by record companies and individuals led to the formal creation of a separate division with the opening of the building at Lincoln Center in 1965. It was named in honor of a generous gift from the Rodgers and Hammerstein organization. [26] Radio station WQXR donated 11,000 78 rpm recordings in 1966. [27] Carleton Sprague Smith envisioned the purpose of the sound archive as "stimulating interest among recording and broadcasting executives, as well as other arts institutions that had potential for playing a cooperative role." [28] Resources include the Rigler-Deutsch Index , which lists of library's extensive holdings of 78 rpm records.

Theatre on Film and Tape Archive
The Theatre on Film and Tape Archive (TOFT) produces video recordings of New York and regional theater productions, and provides research access at its Lucille Lortel screening room. The core of the collection consists of live recordings of Broadway and Off-Broadway productions, with some additional productions from professional regional theaters. The Archive also records interviews and dialogues with notable theater professionals. In addition to live performances, commercial recordings of theater-related films, documentaries, and television programs are also included in the collection. Currently between 50 - 60 live recordings are produced each year, covering most important productions. As of the 2013 annual report, the collection included 7,469 titles, a total of 20,000 items [29]
The archive was established in 1970 by Betty L. Corwin, who served as its director until her retirement in 2000. Corwin and the archive were subsequently awarded a Special Tony Award for "Excellence in the Theatre" at the 55th Annual Tony Awards . [30] In 2001 Patrick Hoffman became TOFT Director.
The collection maintains contracts with all theatrical unions and guilds, thus enabling clearances for the non-commercial videotaping of live theater. The collection is housed on the third floor of the Library for the Performing Arts. The recordings may be viewed by anyone with a professional or research interest, but may not be reproduced. Users consist of theater professionals, students, scholars, journalists, critics, and other researchers. The majority of the collection is cataloged online and searchable by visiting the NYPL website, www.nypl.org.
The collection is considered one of the most comprehensive collections of videotaped theater productions in the world. [31] Archives modeled on TOFT include the Museum of Performance & Design in San Francisco , the Washington Area Performing Arts Video Archive established in Washington, D.C. , and the National Video Archive of Performance in London .

Branch (Circulating) Collections
The beginnings of the circulating music collection are due in great part to its first head librarian, Dorothy Lawton. [32] Lawton took part in the establishment of the music collection at the 58th Street Library in 1920, beginning with a collection of 1,000 books and scores. In 1924 the circulating music collection was officially established as part of the 58th Street Library. [33] Her passion for dance enabled her to get unusual publications, so much that dance critic John Martin complimented her on the growing collection of dance books. [34]
In 1929, the 58th Street Library began a collection of recordings beginning with gifts from Victor and Columbia records, amounting to 500 records. Upon building a listening booth, Lawton reported that by 1933, the listening booth was constantly booked two weeks in advance. [35]
During World War II , she established a concert series for servicemen on Sundays from 3–7 PM. Servicemen could request selections of their choice and could also participate in playing chamber music with instruments that had been loaned to the Library. She established the Orchestra Collection, a set of scores and parts that could be loaned to groups for performance. Currently, the Orchestra Collection loans parts to over 2,000 works. [36]
Upon Lawton's retirement in 1945, chief music critic of the New York Times Olin Downes complimented her on the development of the 58th Street Library, and remarked on her achievements such as attracting donors and enlisting the concern and help of professional musicians. [37] (Many of the rare items that were gifts to the 58th Street Branch were subsequently moved to the Music Division.)
After retiring, Lawton returned to the country of her birth, England, and help organize a newly created music collection at Central Music Library of the Buckingham Palace Road Library (today the Westminster Music Library ), modeling the new library on the one she established at 58th Street. [32] [38] [39]
Currently, the Circulating collections loan books on music, dance, theater, film, and arts administration. They also loan scores, scripts, CDs, videotapes, DVDs, and sets of orchestral parts.

Shelby Collum Davis Museum
The museum component of LPA takes the form of exhibitions in its two main exhibition spaces, The Donald and Mary Oenslager Gallery and the Vincent Astor Gallery, as well as a walled area in the plaza entrance, and additionally display cases distributed throughout the building. Among the purposes of the exhibitions is to show to all visitors that the millions of items belonging to the library are not for the exclusive use of scholars but for anyone who walks in the door. [40] Exhibitions highlights items from the library's collections and keep the name of the library before the public, attracting new and potential donations. [41]
Since the late 1990s, NYPL's exhibitions program has added online exhibitions. Online exhibitions serve as an extension of physical exhibitions, adding more material or allowing a greater depth of exploration.

Public programs
Public programs are free of charge and take place in the 202-seat Bruno Walter Auditorium located on the lower level. The auditorium is used several times a week for musical performances, film screenings and lectures. [42]
WebPage index: 00058
List of pornographic actresses by decade
This is a list of notable pornographic actresses listed by the decade in which they made their debut .
This listing is subordered alphabetically by first name .

1950s

1970s

1980s

1990s

2000s

2010s
WebPage index: 00059
Counterproductive work behavior
Counterproductive work behavior ( CWB ) is employee behavior that goes against the legitimate interests of an organization. [1] These behaviors can harm organizations or people in organizations including employees and clients, customers, or patients. It has been proposed that a person-by-environment interaction can be utilized to explain a variety of counterproductive behaviors. [2] For instance, an employee who is high on trait anger (tendency to experience anger) is more likely to respond to a stressful incident at work (being treated rudely by a supervisor) with CWB.
Some researchers use the CWB term to subsume related constructs that are distinct. Workplace deviance is behavior at work that violates norms for appropriate behavior. [3] Retaliation consists of harmful behaviors done by employees to get back at someone who has treated them unfairly. [4] Workplace revenge are behaviors by employees intended to hurt another person who has done something harmful to them. [5] Workplace aggression consists of harmful acts that harm others in organizations. [6]

Dimensional models
Several typologies of CWB exist.
Using the term deviance (behavior that violates accepted norms), [7] Robinson and Bennett created a four-class typology of CWBs divided the CWBs into the following dimensions: [3]
A five dimension typology of CWB [8]
An 11 dimension typology of CWB [9]
A two-dimensional model of CWBs distinguished by organizational versus person target has gained considerable acceptance. [10] [11] Additional dimensions have been proposed for research purposes, including a legal v. illegal dimension, a hostile v. instrumental aggression dimension, and a task-related v. a non-task-related dimension. [12] CWBs that violate criminal law may have different antecedents than milder forms of CWBs. Similarly, instrumental aggression (i.e., aggression with a deliberate goal in mind) may have different antecedents than those CWBs caused by anger.

Dimensions

Absenteeism
Absenteeism is typically measured by time lost (number of days absent) measures and frequency (number of absence episodes) measures. It is weakly linked to affective predictors such as job satisfaction and commitment. Absences fit into two types of categories. Excused absences are those due to personal or family illness; unexcused absences include an employee who does not come to work in order to do another preferred activity or neglects to call in to a supervisor. Absence can be linked to job dissatisfaction. Major determinants of employee absence are employee affect, demographic characteristics, organizational absence culture, and organization absence policies. Absence due to non-work obligations is related to external features of a job with respect to dissatisfaction with role conflict, role ambiguity, and feelings of tension. Absences due to stress and illness are related to internal and external features of the job, fatigue and gender. Research has found that women are more likely to be absent than men, and that the absence-control policies and culture of an organization will predict absenteeism.

Abuse against others
Physical acts of aggression by members of an organization, committed in organizational settings are considered as workplace violence . While most researchers examine overall workplace aggression, there is a line of research that separates workplace aggression according to its targets, whether interpersonal or organizational. [13] In this model of workplace aggression, trait anger and interpersonal conflict have been found to be significant predictors of interpersonal aggression, while interpersonal conflict, situational constraints, and organizational constraints have been found to be predictors of organizational aggression. Other factors significantly linked to aggression are sex and trait anger, with men and individuals with higher levels of trait anger showing more aggressive behaviors.

Bullying
Workplace bullying consists of progressive and systematic mistreatment of one employee by another. [14] It may include verbal abuse , gossiping , social exclusion , or the spreading of rumors . [14] The terms 'bullying' and ' mobbing ' are sometimes used interchangeably, but 'bullying' is more often used to refer to lower levels of antisocial behavior that do not include workgroup participation. [15] The costs of bullying include losses in productivity , higher absenteeism, higher turnover rates, and legal fees when the victims of bullying sue the organization. [16] Reported incidence of bullying is ambiguous with rates being reported from under 3% to over 37% depending on the method used to gather incidence statistics. [14] [15] The strongest factor predicting bullying behavior seems to be exposure to incidents of bullying. [14] This suggests that bullying is a cascading problem that needs to be curtailed in its earliest stages. In addition to exposure to incidents of bullying, being male also seems to increase the likelihood that one will engage in bullying behavior. [14] It is proposed that the human resources function can provide guidance in the mitigation of bullying behavior by taking an active role in identifying and stopping the behaviors. [17]

Cyber loafing
Cyber loafing can be defined as surfing the web in any form of non-job- related tasks performed by the employee. [18] Cyber loafing has emerged as more and more people use computers at work. One survey showed that 64% of US workers use the internet for personal tasks at work. [19] It has been suggested that cyber-loafing is responsible for a 30–40% decrease in employee productivity [20] and was estimated to have cost US business $5.3 billion in 1999. [21]

Incivility
Workplace incivility is disrespectful and rude behavior in violation of workplace norms for respect." [22] The effects of incivility include increased competitiveness, increases in sadistic behavior, and inattentiveness. [22] A study of cyber incivility showed that higher levels of incivility are associated with lower job satisfaction, lower organizational commitment, and higher turnover rates. [23] Two factors that seem to be associated with becoming a victim of incivility are low levels of agreeableness and high levels of neuroticism . [24] Affective Events Theory suggests that individuals who experience more incidents of incivility may be more sensitive to these behaviors and therefore more likely to report them. [24]

Lateness
Lateness is described as arriving at work later or leaving earlier than required. Problems associated with lateness include compromised organizational efficiency. [25] Tardy and late employees responsible for critical tasks can negatively affect organizational production. [26] Other workers may experience psychological effects of the tardy employee including morale and motivational problems as they attempt to "pick up the slack." [27] Other employees may begin to imitate the example set by the behavior of tardy employees. Lateness costs US business more than $3 billion annually. [28]

Production deviance
Production deviance is ineffective job performance that is done on purpose, such as doing tasks incorrectly or withholding of effort. Such behaviors can be seen in disciplinary actions and safety violations.

Sabotage
Employee sabotage are behaviors that can "damage or disrupt the organization's production, damaging property, the destruction of relationships, or the harming of employees or customers." [29] Research has shown that often acts of sabotage or acts of retaliation are motivated by perceptions of organizational injustice [30] and performed with the intention of causing harm to the target. [31]

Service
Service sabotage originated from counter-productive behavior literature. Lloyd C. Harris and Emmanuel Ogbonna from Cardiff University, UK drew from employee deviance and dysfunctional behaviors studies to conceptualize service sabotage as a disturbing phenomenon in the work place.Service sabotage refer to organizational member behaviors that are intentionally designed negatively to affect service. Empirical evidence suggested that more than 90% employees accept that service sabotage is an everyday occurrence in their organization. [32]

Sexual harassment
Sexual harassment is defined as "unwelcome sexual advances, requests for sexual favors, and other verbal or physical contact when (a) submission to the conduct by the employee is either explicitly or implicitly a term or condition of an individual's employment, (b) submission to or rejection of such conduct by an individual is used as a basis for employment decisions affecting the individual and/or (c) such conduct [that] has the purpose or effect of unreasonably interfering with work performance, or creating an intimidating, hostile or offensive working environment." ( Equal Employment Opportunity Commission , 1980)

Substance abuse
Substance abuse by employees at work is a problem that can have an effect on work attendance, performance, and safety and can lead to other injuries outside of work and health problems.

Theft
Employee theft is defined as employees taking things not belonging to them from an organization. Employee theft is estimated to account for billions of dollars of loss globally each year, [33] with employees accounting for more theft than customers. [34] This may include large embezzlements or the pilfering of pencils and paperclips, but the losses in the aggregate are substantial. At least one study suggests that 45% of companies experience financial fraud, with average losses of $1.7 million. [35] Factors such as Conscientiousness have been shown to be negatively related to theft behaviors. [36] Many organizations use integrity tests during the initial screening process for new employees in an effort to eliminate those considered most likely to commit theft. [37] Causes of employee theft include characteristics of the individual and environmental conditions such as frustrating and unfair working conditions.

Turnover
Turnover is when employees leave the organization, either voluntarily (quitting) or involuntarily (being fired or laid off). Research on voluntary employee job turnover has attempted to understand the causes of individual decisions to leave an organization. It has been found that lower performance, lack of reward contingencies for performance, and better external job opportunities are the main causes. Other variables related to turnover are conditions in the external job market and the availability of other job opportunities, [38] and length of employee tenure. Turnover can be optimal as when a poorly performing employee decides to leave an organization, or dysfunctional when the high turnover rates increase the costs associated with recruitment and training of new employees, or if good employees consistently decide to leave. Avoidable turnover is when the organization could have prevented it and unavoidable turnover is when the employee's decision to leave could not be prevented.

Withdrawal
Employee withdrawal consists of behaviors such as absence, lateness, and ultimately job turnover. Absence and lateness has attracted research as they disrupt organizational production, deliveries and services. Unsatisfied employees withdraw in order to avoid work tasks or pain, and remove themselves from their jobs. [39] Withdrawal behavior may be explained as employee retaliation against inequity in the work setting. [40] Withdrawal may also be part of a progressive model and relate to job dissatisfaction, job involvement, and organizational commitment. [41]

Notable behavior exclusions
CWBs are "active and volitional acts engaged in by individuals, as opposed to accidental or unintentional actions." [42] CWBs, therefore do not include acts that lack volition, such as the inability to successfully complete a task. Nor do CWBs include involvement in an accident, although purposeful avoidance of the safety rules that may have led to the accident would represent a CWB.
The U.S. Department of Health and Human Services (2002) estimates the cost of accidents to organizations to be $145 million annually. Most research on this topic has attempted to evaluate characteristics of the workplace environment that lead to accidents and determination of ways to avoid accidents. There has also been some research on the characteristics of accident-prone employees that has found they are typically younger, more distractible, and less socially adjusted than other employees. Recent research has shown that an organization's safety climate has been associated with lower accident involvement, compliance with safety procedures, and increased proactive safety behaviors.
Another set of behaviors that do not fit easily into the accepted definition of CWBs, are those described as unethical pro-organizational behaviors (UPBs). UPBs represent illegitimate means intended to further the legitimate interests of an organization. [43] UPBs are not necessarily intended to harm the organization, although the UPBs may result in adverse consequences to the organization, such as a loss of trust and goodwill, or in criminal charges against the organization. [43] In law enforcement, UPBs are exhibited in a form of misconduct called Noble Cause Corruption . [44] Noble Cause Corruption occurs when a police officer violates the law or ethical rules in order to reduce crime or the fear of crime. An example of Noble Cause Corruption is testilying , [45] in which a police officer commits perjury to obtain the conviction of a supposed criminal. UPBs have not received the same attention from researchers that CWBs have received. [43]

Organizational citizenship behavior
Counterproductive work behavior and organizational citizenship behavior (OCB), which consists of behaviors that help organizations but go beyond required tasks, have been studied together and are generally found to be related in that individuals who do one are unlikely to do the other. [46]

Current research topics and trends
By definition, counterproductive work behaviors are voluntary acts that are detrimental to an organization. [9] They have important implications for the well-being of an organization. [47] Theft alone is estimated to cause worldwide losses in the billions of dollars each year. [33] These estimated losses do not include losses from other sources, nor do they consider the fact that many losses attributable to CWBs go undetected. [48]
The consequences of CWBs and their persistence in the workplace [49] have led to increased attention being given to the study of such behaviors. [50] Current trends in industrial organizational psychology suggest a continuing increase in the study of CWBs. [47] [51] Research into CWBs appears to fall into three broad categories: (1) classification of CWBs; [1] [9] (2) predicting counterproductive behaviors; [52] [53] [54] and (3) furthering the theoretical framework of CWBs. [47] [55] [56] [57]
A review of peer reviewed journals following this article shows the broad interest in CWBs. A brief list of noted journals includes The International Journal of Selection and Assessment , The Journal of Applied Psychology , Computers in Human Behavior , Personality and Individual Differences, Occupational Health Psychology , Human Resource Management Review , Military Justice, Criminal Justice Ethics, European Journal of Work and Organizational Psychology , and International Journal of Nursing Studies . The variety of journals reporting in the area of CWBs reflects the breadth of the topic and the global interest in studying these behaviors.
Researchers use many sources in attempting to measure CWBs. These include potentially subjective measures such as self-reports, peer reports, and supervisor reports. [58] More objective methods for assessing CWBs include disciplinary records, absentee records, and job performance statistics. [59] Each of these methods present potential problems in the measurement of CWBs. For example, self-reports always have the potential for bias with individuals trying to cast themselves in a good light. [59] Self-reports may also cause problems for researchers when they measure what an incumbent 'can-do' and what an incumbent 'will-do.' [60] Peer and supervisor reports can suffer from personal bias, but they also suffer from lack of knowledge of the private behaviors of the job incumbent whose behavior is being studied. [1] Archival records suffer from lack of information about the private behaviors of incumbents, providing instead information about instances where incumbents are caught engaging in CWBs. Some researchers have proposed a differential detection hypothesis which predicts that there will be discrepancies between reports of detected CWBs and other reports of CWBs. [61]
The lack of accurate measures for CWBs jeopardizes the ability of researchers to find the relationships between CWB and other factors they are evaluating. [61] The primary criticism of research in CWBs has been that too much of the research relies on a single-source method of measurement relying primarily on self-reports of counterproductive work behavior. [58] [61] [62] Several studies have therefore attempted to compare self-reports with other forms of evidence about CWBs. These studies seek to determine whether different forms of evidence converge, or effectively measure the same behaviors. [62] Convergence has been established between self-reports and peer and supervisor reports for interpersonal CWBs but not organizational CWBs. [59] [61] This finding is significant because it promotes the ability of researchers to use multiple sources of evidence in evaluating CWBs. [59]

Correlates, predictors, moderators and mediators

Affect
Affect or emotion at work, especially the experience of negative emotions like anger or anxiety, predict the likelihood of counterproductive work behaviors occurring. [8] Affective personality traits, the tendency for individuals to experience emotions, can also predict CWB. For example, employees with high negative affectivity , the tendency to experience negative emotions, typically display more counterproductive work behaviors than those with positive affectivity , the tendency to experience positive emotions. [63]

Age
Age appears to be an important factor in predicting CWBs. While age does not appear to be strongly related to core task performance, creativity, or performance in training, it does appear to be positively related to organizational citizenship behaviors and negatively related to CWBs. [64] Older employees seem to exhibit less aggression, tardiness, substance abuse, and voluntary absenteeism (although sickness related absenteeism is somewhat higher than younger employees). Some researchers argue that the lower rate of CWBs may be due to better self-regulation and self-control.

Cognitive ability
Research into the relationship between cognitive ability and CWBs is contradictory. When CWBs are operationalized as disciplinary records of detected CWBs, a strong negative relationship between cognitive ability has been found. [65] This relationship did not hold, however, when cognitive ability was operationalized as educational attainment. [65] A longitudinal study of adolescents through young adulthood found that, among those individuals who exhibited conduct disorders as youths, high levels of cognitive ability were associated with higher levels of CWBs, a positive relationship. [53] Other research has found that general mental ability is largely unrelated to self-reports of CWBs including theft (although a weak link to incidents of lateness was detected). [61] In the same study, grade point average showed a stronger relationship to CWBs. [61] Contradictions in the findings may be explained in the differential effects between measures of cognitive ability and self-reported versus detected incidents of CWBs.

Emotional intelligence
Emotional intelligence (EI) has been defined as the ability to identify and manage emotional information in oneself and others and focus energy on required behaviors. [66] The factors making up EI include: [52]
To the extent that EI includes the ability to manage emotions, it can be expected that it will have an influence on CWBs similar to that found for self-control. Research in this area is limited, however, one study looking for the moderating effects of EI on the relationships between distributive justice, procedural justice, and interactional justice failed to find a significant moderating effect in any of these relationships. [52]

Interpersonal conflict
Interpersonal conflict in the workplace can also lead to counterproductive work behaviors. [67] Interpersonal conflict with the supervisor can lead to counterproductive work behaviors such as defiance, undermining , and colluding with coworkers to engage in deviant behavior. [68] Interpersonal conflict with peers can lead to counterproductive work behaviors such as harassment, bullying, and physical altercations. [9] [69]

Organizational constraints
Organizational constraints, the extent to which conditions at work interfere with job tasks, has been shown to relate to CWB so that jobs with high constraints have employees who engage in CWB. [70] Not only do constraints lead to CWB, but CWB can lead to constraints. Employees who engage in CWB can find that constraints increase over time. [71]

Organizational justice
Organizational justice or fairness perceptions have been shown to influence the display of counterproductive work behaviors. [72] Distributive justice, procedural justice, and interactional justice have all been shown to include both counterproductive work behaviors aimed at individuals, such as political deviance and personal aggression; and counterproductive work behaviors aimed at the organization, such as production slowdown and property deviance. [73]
Overall perceptions of unfairness may particularly elicit interpersonal counterproductive work behaviors such as political deviance and personal aggressions. Interpersonal justice and informational justice may also predict counterproductive work behaviors aimed at the supervisor, such as neglecting to follow supervisory instructions, acting rudely toward one's supervisor, spreading unconfirmed rumors about a supervisor, intentionally doing something to get one's supervisor in trouble, and encouraging coworkers to get back at one's supervisor. [68]

Personality
Personality is a predictor of an employee's proclivity toward counterproductive work behaviors. With regard to the Big Five personality traits : conscientiousness , agreeableness , extroversion and openness to experience all predict counterproductive behaviors. When an employee is low in conscientiousness, counterproductive work behaviors related to the organization are more likely to occur. [69] [74] Employees who are low in agreeableness will exhibit counterproductive work behaviors related to interpersonal deviant behaviors. [69] [74] Furthermore, in terms of greater specificity, for employees low in conscientiousness, sabotage and withdrawal are more likely to occur. For employees low in extraversion, theft is likely to occur. Finally, for employees high in openness to experience, production deviance is likely to occur. [75]

Narcissisism
Employees with narcissistic personalities tend to exhibit more counterproductive work behaviors, especially when the workplace is stressful. [76]

Psychopathy
Boddy suggests that because of abusive supervision by corporate psychopaths , large amounts of anti-corporate feeling will be generated among the employees of the organisations that corporate psychopaths work in. This should result in high levels of counterproductive behaviour as employees give vent to their anger with the corporation, which they perceive to be acting through its corporate psychopathic managers in a way that is eminently unfair to them. [77]
According to a 2017 UK study, a high ranking corporate psychopath could trigger lower ranked staff to become workplace bullies as a manifestation of counterproductive work behavior. [78] [79]

Self-control
Self-control has been evaluated as a significant explanation of CWBs. Like, conscientiousness, self-control, or internal control, is seen as a stable individual difference that tends to inhibit deviant behaviors. [80] The identification of self-control as a factor in deviant behaviors flows from work in criminology, where self-control is seen as the strength of one's ability to avoid short-term gain for long-term costs. [80] Using multiple regression analysis, one study compared the effects of 25 characteristics (including self-control, justicial factors, equity factors, positive affect, levels of autonomy, and a variety of other individual characteristics) on CWBs. The study showed that self-control was the best predictor of CWBs and that most of the other factors had negligible predictive value. [57] Cognitive ability and age were among the remaining factors that showed some effect. These additional findings are consistent with research that tends to show older employees exercise a greater level of self-control. [64]

Target personality
One line of research in CWBs looks not at the instigators of CWBs, but the victims' provocative target behavior, or the behaviors of the victims of CWBs, which are seen as potential mediating factors in the frequency and intensity of CWBs originated against them. [24] This line of research suggests that low levels of Agreeableness and Conscientiousness, and high levels of Neuroticism, in the victims of CWBs may lead to more incidents of CWBs, like incivility. Affective Events Theory has been used to explain that some individuals report being the victim of incivility more often because they are more sensitive to it than other workers.

Peer reporting
Normative behavior within organizations tends to discourage workers from reporting the observed CWBs of their peers, although this tendency can be reduced when a group is punished for the CWBs of individual members. [81] There are three factors that seem to be most influential on peer reporting of CWBs: the emotional closeness between the person exhibiting the CWBs and the person observing the CWBs; the severity of the misconduct observed, and the presence of witness. [81] Peers are more likely to report the CWBs of colleagues when the conduct is severe, or when there are other witnesses present, and less likely to report CWBs when they are emotionally close to the person committing the CWBs. A key problem in the use of peer reports of CWBs instead of self-reports of CWBs is that peer reports only capture observed behaviors and are not able to identify CWBs committed secretly. [1]

Managing strategies
A substantial body of research has demonstrated that stable characteristics of individuals are associated with the likelihood of CWBs. Some examples of stable characteristics that have been demonstrated to have relationships with CWBs include Conscientiousness and Agreeability, [35] motivation avoidance, [56] cognitive ability, [65] and self-control. [57] To the extent that these stable conditions predict CWBs, reduction of CWBs in an organization can begin at the recruitment and selection phase of new employees.
Integrity screening is one common form of screening used by organizations [82] as is cognitive ability screening. [65] Personality testing is also common in screening out individuals who may have a higher incidence of CWBs. [36] Work samples have been found to be a more effective screening tool than integrity testing alone, but integrity testing and cognitive testing together are even better screening tools. [80] While the use of screening instruments may be an imperfect decision-making tool, the question often facing the recruitment officer is not whether the instrument is perfect, but whether, relative to other available screening tools, the screening tool is functional. [48]
However, organizations must do more than screen employees in order to successfully manage CWBs. Substantial research has demonstrated that CWBs arise out of situational factors that occur in the day-to-day operations of an organization, including organizational constraints, [83] lack of rewards, [42] illegitimate tasks, [84] interpersonal conflicts, [83] and lack of organizational justice. [59] Research has shown that individuals who are treated unfairly are more likely to engage in CWBs. [52] One major step that organizations can take to reduce the impetus for CWBs is therefore to enhance organizational justice. [85] Maintaining communications and feedback, allowing participation of employees, and supervisory training are other suggestions for mitigating CWBs. [86] Organizations must also pay close attention to employees for signs and sources of interpersonal conflicts so that they can be identified and tended to as necessary. [24] [87]
Combating CWBs comes with some costs, including the costs of selection, monitoring, and implementing preventive measures to reduce triggers for CWBs. Before undertaking costly measures to reduce CWBs, it may be worthwhile for an organization to identify the costs of CWBs. [50] If the cost-benefit analysis does not show a savings, then the organization must decide whether the battle against CWBs is worth fighting. As part of this consideration, the organization should be aware that at least one set of researchers suggest that production deviance (withholding effort) and withdrawal can be a benefit to employees by allowing them to relieve tension in certain circumstances. [88]

Information technology
The increasing use of the Internet in the workplace is making it easier for workers to steal time and engage in counter productive work behavior. Stealing from the workplace can be through the unauthorized use of a work computer or network. The aforementioned type of theft is known as time and resource theft. As social media and gaming sites become more popular, time and resources theft does as well. Companies may use sniffers to monitor their network. Sniffers monitor network traffic, evaluate network capacity, and can be used to reveal evidence of improper use. Some companies go further than sniffers and use software which allows companies to block and monitor websites that they deem undesirable.

See also
WebPage index: 00060
9/11 conspiracy theories
9/11 conspiracy theories are conspiracy theories that attribute the planning and execution of the September 11 attacks against the United States to parties other than, or in addition to, al-Qaeda [1] including that there was advance knowledge of the attacks among high-level government officials. Government investigations and independent reviews have found no evidence for the theories. [2] [3] Proponents of these theories claim there are inconsistencies in the official conclusions, or evidence that was either ignored or overlooked. [4]
The most prominent conspiracy theory is that the collapse of the Twin Towers and 7 World Trade Center were the result of a controlled demolition rather than structural failure due to impact and fire. [5] [6] Another prominent belief is that the Pentagon was hit by a missile launched by elements from inside the U.S. government [7] [8] or that a commercial airliner was allowed to do so via an effective stand-down of the American military. Possible motives claimed by conspiracy theorists for such actions include justifying the invasions of Afghanistan and Iraq (even though the U.S. government concluded Iraq was not involved in the attacks) [9] to advance their geostrategic interests, such as plans to construct a natural gas pipeline through Afghanistan . [10] Other conspiracy theories revolve around authorities having advance knowledge of the attacks and deliberately ignoring or assisting the attackers. [4] [11] [12]
The National Institute of Standards and Technology (NIST) and the technology magazine Popular Mechanics have investigated and rejected the claims made by 9/11 conspiracy theorists. [13] [14] The civil engineering community accepts that the impacts of jet aircraft at high speeds in combination with subsequent fires, not controlled demolition, led to the collapse of the Twin Towers. [15] [16] This also was the conclusion of the 9/11 Commission , chaired by Governor Thomas Kean .

Background
9/11 conspiracy theorists reject some or all of the following official facts about the 9/11 attacks:
This consensus view is backed by various sources, including:

History
Since the attacks, a variety of conspiracy theories have been put forward in Web sites, books, and films. Many groups and individuals advocating 9/11 conspiracy theories identify as part of the 9/11 Truth movement . [31] [32] [33] Within six hours of the attack, a suggestion appeared on an Internet chat room suggesting that the collapse of the towers looked like an act of controlled demolition. "If, in a few days, not one official has mentioned anything about the controlled demolition part," the author wrote, "I think we have a REALLY serious problem." [34] The first theories that emerged focused primarily on various perceived anomalies in the publicly available evidence, and proponents later developed more specific theories about an alleged plot. [10] One false allegation that was widely circulated by e-mail and on the Web is that not a single Jew had been killed in the attack and that therefore the attacks must have been the work of the Mossad , not Islamic terrorists. [10]
The first elaborated theories appeared in Europe. One week after the attacks, the "inside job" theory was the subject of a thesis by a researcher from the French National Centre for Scientific Research published in Le Monde . Other theories sprang from the far corners of the globe within weeks. [35] Six months after the attacks, Thierry Meyssan 's piece on 9/11, L'Effroyable Imposture , topped the French bestseller list. Its publication in English (as 9/11: The Big Lie ) received little attention, but it remains one of the principal sources for "trutherism". [36] 2003 saw the publication of The CIA and September 11 by former German state minister Andreas von Bülow and Operation 9/11 by the German journalist Gerhard Wisnewski; both books are published by Mathias Bröckers , who was at the time an editor at the German newspaper Die Tageszeitung . [10]
While these theories were popular in Europe, they were treated by the U.S. media with either bafflement or amusement, and they were dismissed by the U.S. government as the product of anti-Americanism . [37] [38] In an address to the United Nations on November 10, 2001, United States President George W. Bush denounced the emergence of "outrageous conspiracy theories [...] that attempt to shift the blame away from the terrorists, themselves, away from the guilty." [39]
The 9/11 conspiracy theories started out mostly in the political left but have broadened into what New York Magazine describes as " terra incognita where left and right meet, fusing sixties countercultural distrust with the don’t-tread-on-me variety". [40]
By 2004, conspiracy theories about the September 11 attacks began to gain ground in the United States. One explanation is that the rise in popularity stemmed more from growing criticism of the Iraq War and the newly re-elected President George W. Bush than from any discovery of new or more compelling evidence or an improvement in the technical quality of the presentation of the theories. [10] Knight Ridder news theorized that revelations that weapons of mass destruction did not exist in Iraq, the belated release of the President's Daily Brief of August 6, 2001 , and reports that NORAD had lied to the 9/11 Commission , may have fueled the conspiracy theories. [10]
Between 2004 and the fifth anniversary of the September 11 attacks in 2006, mainstream coverage of the conspiracy theories increased. [10] The U.S. government issued a formal analysis by the National Institute of Standards and Technology (NIST) of the collapse of the World Trade Center. [41] To address the growing publicity of the theories, the State Department revised a webpage in 2006 to debunk them. [42] A 2006 national security strategy paper declared that terrorism springs from "subcultures of conspiracy and misinformation," and that "terrorists recruit more effectively from populations whose information about the world is contaminated by falsehoods and corrupted by conspiracy theories. The distortions keep alive grievances and filter out facts that would challenge popular prejudices and self-serving propaganda." [43] Al-Qaeda has repeatedly claimed responsibility for the attacks, with chief deputy Ayman al-Zawahiri accusing Shia Iran and Hezbollah of denigrating Sunni successes in hurting America by intentionally starting rumors that Israel carried out the attacks. [44] [45] [46] [47] [48] [49]
Some of the conspiracy theories about the September 11 attacks do not involve representational strategies typical of many conspiracy theories that establish a clear dichotomy between good and evil, or guilty and innocent; instead, they call up gradations of negligence and complicity. Matthias Bröckers, an early proponent of such theories, dismisses the official account of the September 11 attacks as being itself a conspiracy theory that seeks "to reduce complexity, disentangle what is confusing," and "explain the inexplicable". [10]
Just before the fifth anniversary of the attacks, mainstream news outlets released a flurry of articles on the growth of 9/11 conspiracy theories, [50] with an article in Time stating that "[t]his is not a fringe phenomenon. It is a mainstream political reality." [11] [51] Several surveys have included questions about beliefs related to the September 11 attacks. In 2008, 9/11 conspiracy theories topped a "greatest conspiracy theory" list compiled by The Daily Telegraph . The list was ranked by following and traction. [52] [53]
In 2010, the "International Center for 9/11 Studies," a private organization that is said to be sympathetic to conspiracy theories, [54] successfully sued for the release of videos collected by NIST of the attacks and aftermath. [54] [55] [56] According to the German daily Frankfurter Allgemeine Zeitung , the videos that were published shortly before the ninth anniversary of the attacks provide "new food for conspiracy theorists." Many of the videos show images of 7 World Trade Center , a skyscraper in the vicinity of the WTC towers that also collapsed on September 11, 2001. [55] Eyewitnesses have repeatedly reported explosions happening before the collapse of both of the towers, while experts consider these theories to be unreasonable. [54]
9/11 truth figures Steven E. Jones and Mike Berger have further added that the death of Osama bin Laden [57] did not change their questions about the attacks, nor provide closure. [58]
According to writer Jeremy Stahl , since Bush left office, the overall number of believers in 9/11 conspiracy theories has dipped, while the number of people who believe in the most "radical" theories has held fairly steady. [59]

Types of conspiracy
The most prominent conspiracy theories can be broadly divided into three main forms:

Theories

Foreknowledge
Conspiracy theorists claim that action or inaction by U.S. officials with foreknowledge was intended to ensure that the attacks took place successfully. For example, Michael Meacher , former British environment minister and member of Tony Blair 's Cabinet said that the United States knowingly failed to prevent the attacks. [63] [64]

Suspected insider trading
Some conspiracy theorists maintain that just before 9/11, an "extraordinary" amount of put options were placed on United Airlines and American Airlines stocks and speculate that insiders may have known in advance of the coming events of 9/11 and placed their bets accordingly. An analysis into the possibility of insider trading on 9/11 concludes that:
This study was intended to address the "great deal of speculation about whether option market activity indicated that the terrorists or their associates had traded in the days leading up to September 11 on advance knowledge of the impending attacks." [66]
In the days leading up to 9/11, analysis shows a rise in the put to call ratio for United Airlines and American Airlines, the two airlines from which planes were hijacked on 9/11. Between September 6 and 7, the Chicago Board Options Exchange recorded purchases of 4,744 "put" option contracts in UAL and 396 call options. On September 10, more trading in Chicago saw the purchase of 4,516 put options in American Airlines, the other airline involved in the hijackings, with a mere 748 call options in American purchased that day. No other airline companies has unusual put to call ratio in the days leading up to the attacks. [67] The 9/11 Commission concluded that all these abnormal patterns in trading were coincidental. [68]
Insurance companies saw anomalous trading activities as well. Citigroup Inc. , which has estimated that its Travelers Insurance unit may pay $500 million in claims from the World Trade Center attack, had about 45 times the normal volume during three trading days before the attack for options that profit, if the stock falls below $40. Citigroup shares fell $1.25 in late trading to $38.09. Morgan Stanley , which occupied 22 floors at the World Trade Center, experienced bigger-than-normal pre-attack trading of options that profited when stock prices fell. Other companies directly affected by the tragedy had similar jumps. [69]
Raytheon , a defense contractor, had an anomalously high number of call options trading on September 10. A Raytheon option that makes money, if shares are more than $25 each had 232 options contracts traded on the day before the attacks, almost six times the total number of trades that had occurred before that day. [ citation needed ]
The initial options were bought through at least two brokerage firms , including NFS , a subsidiary of Fidelity Investments , and TD Waterhouse . It was estimated that the trader or traders would have realized a five million dollar profit. The Securities and Exchange Commission launched an insider trading investigation in which Osama bin Laden was a suspect after receiving information from at least one Wall Street Firm. [70]
The 9/11 Commission Report concluded that "Exhaustive investigations by the Securities and Exchange Commission, FBI, and other agencies have uncovered no evidence that anyone with advance knowledge of the attacks profited through securities transactions." [71] The report further stated:

Air defense stand down theory
A common claim among conspiracy theorists is that the North American Aerospace Defense Command (NORAD) issued a stand down order or deliberately scrambled fighters late to allow the hijacked airplanes to reach their targets without interference. According to this theory, NORAD had the capability of locating and intercepting planes on 9/11, and its failure to do so indicates a government conspiracy to allow the attacks to occur. [73] Conspiracy theorist Mark R. Elsis says: "There is only one explanation for this ... Our Air Force was ordered to Stand Down on 9/11." [2] [74]
One of the first actions taken by the hijackers on 9/11 was to turn off or disable each of the four aircraft's on board transponders. Without these transponder signals to identify the airplane's tail number, altitude, and speed, the hijacked airplanes would have been only blips among 4,500 other blips on NORAD’s radar screens, making them very difficult to track. [75] [73]
On 9/11, only 14 fighter jets were on alert in the contiguous 48 states. There was no automated method for the civilian air traffic controllers to alert NORAD. [76] A passenger airline had not been hijacked in the U.S. since 1979. [77] "They had to pick up the phone and literally dial us," says Maj. Douglas Martin, public affairs officer for NORAD. Only one civilian plane—a chartered Learjet 35 with golfer Payne Stewart and five others on board—was intercepted by NORAD over North America in the decade prior to 9/11, which took one hour and 19 minutes. [78]
Rules in effect at that time, and on 9/11, barred supersonic flight on intercepts. Before 9/11, all other NORAD interceptions were limited to offshore Air Defense Identification Zones (ADIZ). "Until 9/11 there was no domestic ADIZ," says FAA spokesman Bill Schumann. After 9/11, the FAA and NORAD increased cooperation. They set up hotlines between command centers while NORAD increased its fighter coverage and installed radar to watch airspace over the continent. [2]
The longest warning NORAD received of the hijackings was some eight minutes for American Airlines Flight 11, the first flight hijacked. The FAA alerted NORAD to the hijacked Flight 175 at just about the same time it was crashing into the World Trade Center's South Tower. The FAA notified NORAD of the missing – not hijacked – Flight 77 three minutes before it struck the Pentagon. NORAD received no warning of the hijack of United Flight 93 until three minutes after it had crashed in Pennsylvania. [79]

Israeli agents
It has been claimed that Israeli agents may have had foreknowledge of the attacks. Four hours after the attack, the FBI arrested five Israelis who had been filming the smoking skyline from the roof of a white van in the parking lot of an apartment building, for "puzzling behavior". The Israelis were videotaping the events, and one bystander said they acted in a suspicious manner: "They were like happy, you know ... They didn't look shocked to me. I thought it was very strange." [80] [81] [82] While The Forward , a New York Jewish news magazine, reported that the FBI concluded that two of the men were Israeli intelligence operatives, a spokesperson for the Israeli Embassy in the United States said that they had not been involved in any intelligence operation in the United States. [80] The FBI eventually concluded that the five Israelis had no foreknowledge of the attacks. [83]

World Trade Center
The plane crashes and resulting fires caused the collapse of the World Trade Center . Controlled demolition conspiracy theories say the collapse of the North Tower, South Tower, or of 7 World Trade Center was caused by explosives installed in the buildings in advance.
Demolition theory proponents, such as Brigham Young University physicist Steven E. Jones , architect Richard Gage , software engineer Jim Hoffman , and theologian David Ray Griffin , argue that the aircraft impacts and resulting fires could not have weakened the buildings sufficiently to initiate a catastrophic collapse, and that the buildings would not have collapsed completely, nor at the speeds that they did, without additional factors weakening the structures.
In the article "Active Thermotic Material Discovered in Dust from the 9/11 World Trade Center Catastrophe", which appeared in the Open Chemical Physics Journal , authors Niels Harrit of the University of Copenhagen 's Department of Chemistry, Jeffrey Farrer of Brigham Young University 's Department of Physics and Astronomy, Steven E. Jones, and others state that thermite and nano-thermite composites in the dust and debris were found following the collapse of the three buildings, which they conclude to be proof that explosives brought down the buildings. The article contained no scientific rebuttal and the editor in chief of the publication subsequently resigned. [84] [85] [86]
Jones has not explained how the amount of explosive needed to do this could have been positioned in the two buildings without drawing attention, but mentioned efforts to research the buildings' maintenance activity in the weeks prior to the event. Federal investigators at the National Institute of Standards and Technology state that enormous quantities of thermite would have to be applied to the structural columns to damage them, but Jones disputed this, saying that he and others were investigating "superthermite". [84] Brent Blanchard, author of "A History of Explosive Demolition in America", [87] who corresponded with Jones, states that questions about the viability of Jones' theories remain unanswered, such as the fact that no demolition personnel noticed any telltale signs of thermite during the eight months of debris removal following the towers' collapse. Blanchard also said that a verifiable chain of possession needs to be established for the tested beams, which did not occur with the beams Jones tested, raising questions of whether the metal pieces tested could have been cut away from the debris pile with acetylene torches, shears, or other potentially contaminated equipment while on site, or exposed to trace amounts of thermite or other compounds while being handled, while in storage, or while being transferred from Ground Zero to memorial sites.
Jones also said that molten steel found in the rubble was evidence of explosives, as an ordinary airplane fire would not generate enough heat to produce this, citing photographs of red debris being removed by construction equipment, but Blanchard said that if there had been any molten steel in the rubble any excavation equipment encountering it would have been immediately damaged. [84] Other sampling of the pulverized dust by United States Geological Survey and RJ Lee did not report any evidence of thermite or explosives. It has been theorized the "thermite material" found was primer paint. [88] Dave Thomas of Skeptical Inquirer magazine, noting that the residue in question was claimed to be thermotic because of its iron oxide and aluminum composition, pointed out that these substances are found in many items common to the towers. Thomas said that in order to cut through a vertical steel beam, special high-temperature containment must be added to prevent the molten iron from dropping down, and that the thermite reaction is too slow for it to be practically used in building demolition. Thomas pointed out that when Jesse Ventura hired New Mexico Tech to conduct a demonstration showing nanothermite slicing through a large steel beam, the nanothermite produced copious flame and smoke but no damage to the beam, even though it was in a horizontal, and therefore optimal position. [89]
The National Institute of Standards and Technology (NIST) concluded the accepted version was more than sufficient to explain the collapse of the buildings. NIST and many scientists refuse to debate conspiracy theorists because they feel it would give those theories unwarranted credibility. [90] Specialists in structural mechanics and structural engineering accept the model of a fire-induced, gravity-driven collapse of the World Trade Center buildings without the use of explosives. [91] [92] [93] As a result, NIST said that it did not perform any test for the residue of explosive compounds of any kind in the debris. [41]
Soon after the day of the attacks, major media sources published that the towers had collapsed due to heat melting the steel. [94] [95] Knowledge that the burning temperatures of jet fuel would not melt the steel support structure of the WTC contributed to the belief among skeptics that the towers would not have collapsed without external interference (something other than the planes). NIST does not claim that the steel was melted, but rather that the weakened steel, together with the damage caused by the planes' impacts, caused the collapses. [41] NIST reported that a simulation model based on the assumption that combustible vapors burned immediately upon mixing with the incoming oxygen showed that "at any given location, the duration of [gas] temperatures near 1,000 °C was about 15 to 20 [minutes]. The rest of the time, the calculated temperatures were 500 °C or below." [96]
The ability of an uncontrolled blaze to cause the collapse of a steel-framed high-rise building was demonstrated by the destruction of the Plasco Building in Tehran , Iran on January 19, 2017. [97]

The Pentagon
Political activist Thierry Meyssan and filmmaker Dylan Avery claim that American Airlines Flight 77 did not crash into the Pentagon . Instead, they argue that the Pentagon was hit by a missile launched by elements from inside the U.S. government. Some claim that the holes in the Pentagon walls were far too small to have been made by a Boeing 757: "How does a plane 125 ft. wide and 155 ft. long fit into a hole which is only 60 ft. across?" Meyssan’s book, L’Effroyable Imposture (published in English as 9/11: The Big Lie ) became available in more than a dozen languages. When released, the book was heavily criticized by both the mainstream French and American press, and later, from within the 9/11 Truth movement . The French newspaper Liberation called the book "a tissue of wild and irresponsible allegations, entirely without foundation." [98] [99] [100]
In response to the conspiracy theorists' claim of a missile hitting the Pentagon, Mete Sozen, a professor of civil engineering at Purdue University argues that: "A crashing jet doesn't punch a cartoon-like outline of itself into a reinforced concrete building. When Flight 77 hit the Pentagon, one wing hit the ground and the other was sheared off by the Pentagon's load-bearing columns." [98] [101] According to ArchitectureWeek , the reason the Pentagon took relatively little damage from the impact was because Wedge One had recently been renovated. [102] (This was part of a renovation program which had been begun in the 1980s, and Wedge One was the first of five to be renovated. [103] )
Evidence contradicting some conspiracy theorists' claim of a missile's hitting the Pentagon have been described by researchers within the 9/11 Truth Movement, such as Jim Hoffman, in his essay "The Pentagon Attack: What the Physical Evidence Shows", and by others broadly refuting the role of other conspiracies in the attacks. The evidence refuting missile claims includes airplane debris including Flight 77's black boxes , [104] the nose cone, landing gear, [105] an airplane tire, [106] and an intact cockpit seat [107] were observed at the crash site. The remains of passengers from Flight 77 were indeed found at the Pentagon crash site and their identities confirmed by DNA analysis. [108] Many eyewitnesses saw the plane strike the Pentagon. Further, Flight 77 passengers made phone calls reporting that their airplane had been hijacked. For example, passenger Renee May called her mother to tell her that the plane had been hijacked and that the passengers had been herded to the back of the plane. Another passenger named Barbara Olson called her husband (U.S. Solicitor General Theodore Olson ) and said that the flight had been hijacked, and that the hijackers had knives and box cutters . [8] [98] [109] [110] Some conspiracy theories say the phone calls the passengers made were fabricated by voice morphing, the passengers' bodies disposed of, and a missile fired at the Pentagon. [111] [112] [113]
The pressure group Judicial Watch filed a Freedom of Information Act request on December 15, 2004, to force the government to release video recordings from the Sheraton National Hotel, the Nexcomm/Citgo gas station, Pentagon security cameras and the Virginia Department of Transportation. On May 16, 2006, the government released the Pentagon security camera videos to Judicial Watch. [114] The image of American Airlines Flight 77 which appears in the videos has been described as "[a] white blob" and "a white streak" (by the BBC), [115] "a thin white blur" (by The Associated Press ), [116] and "a silver speck low to the ground" (in The Washington Post ). [117] A sequence of five frames from one of the videos already appeared in the media in 2002. [118] Some conspiracy theorists believe the new video does not answer their questions. [119]

Flight 93
The fourth plane hijacked on 9/11, United Airlines Flight 93 , crashed in an open field near Shanksville , Pennsylvania , after the passengers revolted. Out of the four planes hijacked on that day, Flight 93 was the only one not to reach its target. [120]
One of the popular conspiracy theories surrounding this event is that Flight 93 was actually shot down by a U.S. fighter jet. David Ray Griffin and Alex Jones say that large parts of the plane including the main body of the engine landed miles away from the main wreckage site, too far away for an ordinary plane crash. Jones says that planes usually leave a small debris field when they crash, and that this is not compatible with reports of wreckage found farther away from the main crash site. One person claimed that the main body of the engine was found miles away from the main wreckage site with damage comparable to that which a heat-seeking missile would do to an airliner. [98] [120]
According to some theories, the plane had to be shot down by the government because passengers had found out about the alleged plot. [74]
According to Phil Molé of Skeptic magazine, "[this] claim rests largely on unsupported assertions that the main body of the engine and other large parts of the plane turned up miles from the main wreckage site, too far away to have resulted from an ordinary crash. This claim is incorrect, because the engine was found only 300 yards from the main crash site, and its location was consistent with the direction in which the plane had been traveling." [121] Michael K. Hynes, an airline accident expert who investigated the crash of TWA Flight 800 in 1996, says that, at very high velocities of 500 mph or more, it would only take a few seconds to move or tumble across the ground for 300 yards. [98] [121]
Reports of wreckage discovered at Indian Lake by local residents are accurate. CNN reported that investigators found debris from the crash at least eight miles away from the crash site, including in New Baltimore . [122] However, according to CNN, this debris was all very light material that the wind would have easily blown away, and a Pittsburgh Post-Gazette article from September 14, 2001, describes the material as "mostly papers", "strands of charred insulation", and an "endorsed paycheck". The same article quotes FBI agent Bill Crowley that, "Lighter, smaller debris probably shot into the air on the heat of a fireball that witnesses said shot several hundred feet into the air after the jetliner crashed. Then, it probably rode a wind that was blowing southeast at about 9 m.p.h." [123] Also, the distance between the crash site and Indian Lake was misreported in some accounts. According to the BBC, "In a straight line, Indian Lake is just over a mile from the crash site. The road between the two locations takes a roundabout route of 6.9 miles—accounting for the erroneous reports." [120]
Some conspiracy theorists believe a small white jet seen flying over the crash area may have fired a missile to shoot down Flight 93. [124] [ dubious – discuss ] However, government agencies such as the FBI assert this small plane was a Dassault Falcon business jet asked to descend to an altitude of around 1,500 ft to survey the impact. [125] Ben Sliney, who was the FAA operation manager on September 11, 2001, says no military aircraft were near Flight 93. [126]
Some internet videos, such as Loose Change , speculate that Flight 93 safely landed in Ohio , and a substituted plane was involved in the crash in Pennsylvania. Often cited is a preliminary news report that Flight 93 landed at a Cleveland airport; [127] it was later learned that Delta Flight 1989 was the plane confused with Flight 93, and the report was retracted as inaccurate. Several websites within the 9/11 Truth Movement dispute this claim, citing the wreckage at the scene, eyewitness testimony, and the difficulty of secretly substituting one plane for another, and claim that such "hoax theories ... appear calculated to alienate victims' survivors and the larger public from the 9/11 truth movement". The editor of the article has since written a rebuttal to the claims. [128]
Valencia McClatchey, a local woman who took the only photograph of the mushroom cloud from the impact of Flight 93 seconds after it hit the ground, says she has been harassed over the telephone and in person by conspiracy theorists, who claim she faked the photo. The FBI, the Somerset County authorities, the Smithsonian, and the National Park Service’s Flight 93 National Memorial staff have all examined the photograph as well as the film negatives and they consider the photo to be authentic. [129]
While some conspiracy theorists have claimed that passengers of Flight 93 and/or Flight 77 , were murdered or that they were relocated, with the intent that they never be found, [74] others within the 9/11 Truth Movement, such as Jim Hoffman and Scholars for 9/11 Truth & Justice , repudiate such claims.

Hijackers
During the initial confusion surrounding the immediate aftermath of the 9/11 attacks, the BBC published the names and identities of what they believed to be some of the hijackers. [130] Some of the people named were later discovered to be alive, a fact that was seized upon by 9/11 conspiracy theorists as proof that the hijackings were faked. [130] [131] [132] The BBC explained that the initial confusion may have arisen because the names they reported back in 2001 were common Arabic and Islamic names. [130] In response to a request from the BBC, the FBI said that it was confident to have identified all nineteen hijackers, and that none of the other inquiries had raised the issue of doubt about their identities. [130] The New York Times also acknowledged these as cases of mistaken identity. [133]
According to John Bradley, the former managing editor of Arab News in Jeddah, Saudi Arabia, the only public information about the hijackers was a list of names issued by the FBI on September 14, 2001. When the FBI released photographs four days after the cited reports on September 27, the mistaken identities were quickly resolved. According to Bradley, "all of this is attributable to the chaos that prevailed during the first few days following the attack. What we're dealing with are coincidentally identical names." In Saudi Arabia, says Bradley, the names of two of the allegedly surviving attackers, Said al-Ghamdi and Walid al-Shari , are "as common as John Smith in the United States or Great Britain." [131]
According to Thomas Kean, chair of the 9/11 Commission, "Sixteen of the nineteen shouldn't have gotten into the United States in any way at all because there was something wrong with their visas, something wrong with their passports. They should simply have been stopped at the border. That was sixteen of the nineteen. Obviously, if even half of those people had been stopped, there never would have been a plot." [134]
Khalid al Mihdhar and Nawaf al Hazmi had both been identified as al-Qaeda agents by the CIA, but that information was not shared with the FBI or U.S. Immigration, so both men were able to legally enter the U.S. to prepare for the 9/11 attacks. [135]

Foreign governments
There are allegations that individuals within the Pakistani Inter-Services Intelligence (ISI) may have played an important role in financing the attacks . There are also claims that other foreign intelligence agencies, such as the Israeli Mossad , had foreknowledge of the attacks, and that Saudi Arabia may have played a role in financing the attacks. General Hamid Gul , a former head of ISI, believes the attacks were an "inside job" originating in the United States, perpetrated by Israel or neo-conservatives . [136] Francesco Cossiga , former President of Italy from 1985 until his 1992 resignation over Operation Gladio , said that it is common knowledge among the Italian center-left that the 9/11 attacks were a joint operation of the CIA and the Mossad. [137] Subsequent reports indicated that he did not actually believe this. [138] [139]

Israel
A conspiracy theory documented by the Anti-Defamation League , Thom Burnett and others is that the state of Israel was involved in the attacks, and may have planned them. A variety of motives are suggested, including: to cause the United States to attack enemies of Israel; to divert public attention away from Israel's treatment of Palestinians ; to help Zionists take control of world affairs; and to persuade Americans to support Israel. Variants of the theory contend that the attack was organized by Ariel Sharon , Mossad , or the government of Israel. [140] [141] Kevin Barrett, a former lecturer at the University of Wisconsin , is a leading advocate for the theory that Mossad orchestrated the attacks. [142]
Some proponents of this believe that Jewish employees were forewarned by Israeli intelligence to skip work on September 11, resulting in no Jewish deaths at the World Trade Center. According to Cinnamon Stillwell, some 9/11 conspiracy theorists put this number as high as 4,000 Jewish people skipping work. [143] This was first reported on September 17 by the Lebanese Hezbollah -owned satellite television channel Al-Manar and is believed to be based on the September 12 edition of the The Jerusalem Post that said "The Foreign Ministry in Jerusalem has so far received the names of 4,000 Israelis believed to have been in the areas of the World Trade Center and the Pentagon at the time of the attacks." [144]
The number of Jews who died in the attacks is variously estimated at between 270 and 400. [144] [145] [146] [147] The lower figure tracks closely with the percentage of Jews living in the New York area and partial surveys of the victims' listed religion. The U.S. State Department has published a partial list of 76 in response to claims that fewer Jews/Israelis died in the WTC attacks than should have been present at the time. [144] [148] Five Israeli citizens died in the attack. [149]

Antisemitism in conspiracy theories
In 2003, the Anti-Defamation League (ADL) published a report attacking "hateful conspiracy theories" that the 9/11 attacks were carried about by Israelis and Jews, saying they had the potential to "rationalize and fuel global anti-Semitism ." It found that such theories were widely accepted in the Arab and Muslim world , as well as in Europe and the United States.
The ADL's report found that "The Big Lie has united American far-right extremists and white supremacists and elements within the Arab and Muslim world". It asserted that many of the theories were modern manifestation of the 19th century Protocols of the Elders of Zion , which purported to map out a Jewish conspiracy for world domination. [141] [150] The ADL has characterized the Jeff Rense website as carrying anti-Semitic materials, such as "American Jews staged the 9/11 terrorist attacks for their own financial gain and to induce the American people to endorse wars of aggression and genocide on the nations of the Middle East and the theft of their resources for the benefit of Israel". [151]
Pedro A. Sanjuan, a former United Nations diplomat, alleged that antisemitic 9/11 conspiracy theories were quite common at high levels of the organization following the attacks. [152]

Saudi Arabia
British investigative journalists Anthony Summers and Robbyn Swan claimed in their 2011 book The Eleventh Hour that the Saudi Royal Family provided material and financial support to the hijackers and that the Bush Administration covered this up as well as their own alleged incompetence. The authors claim the 9/11 Truth movement helped this coverup by deflecting attention away from these actions. [153] In September 2011 a "Lloyd's insurance syndicate" began legal action against Saudi Arabia demanding the repayment of £136m it paid out to victims of the 9/11 attacks. A number of prominent Saudi charities and banks as well as a leading member of the al-Saud royal family were accused of being "agents and alter egos" for the Saudi state that "knowingly" provided funding to al-Qaeda and encouraged anti Western sentiment. [154]
Such theories revolve around the putative content of the 28 pages of the 2002 report of the U.S. Congress Joint Inquiry that are withheld from publication. [155] [156]
Former Florida Senator Bob Graham , co-chairman of the Joint Inquiry , as well as other former officials who did read the entire version of the Joint Inquiry's report, still partly classified, believe there is a U.S. government's coverup on the Saudi government officials' substantial aid provided to the perpetrators of the 9/11 act, [155] notably the role of Fahad al-Thumairy , a diplomat at the Saudi consulate in Los Angeles. [157]

No-planes theory
Nico Haupt and former chief economist within the Labor Department under the Bush administration, Morgan Reynolds , argue that no planes were used in the attacks. Reynolds claims it is physically impossible that the Boeing planes of Flights 11 and 175 could have penetrated the steel frames of the Towers, and that digital compositing was used to depict the plane crashes in both news reports and subsequent amateur video. "There were no planes, there were no hijackers", Reynolds insists. "I know, I know, I'm out of the mainstream, but that's the way it is". According to David Shayler , 'the only explanation is that they were missiles surrounded by holograms made to look like planes', he says, which would be well beyond the capabilities of contemporaneous hologram technology. "Watch footage frame by frame and you will see a cigar-shaped missile hitting the World Trade Center". Some truth movement veterans have repeatedly refuted the "no-plane" claims. [74] [158] In fact, discussion of no-plane theories has been banned from certain conspiracy theory websites and advocates have sometimes been threatened with violence by posters at other conspiracy theory websites. [159]

Cover-up allegations
Paul Zarembka, in his book, The Hidden History of 9/11 , states that the debris from ground zero was removed without a proper forensic investigation. [160] [161]

Cockpit recorders
According to the 9/11 Commission Report, both black boxes from Flight 77 and both black boxes from Flight 93 were recovered. However, the CVR from Flight 77 was said to be too damaged to yield any data. On April 18, 2002, the FBI allowed the families of victims from Flight 93 to listen to the voice recordings. [162] In April 2006, a transcript of the CVR was released as part of the Zacarias Moussaoui trial. [163]
Two men, Michael Bellone and Nicholas DeMasi, who worked extensively in the wreckage of the World Trade Center, said in the book Behind-The-Scenes: Ground Zero that they helped federal agents find three of the four "black boxes" from the jetliners: [164]

Bin Laden tapes
A series of interviews, audio and videotapes were released in the years following the 9/11 attacks that were reported to be from Osama bin Laden. In the first of these the speaker denied responsibility for the attacks. On September 17, 2001, in a statement issued to Al Jazeera , Bin Laden is quoted as saying: "The U.S. government has consistently blamed me for being behind every occasion its enemies attack it. I would like to assure the world that I did not plan the recent attacks, which seems to have been planned by people for personal reasons." [166]
In a tape released in December 2001 known as 'the Jalalabad tape', the speaker is alleged to have foreknowledge of the attacks. The Central Intelligence Agency claimed the tape was probably from Osama bin Laden . [ citation needed ] Some observers, especially people in the Muslim world , doubted the authenticity of the tape. [167] On December 20, 2001, German TV channel " Das Erste " broadcast an analysis of the White House's translation of the videotape. On the program Monitor , two independent translators and an expert on Oriental Studies found the White House's translation to be both inaccurate and manipulative, stating, "At the most important places where it is held to prove the guilt of bin Laden, it is not identical with the Arabic", and that the words used that indicate foreknowledge can not be heard at all in the original. Prof. Gernot Rotter, professor of Islamic and Arabic Studies at the Asia-Africa Institute at the University of Hamburg , said "The American translators who listened to the tapes and transcribed them apparently wrote a lot of things in that they wanted to hear but that cannot be heard on the tape no matter how many times you listen to it." [168] Some members of Scholars for 9/11 Truth believe that the man in this videotape is not Osama bin Laden at all, citing differences in weight and facial features, along with his wearing of a gold ring, which is forbidden by Muslim law, and writing with his right hand although bin Laden was left-handed. [169]
In an audiotape released in November 2007, Bin Laden claimed responsibility for the attacks and denied the Taliban and the Afghan government or people had any prior knowledge of the attacks. [170] [171] [172] In an interview with al-Jazeera, Khalid Sheikh Mohammed and Ramzi bin al-Shibh , two of al-Qaeda's alleged masterminds of the attacks, also confessed their involvement in the attacks. [173]

Hiding of CIA recruitment efforts
Richard Clarke , who headed the government's anti-terrorism efforts in 2001, theorized CIA director George Tenet ordered the agency to withhold information about Nawaf al-Hazmi and Khalid al-Mihdhar from the rest of the government in an effort to cover up the agency's recruitment of the two. George Tenet released a statement denying the agency deliberately withheld information about the pair and noted Clarke himself said he had no proof. [174]

Motives

Pax Americana
In 2006, members of the group Scholars for 9/11 Truth argued that a group of US neo-conservatives called the Project for a New American Century (PNAC), which included Paul Wolfowitz , Dick Cheney and Donald Rumsfeld , was set on US world dominance and orchestrated the 9/11 attacks as an excuse to hit Iraq, Afghanistan and later Iran. [175] In September 2000 the PNAC released a strategic treatise entitled Rebuilding America's Defences . David Ray Griffin in his 2004 book The New Pearl Harbor: Disturbing Questions About the Bush Administration and 9/11 argued that the treatise may have been the blueprint for 9/11 attacks. Specifically the language in the paper that read "the process of transformation, even if it brings revolutionary change, is likely to be a long one, absent some catastrophic and catalyzing event – like a new Pearl Harbor" was describing an alleged motive.
The Defense Planning Guidance of 1992, was drafted by Paul Wolfowitz on behalf of then Secretary of Defense Dick Cheney . This was described as "a blueprint for permanent American global hegemony " by Andrew Bacevich in his book American Empire: The Realities and Consequences of U.S. Diplomacy . [176]
Matt Taibbi argued in his book The Great Derangement that conspiracy theorists have taken what is written in the paper "completely out of context", and that the "transformation" referenced in the paper is explicitly said to be a decades-long process to turn the Cold War -era military into a "new, modern military" which could deal with more localized conflicts. [177] He said that, for this to be evidence of motive, either those responsible would have decided to openly state their objectives, or would have read the paper in 2000 and quickly laid the groundwork for the 9/11 attacks using it as inspiration. [177]

Invasions
Conspiracy theorists have questioned whether The Oil Factor and 9/11 provided the United States and the United Kingdom with a reason to launch a war they had wanted for some time, and suggest that this gives them a strong motive for either carrying out the attacks, or allowing them to take place. For instance, Andreas von Bülow , a former research minister in the German government, has argued that 9/11 was staged to justify the subsequent wars in Afghanistan and Iraq. [178] Former Malaysian premiere Mahathir Mohamad was quoted as saying that there was "strong evidence" that the attacks were faked so the United States could go to war against Muslims. [179] In spite of these allegations, the Bush administration specifically rejected proposals to immediately attack Iraq in response to 9/11, [180] and acknowledged that there was no evidence of Iraqi involvement in the attacks. [9]

New World Order
Alex Jones and other personalities hold that 9/11 was initiated by a disparate variety of banking, corporate, globalization, and military interests for the purpose of creating a globalist government. Such New World Order conspiracy theories predate 9/11. [59]

Suggested historical precedents
Conspiracy theorists often point to Operation Northwoods as a model for the 9/11 attacks, theorizing the attacks were carried out by the U.S. government as a false flag operation and then blamed on Islamic extremists. [10] [181] Operation Northwoods was an unimplemented, apparently rejected, plan approved by the United States Joint Chiefs of Staff in 1962. One proposal in the plan suggested that covert operatives commit multiple acts of terrorism in U.S. cities and blame Cuba, thus providing a pretext for invasion. [182]
Time magazine contrasted events which inspired past conspiracy theories with those that inspire 9/11 conspiracy theories such as the assassination of John F. Kennedy . Time called the public assassination of Kennedy a "private, intimate affair" when compared with the attack on the World Trade Center, which was witnessed by millions of people and documented by hundreds of videographers; and said, "there is no event so plain and clear that a determined human being can't find ambiguity in it." [51]

Proponents
Many individuals and organizations that support or discuss 9/11 conspiracy theories consider themselves to be part of the 9/11 Truth movement.
Prominent adherents of the movement include, among others, radio talk show host Alex Jones , theologian David Ray Griffin , physicist Steven E. Jones , software engineer Jim Hoffman , architect Richard Gage , film producer Dylan Avery , former Governor of Minnesota Jesse Ventura , former member of the U.S. House of Representatives Cynthia McKinney , [183] actors Daniel Sunjata , Ed Asner , and Charlie Sheen , political science professor Joseph Diaferia and journalist Thierry Meyssan . [184] [185] [186] Adherents of the 9/11 Truth movement come from diverse social backgrounds. [187] [188] [189] The movement draws adherents from people of diverse political beliefs including liberals, conservatives, and libertarians. [189] [190] [191]
Among the organizations that actively discuss and promote such theories are Architects & Engineers for 9/11 Truth , a group that focuses on the collapse of the World Trade Center buildings; 9/11 Truth , founded in 2004; Scholars for 9/11 Truth , founded in 2005, and Scholars for 9/11 Truth & Justice , a group that split from Scholars for 9/11 Truth in 2007 and runs the online publication Journal of 9/11 Studies ; 9/11 Citizens Watch , which was already formed in 2002; and the Hispanic Victims Group . Several of these groups have collected signatures on petitions asking for further investigation of the September 11 attacks. [192] [193] [194]
In 2004, John Buchanan ran for president on a "9/11 Truth" platform. [195]
9/11 Conspiracy theory critic Jonathan Kay asserts that for the most part proponents are not out for financial gain and in some cases have left lucrative careers to become activists. [196]
Dr Michael Wood and Dr Karen Douglas University of Kent psychologists who specialize in conspiracy theories [197] examined the comments sections of over 2000 news articles relating to the collapse of World Trade Center 7. They found that proponents of 9/11 conspiracy theories were more likely to try and debunk the mainstream account than promote their own theories and also were more likely to believe in other conspiracy theories. Proponents of the mainstream account tended to argue for that account and showed a greater hostility toward conspiracy theory proponents. [198]

Dissecting the 9/11 Truth movement community
According to a 2011 analysis in a Skeptical Inquirer article, people involved in this movement, which seemingly is a disparate group with very diversified backgrounds, could be classified into three groups. They join the movement for different reasons, loosely self-assemble to fill different roles and are united by their shared mistrust in experts and the establishment (government and reputable sources of knowledge), and conspiratorial stance. Through their engagement, they each find their own fulfillment and satisfaction. Together, they contribute to the persistence, resilience and exaggerated claims of acceptance (in general public) of the movement. These three groups are: [199]

Media reaction
While discussion and coverage of these theories is mainly confined to Internet pages, books, documentary films, and conversation, a number of mainstream news outlets around the world have covered the issue.
The Norwegian version of the July 2006 Le Monde diplomatique sparked interest when they ran, on their own initiative, a three-page main story on the 9/11 attacks and summarized the various types of 9/11 conspiracy theories (which were not specifically endorsed by the newspaper, only recensed). [200] The Voltaire Network , which has changed position since the September 11 attacks and whose director, Thierry Meyssan , became a leading proponent of 9/11 conspiracy theory, explained that although the Norwegian version of Le Monde diplomatique had allowed it to translate and publish this article on its website, the mother-house, in France, categorically refused it this right, thus displaying an open debate between various national editions. [201] In December 2006, the French version published an article by Alexander Cockburn , co-editor of CounterPunch , which strongly criticized the alleged endorsement of conspiracy theories by the U.S. left-wing, alleging that it was a sign of "theoretical emptiness." [202] [203]
Also, on the Canadian website for CBC News: The Fifth Estate , a program titled, "Conspiracy Theories: uncovering the facts behind the myths of Sept. 11, 2001" was broadcast on October 29, 2003, stating that what they found may be more surprising than any theories. [204] On November 27, 2009, The Fifth Estate aired a documentary entitled The Unofficial Story where several prominent members of the 9/11 Truth Movement made their case. [205] [206]
An article in the September 11, 2006, edition of Time magazine comments that the major 9/11 conspiracy theories "depend on circumstantial evidence, facts without analysis or documentation, quotes taken out of context and the scattered testimony of traumatized eyewitnesses", and enjoy continued popularity because "the idea that there is a malevolent controlling force orchestrating global events is, in a perverse way, comforting". It concludes that "conspiracy theories are part of the process by which Americans deal with traumatic public events" and constitute "an American form of national mourning." [207]
Australian newspaper The Daily Telegraph published an article titled "The CIA couldn't have organised this ..." which said "The same people who are making a mess of Iraq were never so clever or devious that they could stage a complex assault on two narrow towers of steel and glass" and "if there is a nefarious plot in all this bad planning, it is one improvised by a confederacy of dunces". This article mainly attacked a group of scientists led by Professor Steven E. Jones , now called Scholars for 9/11 Truth and Justice . They said "most of them aren't scientists but instructors ... at second-rate colleges". [208]
The Daily Telegraph also published an article in May 2007 that was highly critical of Loose Change 2 , a movie which presents a 9/11 conspiracy theory. [209]
Doug MacEachern in a May 2008 column for The Arizona Republic wrote that while many "9/11 truthers" are not crackpots that espouse "crackpot conspiracy theories", supporters of the theories fail to take into account both human nature and that nobody has come forward claiming they were participants in the alleged conspiracies. [210] This view was seconded by Timothy Giannuzzi, a Calgary Herald op-ed columnist specializing in foreign policy. [211]
On June 7, 2008, The Financial Times Magazine published a lengthy article on the 9/11 Truth Movement and 9/11 conspiracy theories. [212]
Charlie Brooker , a British comedian and multimedia personality, in a July 2008 column published by The Guardian as part of its "Comment is free" series agreed that 9/11 conspiracy theorists fail to take in account human fallacies and added that believing in these theories gives theorists a sense of belonging to a community that shares privileged information thus giving the theorists a delusional sense of power. [213] The commentary generated over 1700 online responses, the largest in the history of the series. [214] In a September 2009 piece, The Guardian were more supportive of 9/11 conspiracy theories however, asking, "when did it become uncool to ask questions? When did questioners become imbeciles?" [215]
On September 12, 2008, Russian State Television broadcast in prime time a documentary made by Member of the European Parliament Giulietto Chiesa entitled Zero , sympathetic to those who question the accepted account of the attacks according to Chiesa. According to Thierry Meyssan in conjunction with the documentary, Russian State Television aired a debate on the subject. The panel consisted of members from several countries including 12 Russians who hold divergent views. The motive of Russian State Television in broadcasting the documentary was questioned by a commentator from The Other Russia who noted that Russian State Television had a history of broadcasting programs involving conspiracy theories involving the United States government . [216]
Nasir Mahmood in a commentary printed by the Pakistan Observer wrote favorably about a 9/11 truth lecture and film festival held in California and quoted a Jewish speaker at that festival who said that none of the 19 suspected hijackers had been proven guilty of anything and compared racism against Muslims resulting from what he called false accusations to the racism against Jews in the Nazi era. [217]
On November 10, 2008, ITN broadcast a story summarizing various 9/11 conspiracy theories. [218]
The emergence of the birther movement in 2009 has led to comparisons between that movement and the 9/11 Truth movement, with both movements seen in a very negative light. Moon landing conspiracy theories have also been compared to the birther and 9/11 conspiracy theories. James Borne, a journalist for The New York Times who covered the September 11 attacks , described his assignment covering a 9/11 truth meeting as "[p]erhaps the most intellectually scary assignment I have had in recent years". [219] [220] [221] [222]
On August 31, 2009, the National Geographic Channel aired the program 9/11 Science and Conspiracy , in which the Energetic Materials Research and Testing Center tested some of the claims frequently made by those who question the accepted 9/11 account. Specifically, the experiments concluded that burning jet fuel alone can sufficiently raise the temperature of a steel support column to the point of structural failure, that a controlled demolition using conventional techniques would leave clear evidence that was not found at Ground Zero, that using thermite is not an effective technique to melt a steel column, and that even if thermite chemical signatures were found, it would be impossible to tell if thermite was actually used or if the traces came from the reaction of aircraft aluminum with other substances in the fire. The testing also concluded that the type of hole found at the Pentagon was consistent with the standard scenario, and that damage from a bombing or missile attack would differ from the damage that occurred. In the program, several prominent 9/11 conspiracy theorists viewed rough edits of the experiments, and expressed their disagreement with the findings. [223] [224]
The British left wing magazine New Statesman listed David Ray Griffin as the 41st most important person who matters today. The magazine said that Griffin's "books on the subject have lent a sheen of respectability that appeals to people at the highest levels of government". The publication listed 9/11 conspiracy theories as "one of the most pernicious global myths". [225] Griffin's book The New Pearl Harbor Revisited was chosen by Publishers Weekly as a "Pick of the Week" in November 2008. [226]
Denver public television KBDI-TV has aired 9/11 truth documentaries several times. The stations spokesperson claimed airing these documentaries has been a boon for the stations fund raising efforts. [227]
Glenn Beck , television and radio host, said of the allegations: "There are limits to debasement of this country, aren't there? I mean, it's one thing to believe that our politicians are capable of being Bernie Madoff . It's another to think that they are willing to kill 3,000 Americans. Once you cross that line, you're in a whole new territory." [228]
In March 2010, The Washington Post editorialized against Yukihisa Fujita , a prominent Japanese politician who has espoused 9/11 conspiracy theories. They described Fujita as a man "susceptible to the imaginings of the lunatic fringe". It went on to say that the U.S.–Japan alliance would be "severely tested" if Fujita's party continued to tolerate these kinds of comments. [229]
For the ninth anniversary of the attacks the Egyptian daily Al-masry Al-youm published an article questioning the U.S. Government story and promoting conspiracy theories. The senior analyst for the semi-official Al-Ahram Center for Political and Strategic Studies and a member of Parliament from the Muslim Brotherhood was quoted.
Gordon Farrer, the technology editor for The Age , theorized in a November 2010 column for the Sydney Morning Herald that the popularity of 9/11 conspiracy theories was a result of two main factors. One revolved around the personality traits of the theorists themselves (cynical, anxious, belief that they are freethinkers ). The second revolved around the high internet search ranking 9/11 conspiracy theories receive, leading to a false air of authority to the theories. Speaking of the theorists. Farrer wrote that "when politicians and media don’t give them voice they feel more threatened, more suspicious, cornered, helpless; and so they go on the attack". [230]
Geraldo Rivera , the host of Geraldo at Large , a news magazine run by Fox News Channel , expressed openness towards claims that question the causes of the collapse of 7 World Trade Center . [231] Andrew Napolitano , a legal analyst for Fox News and former judge at the New Jersey Superior Court , voiced support for skepticism about the collapse of the high-rise building, and for Rivera investigating the event. [231]
Alex Jones was fired by 70 radio stations when he began espousing 9/11 conspiracy theories, but by 2011 was espousing these and other conspiracy theories on morning TV shows and was the subject of lengthy magazine profiles. [40] [232]
On August 29, 2010, BBC Two broadcast a program entitled The Conspiracy Files: 9/11 – Ten Years On . [88]
On September 5, 2011, The Guardian published an article entitled, "9/11 conspiracy theories debunked". The article noted that unlike the collapse of World Trade Centers 1 and 2 a controlled demolition collapses a building from the bottom and explains that the windows popped because of collapsing floors. The article also said there are conspiracy theories that claim that 7 World Trade Center was also downed by a controlled demolition, that the Pentagon being hit by a missile, that the hijacked planes were packed with explosives and flown by remote control, that Israel was behind the attacks, that a plane headed for the Pentagon was shot down by a missile, that there was insider trading by people who had foreknowledge of the attacks were all false. [233]
Toure Neblett , who has Tweeted his suspicions about the attack on the Pentagon, is one of the hosts of the MSNBC program The Cycle , which debuted on June 25, 2012. [234]

Criticism
Critics of these conspiracy theories say they are a form of conspiracism common throughout history after a traumatic event in which conspiracy theories emerge as a mythic form of explanation. [235] A related criticism addresses the form of research on which the theories are based. Thomas W. Eagar, an engineering professor at MIT , suggested they "use the 'reverse scientific method'. They determine what happened, throw out all the data that doesn't fit their conclusion, and then hail their findings as the only possible conclusion." Eagar's criticisms also exemplify a common stance that the theories are best ignored. "I've told people that if the argument gets too mainstream, I'll engage in the debate." According to him, this happened when Steve Jones, a physics professor at Brigham Young University , took up the issue. [236]
Michael Shermer, writing in Scientific American , said: "The mistaken belief that a handful of unexplained anomalies can undermine a well-established theory lies at the heart of all conspiratorial thinking. All the evidence for a 9/11 conspiracy falls under the rubric of this fallacy. Such notions are easily refuted by noting that scientific theories are not built on single facts alone but on a convergence of evidence assembled from multiple lines of inquiry." [237]
Scientific American , [237] Popular Mechanics , [238] and The Skeptic's Dictionary [239] have published articles that rebut various 9/11 conspiracy theories. Popular Mechanics has published a book entitled Debunking 9/11 Myths that expands upon the research first presented in the article. [240] In the foreword for the book Senator John McCain wrote that blaming the U.S. government for the events "mars the memories of all those lost on that day" and "exploits the public's anger and sadness. It shakes Americans' faith in their government at a time when that faith is already near an all-time low. It trafficks in ugly, unfounded accusations of extraordinary evil against fellow Americans." [241] Der Spiegel dismissed 9/11 conspiracy theories as a "panoply of the absurd", stating "as diverse as these theories and their adherents may be, they share a basic thought pattern: great tragedies must have great reasons." [242]
Journalist Matt Taibbi , in his book The Great Derangement , discusses 9/11 conspiracy theories as symptomatic of what he calls the "derangement" of American society; a disconnection from reality due to widespread "disgust with our political system". [177] Drawing a parallel with the Charismatic Movement , he argues that both "chose to battle bugbears that were completely idiotic, fanciful, and imaginary," instead of taking control of their own lives. [177] While critical, Taibbi explains that 9/11 conspiracy theories are different from " Clinton -era black-helicopter paranoia", and constitute more than "a small, scattered group of nutcases [...] they really were, just as they claim to be, almost everyone you meet." [177]
Columnist Matt Mankelow, writing for the online edition of the British Socialist Worker , concludes that 9/11 Truthers, while "desperately trying to legitimately question a version of events", end up playing into the hands of the neoconservatives they are trying to take down by creating a diversion. Mankelow noted that this has irritated many people who are politically left-wing. [243]
David Aaronovitch , a columnist for The Times , in his book entitled Voodoo Histories: The Role of the Conspiracy Theory in Shaping Modern History that was published in May 2009, claimed that the theories strain credulity. [74] Aaronovitch also charged that 9/11 conspiracy theorists have exaggerated the expertise of those supporting their theories, and noted that 9/11 conspiracy theorists including David Ray Griffin cross cite each other. [244] He also claims the popularity of 9/11 conspiracy theories has hurt the War on Terror . According to Aaronovitch, because a significant portion of educated Pakistanis believe that George W. Bush brought the towers down, dealing with the Taliban is difficult "because they actually don't believe the fundamental premise on which the war against terror was waged". [245]
Harvard Law professor Cass Sunstein co-authored a 2009 paper which used members of the 9/11 Truth movement and others as an examples of people who suffer from "crippled epistemologies", to public trust and the political system. He wrote that "[t]hey do not merely undermine democratic debate [...] In extreme cases, they create or fuel violence. If government can dispel such theories, it should do so." [40]
In June 2011 the Royal Institute of British Architects was criticized for hosting a lecture by Richard Gage, president of Architects & Engineers for 9/11 Truth . Rick Bell, the director of the American Institute of Architects New York chapter, who was a witness to the 9/11 attacks, said that "no amount of money" would persuade him to allow the group to talk at his headquarters and said that Gage lacks credibility among the professional community. Eugine Kohn , former spokesperson for the American Institute of Architects, said Gage's theories were "ridiculous", "[t]here were no explosives planted", and "[t]he buildings were definitely brought down by the planes". The decision to host the event was also criticized by the former president of the Royal Institute of British Architects and the founding president of the American Institute of Architects ' United Kingdom chapter. Gage has been warned by the AIA against giving a false impression that he has a relationship with them. A July article in the organization's magazine criticized Gage for continuing to intimate that he has an association with them and claimed there were no architects at an Architects and Engineers for 9/11 Truth screening held in an American Institute of Architects boardroom [246] The Royal Institute of British Architects released a statement saying the perception that the group endorses events held in its buildings is "regrettable", and said they would review policy on "private hire" of its buildings. [247] Anthony Summers and Robbyn Swan offer scathing criticism of many of the above theories in The Eleventh Day , their 2011 investigation of the attacks. [248]
U.S. representative Peter T. King , chairmen of the House Homeland Security Committee , said 9/11 conspiracy theorists "trivialize" the "most tragic event to affect the United States" and that "[p]eople making these claims are disgraceful, and they should be ashamed of themselves". [249]
The hosts of " The Skeptics' Guide to the Universe " (the "SGU") have spoken repeatedly about the "absurdity of 9/11 conspiracy theories". In addition to critiquing the theories using the same or similar arguments as the above, the "SGU" hosts say that, like most conspiracy theories, this one collapses under its own weight and contradicts itself. In order for the 9/11 conspiracy theories to be correct, the U.S. government would not only have to orchestrate the claimed false flag operation regarding the airplanes that crashed into the World Trade Center, but they would also have to orchestrate a superfluous controlled demolition and cover their tracks so flawlessly that it becomes indistinguishable to physicists from the "official story," yet the plan would have to be flawed enough so that "losers in their mothers' basement" will discover the conspiracy. [250]

In politics
Former Canadian Liberal Party leader Stéphane Dion forced a candidate from Winnipeg , Lesley Hughes, to terminate her campaign after earlier writings from Hughes surfaced in which Hughes wrote that U.S., German, Russian and Israeli intelligence officials knew about the 9/11 attacks in advance. [251] [252] Earlier, Peter Kent , Deputy Editor of Global Television Network News and Conservative Party candidate in the 2008 Canadian election, had called for Hughes's resignation saying that the 9/11 Truth movement is "one of Canada’s most notorious hatemongering fringe movements" composed of "conspiracy theorists who are notorious for holding anti-Semitic views." [253] On June 16, 2009, Hughes sued Kent, the Canadian Jewish Congress , the B'nai B'rith of Canada and four senior members of the two organizations alleging the antisemitic allegations were untrue and defamatory and ruined her career. [254] Later another Conservative Party candidate called for the leader of the New Democratic Party to fire a candidate for her pro 9/11 truth views. [255] Zijad Delic head of Canada's largest Muslim advocacy organization, the Canadian Islamic Congress is trying to remove 9/11 conspiracy theorists from the board of the organization, in an effort to what he describes as purifying within and totally canadianize the organization. [256]
In 2008, calls for the resignation of Richard Falk , the special rapporteur on human rights in the Palestinian territories for the United Nations, were partially based on his support investigating the validity of 9/11 conspiracy theories. [257] In 2011 Falk praised a book by David Ray Griffin. Falk was condemned for his remarks by United Nations Secretary General Ban Ki-moon and United States ambassador to the United Nations Susan Rice . [258]
In February 2009, Aymeric Chauprade , a professor of geopolitics at CID military college in Paris, was fired by French Defence Minister Hervé Morin for writing a book entitled Chronicle of the Clash of Civilizations that espoused 9/11 conspiracy theories. [259]
In September 2009, Van Jones , an adviser to US President Barack Obama, resigned after his signature on a 2004 petition calling for an investigation into whether government officials deliberately allowed the 9/11 attacks to occur and other controversial statements came to light drawing criticism. Van Jones said he was a victim of a smear campaign, adding that he does not currently, nor ever has agreed with that theory. [260]
The 9/11 truth movement became an issue in the 2010 Texas Gubernatorial Republican primary when candidate Debra Medina replied when asked by Glenn Beck about US government involvement in the 9/11 attacks: "I think some very good questions have been raised in that regard, there are some very good arguments, and I think the American people have not seen all of the evidence there, so I have not taken a position on that." After being criticized for the remarks by opposing candidates, Medina said that she has never been a 9/11 truth movement member and believes the twin towers were attacked by Muslim terrorists. [261] [262]
On September 23, 2010, Iranian President Mahmoud Ahmadinejad in a speech to the United Nations said that "[t]he majority of the American people, as well as other nations and politicians, believe [...] some segments within the U.S. government orchestrated the attack to reverse the declining U.S. economy and its grips on the Middle East in order also to save the Zionist regime". The remarks prompted the United States delegation as well as others to walk out. [263] U.S. President Barack Obama criticized Ahmadinejad's remarks before the United Nations General Assembly on the following day, saying that "[f]or him to make a statement like that was inexcusable" and called the remarks "offensive" and "hateful". [264] Previously Ahmadinejad had described the 9/11 attacks as a "suspect event" [265] and suggested that the Bush Administration was involved in 9/11. [266] [267] The Iranian president repeated his claims in 2011 with another appearance at the UN and was thereafter criticized in an article appearing in al-Qaeda's magazine, Inspire . The article claimed that Ahmadinejad was jealous of al-Qaeda because the stateless and under-fire Islamic terrorist organization did on 9/11 what Iran could not do. [268]
In 2012, Egyptian President Mohamed Morsi has called for a scientific conference to look into the events of 9/11 and speculated that the attacks were an inside job. According to an international poll that same year, huge majorities in Muslim countries prefer to believe baseless conspiracy theories rather than listen to the mainstream facts of what happened on September 11, 2001, in New York City and Washington. Although al-Qaeda occasionally brags about its "achievement," 75 percent of Egyptian citizens, for example, still deny that Arabs carried out the attacks, as a Pew study reported in July 2011. [269]
In April 2016, the Deputy Prime Minister of Sweden, Åsa Romson , called the events of September 11 an "accident" and refused to apologise for it. [270] [271]

Legal cases
Army specialist April Gallop filed suit claiming that Vice President Dick Cheney , Secretary of Defense Donald Rumsfeld , and other Bush administration officials orchestrated the 9/11 attacks and that the Pentagon was hit by an attack ordered by Cheney. The suit was dismissed in 2010 by Judge Denny Chin , who said the claim was "the product of cynical delusion and fantasy". Her lawyers filed an appeal to the U.S. Court of Appeals which in April 2010 issued a show cause order why the lawyers and Gallop should not be sanctioned for filing a frivolous lawsuit. Her lawyers asked that the judges on the Court of Appeals recuse themselves because their emotions made them prejudge the case and abuse their power. On October 14, 2011, the judges sanctioned her lawyers $15,000 each for both the frivolous lawsuits and the accusations of prejudice. Gallop was not fined because of her unfamiliarity with the law. [272]

See also
WebPage index: 00061
Internet Watch Foundation and Wikipedia
On 5 December 2008, the Internet Watch Foundation (IWF), a British watchdog group , blacklisted content on the English Wikipedia related to Scorpions' 1976 studio album Virgin Killer , due to the presence of its controversial cover artwork , depicting a young girl posing nude, with a faux glass shatter obscuring her genitalia. The image was deemed to be "potentially illegal content" under English law which forbids the possession or creation of indecent photographs of children. The IWF's blacklist are used in web filtering systems such as Cleanfeed .
The URL to the image's description page , which depicts the cover art, was also blacklisted; however thumbnails and the image itself remained accessible. The album cover had been deemed controversial at the time of its release, [1] and was replaced in some markets with an alternate cover image featuring a photo of the band members. [1] The IWF described the image as "a potentially illegal indecent image of a child under the age of 18". [2] Wikipedia's policies state that it does not censor content "that some readers consider objectionable or offensive, even exceedingly so", although it does remove content that is "obviously inappropriate", violates other Wikipedia policies, or is illegal in the United States. [3]
As well as the direct consequence of censoring the article and image for UK-based readers of the English Wikipedia through the affected ISPs (a censoring that could be circumvented), [4] and that the album cover was being made available unfiltered on other major sites including Amazon.co.uk [2] (from which it was later removed), and available for sale in the UK, [5] the action also had some indirect effects on Wikipedia , namely temporarily preventing all editors using said ISPs in the UK from contributing to any page of the encyclopedia, [6] and preventing anonymous edits from these ISPs while the URL remained on the blacklist. This was described by the IWF as unintended "collateral damage". [7] This was due to the proxies used to access Wikipedia, as Wikipedia implements a blocking policy whereby contributors can be blocked if they vandalise the encyclopedia. Therefore, all vandalism coming from one ISP would be directed through one proxy—hence one IP—and all of the ISP's customers using that proxy would be barred from editing.
After invoking its appeals procedure and reviewing the situation, the IWF reversed their blacklisting of the page on 9 December 2008, [8] [9] and announced that they would not blacklist other copies of the image hosted outside the UK. [10]

Background
The album art of the Scorpions' album Virgin Killer , featuring a young girl fully nude with a "smashed glass" effect covering her genitalia, [5] was deemed controversial at the time of its release. [1] The cover was replaced in some markets with an alternate cover image featuring a photo of the band members. RCA Records refused to sell the controversial album cover in the United States. [11] The cover was not the only Scorpions' cover which caused controversy however, as the covers for Taken by Force [12] and Lovedrive [1] have also caused controversy with their content.
In the United Kingdom, access to illegal content (such as child pornography ) was strictly self-regulated by individual internet service providers . This began when BT Group introduced Cleanfeed , a server-side filtering system which uses data obtained from the Internet Watch Foundation . The IWF is a Quango organisation that operates a website where users can report web pages containing illegal or dubious content to be added to their blacklists. [13] This was implemented in order to prevent users from accessing this material, since it is illegal to possess an indecent image of a child under the age of 18 per the Protection of Children Act . [14] British ISPs were later obligated by the government to implement filters for illegal content by the beginning of 2007. [15] [16]

Addition to IWF blacklist
On 5 December 2008 the Internet Watch Foundation added the Wikipedia URLs for the Virgin Killer article and the description page of the image to its blacklist. [17] After the blacklisting, users of major UK ISPs, including BT , Vodafone , Virgin Media / Tesco.net , Be / O2 , EasyNet/UK Online / Sky Broadband , Orange , Demon , and TalkTalk (Opal Telecom), were unable to access the content. [2]
Sarah Robertson, director of communications for the IWF, said that the image was rated "1 on a scale of 1 to 5, where 1 is the least offensive". She described the picture as "erotic posing with no sexual activity". [17] While the image itself has not been flagged as "illegal", IWF determined it to be a "potentially illegal indecent image of a child under the age of 18". [18]
The IWF said they were first notified of the Wikipedia URL on 4 December 2008. This followed the May 2008 reporting of the cover image on Wikipedia by U.S.-based social conservative site WorldNetDaily to the Federal Bureau of Investigation . A subsequent investigation by the FBI concluded that the artwork did not violate any US laws. [19] An officer of the Concerned Women for America , a conservative Christian advocacy group, commented, "By allowing that image to remain posted, Wikipedia is helping to further facilitate perversion and paedophilia". [18] [20] EContent magazine subsequently reported that the discussion page associated with the article declared "Prior discussion has determined by broad consensus that the Virgin Killer cover will not be removed", and asserted that Wikipedia contributors "favour inclusion in all but the most extreme cases". [21] However, according to The Guardian because "the IWF doesn't talk to people outside of the UK they weren't able to appreciate what was going on". Internet security expert Richard Clayton explained that "We see this borderline stuff all the time; it's a no-win", before adding that the decision seems to have been based on taking the image out of context, particularly "given that you can go into HMV and buy a copy on the high street". [22] On 9 December 2008 the IWF reversed its blacklist of the Wikipedia pages on the basis of the "contextual issues involved in this specific case and, in light of the length of time the image has existed and its wide availability". [10]

Effects on Wikipedia
The blacklisting of Virgin Killer also caused other inadvertent issues for Wikipedia users in the United Kingdom. Usually most Internet users have a unique IP address visible to websites. However, as a result of ISPs using the IWF blacklist implemented through Cleanfeed technology, traffic to Wikipedia via those affected ISPs was then routed through a small number of proxy servers . [23] This caused problems for users of the site. Since Wikipedia allows users to anonymously edit its encyclopaedia articles, these individuals are identified only through their IP addresses, which are used to selectively block users who vandalise the site or otherwise break its rules. The proxy filtering makes it impossible to uniquely distinguish users, and to prevent vandalism Wikipedia "instituted a blanket ban on anonymous edits from the six ISPs, which account for 95% of British residential internet users". [24] This had the immediate effect of requiring nearly all registered users in the UK to request the lifting of IP Autoblocks on their accounts before they could edit again, and the de facto permanent effect of barring any contribution from people without user accounts on the site , who contribute merely under an IP address and not a user name.
The MediaWiki software that Wikipedia runs on can interpret X-Forwarded-For (XFF) headers, allowing Wikipedia to identify a user's main IP address rather than the proxy IP address, allowing the ability to block proxy users individually by their client's IP rather than the proxy server IP (avoiding the need to block the whole proxy due to the actions of a single user). [23] However, none of the ISPs subscribing to this system pass XFF information to Wikipedia, having the impact of reversing the normal method of identification and blocking on Wikipedia. [25] IP addresses assumed to be assigned to an individual person or organisation were assigned instead to millions of people and thousands of registered editors. [26] Wikipedia servers saw them all as the IP of the proxy rather than each as the IP of their own machine.
Due to erroneous use of Border Gateway Protocol (BGP) and other routing technology to redirect the connections to the filtering proxies, users of some networks were temporarily prevented from accessing or editing any content hosted by Wikimedia, a problem reminiscent of Pakistan's accidental blocking of YouTube for much of the world instead of only their own citizens. [27]

Responses
On 7 December 2008, the Wikimedia Foundation , a non-profit organisation which supports Wikipedia, issued a press release about the blacklisting of their sites by the IWF stating that they had "no reason to believe the article, or the image contained in the article, has been held to be illegal in any jurisdiction anywhere in the world", and noting that not just the image but the article itself had been blocked. [28]
On 9 December 2008, Jimmy Wales , co-founder of Wikipedia, who holds the "community founder seat" on the Wikimedia Foundation Board of Trustees , told the UK's Channel 4 News that he had briefly considered legal action. [29] [30] [31] After the block had been removed, Mike Godwin , general counsel for the Wikimedia Foundation, stated "there is still plenty to be troubled by in the operations of the Internet Watch Foundation and its blacklist". [32]
On 9 December 2008, the IWF rescinded the block, [33] [34] [35] [36] [37] issuing the following statement: [10]

Aftermath
The incident was commented in some countries implementing or considering to implement Internet filtering or censorship plans. In Australia, Electronic Frontiers Australia vice-chairman Colin Jacobs said that "[the] incident in Britain, in which virtually the entire country was unable to edit Wikipedia because the country's Internet Watch Foundation had blacklisted a single image on the site, illustrated the pitfalls of mandatory ISP filtering". [38] [39] The Sydney Morning Herald has commented that "Ironically, the banning of the image has only made it visible to more people as news sites publicise the issue and the image spreads across sites other than Wikipedia." an example of the Streisand effect . [24]
At the time of the incident Amazon US were also displaying the image on their site and the IWF stated that it "might yet add Amazon US to its list of 'blocked' sites for hosting the picture"; [17] however, Amazon subsequently took the decision to remove the image from their site. [40] In an impact study preparing a bill dealing with cybercrime , the Cabinet of France listed the Virgin Killer block as an example of indiscriminate filtering. [41]
The Electronic Frontier Foundation criticised the IWF's reasoning: [42]
The IWF continues to assert that the image is indeed child porn, and asserts that the image would be blocked if it were on a British server. [43]

See also
WebPage index: 00062
Vulva
The vulva ( Latin : wrapper, covering , plural vulvae or vulvas ) [1] consists of the external female sex organs . [2] The vulva includes the mons pubis , labia majora , labia minora , clitoris , bulb of vestibule , vulval vestibule , urinary meatus , greater and lesser vestibular glands , and the vaginal opening . [3] [4] The urinary meatus is also included as it opens into the vulval vestibule. Other features of the vulva include: the pudendal cleft , sebaceous glands , the urogenital triangle (anterior part of the perineum ), and pubic hair .
As the vulva is the gateway to the uterus (womb), a double layer of protection is provided by the folds of the outer and inner labia . The vulva can be affected by many disorders which can often result in itching . Vulvovaginal health measures can prevent many of these. [2]

Structure

Structures and features
The main structures of the vulva are: the mons pubis , the labia ( majora and minora ) including the frenulum of labia minora , the external part of the clitoris , the urinary meatus , the vaginal opening and hymen , and the greater and lesser vestibular glands .
Other features include: the pudendal cleft , sebaceous glands , the vulval vestibule , and the urogenital triangle (anterior part of the perineum ).
The soft mound (mons pubis) at the front of the vulva is formed by fatty tissue in the pubic region covering the pubic bone . Mons pubis is Latin for "pubic mound" and is present in both sexes . Sometimes a variant term is used specific to women—the mons veneris ("mound of Venus "). [5] The mons pubis separates into the labia —two pairs of folds of tissue that protect the vulvar vestibule.
The outer pair of folds are the labia majora, ( New Latin : larger lips ). The labia majora are divided by the pudendal cleft and they contain and protect the other, more delicate structures of the vulva. The labia majora meet again at the urogenital triangle (the anterior part of the perineum ) between the pudendal cleft and the anus . The color of the outside skin of the labia majora is usually close to the overall skin color of the individual, although there is considerable variation. The inside skin and mucous membrane are often pink or brownish.
The labia minora (smaller lips) are the inner two soft folds of the labia, within the labia majora, and contain numerous sebaceous glands. [6] They meet at the frenulum of the labia minora which is a fold of restrictive tissue. Though called the smaller lips they can often be of considerable size, and may protrude outside the labia majora. Much of the variation among vulvas lies in the significant differences in the size, shape, and color of the labia minora. This variation has also been evidenced in a large display of 400 vulval casts called the Great Wall of Vagina created to fill the lack of information of what a normal vulva looks like. The casts taken from a large and varied group of women showed clearly that there is much variation. [7]
The clitoris is located at the front of the vulva, where the labia minora meet, at the frenulum of clitoris. The visible portion of the clitoris is the clitoral glans . Typically, the clitoral glans is roughly the size and shape of a pea , although it can be significantly larger or smaller. The clitoral glans is highly sensitive, containing as many nerve endings as the homologous organ in males, the glans penis . The clitoral hood , is a protective fold of skin that normally covers the clitoris, however this may not completely cover larger than normal clitorises. The clitoral hood is the female equivalent of the male foreskin . Often the clitoral hood is only partially hidden inside of the pudendal cleft.
The area between the labia minora where the vaginal opening and urinary meatus are located is called the vulval vestibule . The urinary meatus is below the clitoris and just in front of the vagina.
The opening of the vagina is located at the bottom of the vulval vestibule, toward the perineum. The term introitus is more technically correct than "opening", since the vagina is usually collapsed, with the opening closed, unless something is inserted. The introitus is sometimes partly covered by a membrane called the hymen . The hymen will usually rupture during the first episode of vigorous sex, and the blood produced by this rupture has been seen as to signify virginity . However, the hymen may also rupture spontaneously during exercise (including horseback riding ) or be stretched by normal activities such as use of tampons and menstrual cups , or be so minor as to be unnoticeable. In some rare cases, the hymen may completely cover the vaginal opening, requiring surgery .
On either side of the back part of the vaginal opening are the two greater vestibular glands also known as Bartholin's glands . These glands secrete mucus and a vaginal and vulval lubricant. [8] They are homologous to the bulbourethral glands in the male.The lesser vestibular glands also known as Skene's glands, are found on the anterior wall of the vagina. They are homologues of the male prostate gland and are also referred to as the female prostate. [9]
The skin of the vulva is more delicate than other areas of skin. [10] Pubic hair is much coarser than other body hair. It appears at puberty and is considered a secondary sex characteristic . [11] [12] The mons pubis and the labia majora become covered by pubic hair and it can also grow on the inner thighs and perineum. Pubarche is the first appearance of pubic hair and can occur independently of puberty. Premature pubarche may indicate underlying endocrine conditions . [13] Apocrine sweat glands secrete sweat into the pubic hair follicles. This is broken down by bacteria on the skin and produces an odor, [14] which some consider to act as a sex pheromone (sexual attractant).
The tissues of the vulva are highly vascularised and blood supply is provided by the three pudendal arteries . Venous return is via the external and internal pudendal veins . The organs and tissues of the vulva are drained by a chain of superficial inguinal lymph nodes located along the blood vessels. [4] [11]

Nerve supply
The ilioinguinal nerve originates from the first lumbar nerve and gives branches that include the anterior labial nerves which supply the skin of the mons pubis and the labia majora. The perineal nerve is one of the terminal branches of the pudendal nerve and this branches into the posterior labial nerves to supply the labia. The pudendal nerve branches include the dorsal nerve of clitoris which gives sensation to the clitoris.
The pudendal nerve enters the pelvis through the lesser sciatic foramen and continues medial to the internal pudendal artery . The point where the nerve circles the ischial spine is the location where a pudendal block of local anesthetic can be administered to inhibit sensation to the vulva. A number of smaller nerves split off from the pudendal nerve. The deep branch of the perineal nerve supplies the muscles of the perineum and a branch of this supplies the bulb of the vestibule. [4] [15]

Muscle tissue
Pelvic floor muscles help to support the vulvar structures. [4] The voluntary, pubococcygeus muscle , part of the levator ani muscle partially constricts the vaginal opening. [12] Other muscles support the vulvar area. These are the transverse perineal muscles , the bulbospongiosus , and the ischiocavernosus muscles. [11] The muscles are part of the urogenital triangle .

Development

Fetus
The appearance of the external genital region is the same for males and females during the eighth week. [16]
Beginning in the third month of development, the genital tubercle becomes the clitoris. The urogenital folds become the labia minora , and the labioscrotal swellings become the labia majora .

Childhood
At birth, the neonate 's vulva (and breast tissue—see witch's milk ) may be swollen or enlarged as a result of having been exposed, via the placenta , to her mother's increased levels of hormones. The clitoris is proportionally larger than it is likely to be later in life. Within a short period of time as these hormones wear off, the vulva will shrink in size. From then until puberty the vulva doesn't change in appearance, other than growing in proportion with the rest of the body.

Puberty
The onset of puberty produces a number of changes. The structures of the vulva become proportionately larger and may become more pronounced. Coloration may change and pubic hair develops, first on the labia majora, and later spreading to the mons pubis, and sometimes the inner thighs and perineum. The labia minora may grow more prominent and undergo changes in color. [17]
In preadolescent girls, the vulva appears to be positioned further forward than in adults, showing a larger percentage of the labia majora and pudendal cleft when standing. During puberty the mons pubis enlarges, pushing the forward portion of the labia majora away from the pubic bone, and parallel to the ground (when standing). Variations in body fat levels affect the extent to which this occurs.

Post-menopause
During menopause , hormone levels decrease, and as this process happens, reproductive tissues which are sensitive to these hormones shrink in size.The mons pubis, labia, and clitoris are reduced in size in post-menopause, although not usually to pre-puberty proportions.This is a condition called vulval atrophy and the decrease in estrogen can cause pale, itchy or sore skin. [10]

Sexual homology
Most male and female sex organs originate from the same tissues during fetal development; this includes the vulva. The anatomy of the vulva is related to the anatomy of the male genitalia by a shared developmental biology . Organs that have a common developmental ancestry in this way are said to be homologous .
The clitoral glans is homologous to the glans penis in males, and the clitoral body and the clitoral crura are homologous to the corpora cavernosa of the penis . The labia majora, labia minora, and clitoral hood are homologous to the scrotum , shaft skin of the penis , and the foreskin , respectively. The vestibular bulbs beneath the skin of the labia minora are homologous to the corpus spongiosum , the tissue of the penis surrounding the urethra. The greater vestibular glands are homologous to the bulbourethral glands in males.

Function and physiology
The vulva has a sexual function; these external organs are richly innervated and provide pleasure when properly stimulated. There are a number of different secretions associated with the vulva, including urine , sweat , menses , sebum , and secretions from the vestibular glands and vaginal wall . These secretions contain a mix of chemicals, including pyridine , squalene , urea , acetic acid , lactic acid , complex alcohols , glycols , ketones , and aldehydes . During sexual arousal, vaginal lubrication increases. Smegma is a white substance formed from a combination of dead cells, skin oils, moisture and naturally occurring bacteria , that forms in the genitalia. In females it collects around the clitoris and labial folds. [18] It is also found in other mammals
Some women produce aliphatic acids. These acids are a pungent class of chemicals which other primate species produce as sexual-olfactory signals. While there is some debate, researchers often refer to them as human pheromones . These acids are produced by natural bacteria resident on the skin. The acid content varies with the menstrual cycle , rising from one day after menstruation , and peaking mid-cycle, just before ovulation. [ citation needed ]

Sexual arousal
Sexual arousal results in a number of physical changes in the vulva. Vaginal lubrication begins first. Vulva tissue is highly vascularised ; arterioles dilate in response to sexual arousal and the smaller veins will compress after arousal, [4] [16] so that the clitoris and labia minora increase in size. Increased vasocongestion in the vagina causes it to swell, decreasing the size of the vaginal opening by about 30%. The clitoris becomes increasingly erect, and the glans moves towards the pubic bone, becoming concealed by the hood. The labia minora increase considerably in thickness. The labia minora sometimes change considerably in color, going from pink to red in lighter skinned women who have not borne a child, or red to dark red in those that have. Immediately prior to orgasm , the clitoris becomes exceptionally engorged, causing the glans to appear to retract into the clitoral hood. Rhythmic muscle contractions occur in the outer third of the vagina, as well as the uterus and anus. Contractions become less intense and more randomly spaced as the orgasm continues. An orgasm may have as few as one or as many as 15 or more contractions, depending on its intensity. Orgasm may be accompanied by female ejaculation , causing liquid from either the Skene's gland or bladder to be expelled through the urethra. The pooled blood begins to dissipate, although at a much slower rate if an orgasm has not occurred. The vagina and vaginal opening return to their normal relaxed state, and the rest of the vulva returns to its normal size, position and color. [ citation needed ]

Clinical significance
Pruritus vulvae is itching in the vulvar region and is a symptom of many underlying causes. Pubic shaving can result in pseudofolliculitis pubis and folliculitis as well as cuts to the labia and clitoris, and ingrown hairs . [19] Pubic shaving increases the risk of contracting the sexually transmitted viral infection, molluscum contagiosum . [20]
A less common inflammatory disorder is mucosal genital lichen planus . A severe variant of this is vulvovaginal gingival syndrome which can lead to narrowing of the vagina, [21] or vulva destruction. [22]

Vulvodynia
Vulvodynia is chronic pain in the vulvar region. There is no single identifiable cause. A sub-type of this is vulvar vestibulitis but since this is not thought to be an inflammatory condition it is more usually referred to as vestibulodynia . Vulvar vestibulitis usually affects pre-menopausal women.

Infections
Vulvar organs and tissues can become infected with different pathogens , or infested by parasites . Any inflammation caused is called vulvitis . Sexually transmitted infections may cause signs and symptoms on the vulva even though the agents may not be visible in the vulvar region. Vulvovaginal health measures can help to prevent many disorders. [23] Vaginitis can have many causes and different health measures can help its prevention . The following infections include those that can also be classed as sexually transmitted infections . Infections of the vagina such as vaginosis and of the uterus may produce vaginal discharge which can be an irritant when it comes into contact with the vulvar tissue, causing itching , inflammation and discomfort. [24] [25] Bacterial infections include: Chancroid caused by Haemophilus ducreyi ; Granuloma inguinale caused by Klebsiella granulomatis ; Syphilis caused by Treponema pallidum ; and Gonorrhea caused by the bacterium Neisseria gonorrhoeae .
Viral infections include genital herpes caused by the herpes simplex virus (1 and 2), transmissible with or without visible blisters; the lentivirus HIV ( human immunodeficiency virus )—transmissible in venereal fluids, semen, breast milk, and blood; HPV ( Human papillomavirus )—skin and mucosal contact. 'High risk' types of HPV can cause vulvar cancer . [26] [27] Some other types of HPV cause genital warts . Molluscum contagiosum caused by a poxvirus ( molluscum contagiosum virus MCV) transmissible on close contact.
A common fungal infection , commonly known as thrush is vaginal yeast infection a type of candidiasis caused by a number of species of Candida .
Parasitic infections include trichomoniasis , pediculosis pubis and scabies . Trichomoniasis is a microparasitic infection caused by the protozoan Trichomonas vaginalis . This is the most common vulval infection (in industrialised societies) and is transmitted by sexual contact.
Pediculosis pubis commonly called crabs , is a disease caused by the ectoparasite crab louse ( Pthiras pubis) .
Scabies also known as the seven year itch is caused by another ectoparasite, the mite Sarcoptes scabiei usually transmitted by skin to skin contact.

Cancer
Many malignancies can develop in vulvar structures. [4] Most vulvar cancers are squamous cell carcinomas and are usually found in the labia particularly the labia majora. [28] The second most common vulval cancer (though not very common) is vulval melanoma . [29] A vulvectomy may need to be performed in order to remove some or all of the vulva. This procedure is usually performed as a last resort in certain cases of cancer , [30] vulvar dysplasia or vulvar intraepithelial neoplasia . [31]
Signs and symptoms can include: itching , or bleeding ; skin changes including rashes, sores, lumps or ulcers , and changes in vulval skin coloration. Pelvic pain might also occur. [32]

Other

Childbirth
The vulvar region is at risk for trauma during childbirth . [35] During childbirth, the vagina and vulva must stretch to accommodate the baby's head (approximately 9.5 cm (3.7 in)). This can result in tears known as perineal tears in the vaginal opening, and other structures within the perineum . [36] An episiotomy (a pre-emptive surgical cutting of the perineum) is sometimes performed to facilitate delivery and limit tearing. Perineal tearing or cutting does leave scar tissue .
No advantages have been demonstrated in the shaving of pubic hair prior to childbirth. Rates of complications remain the same between women who were shaved and those unshaven. [37] [38]

Surgery
Genitoplasties are surgical procedures that can be carried out to repair, restore or alter vulvar tissues, particularly following damage caused by injury or cancer treatment. These procedures include vaginoplasty which can also be performed as a cosmetic surgery . Other cosmetic surgeries to change the appearance of external structures include labiaplasties .
Elective vulvar surgery has been criticized by clinicians. [39] [40] The American College of Obstetricians and Gynecologists recommends that women be informed of the risks of these surgeries. They refer to the lack of data relevant to their safety and effectiveness and to the potential associated risks such as infection , altered sensation, dyspareunia , adhesions , and scarring . [41] There is also a percentage of people seeking elective surgery who may be suffering from body dysmorphic disorder and surgery in these cases can be counterproductive. [42]

Society and culture
Many cultures have no or few taboos on exposure of the breasts, but the vulva and pubic triangle are always the first areas to be covered. A Khoisan woman Saartjie Baartman , the so-called "Hottentot Venus" who was exhibited in London at the beginning of the nineteenth century, was paid to display her large buttocks , but she never revealed her vulva. [43] Khoisan women were said to have elongated labia , leading to questions about, and requests to exhibit, their sinus pudoris , "curtain of shame", or tablier (the French word for "apron"). To quote Georges Cuvier , "The labia minora , or inner lips, of the ordinary female genitalia are greatly enlarged in [Khoisan] women, and may hang down three or four inches below the vagina when women stand, thus giving the impression of a separate and enveloping curtain of skin". [44]
The naming of the external genitalia (in both sexes) as pudenda membra (parts to be ashamed of) dates from the mid-17th century. [45] The naming clearly influenced the general perception of the vulva and this is shown in depicted gynaecological procedures. The examiner is adopting the compromise procedure where the woman's genitals cannot be seen.
In some cultures, including modern Western culture, women have shaved or otherwise removed the hair from part or all of the vulva. When high-cut swimsuits became fashionable, women who wished to wear them would remove the hair on either side of their pubic triangles, to avoid exhibiting pubic hair . Other women relish the beauty of seeing their vulva with hair, or completely hairless, and find one or the other more comfortable. The removal of hair from the vulva is a fairly recent phenomenon in the United States , Canada , and Western Europe , usually in the form of bikini waxing or Brazilian waxing , but has been prevalent in many Eastern European and Middle Eastern cultures for centuries, usually due to the idea that it may be more hygienic, or originating in prostitution and pornography. Hair removal may include all, most, or some of the hair. French waxing leaves a small amount of hair on either side of the labia or a strip directly above and in line with the pudendal cleft called a landing strip .
Islam teaching includes Muslim hygienical jurisprudence a practice of which is the removal of pubic hair. [46]
Several forms of genital piercings can be done in the female genital area, and include the Christina piercing , the Nefertiti piercing , the fourchette piercing , and labia piercings . Piercings are usually performed for aesthetic purposes, but some forms like the clitoral hood piercing might also enhance pleasure during sex . Though they are common in traditional cultures , intimate piercings are a fairly recent trend in Western society . [47] [48] [49]

Altering the female genitalia
The most prevalent form of genital alteration in some countries is female genital mutilation : removal of any part of the female genitalia for cultural, religious or other non-medical reasons. This practice is highly controversial as it is often done to non-consenting minors and for debatable (often misogynistic) reasons. An estimated 100 to 140 million girls and women in Africa and Asia have experienced some form of genital mutilation. [50] [51]
Female genital surgery includes laser resurfacing of the labia to remove wrinkles, labiaplasty (reducing the size of the labia) and vaginal tightening . In September 2007, the American College of Obstetricians and Gynecologists issued a committee opinion on these and other female genital surgeries, including "vaginal rejuvenation", "designer vaginoplasty ", "revirgination", and " G-spot amplification". This opinion states that the safety of these procedures has not been documented. ACOG recommends that women seeking these surgeries need to be informed about the lack of data supporting these procedures and the potential associated risks such as infection , altered sensation, dyspareunia , adhesions , and scarring . [41]
With the growing popularity of female cosmetic genital surgeries, the practice increasingly draws criticism from an opposition movement of cyberfeminist activist groups and platforms, called the labia pride movement . The major point of contention is that heavy advertising for these procedures, in combination with a lack of public education, fosters body insecurities in women with larger labia in spite of the fact that there is normal and pronounced individual variation in the size of labia. The preference for smaller labia is a matter of a fashion fad and is without clinical or functional significance. [52] [53]

Etymology
The word vulva was taken from the Medieval Latin word volva or vulva ("womb, female genitals"), probably from the Old Latin volvere ("to roll"; lit. "wrapper"). [54]

Alternative terms
The term pudendum , which denotes the external genitalia, comes from the Latin pudenda membra , meaning parts to be ashamed of. [45] As with nearly any aspect of the human body involved in sexual or excretory functions, there are many slang words for the vulva. [55] " Cunt ", a medieval word for the vulva and once the standard term, has become in its literal sense a vulgarism , and in other uses one of the strongest abusive swearwords in English-speaking cultures. Two widespread terms for the vulva, pussy and fanny (in the UK), which used to be a common pet name [56] and nickname [57] respectively, have other non-sexual meanings that lend themselves to double entendres . [58] [59] [60]

Art
Sheela na gigs are figurative carvings of naked women displaying an exaggerated vulva. They are found in ancient and medieval European contexts. They are displayed on many churches, but their origin and significance is debatable. A main line of thinking is that they were used to ward off evil spirits .
Other cultures have long celebrated and even worshipped the vulva. Some Hindu sects revere it under the name yoni [61] and texts seem to indicate a similar attitude in some ancient Middle Eastern religions. [ citation needed ]
L'Origine du monde ("Origin of the world") painted by Gustave Courbet in 1866 was the first realistic painting of a vulva to be exhibited in Western art. This example of eroticism is also referenced as inspiring Catherine Breillat 's filming of the female genitalia in her 2004 film Anatomie de l'enfer ( Anatomy of Hell ). [62]
British artist Jamie McCartney used casts of four hundred vulvas to create the installation known as the Great Wall of Vagina in 2011. The vagina casts are life size. Explanations written by the project's sexual health adviser accompany these. The purpose of the artist was to "address some of the stigmas and misconceptions that are commonplace". [63] [64] [65]
Starr Goode explores the image and possible meanings of the Sheela na gig and Baubo images in particular, but writes also about the recurring image worldwide. Through hundreds of photographs, she demonstrates that the image of a female displaying her vulva is not an anomaly of European religious art or architecture, but that similar images are found in the visual arts and in mythical narratives of Goddesses and Heroines parting their thighs to reveal what she calls, "sacred powers." Her theory is that "the image is so rooted in our psyches that it seems as if the icon is the original cosmological center of the human imagination." [66]

Additional images
WebPage index: 00063
Nudity
Nudity , or nakedness , is the state of wearing no clothing . [1] The wearing of clothing is a predominantly human characteristic arising from functional needs such as protection from the elements and from cold temperatures, after the loss of body hair, and migration to colder regions. [2] The amount of clothing worn depends on functional considerations, such as a need for warmth, as well as social circumstances. In some situations, a minimum amount of clothing or none at all may be considered socially acceptable, while in others much more clothing may be expected. Social considerations involve issues of modesty , decency and social norms , besides other considerations, and these may depend on the context. There may also be legal considerations .

Terminology
Full nudity refers to complete nudity, while partial nudity refers to less than full nudity, with parts of the body covered in some manner. The term partial nudity is sometimes used to refer to exposure of skin beyond what the person using the expression considers to be within the limits of modesty . If the exposure is within the standards of modesty of a given culture and setting (e.g. wearing a bikini at a non-nude beach), terms such as nudity, partial or otherwise, are not normally used. If however, the degree of exposure exceeds the cultural norms of the setting, or if the activity or setting includes nudity as an understood part of its function, such as a nude beach , terminology relating to nudity and degrees thereof are typically used. Toplessness is regarded by most people as partial nudity.
Full frontal nudity describes a state of full nudity with the subject facing forward with the whole front of the body exposed, including intimate parts such as a man's penis or woman's vulva . Partial frontal nudity typically only refers to the exposure of the breasts . Non-frontal nudity describes nudity where the whole back side of the body, including the buttocks , is exposed, or a side-view from any other direction.

History
Hair probably evolved in mammals before about 220 million years ago. The closest genetic relatives of humans, apes and especially chimpanzees , possess an almost complete covering of fur.
Humans are today the only naked primate in nature, that is, most of the body is not naturally covered by fur. Reliable information on the development of nudity and the passage of time are not yet possible because hair does not fossilize.
Researchers at the University of Utah in 2004 found that human skin contains photoreceptors like those in the retina, allowing it to mount an immediate defence against damaging ultraviolet radiations. They suspect that the protein that protects the skin from sunlight evolved following the loss of protective hair, which happened about 1.2 million years ago. [3]

Public nudity
People have a variety of views on nudity, both of their own as well as those of others. This would depend on their level of inhibition , cultural background and upbringing, as well as on context. A society's attitude to public nudity varies depending on the culture, time, location and context of an activity. There are many exceptions and particular circumstances in which nudity is tolerated, accepted or even encouraged in public spaces . Such examples would include a nude beach , within some intentional communities (such as naturist resorts or clubs) and at special events.
In general and across cultures, public indications of sexual arousal are commonly regarded as embarrassing , both to the person aroused and the onlooker, and for this reason those parts of the human body that would indicate arousal are normally covered. Arousal is most evidently indicated by the sex organs and women's breasts , which are routinely covered, even when other parts of the body may be freely uncovered. Yet the nudity taboo may have meanings deeper than the immediate possibility of sexual arousal, for example, in the cumulative weight of tradition and habit . Clothing also expresses and symbolizes authority, and more general norms and values besides those of a sexual nature.
While some European countries, such as Germany , are rather tolerant of public nudity, [4] in many countries public nudity may meet social disapproval or even constitute a misdemeanor of indecent exposure . In 2012, the city council of San Francisco proposed a ban on public nudity in the inner city area. This was met by harsh resistance since the city is usually known for its liberal culture. [5] [6] Similarly, park rangers began filing tickets against nudists at San Onofre State Beach in 2010, also a place with long tradition of public nudity. [7]

Public social nude events
Some people take part in non-sexual public nude events. These may be in a naturist resort or club or at a nude beach . Outdoor nude recreation can take place in private or rural areas, though generally limited to warm weather.
Others practice casual public nudity. Topfree sunbathing is considered acceptable by many on the beaches of Finland , France, Spain, Italy and most of the rest of Europe (and even in some outdoor swimming pools); however, exposure of the genitals is restricted to nudist areas in most regions. In the United States, topfree sunbathing and wearing thongs are not common in many areas, but are limited to nude beaches in various locations. It is normally acceptable for men in the U.S. to be barechested or shirtless when engaged in outdoor recreational activities.
Where the social acceptability of nudity in certain places may be well understood, the legal position is often less clear cut. In England, for example, the law does not actually prohibit simple public nudity, but does forbid indecent exposure [ citation needed ] . In practice, this means that successful prosecution hangs on whether there is a demonstrable intention to shock others, rather than simply a desire to be nude in a public place. Specifically, using nudity to "harass, alarm or distress" others is an offence against the Public Order Act of 1986. Occasional attempts to prove this point by walking naked around the country therefore often result in periods of arrest, followed by release without charge, and inconsistencies in the approach between different police jurisdictions. Differences in the law between England and Scotland appear to make the position harder for naked ramblers once they reach Scotland.
Photography of installations of massed nude people in public places, as made repeatedly around the world by Spencer Tunick , claim artistic merit.

Means of attracting attention
Nudity is at times used to draw attention to a cause, with the participants desiring to remain anonymous. Public nude events are at times staged as a forum for usually unrelated messages, such as clothing-optional bike rides . At times, the cause is merely a personal justification for taking part in a nude event, which are popular in their own right. Many nude calendars are produced each year featuring naked men or women. Some of these are produced to raise money for charities or other causes. Nudity, like sexuality, is also used to draw attention for a commercial purpose, such as for promotion or advertising .

Private nudity

Personal nudity
In the privacy of their own homes, people are more casual in relation to clothing, though what each considers appropriate varies considerably. What and how much clothing a person removes depends on a number of considerations, including the cultural background and on whether the person is alone in the privacy of their own homes. A person's cultural background as well as their religious teachings will affect the way they view their own nudity, alone or in the presence of others, as well as viewing the nudity of others. Some cultures deprecate nudity even in a private context.
Another factor is the level of privacy to which a person can be assured - for example, some parts of a home may be seen from the outside or there may be a possibility of others walking in. The expectation of privacy may be confined to the home and sometimes the backyard. Inside the home, it may be restricted to the bedroom or just the bathroom. If a person is not alone, their comfort in removing clothing in front of another person will generally depend on the nature of a relationship of those who jointly occupy the same private space, as well as the attitudes of others to nudity. Besides the nature of a relationship, attitudes and incidences of nudity will also depend on the level of inhibition that each person has, as well as the level of privacy to which that they can be assured. Sometimes a person may unintentionally intrude on a person who is in the nude, which may lead to embarrassment of one or both of the people. The nude person may seek to quickly cover their private parts, while the clothed person may turn away, but this also depends on cultural differences and the relationship of the people.
In the case of nudity in front of those who do not normally occupy the same private space, that will usually depend on whether the outsider is comfortable with the nudity and whether the nudity is reciprocated, as in the case of social nudism . Social nudism may take place in any private social context, such as at one's home with friends or with acquaintances at a nudist facility or event, such as a naturist club, community center, resort or other facility. Some social gatherings may organise party games , which may involve some level of nudity, such as strip games . Strip games can be played by single-sex groups or by mixed groups and may be intended to generate an atmosphere of fun and lighten the social atmosphere, or to heighten the sexual atmosphere .
A 1999 survey by the Federation of Canadian Naturists found, besides other things, that 39% of Canadians "have walked or would walk around their house nude"; that naturists tend to have above average incomes; that urban dwellers are more likely to be naturists than country dwellers; and that people under the age of 25 are the most likely to be naturists. [8] According to a 2004 United States survey, 31% of men and 14% of women report sleeping in the nude, [9] while a 1996 BBC survey revealed that in the UK 47% of men and 17% of women do. [10]

Sexual nudity
Nudity in front of a sexual partner is widely accepted, but not in all cases. For example, some partners insist on nudity only at the time and place of sex , or with subdued lighting; during bathing with the partner or afterward; covered by a sheet or blanket, or while sleeping.

Personal privacy issues
The invention of photography and more recently the video camera has opened the art of capturing images of people and scenes at a relatively low cost to the true amateur. A person can now capture images in both public and private situations. A feature of most private photographs and videos is that they are not intended for viewing outside of a very limited range of people, and seldom if ever by the general public. Amateur photography , which includes nude photography, which has previously been produced for personal enjoyment, is increasingly being more widely disseminated through the internet, at times without the knowledge and consent of the subject of the photograph, and to their subsequent embarrassment. Also, the use of secret photography to capture images of an unsuspecting person (undressed or not, and whether for personal use, or intended for posting on the Internet) creates additional personal privacy issues.

Children
There are differences of opinion as to whether, and if so to what extent, parents should appear naked in front of their children. Gordon and Schroeder report that parental nudity varies considerably from family to family. [11] They say that "there is nothing inherently wrong with bathing with children or otherwise appearing naked in front of them", noting that doing so may provide an opportunity for parents to provide important information. They note that by ages five to six, children begin to develop a sense of modesty, and recommend to parents who wish to be sensitive to their children's wishes that they limit such activities from that age onwards. Bonner recommends against nudity in the home if children exhibit sexual play of a type that is considered problematic. [12]
A U.S. study by Alfred Kinsey found that 75% of the participants stated that there was never nudity in the home when they were growing up, 5% of the participants said that there was "seldom" nudity in the home, 3% said "often", and 17% said that it was "usual". The study found that there was no significant difference between what was reported by men and by women with respect to frequency of nudity in the home. [13]
In a 1995 review of the literature, Paul Okami concluded that there was no reliable evidence linking exposure to parental nudity to any negative effect. [14] Three years later, his team finished an 18-year longitudinal study that showed that, if anything, such exposure was associated with slight beneficial effects, particularly for boys. [15]

Children seeing nudity
Attitudes toward children seeing nude people vary substantially, depending on the child's culture, age and the context of the nudity (see also the section Home above).
Television and radio regulations in many countries require broadcasters to avoid transmitting images or language considered inappropriate for children from 5:30 am to 9 pm (the so-called " watershed "). In the United Kingdom, the Broadcasting Code states, "Nudity before the watershed must be justified by the context." [16] In the U.S., the safe harbor rule forbids depictions of nudity between the hours of 6 am and 10 pm. Violators may be subject to civil legal action and sanctions if the Federal Communications Commission (FCC) determines the broadcaster did not meet its standards of "decency". "Material is indecent if, in context, it depicts or describes sexual or excretory organs or activities in terms patently offensive as measured by contemporary community standards for the broadcast medium." [17]
Attitudes to nudity vary substantially throughout Europe. Male and female nudity in Scandinavia is not uncommon. The region has a very open attitude about nudity, although it strictly prohibits children's access to pornography. [18]

Communal showering
Another issue has been the nudity of children in front of other children.
In continental Europe , students tend to shower communally after physical education classes, separated by gender. Fathers taking their young daughters or mothers taking their young sons into the gender-separated changing rooms is mostly viewed as non-controversial, although some public baths have introduced family changing rooms. Some private gymnasiums have instituted rules specifically banning family members of opposite genders taking their children into single-sex locker rooms. [ citation needed ]
In the U.S. and some of the English-speaking majority of Canada, students at public schools have historically been required to shower communally with classmates of the same sex after physical education classes. In the U.S., public objections and the threat of lawsuits have resulted in a number of school districts in recent years changing policy to make showers optional. Private boarding schools and military academies in the U.S. often have communal showers, since the focus there is on 24-hours-a-day education and rooming, rather than just acting as day schools. Students in these establishments need places to clean themselves daily. [19] A court case in Colorado noted that students have a reduced expectation of personal privacy in regards to "communal undress" while showering after physical education classes. [20] According to an interview with a middle school principal , most objections to showering at school that he had heard were actually from the students' parents rather than from the students. [21]

Children and naturism
Children who are within a naturist home will usually also be naked, together with their family, and may see and be seen by non-family members in the nude. They may also be taken to naturist venues and events where they, their families and others would also generally be nude.

Depictions of nudity

Nudity in film
Nudity in film has since the development of the medium been controversial, and most nude scenes in films have had to be justified as being part of the story, in the concept of "artistically justifiable nudity". In some cases nudity is itself the object of a film or is used in the development of the character of the subject. There are cases where nudity has been used to emphasize gender equality in the future. [22] [23] [24] In some cases, nudity has been criticized as "superfluous" or "gratuitous" to the plot, and some film producers have been accused of including nudity in a film to appeal to certain audiences. Many actors and actresses have appeared nude, or exposing parts of their bodies or dressed in ways considered provocative by contemporary standards at some point in their careers.
Erotic films usually contain nudity, and nudity in a sexual context is common in pornographic films . A film on naturism or about people for whom nudity is common may contain non-sexual nudity, and some other non-pornographic films may contain very brief nude scenes. The vast majority of nudity in film is found in pornographic films.

Visual media
Mainstream art generally reflects – with some exceptions – social standards of aesthetics and morality of a society at various periods of time. Beyond mainstream standards, artistic expression may be merely tolerated, or be considered as fringe. Since prehistoric time, humans, both male and female, have been depicted in all states of dress, including all states of undress. Nudity in all styles has been and continues to be found in art. Nudity is also a subject of many literary works and in film. All professionally produced works of art use stylised compositions to depict the nude body. This also applies to cinema, where even nude scenes are staged and rehearsed.
The erotic aspect of nudity in the arts has been an important factor in its attraction, and has come to be associated with certain states and emotions, such as innocence, playfulness, vulnerability, etc. Pornography does not necessarily involve a naked person, but it involves sexualized scenes, and usually it does not claim to have any artistic merit.
The visual arts were at times the only means available to the general public to view a nude body. Today, the opportunities available for the viewing of the nude body are very wide, and these include magazines, television, films, and the Internet.

Child nudity
Depictions of child nudity or children with nude adults appear in works of art in various cultures and historical periods. These attitudes have changed over time and have become increasingly frowned upon particularly in recent years, [25] especially in the case of photography. In recent years, there have been a few incidents in which snapshots taken by parents of their infant or toddler children bathing or otherwise naked were challenged as child pornography . [26]
In May 2008, police in Sydney, Australia, raided an exhibition by the photographer Bill Henson featuring images of naked children on allegations of child pornography. [27] [28] Comparable artworks by Henson had been exhibited without incident since 1975, perhaps indicating that this sensitivity has heightened in recent years.
In June 2008, it was reported in The Age that police would have no basis to prosecute Henson over his photographs of naked teenagers, after they were declared "mild and justified" and given a PG rating [29] by the Australian Classification Board , suggesting viewing by children under the age of 16 is suitable with parental guidance. [30] Out of protest, the Art Monthly Australia magazine published an image of the 6-year-old Olympia Nelson taken by her mother, Polixeni Papapetrou . According to the then-11-year-old Olympia, she did not believe the photograph amounted to abuse and was upset with Prime Minister Kevin Rudd 's remark that he hated it. Olympia's father, art critic Professor Robert Nelson , defended it, saying: "It has nothing to do with pedophilia . The connection between artistic pictures and pedophilia cannot be made and there is no evidence for it." [31] [32]

Uses of nudity

Full body scanner
A full-body scanner is a device that creates an image of a person's nude body through their clothing to look for hidden objects without physically removing their clothes or making physical contact. They are increasingly being deployed at airports and train stations in many countries.
One technology used under the name "full-body scanner" is the millimeter wave scanner , the active form of which reflects extremely high frequency radio waves off the body to make an image on which one can see some types of objects hidden under the clothes. Passive millimeter wave screening devices rely on only the raw energy that is naturally emitted from the human body or objects concealed on the body; passive devices do not transmit millimeter waves. [33] [34] Another technology in use is the backscatter X-ray .

Imposed nudity
In some situations, nudity is imposed on a person. For example, imposed nudity (full or partial) can be part of a corporal punishment or as humiliation , especially when administered in public. In fact, torture manuals have distinguished between the male and female psychological aversion to self-exposure versus being disrobed.
Nazis used forced nudity to attempt to humiliate inmates in concentration camps . This was depicted in the film Schindler's List . [35]
In 2003, Abu Ghraib prison in Baghdad ( Iraq ) gained international notoriety for accounts of torture and abuses by members of the United States Army Reserve during the post-invasion period . Photographic images were circulated that exposed the posing of prisoners naked, sometimes bound, and being intimidated and otherwise humiliated, resulting in widespread condemnation of the abuse.

Western culture

Functional nudity
Functional nudity for a short time, such as when changing clothes on a beach, is sometimes acceptable, while staying nude on the beach generally is not nor is it legal in some jurisdictions. On designated nude beaches , it is acceptable and legal to be nude.
Breastfeeding in public is forbidden in some jurisdictions , not legislated for in others, and a legal right in public and the workplace in yet others. Where it is a legal right, some mothers may be reluctant to breastfeed , [36] [37] and some people may object to the practice. [38]

Toplessness and "topfreedom"
In some cultures, toplessness is regarded as partial nudity, and the exposure of breasts or nipples may be regarded as indecent exposure. However, in many western societies and in appropriate settings, such as while suntanning, toplessness is not, of itself, normally regarded as indecent. [ citation needed ] In the United States, however, exposure of female nipples is a criminal offense in many states and not usually allowed in public (see indecent exposure ), while in the United Kingdom, nudity may not be used to "harass, alarm or distress" according to the Public Order Act of 1986. [39] Different standards apply to art, with one example being the dome of the US Capitol featuring a fresco depicting goddesses with their breasts exposed.
Prosecution of cases has given rise to a movement advocating " topfreedom ", promoting equal rights for women to have no clothing above the waist, on the same basis that would apply to men in the same circumstances. The term topfree rather than topless is advocated to avoid the latter term's perceived sexual connotations.

Naturism
Naturism (or nudism) is a cultural and political movement practising, advocating and defending private and public nudity . It is also a lifestyle based on personal, family and/or social preference. [40] [41]
Naturists reject contemporary standards of modesty , which discourage personal, family and social nudity. They instead seek to create a social environment where individuals feel comfortable in the company of nude people, and being seen nude, either just by other naturists, or also by the general public. [40] [41]

Water activities
The trend in some European countries (for instance Germany, Finland and the Netherlands ) is to allow both genders to bathe together naked. Many German spas allow mixed nude bathing. For example, the Friedrichsbad in Baden-Baden has designated times when mixed nude bathing is permitted. Most German (not to mention French, Spanish and Greek) beaches and swimming pools offer FKK (clothing-optional) areas. In general, continental Europeans have a more relaxed attitude about nudity than is seen in the British-influenced world. Some have attributed this difference to the influence of Queen Victoria 's husband Albert , who was raised in a very restricting religious sect (see Victorian morality ).
The sauna , originating from Finland , is attended nude in its source country [42] as well as in most Scandinavian and in the German-speaking countries of Europe. [43] This is true even when a swimsuit must be worn in the swimming pool area of the same complex. [42] Saunas are very common in modern Finland , where there is one sauna for every three people [44] and became very popular in the remainder of Europe in recent decades. German soldiers had got to know the Finnish saunas during their fight against the Soviet Union in the Continuation War , where Germany and Finland fought on the same side. Finnish hygiene depended so exclusively on saunas, that they had built saunas not only in mobile tents but even in bunkers. [43] . After the war, the German soldiers brought the habit back to Germany and Austria, where it became popular in the second half of the 20th century. [43] The German sauna culture also became popular in neighbouring contries such as Switzerland, Belgium, the Netherlands and Luxemburg. [45] In contrast to Scandinavia, public sauna facilities in these countries commonly do not seggregate genders while still keeping the rule of general nudity. [46] [45]
In Russia , public banyas are also attended nude, however, they are always segregated by gender, either by having separate sections, or by days of the week. Shared areas (such as swimming pools), if present, can only be attended in bathing suits.

Non-Western attitudes
Attitudes in Western cultures are not all the same as explained above, and likewise attitudes in non-Western cultures are many and variant. In almost all cultures, acceptability of nudity depends on the situation.
Cultural and/or religious traditions usually dictate what is proper and what is not socially acceptable. Many non-Western cultures allow women to breastfeed in public, while some have very strict laws about showing any bare skin.

Africa

The curse of nakedness
In Africa, women have used stripping naked on purpose as a curse, both historically, and in modern times. The idea is that women give life and they can take it away. The curse initiates an extreme form of ostracism , which anthropologist Terisa Turner has likened to "social execution". The curse extends to foreign men as well, and is believed to cause impotence, madness or other similar harm. [47] The threat has been used successfully in mass protests against the petroleum industry in Nigeria, [48] by Leymah Gbowee during the Second Liberian Civil War , [49] and against President Laurent Gbagbo of the Ivory Coast . [50]

Clothing and nudity
Different traditions exist among, for example, sub-Saharan Africans , partly persisting in the post-colonial era. Whereas it is the norm among some ethnic and family groups including some Burkinabese and Nilo-Saharan (e.g. Nuba and Surma people ) in daily life or on particular occasions not to wear any clothes or without any covering below the waist – for example, at highly attended stick-fighting tournaments well-exposed young men use the occasion to catch the eye of a prospective bride.

Liberia
In modern Liberia , soldiers under General "Butt Naked" Joshua Blahyi fought naked in order to terrorize their opponents. [51] Nude except for lace-up leather shoes and a gun, the general led his fierce Butt Naked Battalion into battle on behalf of the warlord Roosevelt Johnson , who hired the unclothed warriors for their fearlessness and fighting skills.

Brazil
In Brazil , the Yawalapiti , an indigenous Xingu tribe in the Amazon Basin , practice a funeral ritual known as Quarup , to celebrate life, death and rebirth, and also involves the presentation of all young girls who have begun menstruating since the last Quarup and whose time has come to choose a partner.

Asia
In Japan, public baths are very common. Bathing nude with family members or friends in public bath houses, saunas, or natural hot springs ( Onsen ) is popular.
In Korea , public baths ( Jjimjilbang ) are widespread and communal nude bathing is normal, although nudity is not permitted in unisex areas.
Nudity is considered shamelessness in the conservative society of India , although nude beaches can be found in Goa and nude saints like those of the Digambara sect of Jainism and Hindu Sadhus are respected and worshipped.
In many Muslim countries , public nudity is illegal.

See also
WebPage index: 00064
Heavy metal music
WebPage index: 00065
Internet Watch Foundation
The Internet Watch Foundation ( IWF ) is a registered charity [3] based in Cambridgeshire , England. It states that its remit is "to minimise the availability of 'potentially criminal' Internet content, specifically images of child sexual abuse (including child pornography ) hosted anywhere, and criminally obscene adult content in the UK". Content inciting racial hatred was removed from the IWF's remit after a police website was set up for the purpose in April 2011. [4] The IWF clarifies on its website that potentially criminal activity is addressed, as content can be confirmed to be criminal only by a court of law . As part of its function, the IWF says that it will "supply partners with an accurate and current URL list to enable blocking of child sexual abuse content". It has "an excellent and responsive national Hotline reporting service" for receiving reports from the public. [5] In addition to receiving referrals from the public, its agents also proactively search the peer-to-peer networks of the deep web to identify potentially illegal images. It can then ask service providers to take down the websites containing the images or to block them if they fall outside UK jurisdiction . [6]
From 2010 the Office of Government Commerce (OGC) required all procurement specifications for the provision of Internet-related services to government agencies and public bodies to require the Internet service provider (ISP) to block access to sites  [ sic ] on the IWF list. [7]
The IWF operates in informal partnership with the police, government, public, and Internet service providers. Originally formed to police suspected child pornography online, the IWF's remit was later expanded to cover criminally obscene material. [8]
The IWF is an incorporated charity, limited by guarantee, and largely funded by voluntary contributions from UK communications service providers, including ISPs, mobile phone operators , Internet trade associations , search engines , hardware manufacturers, and software providers . It also receives funding from the Association for Payment Clearing Services and the European Union . [9]
The IWF is governed by a Board of Trustees which consists of an independent chair, six non-industry representatives, and three industry representatives. The Board monitors and reviews IWF's remit, strategy, policy and budget to enable the IWF to achieve its objectives. The IWF operates from offices in Cambridge Research Park, near Cambridge . [10]
It has been criticized as an ineffective quango that does not deserve its charity status, for producing excessive numbers of false positives, for the secrecy of its proceedings, and for poor technical implementations of its policies that degraded the response time of the whole UK internet.

History

Background
During 1996 the Metropolitan Police told the Internet Service Providers Association (ISPA) that the content carried by some of the newsgroups made available by them was illegal, that they considered the ISPs involved to be publishers of that material, and that they were therefore breaking the law. In August 1996, Chief Inspector Stephen French, of the Metropolitan Police Clubs & Vice Unit , sent an open letter to the ISPA, requesting that they ban access to a list of 132 newsgroups, many of which were deemed to contain pornographic images or explicit text. [11]
The list was arranged so that the first section consisted of unambiguously titled paedophile newsgroups, then continued with other kinds of groups which the police wanted to restrict access to, including alt.binaries.pictures.erotica.cheerleaders and alt.binaries.pictures.erotic.centerfolds . [12]
Although this action had taken place without any prior debate in Parliament or elsewhere, the police, who appeared to be doing their best to create and not simply to enforce the law, were not acting entirely on their own initiative. Alan Travis , Home Affairs editor of the newspaper The Guardian , explained in his book Bound and Gagged that Ian Taylor , the Conservative Science and Industry Minister at the time, had underlined an explicit threat to ISPs that if they did not stop carrying the newsgroups in question, the police would act against any company that provided their users with "pornographic or violent material". Taylor went on to make it clear that there would be calls for legislation to regulate all aspects of the Internet unless service providers were seen to wholeheartedly "responsible self-regulation". [13]
The ISP Demon Internet regarded the police request as "unacceptable censorship"; however, its attitude annoyed ISPA chairman Shez Hamill, who said:
Following this, a tabloid-style exposé of Demon Internet appeared in the Observer newspaper, which alleged that Clive Feather (a director of Demon) "provides paedophiles with access to thousands of photographs of children being sexually abused". [14]
During the summer and autumn of 1996 the UK police made it known that they were planning to raid an ISP with the aim of launching a test case regarding the publication of obscene material over the Internet. The direct result of the campaign of threats and pressure was the establishment of the Internet Watch Foundation (initially known as the Safety Net Foundation) in September 1996. [15]

Foundation of IWF
Facilitated by the Department of Trade & Industry (DTI), discussions were held between certain ISPs, the Metropolitan Police, the Home Office , and a body called the "Safety Net Foundation" (formed by the Dawe Charitable Trust ). This resulted in the "R3 Safety Net Agreement", where "R3" referred to the triple approach of rating, reporting, and responsibility. In September 1996, this agreement was made between the ISPA, LINX , and the Safety Net Foundation, which was subsequently renamed the Internet Watch Foundation. The agreement set requirements for associated ISPs regarding identifiability and traceability of Internet users; ISPs had to cooperate with the IWF to identify providers of illegal content and facilitate easier traceability. [16]
Demon Internet was a driving force behind the IWF's creation, and one of its employees, Clive Feather, became the IWF's first chair of the Funding Board [17] and solicitor Mark Stephens the First Chair of the IWF's Policy Board. The Policy Board developed codes, guidance, operational oversight and a hotline for reporting content.
The Funding Board, made up of industry representatives and Chair of Policy Board, provided the wherewithal for the IWF's day to day activities as set down and required by the Policy Board.
After 3 years of operation, the IWF was reviewed for the DTI and the Home Office by consultants KPMG and Denton Hall . Their report was delivered in October 1999 and resulted in a number of changes being made to the role and structure of the organisation, and it was relaunched in early 2000, endorsed by the government and the DTI, which played a "facilitating role in its creation", according to a DTI spokesman. [17]
At the time, Patricia Hewitt , then Minister for E-Commerce , said: "The Internet Watch Foundation plays a vital role in combating criminal material on the Net." To counter accusations that the IWF was biased in favour of the ISPs, a new independent chairman was appointed, Roger Darlington, former head of research at the Communication Workers Union . [17]

The website
The IWF's website offers a web-based government-endorsed method for reporting suspect online content and remains the only such operation in the United Kingdom. It acts as a Relevant Authority in accordance with the Memorandum of Understanding (MOU) [18] concerning Section 46 of the Sexual Offences Act 2003 (meaning that its analysts will not be prosecuted for looking at illegal content in the course of their duties). [19] Reports can be submitted anonymously. According to the IWF MOU "If potentially illegal content is hosted in the UK the IWF will work with the relevant service provider and British police agency to have the content ‘taken down’ and assist as necessary to have the offender(s) responsible for distributing the offending content detected." Potentially illegal content includes:
However, almost the whole of the IWF site is concerned with suspected images of child sexual abuse with little mention of other criminally obscene material, also within their remit. Images judged by the IWF to be images of child sexual abuse are blocked.
The Government claimed that they would also be handling images of adult " extreme pornography ", [22] which became illegal for people in the UK to possess on 26 January 2009. The IWF includes "extreme pornography" as an example under "criminally obscene content", meaning that they will report material hosted in the UK, or uploaded by someone in the UK, but regarding blocking sites "with those categories, our remit will only go so far as to refer sites hosted in the UK to the appropriate authorities." [23]
The IWF states that it works in partnership with UK Government departments such as the Home Office and the Department for Business, Enterprise and Regulatory Reform to influence initiatives and programmes developed to combat online abuse.
They are funded by the European Union and the online industry. This includes Internet service providers, mobile operators and manufacturers, content service providers, telecommunications and filtering companies, search providers and the financial sector as well as blue-chip and other organisations who support the IWF for corporate social responsibility reasons.
Through their "Hotline" reporting system, the organisation helps ISPs to combat abuse of their services through a " notice and take down " service by alerting them to any potentially illegal content within their remit on their systems and simultaneously invites the police to investigate the publisher.
The IWF has connections [ clarification needed ] with the Virtual Global Taskforce , the Serious Organised Crime Agency and the Child Exploitation and Online Protection Centre .

Management
Susie Hargreaves was appointed CEO in September 2011 [24]
As of 2011 [update] : [25]

Cross-border aspects
Previously, the IWF passed on notifications of suspected child pornography hosted on non-UK servers to the UK National Criminal Intelligence Service which in turn forwards it to Interpol or the relevant foreign police authority. It now works with the Serious Organised Crime Agency instead. The IWF does not, however, pass on notifications of other types of potentially illegal content hosted outside the UK. [26]

Blacklist of web pages
The IWF compiles and maintains a list of URLs for individual webpages with child sexual abuse content called the child abuse image content list or CAIC list. A whole website will only be included on the list if that whole domain is dedicated to the distribution of child sexual abuse images. [27] It says "every URL on the list depicts indecent images of children, advertisements for or links to such content, on a publicly available website. The list typically contains 500 - 800 URLs at any one time and is updated twice a day to ensure all entries are still live". [28] Offending UK URLs are not listed as they are taken down very quickly; URLs elsewhere are listed only until they are removed. The list is applied by the ISPs of 95% of commercial Internet customers in the UK. According to the IWF website, blocking applies only to potentially criminal URLs related to child sexual abuse content on publicly available websites; the distribution of images through other channels such as peer-to-peer is a matter for "our police partners", and IWF has no plans to extend the type of content included on the list. [27]
A staff of four police-trained analysts are responsible for this work, [29] and the director of the service has claimed that the analysts are capable of adding an average of 65-80 new URLs to the list each week, and act on reports received from the public rather than pursuing investigative research. [30]
Between 2004 and 2006, BT Group introduced its Cleanfeed technology which was then used by 80% of internet service providers. [31] BT spokesman Jon Carter described Cleanfeed's function as "to block access to illegal Web sites that are listed by the Internet Watch Foundation", and described it as essentially a server hosting a filter that checked requested URLs for Web sites on the IWF list, and returning an error message of "Web site not found" for positive matches. [32]
In 2006, Home Office minister Alan Campbell pledged that all ISPs would block access to child abuse websites by the end of 2007. [33] By the middle of 2006 the government reported that 90% of domestic broadband connections were either currently blocking or had plans to by the end of the year. The target for 100% coverage was set for the end of 2007, [34] however in the middle of 2008 it stood at 95%. [35] In February 2009, the Government said that it is looking at ways to cover the final 5%. [36] In an interview in March 2009, a Home Office spokesperson mistakenly thought that the IWF deleted illegal content, and didn't look at the content they rate. [33] [37]
Although the IWF's blacklist causes content to be censored even if the content has not been found to be illegal by a court of law, IWF Director of Communications Sarah Robertson claimed, on 8 December 2008, that the IWF is opposed to the censorship of legal content. In the case of the IWF's blacklisting of cover art hosted on Wikipedia just a few days prior, she claimed that “The IWF found the image to be illegal”, despite the body not having any legal jurisdiction to do so. [38]
In March 2009 a Home Office spokesperson said that ISPs were being pressured to sign up to the IWF's blacklist in order to block child pornography websites and said that there was no alternative to using the IWF's blacklist. Zen Internet previously refused to use the IWF's blacklist citing "concerns over its effectiveness", [33] however it quietly joined the foundation in September 2009 while still maintaining its concerns. [39]
As of 2009, the blacklist was said to contain about 450 URLs. [40] A 2009 study by researcher Richard Clayton at the University of Cambridge found that about a quarter of them were specific pages on otherwise legitimate free file hosting services , among them RapidShare , Megaupload , SendSpace and Zshare . [40] Listing these pages on the confidential blacklist of pages would cause all accesses to the sites hosting them to be referred to the IWF, potentially causing unintended interference as discussed below.

Incidents

R v Walker
R v Walker , sometimes called the "Girls (Scream) Aloud Obscenity Trial", was the first prosecution for written material under Section 2(1) of the Obscene Publications Act in nearly two decades. [41] It involved the prosecution of Darryn Walker for posting a story entitled "Girls (Scream) Aloud" on an internet erotic story site in 2008. The story was a fictional written account describing the kidnap, rape and murder of pop group Girls Aloud . [42] It was reported to the IWF who passed the information on to Scotland Yard ’s Obscene Publications Unit . During the trial the prosecution claimed that the story could be "easily accessed" by young fans of Girls Aloud. However, the defence demonstrated that it could only be located by those specifically searching for such material. As a result the case was abandoned and the defendant cleared of all charges. [43] [44]

Wikipedia
On 5 December 2008, the IWF system started blacklisting a Wikipedia article covering the Scorpions ' 1976 album Virgin Killer , and an image of its original LP cover art which appeared on that article. Users of some major ISPs, including BT , Vodafone , Virgin Media / Tesco.net , Be / O2 , EasyNet/UK Online / Sky Broadband , PlusNet , Demon, and TalkTalk (Opal Telecom), were unable to access the filtered content. Although controversial, the album and image are still available, both through Internet shopping sites and from physical shops. The image had been reported to the IWF by a reader, and the IWF determined that it could be seen as potentially illegal. The IWF estimated the block affected 95% of British residential users. [45] [46] The IWF has since rescinded the block, [47] [48] issuing the following statement: [49]
Additionally, many UK Internet users were unable to edit Wikipedia pages unless registered and logged in with Wikipedia. [50] This is reported to be due to the single blacklisted article causing all Wikipedia traffic from ISPs using the system to be routed through a transparent proxy server. Wikipedia distinguishes unlogged-in users from each other by their IP address, so interpreted all unlogged-in users from a particular ISP as a single user editing massively from the proxy address, which triggered Wikipedia's anti-abuse mechanism, blocking them. [51]

Wayback Machine
On 14 January 2009 some UK users reported that all of the 85 billion pages of the Internet Archive (Wayback Machine) had been blocked, although the IWF's policy is to block only individual offending webpages, not whole domains. [52] According to IWF chief executive Peter Robbins this was due to a "technical hitch". [53] Because the Internet Archive's web site contained URLs on the IWF's blacklist, requests sent there from Demon Internet carried a particular header, which clashed with the Internet Archive's internal mechanism to convert web links when serving archived versions of web pages. [40] The actual blocked URL which had caused the incident never became publicly known. [40]

Unintended effects

Of proxy server used by ISPs
Many ISPs implement IWF filtering by using a transparent proxy server of their own, unconnected with IWF. [54] Quoting Plusnet "If the IP address matches that of a server that's used to host one of the websites on the IWF list then your request is diverted to a proxy server." [54] The hosting server itself is not blacklisted, the problem is due to requesting a page from a server which also hosts a listed page. The IWF lists the Internet companies which "have voluntarily committed to block access to child sexual abuse web pages". [55] These companies may use transparent proxies or other techniques.
Using a transparent proxy has the unintended side effect, quite independent of IWF filtering, of appearing to websites connected to as originating from the proxy IP instead of the user's real IP. Some sites detect the user's IP and adjust their behaviour accordingly. [51] For example, if trying to download files from a file distribution website which restricts free-of-charge usage by enforcing a delay of typically 30 minutes between downloads, any attempt to download is interpreted as originating from the ISP's proxy rather than the user. The consequence is that if any user of that ISP has downloaded any file from the site in the last half-hour (which is very likely for a large ISP), the download is not allowed. [56] This is an unintended consequence of ISP's use of proxy servers, not IWF filtering. File sharing sites distribute files of all types; for example Linux distribution files, which are very large. [57] The use of proxy servers is also reported to have caused the problem with editing Wikipedia (but not the blocking of the actual offending web page) reported above.

Criticism

Ineffectiveness
IWF filtering has been criticised as interfering with legitimate Internet activity while being ineffective against anyone intending to access objectionable content. One carefully argued discussion, while opposing such things as child pornography and terrorism, points out that filtering has side effects, as discussed in this section, and would not stop access to material such as child porn as it would not stop email, ftp, https, p2p, usenet, irc, or many other ways to access the same content. As there are simple encryptions systems, it never can stop it - at best it just drives it underground and harder to assess and track. [58]

Charity status
In February 2009 a Yorkshire-based software developer lodged a formal complaint regarding the IWF status as a charity with the Charity Commission , in which he pointed out that "regulating the worst of the internet" was "not really a charitable purpose", and that the IWF existed mainly to serve the interests of ISPs subscribing to it rather than the public. An IWF spokesperson said that the IWF had attained charitable status in 2004 "in order to subject itself to more robust governance requirements and the higher levels of scrutiny and accountability which charity law, alongside company law, brings with it". [59] The IWF is listed by fakecharities.org, "a directory of those so-called charities that receive substantial funding from either the UK or EU governments". [60] It has also been termed a quango by critics, implying poor management and lack of accountability. [61]

False positives
Following the IWF's blacklisting of the Wikipedia article, the organisation's operating habits came under scrutiny. J.R. Raphael of PC World stated that the incident had raised serious free-speech issues, and that it was alarming that one non-governmental organisation was ultimately acting as the "morality police" for about 95% of UK's Internet users. [62] Frank Fisher of The Guardian criticized the IWF for secretiveness and lack of legal authority, among other things, and noted that the blacklist could contain anything and that the visitor of a blocked address may not know if their browsing is being censored. [63]

Pressure to implement filtering
The government believes that a self-regulatory system is the best solution, and the Metropolitan Police also believe that working with ISPs, rather than trying to force them via legislation, is the way forward. [17] The IWF has a list of URLs considered to host objectionable material (distinct from the actual, confidential, blacklist of pages [ clarification needed ] ) which is available to ISPs, [64] but ISPs are not obliged to subscribe to it.

Legality
As a "self-appointed, self-regulated internet watchdog, which views user-submitted content and compiles a list of websites that it deems to contain illegal images" there have been questions raised regarding the legality of their viewing content that would normally constitute a criminal offence. [37]

Secrecy
The IWF has been criticized for blacklisting legal content and for not telling websites that they are being blocked. [65] In these circumstances the owner(s) of the blocked webpage might not even know they have offending content on their site, which means that the content would still be readily available to anyone outside of the UK.

Technical issues
The blacklisting of sites may be concealed by a generic HTTP 404 "page not found" message rather than an explanation that the content has been censored. The exact method of censorship is determined by the implementing ISP; BT, for example, return HTTP 404 pages, whereas Demon return a message stating that the page is censored, and why. [66]
At the time of the Wikipedia blocking , performance issues accessing the site from the UK were reported. [67]
In October 2014 users on Sky Broadband reported very slow and intermittent performance of image host Imgur . [68] Clicking on an image would typically result in the site appearing to be down. Accessing via HTTPS causes images to load normally because it bypasses the proxy used on sites with blacklisted content .

See also
WebPage index: 00066
Child pornography laws in the United States
Child pornography laws in the United States specify that child pornography is illegal under federal law and in all states. The Supreme Court of the United States has found child pornography to be " legally obscene ", a term that refers to offensive or violent forms of pornography that have been declared to be outside the protections of the First Amendment to the United States Constitution . [1] Federal sentencing guidelines on child pornography differentiate between production, distribution, and purchasing/receiving, and also include variations in severity based on the age of the child involved in the materials, with significant increases in penalties when the offense involves a prepubescent child or a child under the age of 12. [2] U.S. law distinguishes between pornographic images of an actual minor, realistic images that are not of an actual minor , and non-realistic images such as drawings. The latter two categories are legally protected unless found to be obscene , whereas the first does not require a finding of obscenity.

Reporting requirements
Under the Crime Victims’ Rights Act (CVRA),46 codified at 18 U.S.C. § 3771, federal law enforcement officials must notify a child pornography victim (or his or her guardian if the victim is still a minor) each time the officials charge an offender with a child pornography offense related to an image depicting the victim. Such notifications can be emotionally traumatic. [3]

Obscenity as a form of unprotected speech
In the United States, pornography is considered a form of personal expression governed by the First Amendment to the United States Constitution . Pornography is generally protected speech, unless it is obscene , as the Supreme Court of the United States held in 1973 in Miller v. California .
Child pornography is also not protected by the First Amendment, but importantly, for different reasons. In 1982 the Supreme Court held in New York v. Ferber that child pornography, even if not obscene, is not protected speech. The court gave a number of justifications why child pornography should not be protected, including that the government has a compelling interest in safeguarding the physical and psychological well-being of minors.

Record-keeping requirements
The initial iteration of 18 U.S.C. § 2257 , first passed in 1988, mandated that producers of pornographic media keep records of the age and identity of performers and affix statements as to the location of the records to depictions. However, rather than penalties for noncompliance, the statute created a rebuttable presumption that the performer was a minor. Pub. L. 100-690. This version was struck down as unconstitutional under the First Amendment in American Library Association v. Thornburgh , 713 F. Supp. 469 (D.D.C. 1989), vacated as moot , 956 F.2d 1178 (D.C. Cir. 1992).
After Thornburgh, Congress amended 2257 to impose direct criminal penalties for noncompliance with the record-keeping requirements. The same plaintiffs challenged the amended statute and accommanying regulations, but the new version was upheld in American Library Association v. Reno , 33 F.3d 78 (D.C. Cir. 1994).
In Sundance Association, Inc. v. Reno , 139 F.3d 804 (10th Cir. 1998), the Tenth Circuit rejected the regulation's distinction between primary and secondary producers and entirely exempted from the record-keeping requirements those who merely distribute or those whose activity "does not involve hiring, contracting for, managing, or otherwise arranging for the participation of the performers depicted". 18 U.S.C. § 2257(h)(3).
However, after 2257 was amended in 2006 by the Adam Walsh Act, the court ruled that Sundance ’s restrictions no longer applied to the amended statute and generally ruled in the government's favor on its motion for summary judgment. Free Speech Coalition v. Gonzales , 483 F. Supp. 2d 1069 (D. Colo. 2006). [4]

Simulated pornography
Simulated child pornography was made illegal with the Child Pornography Prevention Act of 1996 (CPPA). The CPPA was short-lived. In 2002, the Supreme Court of the United States in Ashcroft v. Free Speech Coalition held that the relevant portions of the CPPA were unconstitutional because they prevented lawful speech. Referring to Ferber , the court stated that "the CPPA prohibits speech that records no crime and creates no victims by its production. Virtual child pornography is not 'intrinsically related' to the sexual abuse of children".

1466A - Obscene visual representations of the sexual abuse of children
In response to the demise of the CPPA, on April 30, 2003, President George W. Bush signed into law the PROTECT Act of 2003 (also known as the Amber Alert Law ). [5]
The law enacted 18 U.S.C. § 1466A , which criminalizes material that has "a visual depiction of any kind, including a drawing, cartoon, sculpture or painting" that "depicts a minor engaging in sexually explicit conduct and is obscene" or "depicts an image that is, or appears to be, of a minor engaging in ... sexual intercourse ... and lacks serious literary, artistic, political, or scientific value". By its own terms, the law does not make all simulated child pornography illegal, only that found to be obscene or lacking in serious value. [ citation needed ]
In November 2005 in Richmond , Virginia, Dwight Whorley was convicted under 18 U.S.C. sec. 1466A for using a Virginia Employment Commission computer to receive " obscene Japanese anime cartoons that graphically depicted prepubescent female children being forced to engage in genital-genital and oral-genital intercourse with adult males". [6] [7] [8] He was also convicted of possessing child pornography involving real children. He was sentenced to 20 years in prison. [9]
On December 18, 2008, the Fourth Circuit Court of Appeals affirmed the conviction. [10] The court stated that "it is not a required element of any offense under this section that the minor depicted actually exists [ sic ]". Attorneys for Mr. Whorley have said that they will appeal to the Supreme Court. [11] [12]
The request for en banc rehearing of United States v. Whorley from the Court of Appeals was denied on June 15, 2009. A petition for writ of certiorari was filed with the Supreme Court on September 14, 2009, and denied on January 11, 2010, without comment. [13]

Section 2252A
The PROTECT Act also amended 18 U.S.C. § 2252A , which was part of the original CPPA. The amendment added paragraph (a)(3), which criminalizes knowingly advertising or distributing "an obscene visual depiction of a minor engaging in sexually explicit conduct; or a visual depiction of an actual minor engaging in sexually explicit conduct". The law draws a distinction between obscene depiction of any minor, and mere depiction of an actual minor.
The bill addresses various aspects of child abuse, prohibiting some illustrations and computer-generated images depicting children in a pornographic manner. [14] [15] [16] Provisions against virtual child pornography in the Child Pornography Prevention Act of 1996 were ruled unconstitutional by the U.S. Supreme Court in 2002 on the grounds that the restrictions on speech were not justified by a compelling government interest (such as protecting real children). The provisions of the PROTECT Act instead prohibit such material if it qualifies as obscene as defined by the Miller Test ; the Supreme Court has ruled that such material is not protected by the First Amendment.
In May 2008, the Supreme Court upheld the 2003 federal law Section 2252A(a)(3)(B) of Title 18, United States Code that criminalizes the pandering and solicitation of child pornography, in a 7–2 ruling penned by Justice Antonin Scalia . The court ruling dismissed the United States Court of Appeals for the 11th Circuit's finding the law unconstitutionally vague. [17] [18] Attorney James R. Marsh, founder of the Children's Law Center in Washington, D.C., wrote that although the Supreme Court's decision has been criticized by some, he believes it correctly enables legal personnel to fight crime networks where child pornography is made and sold. [19] Child pornography is illegal in the US and is not looked at in terms of the typical guidelines of the First Amendment , due to the assumption that it always harms children when it is made, sold, and/or owned. [ citation needed ]

Further developments
In 1994, the U.S. Court of Appeals for the 3rd Circuit ruled in United States v. Knox that the federal statute contains no requirement that genitals be visible or discernible. The court ruled that non-nude visual depictions can qualify as lascivious exhibitions and that this construction does not render the statute unconstitutionally overbroad . [20]
In 2014, the Supreme Judicial Court of Massachusetts found that certain photos of nude children, culled from ethnographic and nudist publications, were not lascivious exhibitions and hence were not pornographic; the court ordered dropping of charges against a prisoner who had been found in possession of the photos. [21]
In at least one instance, in North Carolina, teenagers in the United States have been prosecuted as adults for possession of images of themselves. As of September 2015 20 states had enacted " Romeo and Juliet laws " which decriminalized such consensual activity with respect to oneself and other teenagers. [22] [23]

See also
WebPage index: 00067
Cyberspace
Cyberspace is "the notional environment in which communication over computer networks occurs." [1] The word became popular in the 1990s when the uses of the Internet, networking, and digital communication were all growing dramatically and the term "cyberspace" was able to represent the many new ideas and phenomena that were emerging. [2]
The parent term of cyberspace is " cybernetics ", derived from the Ancient Greek κυβερνήτης ( kybernētēs , steersman, governor, pilot, or rudder), a word introduced by Norbert Wiener for his pioneering work in electronic communication and control science. This word first appeared in the novel Neuromancer by William Gibson (Page 4, Phantasia Press Edition, Bloomfield, MI, 1986), one of the first cyberpunk hardcovers published.
As a social experience, individuals can interact, exchange ideas, share information, provide social support, conduct business, direct actions, create artistic media, play games, engage in political discussion, and so on, using this global network. They are sometimes referred to as cybernauts . The term cyberspace has become a conventional means to describe anything associated with the Internet and the diverse Internet culture . The United States government recognizes the interconnected information technology and the interdependent network of information technology infrastructures operating across this medium as part of the US national critical infrastructure . Amongst individuals on cyberspace, there is believed to be a code of shared rules and ethics mutually beneficial for all to follow, referred to as cyberethics . Many view the right to privacy as most important to a functional code of cyberethics . [3] Such moral responsibilities go hand in hand when working online with global networks, specifically, when opinions are involved with online social experiences. [4]
According to Chip Morningstar and F. Randall Farmer , cyberspace is defined more by the social interactions involved rather than its technical implementation. [5] In their view, the computational medium in cyberspace is an augmentation of the communication channel between real people; the core characteristic of cyberspace is that it offers an environment that consists of many participants with the ability to affect and influence each other. They derive this concept from the observation that people seek richness, complexity, and depth within a virtual world.

Origins of the term
The term “cyberspace” first appeared in the visual arts in the late 1960s, when Danish artist Susanne Ussing (1940-1998) and her partner architect Carsten Hoff (b. 1934) constituted themselves as Atelier Cyberspace. Under this name the two made a series of installations and images entitled “sensory spaces” that were based on the principle of open systems adaptable to various influences, such as human movement and the behaviour of new materials. [6]
Atelier Cyberspace worked at a time when the Internet did not exist and computers were more or less off-limit to artists and creative engagement. In a 2015-interview with Scandinavian art magazine Kunstkritikk, Carsten Hoff recollects, that although Atelier Cyberspace did try to implement computers, they had no interest in the virtual space as such: [6]
And in the same interview Hoff continues:
The works of Atelier Cyberspace were originally shown at a number of Copenhagen venues and have later been exhibited at The National Gallery of Denmark in Copenhagen as part of the exhibition “What’s Happening?” [7]
The term "cyberspace" first appeared in fiction in the 1980s in the work of cyberpunk science fiction author William Gibson , first in his 1982 short story " Burning Chrome " and later in his 1984 novel Neuromancer . [8] In the next few years, the word became prominently identified with online computer networks. The portion of Neuromancer cited in this respect is usually the following: [9]
Now widely used, the term has since been criticized by Gibson, who commented on the origin of the term in the 2000 documentary No Maps for These Territories :

Metaphorical
Don Slater uses a metaphor to define cyberspace, describing the "sense of a social setting that exists purely within a space of representation and communication . . . it exists entirely within a computer space, distributed across increasingly complex and fluid networks." The term "Cyberspace" started to become a de facto synonym for the Internet, and later the World Wide Web , during the 1990s, especially in academic circles [10] and activist communities. Author Bruce Sterling , who popularized this meaning, [11] credits John Perry Barlow as the first to use it to refer to "the present-day nexus of computer and telecommunications networks." Barlow describes it thus in his essay to announce the formation of the Electronic Frontier Foundation (note the spatial metaphor) in June, 1990: [12]
As Barlow, and the EFF, continued public education efforts to promote the idea of " digital rights ", the term was increasingly used during the Internet boom of the late 1990s.

Virtual environments
Although the present-day, loose use of the term "cyberspace" no longer implies or suggests immersion in a virtual reality, current technology allows the integration of a number of capabilities (sensors, signals, connections, transmissions, processors, and controllers) sufficient to generate a virtual interactive experience that is accessible regardless of a geographic location. It is for these reasons cyberspace has been described as the ultimate tax haven . [13]
In 1989, Autodesk , an American multinational corporation that focuses on 2D and 3D design software, developed a virtual design system called Cyberspace. [14]

Recent definitions of Cyberspace
Although you can find several definitions of cyberspace both in scientific literature and in official governmental sources, there is no fully agreed official definition yet. According to F. D. Kramer there are 28 different definitions of the term cyberspace. See in particular the following links: "Cyberpower and National Security: Policy Recommendations for a Strategic Framework," in Cyberpower and National Security, FD Kramer, S. Starr, L.K. Wentz (ed.), National Defense University Press, Washington (DC) 2009; see also Mayer, M., Chiarugi, I., De Scalzi, N., https://www.academia.edu/14336129/International_Politics_in_the_Digital_Age .
The most recent draft definition is the following: Cyberspace is a global and dynamic domain (subject to constant change) characterized by the combined use of electrons and electromagnetic spectrum, whose purpose is to create, store, modify, exchange, share and extract, use, eliminate information and disrupt physical resources. Cyberspace includes: a) physical infrastructures and telecommunications devices that allow for the connection of technological and communication system networks, understood in the broadest sense (SCADA devices, smartphones/tablets, computers, servers, etc.); b) computer systems (see point a) and the related (sometimes embedded) software that guarantee the domain's basic operational functioning and connectivity; c) networks between computer systems; d) networks of networks that connect computer systems (the distinction between networks and networks of networks is mainly organizational); e) the access nodes of users and intermediaries routing nodes; f) constituent data (or resident data). Often, in common parlance (and sometimes in commercial language), networks of networks are called Internet (with a lowercase i), while networks between computers are called intranet. Internet (with a capital I, in journalistic language sometimes called the Net) can be considered a part of the system a). A distinctive and constitutive feature of cyberspace is that no central entity exercises control over all the networks that make up this new domain. [15]
Just as in the real world there is no world government, cyberspace lacks an institutionally predefined hierarchical center. To cyberspace, a domain without a hierarchical ordering principle, we can therefore extend the definition of international politics coined by Kenneth Waltz: as being "with no system of law enforceable." This does not mean that the dimension of power in cyberspace is absent, nor that power is dispersed and scattered into a thousand invisible streams, nor that it is evenly spread across myriad people and organizations, as some scholars had predicted. On the contrary, cyberspace is characterized by a precise structuring of hierarchies of power. [16]

Cyberspace as an Internet metaphor
While cyberspace should not be confused with the Internet, the term is often used to refer to objects and identities that exist largely within the communication network itself, so that a website , for example, might be metaphorically said to "exist in cyberspace". [17] According to this interpretation, events taking place on the Internet are not happening in the locations where participants or servers are physically located, but "in cyberspace".
Firstly, cyberspace describes the flow of digital data through the network of interconnected computers: it is at once not "real", since one could not spatially locate it as a tangible object, and clearly "real" in its effects. Secondly, cyberspace is the site of computer-mediated communication (CMC), in which online relationships and alternative forms of online identity were enacted, raising important questions about the social psychology of Internet use, the relationship between "online" and "offline" forms of life and interaction, and the relationship between the "real" and the virtual. Cyberspace draws attention to remediation of culture through new media technologies: it is not just a communication tool but a social destination, and is culturally significant in its own right. Finally, cyberspace can be seen as providing new opportunities to reshape society and culture through "hidden" identities, or it can be seen as borderless communication and culture. [18]
The "space" in cyberspace has more in common with the abstract, mathematical meanings of the term (see space ) than physical space. It does not have the duality of positive and negative volume (while in physical space for example a room has the negative volume of usable space delineated by positive volume of walls, Internet users cannot enter the screen and explore the unknown part of the Internet as an extension of the space they are in), but spatial meaning can be attributed to the relationship between different pages (of books as well as webservers ), considering the unturned pages to be somewhere "out there." The concept of cyberspace therefore refers not to the content being presented to the surfer, but rather to the possibility of surfing among different sites, with feedback loops between the user and the rest of the system creating the potential to always encounter something unknown or unexpected.
Videogames differ from text-based communication in that on-screen images are meant to be figures that actually occupy a space and the animation shows the movement of those figures. Images are supposed to form the positive volume that delineates the empty space. A game adopts the cyberspace metaphor by engaging more players in the game, and then figuratively representing them on the screen as avatars . Games do not have to stop at the avatar-player level, but current implementations aiming for more immersive playing space (i.e. Laser tag ) take the form of augmented reality rather than cyberspace, fully immersive virtual realities remaining impractical.
Although the more radical consequences of the global communication network predicted by some cyberspace proponents (i.e. the diminishing of state influence envisioned by John Perry Barlow [19] ) failed to materialize and the word lost some of its novelty appeal, it remains current as of 2006 [update] . [4] [20]
Some virtual communities explicitly refer to the concept of cyberspace, for example Linden Lab calling their customers " Residents " of Second Life , while all such communities can be positioned "in cyberspace" for explanatory and comparative purposes (as did Sterling in The Hacker Crackdown , followed by many journalists), integrating the metaphor into a wider cyber-culture .
The metaphor has been useful in helping a new generation of thought leaders to reason through new military strategies around the world, led largely by the US Department of Defense (DoD). [21] The use of cyberspace as a metaphor has had its limits, however, especially in areas where the metaphor becomes confused with physical infrastructure. It has also been critiqued as being unhelpful for falsely employing a spatial metaphor to describe what is inherently a network. [22]

Alternate realities in philosophy and art

Predating computers
A forerunner of the modern ideas of cyberspace is the Cartesian notion that people might be deceived by an evil demon that feeds them a false reality. This argument is the direct predecessor of modern ideas of a brain in a vat and many popular conceptions of cyberspace take Descartes's ideas as their starting point.
Visual arts have a tradition, stretching back to antiquity , of artifacts meant to fool the eye and be mistaken for reality. This questioning of reality occasionally led some philosophers and especially theologians [ citation needed ] to distrust art as deceiving people into entering a world which was not real (see Aniconism ). The artistic challenge was resurrected with increasing ambition as art became more and more realistic with the invention of photography, film (see Arrival of a Train at La Ciotat ), and immersive computer simulations.

Influenced by computers

Philosophy
American counterculture exponents like William S. Burroughs (whose literary influence on Gibson and cyberpunk in general is widely acknowledged [23] [24] ) and Timothy Leary [25] were among the first to extoll the potential of computers and computer networks for individual empowerment. [26]
Some contemporary philosophers and scientists (e.g. David Deutsch in The Fabric of Reality ) employ virtual reality in various thought experiments . For example, Philip Zhai in Get Real: A Philosophical Adventure in Virtual Reality connects cyberspace to the platonic tradition:
Note that this brain-in-a-vat argument conflates cyberspace with reality , while the more common descriptions of cyberspace contrast it with the "real world".

A New Communication Model
The technological convergence of the mass media is the result of a long adaptation process of their communicative resources to the evolutionary changes of each historical moment. Thus, the new media became (plurally) an extension of the traditional media on the cyberspace, allowing to the public access information in a wide range of digital devices. [27] In other words, it is a cultural virtualization of human reality as a result of the migration from physical to virtual space (mediated by the ICTs), ruled by codes, signs and particular social relationships. Forwards, arise instant ways of communication, interaction and possible quick access to information, in which we are no longer mere senders, but also producers, reproducers, co-workers and providers. New technologies also help to “connect” people from different cultures outside the virtual space, what was unthinkable fifty years ago. In this giant relationships web, we mutually absorb each other’s beliefs, customs, values, laws and habits, cultural legacies perpetuated by a physical-virtual dynamics in constant metamorphosis (ibidem). In this sense, Professor Doctor Marcelo Mendonça Teixeira created, in 2013, a new model of communication to the virtual universe , based in Claude Elwood Shannon (1948) article "A Mathematical Theory of Communication".

Art
Having originated among writers, the concept of cyberspace remains most popular in literature and film. Although artists working with other media have expressed interest in the concept, such as Roy Ascott , "cyberspace" in digital art is mostly used as a synonym for immersive virtual reality and remains more discussed than enacted. [28]

Computer crime
Cyberspace also brings together every service and facility imaginable to expedite money laundering. One can purchase anonymous credit cards, bank accounts, encrypted global mobile telephones, and false passports. From there one can pay professional advisors to set up IBCs (International Business Corporations, or corporations with anonymous ownership) or similar structures in OFCs (Offshore Financial Centers). Such advisors are loath to ask any penetrating questions about the wealth and activities of their clients, since the average fees criminals pay them to launder their money can be as much as 20 percent. [29]

5-level model
In 2010, a 5-level model was designed in France. According to this model, cyberspace is composed of 5 layers based on information discoveries: language, writing, printing, Internet, etc. This original model links the world of information to telecommunication technologies.

Popular culture examples

See also

Notes
WebPage index: 00068
OTRS
OTRS , an initialism for Open-source Ticket Request System , is a free and open-source trouble ticket system software package that a company, organization, or other entity can use to assign tickets to incoming queries and track further communications about them. It is a means of managing incoming inquiries, complaints, support requests, defect reports, and other communications.
OTRS is part of the Lisog open source stack initiative.
Every ticket generated by the system has persistence or "history" showing what happened to the ticket within its life cycle. OTRS has the ability to merge multiple requests about the same incident, thus making it possible to work on an incident rather than on singular requests. [4] OTRS is a multiuser system which means that multiple agents may work simultaneously on the tickets in OTRS, reading the incoming messages, bringing them in order, and answering them. OTRS is highly scalable, capable of handling thousands of tickets per day and a nearly unlimited number of simultaneously working agents. [ citation needed ]
OTRS has integrated functionality for creating, reworking and searching FAQ texts. The FAQ texts may be incorporated into the agents' answers on tickets.
By using a multilingual web user interface, OTRS is usable independently from the respective operating systems since it is operated from a web browser . Furthermore, this facilitates the usage of OTRS by external agents or even customers participating in, working on or contributing to tickets.
OTRS establishes a framework of functions. For example, the System for Incident Response in Operational Security (SIRIOS) of the Federal Office for Information Security , Germany, is based on OTRS.

History
-

Overview
The Open-source Ticket Request System (OTRS) is more than a mailing list notification system for ticket requests.
Since its beginnings OTRS has been implemented in the programming language Perl . The web interface is made more user-friendly by using JavaScript (which can be switched off for security reasons). Different functionalities are implemented as reusable backend modules, making it possible to create custom modules to extend the functionality of the OTRS system.
The web interface itself uses its own templating mechanism called DTL (Dynamic Template Language) to facilitate the display of the systems output data.
Originally, OTRS worked only on MySQL databases. Support has since been added for PostgreSQL , Oracle , DB2 and Microsoft SQL Server . OTRS may be used on many UNIX or UNIX-like platforms (e.g. Linux , macOS , FreeBSD , etc.) as well as on Microsoft Windows .
The scalability of OTRS systems may be increased by using mod perl for the Apache Webserver or by separating the database and web server systems, allowing a large number of simultaneously working agents and high volumes of tickets.
In UNIX and UNIX-like environments OTRS works closely with system programs like the mail transfer agent Postfix or the mail filter procmail .

Addons
OTRS has a plugin mechanism, and many programmers have written add-ons to bring in new functions. In March 2011 a public repository named OPAR (OTRS Package ARchive) [6] started; until August 2015 about 140 add-ons were published.

See also
WebPage index: 00069
Wikibooks
Wikibooks (previously called Wikimedia Free Textbook Project and Wikimedia-Textbooks ) is a wiki -based Wikimedia project hosted by the Wikimedia Foundation for the creation of free content textbooks and annotated texts that anyone can edit.
In June 2016, Compete.com estimated that Wikibooks had 1,478,812 unique visitors. [2]

History
The wikibooks.org domain was registered on July 19, 2003 ( 2003-07-19 ) , [3] and launched to host and build free textbooks on subjects such as organic chemistry and physics . Two major sub-projects, Wikijunior and Wikiversity , were created within Wikibooks before its official policy was later changed so that future incubator type projects are started according to the Wikimedia Foundation's new project policy. In August 2006, Wikiversity became an independent Wikimedia Foundation project. [ citation needed ]

Wikijunior
Wikijunior is a subproject of Wikibooks that specializes in books for children. The project consists of both a magazine and a website, and is currently being developed in English, Danish, Finnish, French, German, Italian, Japanese, Spanish and Arabic. It is funded by a grant from the Beck Foundation.

Book content
While some books are original, others began as text copied over from other sources of free content textbooks found on the Internet. All of the site's content is released under a Creative Commons Attribution-Share Alike license (or a compatible license). This means that, as with its sister project, Wikipedia, contributions remain copyrighted to their creators, while the licensing ensures that it can be freely distributed and reused subject to certain conditions.
Wikibooks differs from Wikisource in that Wikisource collects exact copies and original translations of existing free content works, such as the original text of Shakespearean plays , while Wikibooks is dedicated either to original works, significantly altered versions of existing works or annotations to original works.
The project is working towards completion of textbooks on numerous subjects, which founders hope will be followed by mainstream adoption and use of textbooks developed and housed there.

See also
WebPage index: 00070
MediaWiki
MediaWiki is free and open-source wiki software . Originally developed by Magnus Manske and improved by Lee Daniel Crocker , it runs on many websites, including Wikipedia , Wiktionary and Wikimedia Commons . [4] [5] It is written in the PHP programming language and stores the contents into a database . Like WordPress , which is based on a similar licensing and architecture, it has become the dominant software in its category. The first version of the software was deployed to serve the needs of the Wikipedia encyclopedia in 2002. [6] Wikipedia and other Wikimedia projects continue to define a large part of the requirement set for MediaWiki. [7] The software is optimized to efficiently handle large projects, which can have terabytes of content and hundreds of thousands of hits per second. [7] [8] Because Wikipedia is one of the world's largest websites, achieving scalability through multiple layers of caching and database replication has been a major concern for developers. The software has more than 900 configuration settings [9] and more than 2,200 extensions available for enabling various features to be added or changed. [10] On Wikipedia alone, more than 1000 automated and semi-automated bots and other tools have been developed to assist in editing. [11] It has also been deployed by some companies as an internal knowledge management system, [12] and some educators have assigned students to use MediaWiki for collaborative group projects. [13]

License
MediaWiki is free and open source software and is distributed under the terms of the GNU General Public License version 2 or any later version while its documentation is released under the Creative Commons BY-SA 3.0 license and partly in the public domain . [14] Specifically, the manuals and other content at MediaWiki.org are Creative Commons -licensed, while the set of help pages intended to be freely copied into fresh wiki installations and/or distributed with MediaWiki software is public domain. This was done to eliminate legal issues arising from the help pages being imported into wikis with licenses that are incompatible with the Creative Commons license. [15] MediaWiki development has generally favored the use of open-source media formats. [16]

Development
MediaWiki has an active volunteer community for development and maintenance. Users who have made meaningful contributions to the project by submitting patches are generally, upon request, granted access to commit revisions to the project's Apache Subversion and now Git / Gerrit repository. [17] There is also a small group of paid programmers who primarily develop projects for the Wikimedia Foundation . Wikimedia participates in the Google Summer of Code by facilitating the assignment of mentors to students wishing to work on MediaWiki core and extension projects. [18] As of early November 2012, there were about two hundred developers who had committed changes to the MediaWiki core or extensions within the past year. [19] Major MediaWiki releases are generated approximately every three to eight months by taking snapshots of the development trunk, which is kept continuously in a runnable state; [20] minor releases , or point releases , are issued as needed to correct bugs (especially security problems).
MediaWiki also has a public bug tracker, phabricator.wikimedia.org , which runs Phabricator . The site is also used for feature and enhancement requests. [21]

History
When Wikipedia was first launched in January 2001, it ran on the existing wiki software UseModWiki , which was written in Perl and stored all wiki pages in text files. This software soon proved limiting, both in its functionality and its performance. In mid-2001, Magnus Manske , a developer and student at the University of Cologne , who was also a Wikipedia editor, began working on new software that would replace UseModWiki, specifically for use by Wikipedia. This software was written in PHP and stored all its information in a MySQL database. It launched on the English Wikipedia in January 2002, and was gradually deployed on all the Wikipedia language sites of that time. This software was referred to as "the PHP script" and as "phase II", with the name "phase I" retroactively given to the use of UseModWiki.
Increasing usage soon caused load problems again, and soon afterward, another rewrite of the software began, done by Lee Daniel Crocker , which was first known as "phase III". This new software was also written in PHP with a MySQL backend, and kept the basic interface of the phase II software, but was meant to be more scalable. It went live on Wikipedia in July 2002.
The Wikimedia Foundation was announced on June 20, 2003, and in July, Wikipedia contributor Daniel Mayer suggested the name "MediaWiki" for the software, as a play on "Wikimedia". [22] The name was gradually phased in beginning in August 2003. The name has frequently caused confusion due to its (intentional) similarity to the "Wikimedia" name (which itself is similar to "Wikipedia"). [23]
The product logo was created by Erik Möller using a flower photograph taken by Florence Nibart-Devouard , and was originally submitted to an international logo contest for a new Wikipedia logo held in mid-2003. [24] The logo came in third place, and was chosen to represent MediaWiki instead of Wikipedia, with the second place logo used for the Wikimedia Foundation. [25] The double square brackets symbolize the syntax MediaWiki uses for creating hyperlinks to other wiki pages, and the sunflower represents the diversity of content on Wikipedia, the constant growth and also the wildness. [26]
Later, Brion Vibber, the Chief Technical Officer of the Wikimedia Foundation , [27] took up the role of release manager and most active developer. [6] [28]
Major milestones in MediaWiki's development have included the categorization system, added in 2004; parser functions , added in 2006; flagged revisions , added in 2008; [29] the "ResourceLoader", a delivery system for CSS and JavaScript, added in 2011; [30] and the VisualEditor , a WYSIWYG (What You See Is What You Get) editor, added in 2013. [31]

Version history
The first version of MediaWiki, 1.1, was released in December 2003. The current stable version of MediaWiki, 1.28.0, was released in November 2016.

Sites using MediaWiki
MediaWiki's most famous use has been in Wikipedia and, to a lesser degree, Wikimedia's other projects. Wikia , a wiki farm , runs on MediaWiki. Other public wikis that run on MediaWiki include wikiHow and WikiLeaks .
A number of alternative wiki encyclopedias to Wikipedia run on MediaWiki, including Citizendium , Metapedia , Scholarpedia and Conservapedia . [32] MediaWiki is also used internally by a large number of companies, including Novell and Intel . [33] [34]
Notable usages of MediaWiki within governments include Intellipedia , used by the United States Intelligence Community , and Diplopedia , used by the United States Department of State . United Nations agencies such as the U.N. Development Programme and INSTRAW chose to implement their wikis using MediaWiki because "this software runs Wikipedia and is therefore guaranteed to be thoroughly tested, will continue to be developed well into the future, and future technicians on these wikis will be more likely to have exposure to MediaWiki than any other wiki software." [35]

Key features
MediaWiki provides a rich core feature set and a mechanism to attach extensions to provide additional functionality.

Internationalization and localisation
Due to the strong emphasis on multilingualism in the Wikimedia projects, internationalization and localization has received significant attention by developers. The user interface has been fully or partially translated into more than 300 languages on translatewiki.net , [36] and can be further customized by site administrators (the entire interface is editable through the wiki).
Several extensions, most notably those collected in the MediaWiki Language Extension Bundle , are designed to further enhance the multilingualism and internationalization of MediaWiki.

Installation and configuration
Installation of MediaWiki requires that the user have administrative privileges on a server running both PHP and a compatible type of SQL database . Some users find that setting up a virtual host is helpful if the majority of one's site runs under a framework (such as Zope or Ruby on Rails ) that is largely incompatible with MediaWiki. [37] Cloud hosting can enable a user to dispense with the task of building a new server by hand. [38]
An installation PHP script is accessed via a web browser to initialize the wiki's settings. It prompts the user for a minimal set of required parameters, leaving further changes, such as enabling uploads, [39] adding a site logo, [40] and installing extensions, to be made by modifying configuration settings [41] contained in a file called LocalSettings.php . [42] Some aspects of MediaWiki can be configured through special pages or by editing certain pages; for instance, abuse filters can be configured through a special page, [43] and certain gadgets can be added by creating JavaScript pages in the MediaWiki namespace. [44] The MediaWiki community publishes a comprehensive installation guide. [45]

Markup
One of the earliest differences between MediaWiki (and its predecessor, UseModWiki ) and other wiki engines was the use of " free links " instead of CamelCase . When MediaWiki was created, it was typical for wikis to require text like "WorldWideWeb" to create a link to a page about the World Wide Web : links in MediaWiki, on the other hand, are created by surrounding words with double square brackets, and any spaces between them are left intact, e.g. [[World Wide Web]] . This change was logical for the purpose of creating an encyclopedia, where accuracy in titles is important.
MediaWiki uses an extensible [46] lightweight wiki markup designed to be easier to use and learn than HTML . Tools exist for converting content such as tables between MediaWiki markup and HTML. [47] Efforts have been made to create a MediaWiki markup spec, but a consensus seems to have been reached that Wikicode requires context-sensitive grammar rules. [48] [49] The following side-by-side comparison illustrates the differences between wiki markup and HTML:
(Quotation above from Alice's Adventures in Wonderland by Lewis Carroll )

Editing interface
MediaWiki's page-editing tools have been described as somewhat challenging to learn. [50] A survey of students assigned to use a MediaWiki-based wiki found that when they were asked an open question about main problems with the wiki, 24% cited technical problems with formatting, e.g. "Couldn't figure out how to get an image in. Can't figure out how to show a link with words; it inserts a number." [51]
To make editing long pages easier, MediaWiki allows the editing of a subsection of a page (as identified by its header). A user can also indicate whether or not an edit is minor. Correcting spelling, grammar or punctuation are examples of minor edits, whereas adding paragraphs of new text is an example of a non-minor edit.
Sometimes while one user is editing, a second user saves an edit to the same part of the page. Then, when the first user attempts to save the page, an edit conflict occurs. The second user is then given an opportunity to merge his content into the page as it now exists following the first user's page save. An optional extension gives selected user groups priority when edit conflicts occur. [52]
MediaWiki's user interface has been localized in many different languages. A language for the wiki content itself can also be set, to be sent in the "Content-Language" HTTP header and "lang" HTML attribute .

Application programming interface
MediaWiki has an extensible web API ( application programming interface ) that provides direct, high-level access to the data contained in the MediaWiki databases. Client programs can use the API to log in, get data, and post changes. The API supports thin web-based JavaScript clients and end-user applications (such as vandal-fighting tools). The API can be accessed by the backend of another web site. [53] An extensive Python bot library, Pywikipediabot, [54] and a popular semi-automated tool called AutoWikiBrowser, also interface with the API. [55] The API is accessed via URLs such as http://en.wikipedia.org/w/api.php?action=query&list=recentchanges . In this case, the query would be asking Wikipedia for information relating to the last 10 edits to the site. One of the perceived advantages of the API is its language independence; it listens for HTTP connections from clients and can send a response in a variety of formats, such as XML , serialized PHP, YAML , or JSON . [56] Client code has been developed to provide layers of abstraction to the API. [57]

Rich content
MediaWiki supports rich content generated through specialized syntax. For example, the software comes with optional support for rendering mathematical formulas using LaTeX and a special parser written in OCaml . Similar functionality for other content, ranging from graphical timelines over mathematical plotting and musical scores to Egyptian hieroglyphs , is available in the form of extensions and also aesthetic sense has improved considerably.
The software has become more powerful at dealing with a wide variety of uploaded media files. Its richest functionality is in the area of images, where image galleries and thumbnails can be generated with relative ease. There is also support for Exif metadata . The use of MediaWiki to operate the Wikimedia Commons , one of the largest free content media archives, has driven the need for further functionality in this area.
Because any WYSIWYG editor would have to know wikitext grammar, and no full grammar for wikitext exists, MediaWiki currently provides no native WYSIWYG support. [58] It does come with a customizable graphical toolbar for simplifying the process of learning the wiki syntax. [59] Various extensions exist for handling WYSIWYG editing to different degrees, [60] some using variations of the popular CKEditor . Wikia , a popular wiki farm, uses a WYSIWYG extension that, being designed to be a modal editor, allows the user to flip back and forth between WYSIWYG and WikiText and Preview modes in a single editing session. [ citation needed ] MediaWiki also has an interface to allow the transparent use of external editors for uploaded files and wiki pages. [61]

Tracking edits
Among the features of MediaWiki to assist in tracking edits is a Recent Changes feature that provides a list of recent edits to the wiki. This list contains basic information about those edits such as the editing user, the edit summary, the page edited, as well as any tags (e.g. "possible malware link") [62] added by customizable abuse filters and other extensions to aid in combating unhelpful edits. [63] On more active wikis, so many edits occur that it is hard to track Recent Changes manually. Anti-vandal software, including user-assisted tools [64] are sometimes employed on such wikis to process Recent Changes items. Server load can be reduced by sending a continuous feed of Recent Changes to an IRC channel that these tools can monitor, eliminating their need to send requests for a refreshed Recent Changes feed to the API. [65] [66]
Another important tool is watchlisting. Each logged-in user has a watchlist to which the user can add whatever pages he or she wishes. When an edit is made to one of those pages, a summary of that edit appears on the watchlist the next time it is refreshed. [67] As with the recent changes page, recent edits that appear on the watchlist contain clickable links for easy review of the article history and specific changes made.
There is also capability to review all edits made by any particular user. In this way, if an edit is identified as problematic, it is possible to check the user's other edits for issues.
MediaWiki allows one to link to specific versions of articles. This has been useful to the scientific community, in that expert peer reviewers could analyse articles, improve them and provide links to the trusted version of that article. [68]

Navigation
Navigation through the wiki is largely through internal wikilinks.
These implement page existence detection, in which a link is colored blue if the target page exists on the local wiki and red if it does not. When a user clicks on a red link, they are prompted to create an article with that title. Page existence detection makes it practical for users to create "wikified" articles — that is, articles containing links to other pertinent subjects — without those other articles being yet in existence.
The red/blue distinction alerts:
Interwiki links function much the same way as namespaces. A set of interwiki prefixes can be configured to cause, for instance, a page title of wikiquote:Jimbo Wales to direct the user to the Jimbo Wales article on Wikiquote . [69] Unlike internal wikilinks, interwiki links lack page existence detection functionality, and accordingly there is no way to tell whether a blue interwiki link is broken or not.

Content organization

Page tabs and associated pages
Page tabs are displayed at the top of pages. These tabs allow users to perform actions or view pages that are related to the current page. The available default actions include viewing, editing, and discussing the current page. The specific tabs displayed depend on whether or not the user is logged into the wiki and whether the user has sysop privileges on the wiki. For instance, the ability to move a page or add it to one's watchlist is usually restricted to logged-in users. The site administrator can add or remove tabs by using JavaScript or installing extensions. [70]
Each page has an associated history page from which the user can access every version of the page that has ever existed and generate diffs between two versions of his choice. Users' contributions are displayed not only here, but also via a "user contributions" option on a sidebar. Carl Challborn & Teresa Reimann note that "While this feature may be a slight deviation from the collaborative, 'ego-less' spirit of wiki purists, it can be very useful for educators who need to assess the contribution and participation of individual student users." [71]

 Namespaces
MediaWiki provides many features beyond hyperlinks for structuring content. One of the earliest features is namespaces . One of Wikipedia's earliest problems had been the separation of encyclopedic content from pages pertaining to maintenance and communal discussion, as well as personal pages about encyclopedia editors. Namespaces are prefixes before a page title (such as " User: " or " Talk: ") that serve as descriptors for the page's purpose and allow multiple pages with different functions to exist under the same title. For instance, a page titled " [[The Terminator]] ", in the default namespace, could describe the 1984 movie starring Arnold Schwarzenegger , while a page titled " [[User:The Terminator]] " could be a profile describing a user who chooses this name as a pseudonym. More commonly, each namespace has an associated " Talk: " namespace, which can be used to discuss its contents, such as " User talk: " or " Template talk: ". The purpose of having discussion pages is to allow content to be separated from discussion surrounding the content. [72] [73]
Namespaces can be viewed as folders that separate different basic types of information or functionality. Custom namespaces can be added by the site administrators. There are 16 namespaces by default for content, with 2 "pseudo-namespaces" used for dynamically generated " Special: " pages and links to media files. Each namespace on MediaWiki is numbered: content page namespaces have even numbers and their associated talk page namespaces have odd numbers. [74]

Category tags
Users can create new categories and add pages and files to those categories by appending one or more category tags to the content text. Adding these tags creates links at the bottom of the page that take the reader to the list of all pages in that category, making it easy to browse related articles. [75] The use of categorization to organize content has been described as a combination of:

Subpages
In addition to namespaces, content can be ordered using subpages . This simple feature provides automatic breadcrumbs of the pattern [[Page title/Subpage title]] from the page after the slash (in this case, "Subpage title") to the page before the slash (in this case, "Page title").

Customization
If the feature is enabled, users can customize their stylesheets and configure client-side JavaScript to be executed with every pageview. On Wikipedia, this has led to a large number of additional tools and helpers developed through the wiki and shared among users. For instance, Lupin's navigation popups is a custom JavaScript tool that shows previews of articles when the user hovers over links, and also provides shortcuts for common maintenance tasks. [77] Another example is wikEd , a full-featured MediaWiki-integrated text editor that provides syntax highlighting and search and replace functions. [44]
The entire MediaWiki user interface can be edited through the wiki itself by users with the necessary permissions (typically called "administrators"). This is done through a special namespace with the prefix "MediaWiki:", where each page title identifies a particular user interface message. Using an extension, [78] it is also possible for a user to create personal scripts, and to choose whether certain sitewide scripts should apply to them by toggling the appropriate options in the user preferences page.

Templates
The "MediaWiki:" namespace was also originally used for creating custom text blocks that could then be dynamically loaded into other pages using a special syntax. This content was later moved into its own namespace, "Template:".
Templates are text blocks that can be dynamically loaded inside another page whenever that page is requested. The template is a special link in double curly brackets (for example " {{Disputed|date=October 2008}} "), which calls the template (in this case located at Template:Disputed ) to load in place of the template call.
Templates are structured documents containing attribute–value pairs . They are defined with parameters , to which are assigned values when transcluded on an article page. The name of the parameter is delimited from the value by an equals sign . A class of templates known as infoboxes is used on Wikipedia to collect and present a subset of information about its subject, usually on the top (mobile view) or top right-hand corner (desktop view) of the document.
Templates are processed by a template processor , a template engine which produces a web document and a style sheet used for page layout of the document. This enables the design of the template to be separated from the content it manipulates.
A related method, called template substitution (called by adding subst: at the beginning of a template link) inserts (like a copy and paste operation) the contents of the template into the target page, instead of loading the template contents dynamically whenever the page is loaded. This can lead to inconsistency when using templates, but may be useful in certain cases, and in most cases requires fewer server resources (the actual amount of savings can vary depending on wiki configuration and the complexity of the template).
Templates have found many different uses. Templates enable users to create complex table layouts that are used consistently across multiple pages, and where only the content of the tables gets inserted using template parameters. Templates are often used to identify problems with a Wikipedia article by putting a template in the article. This template then outputs a graphical box stating that the article content is disputed or in need of some other attention, and also categorize it so that articles of this nature can be located. Templates are also used on user pages to send users standard messages welcoming them to the site, [79] giving them awards for outstanding contributions, [80] [81] warning them when their behavior is considered inappropriate, [82] notifying them when they are blocked from editing, [83] and so on.

Groups and restriction of access
MediaWiki offers flexibility in creating and defining user groups. For instance, it would be possible to create an arbitrary "ninja" group that can block users and delete pages, and whose edits are hidden by default in the recent changes log. It is also possible to set up a group of "autoconfirmed" users that one becomes a member of after making a certain number of edits and waiting a certain number of days. [84] Some groups that are enabled by default are bureaucrats and sysops. Bureaucrats have power to change other users' rights. Sysops have power over page protection and deletion and the blocking of users from editing. MediaWiki's available controls on editing rights have been deemed sufficient for publishing and maintaining important documents such as a manual of standard operating procedures in a hospital. [85]
When a page consists only of useless content, there are several ways to remove that content. The simplest way, available to all users, is simply to blank the page. However, this interferes with page existence detection, unless an extension is installed to treat blanked pages as though they were nonexistent. [86] Blanking also leaves the content accessible through the history page, an outcome that, while potentially increasing transparency by allowing non-sysops to easily review the content removal decision for appropriateness, might be unacceptable or even unlawful [87] in some cases. Another option is for a sysop to delete the page, and thereby prevent it from being viewed by non-sysops. Another level of deletion, called RevisionDelete, can be used by a group (e.g. "Oversighters") to prevent a page from being viewed by non-members of that group. [88] It is also possible, using certain extensions, to remove content from being viewed through any of the normal channels on the wiki, [89] or even to completely delete revisions from the database. [90]
MediaWiki comes with a basic set of features related to restricting access, but its original and ongoing design is driven by functions that largely relate to content, not content segregation. As a result, with minimal exceptions (related to specific tools and their related "Special" pages), page access control has never been a high priority in core development and developers have stated that users requiring secure user access and authorisation controls should not rely on MediaWiki, since it was never designed for these kinds of situations. For instance, it is extremely difficult to create a wiki where only certain users can read and access some pages. [91] Here, wiki engines like TWiki , MoinMoin and WikkaWiki provide more flexibility by supporting advanced security mechanisms like access control lists .

Extensibility
The MediaWiki codebase contains various "hooks" using callback functions to add additional PHP code in an extensible way. This allows developers to write extensions without necessarily needing to modify the core or having to submit their code for review. Installing an extension typically consists of adding a line to the configuration file, though in some cases additional changes such as database updates or core patches are required.
Five main extension points were created to allow developers to add features and functionalities to MediaWiki. Hooks are run every time a certain event happens; for instance, the ArticleSaveComplete hook occurs after a save article request has been processed. [92] This can be used, for example, by an extension that notifies selected users whenever a page edit occurs on the wiki from new or anonymous users. [93] New tags can be created to process data with opening and closing tags ( <newtag>...</newtag> ). [94] Parser functions can be used to create a new command ( {{#if:...|...|...}} ). [95] New special pages can be created to perform a specific function. These pages are dynamically generated. For example, a special page might show all pages that have one or more links to an external site or it might create a form providing user submitted feedback. [96] Skins allow users to customize the look and feel of MediaWiki. [97] A minor extension point allows the use of Amazon S3 to host image files. [98]

Extensions

Resources to developers
MediaWiki can be made more advanced and useful for various purposes through its extensions. These extensions vary greatly in complexity.
The Wikimedia Foundation operates a Git server where many extensions host their repository. Most of them also have a documentation page on the MediaWiki website.
Some other sites also known for development of – or support for – extensions are MediaWiki.org, which maintains an extension matrix; [10] and Google Code . [99]
MediaWiki code review was itself historically facilitated through a MediaWiki extension. [100] As of March 2012, it has been done through Gerrit .
Since version 1.16, MediaWiki also used the jQuery library. [101]

For parser functions
Among the most popular extensions is a parser function extension, ParserFunctions, that allows different content to be rendered based on the result of conditional statements . [102] These conditional statements can perform functions such as evaluating whether a parameter is empty, comparing strings, evaluating mathematical expressions, and returning one of two values depending on whether a page exists. It was designed as a replacement for a notoriously inefficient template called {{Qif}}. [103] Schindler recounts the history of the ParserFunctions extension as follows: [29]
Another parser functions extension, StringFunctions, was developed to allow evaluation of string length, string position, and so on. Wikimedia communities, having created awkward workarounds to accomplish the same functionality, [104] clamored for it to be enabled on their projects. [105] Much of its functionality was eventually integrated into the ParserFunctions extension, [106] albeit disabled by default and accompanied by a warning from Tim Starling that enabling string functions would allow users "to implement their own parsers in the ugliest, most inefficient programming language known to man: MediaWiki wikitext with ParserFunctions." [107]

For footnotes and academic-related display
Another very popular extension is a citation extension that enables footnotes to be added to pages using inline references. [108] This extension has, however, been criticized for being difficult to use and requiring the user to memorize complex syntax. A tool called ProveIt was proposed as a compensation. [109] A gadget called RefToolbar has also been created to make it easier to create citations using common templates. MediaWiki has some extensions that are well-suited for academia, such as mathematics extensions [110] and an extension that allows molecules to be rendered in 3D . [111]

Integration
A generic Widgets framework has been created that allows MediaWiki to integrate with virtually anything. Other examples of extensions that could improve a wiki are category suggestion extensions [112] and extensions for inclusion of Flash Videos , [113] YouTube videos, [114] and RSS feeds . [115] An extension to integrate with Facebook is forthcoming. [116] Metavid , a site that archives video footage of the U.S. Senate and House floor proceedings, was created using code extending MediaWiki into the domain of collaborative video authoring. [117] One extension, Viskimap, makes use of graphic organizers to visualize the relationships between content pages, so that students can easily get an understanding of the content elements and their relations, as they navigate through the wiki pages. [118]

Combating linkspam
There are many spambots that search the Internet for MediaWiki installations and add linkspam to them, despite the fact that MediaWiki uses the nofollow attribute to discourage such attempts at search engine optimization . [119] Part of the problem is that third party republishers, such as mirrors , may not independently implement the nofollow tag on their websites, so marketers can still get PageRank benefit by inserting links into pages when those entries appear on third party websites. [120] Anti-spam extensions have been developed to combat the problem by introducing CAPTCHAs , [121] blacklisting certain URLs, [122] and allowing bulk deletion of pages recently added by a particular user. [123]

Searches and queries
MediaWiki comes pre-installed with a standard text-based search (since 2014 uses the CirrusSearch engine). Extensions exist to let MediaWiki use third-party search tools like Lucene (used on Wikimedia sites) [124] and Sphinx . [125]
Various MediaWiki extensions have also been created to allow for more complex, faceted search , on both data entered within the wiki and on metadata such as pages' revision history. [126] [127] Example of extensions facilitating such analyses include Semantic MediaWiki , [128] [129] which provides the ability to add structured and searchable relations and attributes to wiki pages, WikiTrust , which implements a system for checking the author, origin, and reliability of wiki text, and DynaTable. [130]
An extension called Woogle [131] attempts to add enterprise search engine functionality to MediaWiki. [132]

Database
MediaWiki can use either the MySQL / MariaDB , PostgreSQL or SQLite relational database management system . There is limited support for Oracle Database . [133] A MediaWiki database contains several dozen tables , including a page table that contains page titles, page ids, and other metadata; [134] and a revision table to which is added a new row every time an edit is made, containing the page id, a brief textual summary of the change performed, the user name of the article editor (or its IP address the case of an unregistered user) and a timestamp. [135] [136]
In a 4½ year period, the MediaWiki database had 170 schema versions. [137] Possibly the largest schema change was done in MediaWiki 1.5, when the storage of metadata was separated from that of content, to improve performance flexibility. When this upgrade was applied to Wikipedia, the site was locked for editing, and the schema was converted to the new version in about 22 hours. Some software enhancement proposals, such as a proposal to allow sections of articles to be watched via watchlist, have been rejected because the necessary schema changes would have required excessive Wikipedia downtime. [138]

Performance and storage
Because it is used to run one of the highest-traffic sites on the Web, Wikipedia, MediaWiki performance and scalability have been highly optimized. [28] MediaWiki supports Squid , load-balanced database replication, client-side caching, memcached or table-based caching for frequently accessed processing of query results, a simple static file cache, feature-reduced operation, revision compression, and a job queue for database operations. According to Wikimedia Networking Coordinator Mark Bergsma, MediaWiki developers have attempted to optimize the software by not doing anything stupid, avoiding expensive algorithms, database queries, etc., caching every result that is expensive and has temporal locality of reference, and focusing on the hot spots in the code through profiling . [139]
MediaWiki code is designed to allow for data to be written to a master database and read from slave databases, although the master can be used for some read operations if the slaves are not yet up to date. Metadata , such as article revision history, article relations (links, categories etc.), user accounts and settings can be stored in core databases and cached; the actual revision text, being more rarely used, can be stored as append-only blobs in external storage. The software is suitable for the operation of large scale wiki farms such as Wikimedia , which had about 800 wikis as of August 2011. However, MediaWiki comes with no built-in GUI to manage such installations.
Empirical evidence shows most revisions in MediaWiki databases tend to differ only slightly from previous revisions. Therefore, subsequent revisions of an article can be concatenated and then compressed, achieving very high data compression ratios of up to 100x. [139]
For more information on the architecture, such as how it stores wikitext and assembles a page, see External links .

Limitations
The parser serves as the de facto standard for the MediaWiki syntax, as no formal syntax has been defined. Due to this lack of a formal definition, it has been difficult to create WYSIWYG editors for MediaWiki (although one called VisualEditor is in progress [140] ), or to port the parsing to another language.
MediaWiki is not designed to be a suitable replacement for dedicated online forum or blogging software, [141] although extensions do exist to allow for both of these. [142] [143]
It is common for new MediaWiki users to make certain mistakes, such as forgetting to sign posts with four tildes (~~~~), [144] or manually entering a plaintext signature, [145] due to unfamiliarity with the idiosyncratic particulars involved in communication on MediaWiki discussion pages. On the other hand, the format of these discussion pages has been cited as a strength by one educator, who stated that it provides more fine-grain capabilities for discussion than traditional threaded discussion forums. For example, instead of 'replying' to an entire message, the participant in a discussion can create a hyperlink to a new wiki page on any word from the original page. Discussions are easier to follow since the content is available via hyperlinked wiki page, rather than a series of reply messages on a traditional threaded discussion forum. However, except in few cases, students were not using this capability, possibly because of their familiarity with the traditional linear discussion style and a lack of guidance on how to make the content more ' link-rich '. [146]
MediaWiki has little support for the creation of dynamically assembled documents, or pages that aggregate data from other pages. While it is possible to create new "special" pages, it requires coding an extension in PHP and thus administrative rights to the server running MediaWiki. Some research has been done on enabling such features directly within MediaWiki. [147] The Semantic MediaWiki extension provides these features, but it is not in use on Wikipedia. The Wikibase Repository and Wikibase Repository client are however implemented in Wikidata and Wikipedia respectively, and to some extent provides semantic web features, and linking of centrally stored data to infoboxes in various Wikipedia articles.
Upgrading MediaWiki is usually fully automated, requiring no changes to the site content or template programming. Historically troubles have been encountered when upgrading from significantly older versions. [148]

Security
MediaWiki developers have enacted security standards, both for core code and extensions. [149] SQL queries and HTML output are usually done through wrapper functions that handle validation, escaping, filtering for prevention of cross-site scripting and SQL injection . [150] As of April 2010, approximately 50 of MediaWiki's extensions had unresolved security issues. [151] Many security issues have had to be patched after a MediaWiki version release, [152] and accordingly MediaWiki.org states, "The most important security step you can take is to keep your software up to date" by subscribing to the announcement listserv and installing security updates that are announced. [153] A PHPIDS Extension for MediaWiki has been developed to identify intrusions. [154]

Developer community
MediaWiki developers are spread around the world, though with a majority in the United States and Europe. Face-to-face meetings and programming sessions for MediaWiki developers have been held once or several times a year since 2004. [155]

Support
Support for MediaWiki users consists of:

Comparison to other online collaboration software
Users of online collaboration software are familiar with MediaWiki's functions and layout due to its noted use on Wikipedia. Compared to other wikis, MediaWiki is also fairly aesthetically pleasing, though simple, and has an easily customized side menu and stylesheet . [159] However, in one assessment, Confluence was deemed to be a superior product due to its very usable API and ability to better support multiple wikis. [111] Wiki providers Socialtext , eXo Platform and JotSpot have/had project management features that MediaWiki lacks. [160]
A study was done at the University of Hong Kong comparing TWiki to MediaWiki. The authors noted that TWiki has been considered as a collaborative tool for development of educational papers and technical projects, whereas MediaWiki's noted use is due to Wikipedia. Although both platforms allow discussion and tracking of progress, TWiki has a "Report" part that MediaWiki lacks. Students perceived MediaWiki as being easier to use and more enjoyable than TWiki. When asked whether they recommended using MediaWiki for knowledge management course group project, 15 out of 16 respondents expressed their preference for MediaWiki giving answers of great certainty, such as "of course", "for sure". [161] TWiki and MediaWiki both have flexible plug-in architecture. [162] A study that compared students' experience with MediaWiki to that with Google Documents found that students gave the latter a much higher rating on user-friendly layout. [163]

See also
WebPage index: 00071
MySQL
MySQL (officially pronounced as / m aɪ ˌ ɛ s k juː ˈ ɛ l / "My S-Q-L", [6] ) is an open-source relational database management system (RDBMS). [7] Its name is a combination of "My", the name of co-founder Michael Widenius ' daughter, [8] and " SQL ", the abbreviation for Structured Query Language . The MySQL development project has made its source code available under the terms of the GNU General Public License , as well as under a variety of proprietary agreements. MySQL was owned and sponsored by a single for-profit firm, the Swedish company MySQL AB , now owned by Oracle Corporation . [9] For proprietary use, several paid editions are available, and offer additional functionality.
MySQL is a central component of the LAMP open-source web application software stack (and other " AMP " stacks). LAMP is an acronym for " Linux , Apache , MySQL, Perl / PHP / Python ". Applications that use the MySQL database include: TYPO3 , MODx , Joomla , WordPress , phpBB , MyBB , and Drupal . MySQL is also used in many high-profile, large-scale websites , including Google [10] [11] (though not for searches), Facebook , [12] [13] [14] Twitter , [15] Flickr , [16] and YouTube . [17]

Overview
MySQL is written in C and C++ . Its SQL parser is written in yacc , but it uses a home-brewed lexical analyzer . [18] MySQL works on many system platforms , including AIX , BSDi , FreeBSD , HP-UX , eComStation , i5/OS , IRIX , Linux , macOS , Microsoft Windows , NetBSD , Novell NetWare , OpenBSD , OpenSolaris , OS/2 Warp, QNX , Oracle Solaris , Symbian , SunOS , SCO OpenServer , SCO UnixWare , Sanos and Tru64 . A port of MySQL to OpenVMS also exists. [19]
The MySQL server software itself and the client libraries use dual-licensing distribution. They are offered under GPL version 2, [20] beginning from 28 June 2000 [21] (which in 2009 has been extended with a FLOSS License Exception) [22] or to use a proprietary license. [23]
Support can be obtained from the official manual. [24] Free support additionally is available in different IRC channels and forums. Oracle offers paid support via its MySQL Enterprise products. They differ in the scope of services and in price. Additionally, a number of third party organisations exist to provide support and services, including MariaDB and Percona .
MySQL has received positive reviews, and reviewers noticed it "performs extremely well in the average case" and that the "developer interfaces are there, and the documentation (not to mention feedback in the real world via Web sites and the like) is very, very good". [25] It has also been tested to be a "fast, stable and true multi-user, multi-threaded sql database server". [26]

History
MySQL was created by a Swedish company, MySQL AB , founded by David Axmark , Allan Larsson and Michael "Monty" Widenius . Original development of MySQL by Widenius and Axmark began in 1994. [27] The first version of MySQL appeared on 23 May 1995. It was initially created for personal usage from mSQL based on the low-level language ISAM , which the creators considered too slow and inflexible. They created a new SQL interface, while keeping the same API as mSQL. By keeping the API consistent with the mSQL system, many developers were able to use MySQL instead of the (proprietarily licensed) mSQL antecedent. [ citation needed ] [ dubious – discuss ]

Milestones
Additional milestones in MySQL development included:

Legal disputes and acquisitions
On 15 June 2001, NuSphere sued MySQL AB, TcX DataKonsult AB and its original authors Michael ("Monty") Widenius and David Axmark in U.S District Court in Boston for "breach of contract, tortious interference with third party contracts and relationships and unfair competition". [44] [45]
In 2002, MySQL AB sued Progress NuSphere for copyright and trademark infringement in United States district court . NuSphere had allegedly violated MySQL's copyright by linking MySQL's GPL'ed code with NuSphere Gemini table without being in compliance with the license. [46] After a preliminary hearing before Judge Patti Saris on 27 February 2002, the parties entered settlement talks and eventually settled. [47] After the hearing, FSF commented that "Judge Saris made clear that she sees the GNU GPL to be an enforceable and binding license." [48]
In October 2005, Oracle Corporation acquired Innobase OY, the Finnish company that developed the third-party InnoDB storage engine that allows MySQL to provide such functionality as transactions and foreign keys . After the acquisition, an Oracle press release mentioned that the contracts that make the company's software available to MySQL AB would be due for renewal (and presumably renegotiation) some time in 2006. [49] During the MySQL Users Conference in April 2006, MySQL issued a press release that confirmed that MySQL and Innobase OY agreed to a "multi-year" extension of their licensing agreement. [50]
In February 2006, Oracle Corporation acquired Sleepycat Software , [51] makers of the Berkeley DB , a database engine providing the basis for another MySQL storage engine. This had little effect, as Berkeley DB was not widely used, and was dropped (due to lack of use) in MySQL 5.1.12, a pre-GA release of MySQL 5.1 released in October 2006. [52]
In January 2008, Sun Microsystems bought MySQL for $1 billion. [53]
In April 2009, Oracle Corporation entered into an agreement to purchase Sun Microsystems, [54] then owners of MySQL copyright and trademark. Sun's board of directors unanimously approved the deal. It was also approved by Sun's shareholders, and by the U.S. government on 20 August 2009. [55] On 14 December 2009, Oracle pledged to continue to enhance MySQL [56] as it had done for the previous four years.
A movement against Oracle's acquisition of MySQL, to "Save MySQL" [57] from Oracle was started by one of the MySQL founders, Monty Widenius . The petition of 50,000+ developers and users called upon the European Commission to block approval of the acquisition. At the same time, several Free Software opinion leaders (including Eben Moglen , Pamela Jones of Groklaw , Jan Wildeboer and Carlo Piana , who also acted as co-counsel in the merger regulation procedure) advocated for the unconditional approval of the merger. [ citation needed ] As part of the negotiations with the European Commission, Oracle committed that MySQL server will continue until at least 2015 to use the dual-licensing strategy long used by MySQL AB, with proprietary and GPL versions available. The antitrust of the EU had been "pressuring it to divest MySQL as a condition for approval of the merger". But, as revealed by WikiLeaks , the US Department of Justice, at the request of Oracle, pressured the EU to approve the merger unconditionally. [58] The European Commission eventually unconditionally approved Oracle's acquisition of MySQL on 21 January 2010. [59]
In January 2009, prior to Oracle's acquisition of MySQL, Monty Widenius started a GPL-only fork, MariaDB . MariaDB is based on the same code base as MySQL server 5.5 and aims to maintain compatibility with Oracle-provided versions. [60]

Features
MySQL is offered under two different editions: the open source MySQL Community Server and the proprietary Enterprise Server . [61] MySQL Enterprise Server is differentiated by a series of proprietary extensions which install as server plugins, but otherwise shares the version numbering system and is built from the same code base.
Major features as available in MySQL 5.6:
The developers release minor updates of the MySQL Server approximately every two months. The sources can be obtained from MySQL's website or from MySQL's GitHub repository, both under the GPL license.

Limitations
When using some storage engines other than the default of InnoDB, MySQL does not comply with the full SQL standard for some of the implemented functionality, including foreign key references [68] and check constraints. [69]
Up until MySQL 5.7, triggers are limited to one per action / timing, meaning that at most one trigger can be defined to be executed after an INSERT operation, and one before INSERT on the same table. [70] No triggers can be defined on views. [70]
MySQL database's inbuilt functions like UNIX_TIMESTAMP() will return 0 after 03:14:07 UTC on 19 January 2038 . [71]

Deployment
MySQL can be built and installed manually from source code, but it is more commonly installed from a binary package unless special customizations are required. On most Linux distributions , the package management system can download and install MySQL with minimal effort, though further configuration is often required to adjust security and optimization settings.
Though MySQL began as a low-end alternative to more powerful proprietary databases, it has gradually evolved to support higher-scale needs as well. It is still most commonly used in small to medium scale single-server deployments, either as a component in a LAMP -based web application or as a standalone database server. Much of MySQL's appeal originates in its relative simplicity and ease of use, which is enabled by an ecosystem of open source tools such as phpMyAdmin . In the medium range, MySQL can be scaled by deploying it on more powerful hardware, such as a multi-processor server with gigabytes of memory.
There are, however, limits to how far performance can scale on a single server ('scaling up'), so on larger scales, multi-server MySQL ('scaling out') deployments are required to provide improved performance and reliability. A typical high-end configuration can include a powerful master database which handles data write operations and is replicated to multiple slaves that handle all read operations. [72] The master server continually pushes binlog events to connected slaves so in the event of failure a slave can be promoted to become the new master, minimizing downtime. Further improvements in performance can be achieved by caching the results from database queries in memory using memcached , or breaking down a database into smaller chunks called shards which can be spread across a number of distributed server clusters. [73]

Backup software
mysqldump is a logical backup tool included with both community and enterprise editions of MySQL. It supports backing up from all storage engines. MySQL Enterprise Backup is a hot backup utility included as part of the MySQL Enterprise subscription from Oracle, offering native InnoDB hot backup, as well as backup for other storage engines.
XtraBackup is an open-source MySQL hot backup software program. Features include hot, non-locking backups for InnoDB storage, incremental backups, streaming, parallel-compressed backups, throttling based on the number of I/O operations per second, etc. [74]

High availability Software
MySQL Fabric is an integrated system for managing a collection of MySQL servers, and a framework on top of which high availability and database sharding is built. MySQL Fabric is open-source, and supports procedure execution in the presence of failure, providing an execution model usually called resilient execution. MySQL client libraries are extended so they are hiding the complexities of handling failover in the event of a server failure, as well as correctly dispatching transactions to the shards. [75]

Cloud deployment
MySQL can also be run on cloud computing platforms such as Amazon EC2 . Some common deployment models for MySQL on the cloud are:

User interfaces

Graphical user interfaces
A graphical user interface (GUI) is a type of interface that allows users to interact with electronic devices or programs through graphical icons and visual indicators such as secondary notation, as opposed to text-based interfaces, typed command labels or text navigation. GUIs are easier to learn than command-line interfaces (CLIs), which require commands to be typed on the keyboard.
Third-party proprietary and free graphical administration applications (or "front ends") are available that integrate with MySQL and enable users to work with database structure and data visually. Some well-known front ends are:

Command-line interfaces
A command-line interface is a means of interacting with a computer program where the user issues commands to the program by typing in successive lines of text (command lines). MySQL ships with many command line tools, from which the main interface is the mysql client. [81] [82]
MySQL Utilities is a set of utilities designed to perform common maintenance and administrative tasks. Originally included as part of the MySQL Workbench, the utilities are a stand-alone download available from Oracle.
Percona Toolkit is a cross-platform toolkit for MySQL, developed in Perl . [83] Percona Toolkit can be used to prove replication is working correctly, fix corrupted data, automate repetitive tasks, and speed up servers. Percona Toolkit is included with several Linux distributions such as CentOS and Debian , and packages are available for Fedora and Ubuntu as well. Percona Toolkit was originally developed as Maatkit, but as of late 2011, Maatkit is no longer developed.

Application programming interfaces
Many programming languages with language-specific APIs include libraries for accessing MySQL databases. These include MySQL Connector/Net for integration with Microsoft's Visual Studio (languages such as C# and VB are most commonly used) and the JDBC driver for Java. In addition, an ODBC interface called MySQL Connector/ODBC allows additional programming languages that support the ODBC interface to communicate with a MySQL database, such as ASP or ColdFusion . The HTSQL – URL -based query method also ships with a MySQL adapter, allowing direct interaction between a MySQL database and any web client via structured URLs.

Project forks
In software engineering , a project fork happens when developers take a copy of source code from one software package and start independent development on it, creating a distinct and separate piece of software –  a new (third-party) version. The term often implies not merely creating a development branch , but also a split in the developer community (a form of schism ). [84] MySQL forks include the following:

Current

Abandoned

See also

Notes
WebPage index: 00072
URL redirection
URL redirection , also called URL forwarding , is a World Wide Web technique for making a web page available under more than one URL address. When a web browser attempts to open a URL that has been redirected, a page with a different URL is opened. Similarly, domain redirection or domain forwarding is when all pages in a URL domain are redirected to a different domain, as when wikipedia.com and wikipedia.net are automatically redirected to wikipedia.org . URL redirection is done for various reasons: for URL shortening ; to prevent broken links when web pages are moved; to allow multiple domain names belonging to the same owner to refer to a single web site ; to guide navigation into and out of a website; for privacy protection; and for hostile purposes such as phishing attacks.

Purposes
There are several reasons to use URL redirection:

Similar domain names
A user might mistype a URL, for example, "example.com" and "exmaple.com". Organizations often register these "misspelled" domains and redirect them to the "correct" location: example.com. The addresses example.com and example.net could both redirect to a single domain, or web page, such as example.org. This technique is often used to "reserve" other top-level domains (TLD) with the same name, or make it easier for a true ".edu" or ".net" to redirect to a more recognizable ".com" domain.

Moving pages to a new domain
Web pages may be redirected to a new domain for three reasons:
With URL redirects, incoming links to an outdated URL can be sent to the correct location. These links might be from other sites that have not realized that there is a change or from bookmarks/favorites that users have saved in their browsers. The same applies to search engines . They often have the older/outdated domain names and links in their database and will send search users to these old URLs. By using a "moved permanently" redirect to the new URL, visitors will still end up at the correct page. Also, in the next search engine pass, the search engine should detect and use the newer URL.

Logging outgoing links
The access logs of most web servers keep detailed information about where visitors came from and how they browsed the hosted site. They do not, however, log which links visitors left by. This is because the visitor's browser has no need to communicate with the original server when the visitor clicks on an outgoing link. This information can be captured in several ways. One way involves URL redirection. Instead of sending the visitor straight to the other site, links on the site can direct to a URL on the original website's domain that automatically redirects to the real target. This technique bears the downside of the delay caused by the additional request to the original website's server. As this added request will leave a trace in the server log, revealing exactly which link was followed, it can also be a privacy issue. [1] The same technique is also used by some corporate websites to implement a statement that the subsequent content is at another site, and therefore not necessarily affiliated with the corporation. In such scenarios, displaying the warning causes an additional delay.

Short aliases for long URLs
Web applications often include lengthy descriptive attributes in their URLs which represent data hierarchies, command structures, transaction paths and session information. This practice results in a URL that is aesthetically unpleasant and difficult to remember, and which may not fit within the size limitations of microblogging sites. URL shortening services provide a solution to this problem by redirecting a user to a longer URL from a shorter one.

Meaningful, persistent aliases for long or changing URLs
Sometimes the URL of a page changes even though the content stays the same. Therefore, URL redirection can help users who have bookmarks. This is routinely done on Wikipedia whenever a page is renamed.

Post/Redirect/Get
Post/Redirect/Get (PRG) is a web development design pattern that prevents some duplicate form submissions, creating a more intuitive interface for user agents (users).

Device targeting and geotargeting
Redirects can be effectively used for targeting purposes like device targeting or geotargeting . Device targeting has become increasingly important with the rise of mobile clients. There are two approaches to serve mobile users: Make the website responsive or redirect to a mobile website version. If a mobile website version is offered, users with mobile clients will be automatically forwarded to the corresponding mobile content. For device targeting, client side redirects or non-cacheable server side redirects are used. Geotargeting is the approach to offer localized content and automatically forward the user to a localized version of the requested URL. This is helpful for websites that target audience in more than one location and/or language. Usually server side redirects are used for Geotargeting but client side redirects might be an option as well, depending on requirements. [2]

Manipulating search engines
Redirects have been used to manipulate search engines with unethical intentions, e.g. sneaky redirects or URL hijacking . The goal of misleading redirects is to drive search traffic to landing pages, which do not have enough ranking power on their own or which are only remotely or not at all related to the search target. The approach requires a rank for a range of search terms with a number of URLs that would utilize sneaky redirects to forward the searcher to the target page. This method had a revival with the uprise of mobile devices and device targeting. URL hijacking is an off-domain redirect technique [3] that exploited the nature of the search engine's handling for temporary redirects. If a temporary redirect is encountered, search engines have to decide whether they assign the ranking value to the URL that initializes the redirect or to the redirect target URL. The URL that initiates the redirect may be kept to show up in search results, as the redirect indicates a temporary nature. Under certain circumstances it was possible to exploit this behaviour by applying temporary redirects to well ranking URLs, leading to a replacement of the original URL in search results by the URL that initialized the redirect, therefore "stealing" the ranking. This method was usually combined with sneaky redirects to re-target the user stream from the search results to a target page. Search engines have developed efficient technologies to detect these kind of manipulative approaches. Major search engines usually apply harsh ranking penalties on sites that get caught applying techniques like these. [4]

Manipulating visitors
URL redirection is sometimes used as a part of phishing attacks that confuse visitors about which web site they are visiting. [5] Because modern browsers always show the real URL in the address bar, the threat is lessened. However, redirects can also take you to sites that will otherwise attempt to attack in other ways. For example, a redirect might take a user to a site that would attempt to trick them into downloading antivirus software and, ironically, installing a trojan of some sort instead.

Removing 
When a link is clicked, the browser sends along in the HTTP request a field called referer which indicates the source of the link. This field is populated with the URL of the current web page, and will end up in the logs of the server serving the external link. Since sensitive pages may have sensitive URLs (for example, http://company.com/plans-for-the-next-release-of-our-product ), it is not desirable for the referer URL to leave the organization. A redirection page that performs referrer hiding could be embedded in all external URLs, transforming for example http://externalsite.com/page into http://redirect.company.com/http://externalsite.com/page . This technique also eliminates other potentially sensitive information from the referer URL, such as the session ID , and can reduce the chance of phishing by indicating to the end user that they passed a clear gateway to another site.

Implementation
Several different kinds of response to the browser will result in a redirection. These vary in whether they affect HTTP headers or HTML content. The techniques used typically depend on the role of the person implementing it and their access to different parts of the system. For example, a web author with no control over the headers might use a Refresh meta tag whereas a web server administrator redirecting all pages on a site is more likely to use server configuration.

Manual redirect
The simplest technique is to ask the visitor to follow a link to the new page, usually using an HTML anchor like:
This method is often used as a fall-back — if the browser does not support the automatic redirect, the visitor can still reach the target document by following the link.

HTTP status codes 3xx
In the HTTP protocol used by the World Wide Web , a redirect is a response with a status code beginning with 3 that causes a browser to display a different page. If a client encounters a redirect, it needs to make a number of decisions how to handle the redirect. Different status codes are used by clients to understand the purpose of the redirect, how to handle caching and which request method to use for the subsequent request.
HTTP/1.1 defines several status codes for redirection ( RFC 7231 ):

Redirect status codes and characteristics
[6]
All of these status codes require the URL of the redirect target to be given in the Location: header of the HTTP response. The 300 multiple choices will usually list all choices in the body of the message and show the default choice in the Location: header.
(Status codes 304 not modified and 305 use proxy are not redirects).

Example HTTP response for a 301 redirect
A HTTP response with the 301 "moved permanently" redirect looks like this:

Using server-side scripting for redirection
Web authors producing HTML content can't usually create redirects using HTTP headers as these are generated automatically by the web server program when serving an HTML file. The same is usually true even for programmers writing CGI scripts, though some servers allow scripts to add custom headers (e.g. by enabling "non-parsed-headers"). Many web servers will generate a 3xx status code if a script outputs a "Location:" header line. For example, in PHP , one can use the "header" function:
More headers may be required to prevent caching. [7] The programmer must ensure that the headers are output before the body. This may not fit easily with the natural flow of control through the code. To help with this, some frameworks for server-side content generation can buffer the body data. In the ASP scripting language, this can also be accomplished using response.buffer=true and response.redirect "http://www.example.com/" HTTP/1.1 allows for either a relative URI reference or an absolute URI reference. [8] If the URI reference is relative the client computes the required absolute URI reference according to the rules defined in RFC 3986 . [9]

Apache mod_rewrite
The Apache HTTP Server mod_alias extension can be used to redirect certain requests. Typical configuration directives look like:
For more flexible URL rewriting and redirection, Apache mod_rewrite can be used. E.g., to redirect a requests to a canonical domain name:
Such configuration can be applied to one or all sites on the server through the server configuration files or to a single content directory through a .htaccess file.

nginx rewrite
Nginx has an integrated http rewrite module, [10] which can be used to perform advanced URL processing and even web-page generation (with the return directive). A showing example of such advanced use of the rewrite module is mdoc.su , which implements a deterministic URL shortening service entirely with the help of nginx configuration language alone. [11] [12]
For example, if a request for /DragonFlyBSD/HAMMER.5 were to come along, it would first be redirected internally to /d/HAMMER.5 with the first rewrite directive below (only affecting the internal state, without any HTTP replies issued to the client just yet), and then with the second rewrite directive, an HTTP response with a 302 Found status code would be issued to the client to actually redirect to the external cgi script of web- man : [13]

Refresh Meta tag and HTTP refresh header
Netscape introduced the meta refresh feature which refreshes a page after a certain amount of time. This can specify a new URL to replace one page with another. This is supported by most web browsers. [14] [15] A timeout of zero seconds effects an immediate redirect. This is treated like a 301 permanent redirect by Google, allowing transfer of PageRank to the target page. [16]
This is an example of a simple HTML document that uses this technique:
This technique can be used by web authors because the meta tag is contained inside the document itself. The meta tag must be placed in the "head" section of the HTML file. The number "0" in this example may be replaced by another number to achieve a delay of that many seconds. The anchor in the "body" section is for users whose browsers do not support this feature.
The same effect can be achieved with an HTTP refresh header:
This response is easier to generate by CGI programs because one does not need to change the default status code.
Here is a simple CGI program that effects this redirect:
Note: Usually, the HTTP server adds the status line and the Content-length header automatically.
The W3C discourage the use of meta refresh, since it does not communicate any information about either the original or new resource, to the browser (or search engine ). The W3C's Web Content Accessibility Guidelines (7.4) discourage the creation of auto-refreshing pages, since most web browsers do not allow the user to disable or control the refresh rate. Some articles that they have written on the issue include W3C Web Content Accessibility Guidelines (1.0): Ensure user control of time-sensitive content changes , Use standard redirects: don't break the back button! and Core Techniques for Web Content Accessibility Guidelines 1.0 section 7 .

JavaScript redirects
JavaScript can cause a redirect by setting the window.location attribute, e.g.:
Normally JavaScript pushes the redirector site's URL to the browser's history. It can cause redirect loops when users hit the back button. With the following command you can prevent this type of behaviour. [17]
However, HTTP headers or the refresh meta tag may be preferred for security reasons and because JavaScript will not be executed by some browsers and many web crawlers .

Frame redirects
A slightly different effect can be achieved by creating an inline frame:
One main difference to the above redirect methods is that for a frame redirect, the browser displays the URL of the frame document and not the URL of the target page in the URL bar. This cloaking technique may be used so that the reader sees a more memorable URL or to fraudulently conceal a phishing site as part of website spoofing . [18]
Before HTML5, [19] the same effect could be done with an HTML frame that contains the target page:

Redirect chains
One redirect may lead to another. For example, the URL http://www.wikipedia .com /wiki/URL_redirection (with domain name in .com ) is first redirected to http://www.wikipedia .org /wiki/URL redirection (with domain name in .org ), then to the HTTPS URL https: //www.wikipedia.org/wiki/URL redirection and finally to the language-specific site https:// en .wikipedia.org/wiki/URL redirection. This is unavoidable if the different links in the chain are served by different servers though it should be minimised by rewriting the URL as much as possible on the server before returning it to the browser as a redirect.

Redirect loops
Sometimes a mistake can cause a page to end up redirecting back to itself, possibly via other pages, leading to an infinite sequence of redirects. Browsers should stop redirecting after a certain number of hops and display an error message.
The HTTP/1.1 Standard states: [20]
Note that the URLs in the sequence might not repeat, e.g.: http://www.example.com/1 -> http://www.example.com/2 -> http://www.example.com/3 ...

Services
There exist services that can perform URL redirection on demand, with no need for technical work or access to the web server your site is hosted on.

URL redirection services
A redirect service is an information management system, which provides an internet link that redirects users to the desired content. The typical benefit to the user is the use of a memorable domain name, and a reduction in the length of the URL or web address. A redirecting link can also be used as a permanent address for content that frequently changes hosts, similarly to the Domain Name System . Hyperlinks involving URL redirection services are frequently used in spam messages directed at blogs and wikis. Thus, one way to reduce spam is to reject all edits and comments containing hyperlinks to known URL redirection services; however, this will also remove legitimate edits and comments and may not be an effective method to reduce spam. Recently, URL redirection services have taken to using AJAX as an efficient, user friendly method for creating shortened URLs. A major drawback of some URL redirection services is the use of delay pages, or frame based advertising, to generate revenue.

History
The first redirect services took advantage of top-level domains (TLD) such as " .to " (Tonga), " .at " (Austria) and " .is " (Iceland). Their goal was to make memorable URLs. The first mainstream redirect service was V3.com that boasted 4 million users at its peak in 2000. V3.com success was attributed to having a wide variety of short memorable domains including "r.im", "go.to", "i.am", "come.to" and "start.at". V3.com was acquired by FortuneCity.com, a large free web hosting company, in early 1999. [21] As the sales price of top level domains started falling from $70.00 per year to less than $10.00, use of redirection services declined. With the launch of TinyURL in 2002 a new kind of redirecting service was born, namely URL shortening . Their goal was to make long URLs short, to be able to post them on internet forums. Since 2006, with the 140 character limit on the extremely popular Twitter service, these short URL services have been heavily used.

Referrer masking
Redirection services can hide the referrer by placing an intermediate page between the page the link is on and its destination. Although these are conceptually similar to other URL redirection services, they serve a different purpose, and they rarely attempt to shorten or obfuscate the destination URL (as their only intended side-effect is to hide referrer information and provide a clear gateway between other websites.) This type of redirection is often used to prevent potentially-malicious links from gaining information using the referrer, for example a session ID in the query string. Many large community websites use link redirection on external links to lessen the chance of an exploit that could be used to steal account information, as well as make it clear when a user is leaving a service, to lessen the chance of effective phishing .
Here is a simplistic example of such a service, written in PHP .
The above example does not check who called it (e.g. by referrer, although that could be spoofed). Also, it does not check the url provided. This means that a malicious person could link to the redirection page using a url parameter of his/her own selection, from any page, which uses the web server's resources.

Security issues
URL redirection can be abused by attackers for phishing attacks, such as open redirect and covert redirect . "An open redirect is an application that takes a parameter and redirects a user to the parameter value without any validation." [22] "Covert redirect is an application that takes a parameter and redirects a user to the parameter value WITHOUT SUFFICIENT validation." [23] It was disclosed in May 2014 by a mathematical doctoral student Wang Jing from Nanyang Technological University, Singapore. [24]

See also
WebPage index: 00073
PhpWiki
PhpWiki is a web-based wiki software application. It began as a clone of WikiWikiWeb and was the first wiki written in PHP . [2] PhpWiki has been used to edit and format paper books for publication. [3]

History
The first version, by Steve Wainstead, was in December 1999 and was the first Wiki written in PHP to be publicly released. The first version ran under PHP 3.x and ran on DBM files only. It was a feature-for-feature reimplementation of the original WikiWikiWeb at c2.com. [ citation needed ]
In early 2000 Arno Hollosi contributed a second database library to run PhpWiki on MySQL. [ citation needed ] From then on the features and contributions started to grow, including a templating system, color diffs , rewrites of the rendering engine and much more. Arno was interested in running a wiki for the game Go. [4]
Jeff Dairiki was the next major contributor, and soon headed the project for the next few years, then Reini Urban up to 1.4, and then Marc-Etienne Vargenau since 1.5.
Supports Wikicreole 1.0 including additions and MediaWiki markup syntax since Version 1.4.0. With Version 1.5.0 PHP 4 was deprecated.

See also
WebPage index: 00074
Java (programming language)
Java is a general-purpose computer programming language that is concurrent , class-based , object-oriented , [14] and specifically designed to have as few implementation dependencies as possible. It is intended to let application developers " write once, run anywhere " (WORA), [15] meaning that compiled Java code can run on all platforms that support Java without the need for recompilation. [16] Java applications are typically compiled to bytecode that can run on any Java virtual machine (JVM) regardless of computer architecture . As of 2016, Java is one of the most popular programming languages in use , [17] [18] [19] [20] particularly for client-server web applications, with a reported 9 million developers. [21] Java was originally developed by James Gosling at Sun Microsystems (which has since been acquired by Oracle Corporation ) and released in 1995 as a core component of Sun Microsystems' Java platform . The language derives much of its syntax from C and C++ , but it has fewer low-level facilities than either of them.
The original and reference implementation Java compilers , virtual machines, and class libraries were originally released by Sun under proprietary licenses. As of May 2007, in compliance with the specifications of the Java Community Process , Sun relicensed most of its Java technologies under the GNU General Public License . Others have also developed alternative implementations of these Sun technologies, such as the GNU Compiler for Java (bytecode compiler), GNU Classpath (standard libraries), and IcedTea -Web (browser plugin for applets).
The latest version is Java 8 which is the only version currently supported for free by Oracle, although earlier versions are supported both by Oracle and other companies on a commercial basis.

History
James Gosling , Mike Sheridan, and Patrick Naughton initiated the Java language project in June 1991. [22] Java was originally designed for interactive television, but it was too advanced for the digital cable television industry at the time. [23] The language was initially called Oak after an oak tree that stood outside Gosling's office. Later the project went by the name Green and was finally renamed Java , from Java coffee . [24] Gosling designed Java with a C/C++-style syntax that system and application programmers would find familiar. [25]
Sun Microsystems released the first public implementation as Java 1.0 in 1995. [26] It promised "Write Once, Run Anywhere" (WORA), providing no-cost run-times on popular platforms . Fairly secure and featuring configurable security, it allowed network- and file-access restrictions. Major web browsers soon incorporated the ability to run Java applets within web pages, and Java quickly became popular. The Java 1.0 compiler was re-written in Java by Arthur van Hoff to comply strictly with the Java 1.0 language specification. [27] With the advent of Java 2 (released initially as J2SE 1.2 in December 1998 – 1999), new versions had multiple configurations built for different types of platforms. J2EE included technologies and APIs for enterprise applications typically run in server environments, while J2ME featured APIs optimized for mobile applications. The desktop version was renamed J2SE . In 2006, for marketing purposes, Sun renamed new J2 versions as Java EE , Java ME , and Java SE , respectively.
In 1997, Sun Microsystems approached the ISO/IEC JTC 1 standards body and later the Ecma International to formalize Java, but it soon withdrew from the process. [28] [29] [30] Java remains a de facto standard , controlled through the Java Community Process . [31] At one time, Sun made most of its Java implementations available without charge, despite their proprietary software status. Sun generated revenue from Java through the selling of licenses for specialized products such as the Java Enterprise System.
On November 13, 2006, Sun released much of its Java virtual machine (JVM) as free and open-source software , (FOSS), under the terms of the GNU General Public License (GPL). On May 8, 2007, Sun finished the process, making all of its JVM's core code available under free software /open-source distribution terms, aside from a small portion of code to which Sun did not hold the copyright. [32]
Sun's vice-president Rich Green said that Sun's ideal role with regard to Java was as an "evangelist". [33] Following Oracle Corporation 's acquisition of Sun Microsystems in 2009–10, Oracle has described itself as the "steward of Java technology with a relentless commitment to fostering a community of participation and transparency". [34] This did not prevent Oracle from filing a lawsuit against Google shortly after that for using Java inside the Android SDK (see Google section below). Java software runs on everything from laptops to data centers , game consoles to scientific supercomputers . [35] On April 2, 2010, James Gosling resigned from Oracle. [36]
In January 2016, Oracle announced that Java runtime environments based on JDK 9 will discontinue the browser plugin. [37]

Principles
There were five primary goals in the creation of the Java language: [16]

Versions
As of 2015 [update] , only Java 8 is officially supported. Major release versions of Java, along with their release dates:

Practices

Java platform
One design goal of Java is portability, which means that programs written for the Java platform must run similarly on any combination of hardware and operating system with adequate runtime support. This is achieved by compiling the Java language code to an intermediate representation called Java bytecode , instead of directly to architecture-specific machine code . Java bytecode instructions are analogous to machine code, but they are intended to be executed by a virtual machine (VM) written specifically for the host hardware. End users commonly use a Java Runtime Environment (JRE) installed on their own machine for standalone Java applications, or in a web browser for Java applets .
Standard libraries provide a generic way to access host-specific features such as graphics, threading , and networking .
The use of universal bytecode makes porting simple. However, the overhead of interpreting bytecode into machine instructions made interpreted programs almost always run more slowly than native executables . Just-in-time (JIT) compilers that compile bytecodes to machine code during runtime were introduced from an early stage. Java itself is platform-independent and is adapted to the particular platform it is to run on by a Java virtual machine for it, which translates the Java bytecode into the platform's machine language. [39]

Implementations
Oracle Corporation is the current owner of the official implementation of the Java SE platform, following their acquisition of Sun Microsystems on January 27, 2010. This implementation is based on the original implementation of Java by Sun. The Oracle implementation is available for Microsoft Windows (still works for XP, while only later versions currently officially supported), macOS , Linux , and Solaris . Because Java lacks any formal standardization recognized by Ecma International , ISO/IEC, ANSI, or other third-party standards organization, the Oracle implementation is the de facto standard .
The Oracle implementation is packaged into two different distributions: The Java Runtime Environment (JRE) which contains the parts of the Java SE platform required to run Java programs and is intended for end users, and the Java Development Kit (JDK), which is intended for software developers and includes development tools such as the Java compiler , Javadoc , Jar , and a debugger .
OpenJDK is another notable Java SE implementation that is licensed under the GNU GPL. The implementation started when Sun began releasing the Java source code under the GPL. As of Java SE 7, OpenJDK is the official Java reference implementation.
The goal of Java is to make all implementations of Java compatible. Historically, Sun's trademark license for usage of the Java brand insists that all implementations be "compatible". This resulted in a legal dispute with Microsoft after Sun claimed that the Microsoft implementation did not support RMI or JNI and had added platform-specific features of their own. Sun sued in 1997, and, in 2001, won a settlement of US$20 million, as well as a court order enforcing the terms of the license from Sun. [40] As a result, Microsoft no longer ships Java with Windows .
Platform-independent Java is essential to Java EE , and an even more rigorous validation is required to certify an implementation. This environment enables portable server-side applications.

Performance
Programs written in Java have a reputation for being slower and requiring more memory than those written in C++. [41] [42] However, Java programs' execution speed improved significantly with the introduction of just-in-time compilation in 1997/1998 for Java 1.1 , [43] the addition of language features supporting better code analysis (such as inner classes, the StringBuilder class, optional assertions, etc.), and optimizations in the Java virtual machine, such as HotSpot becoming the default for Sun's JVM in 2000. With Java 1.5, the performance was improved with the addition of the java.util.concurrent package, including Lock free implementations of the ConcurrentMaps and other multi-core collections, and it was improved further Java 1.6.
Some platforms offer direct hardware support for Java; there are microcontrollers that can run Java in hardware instead of a software Java virtual machine [ citation needed ] , and some ARM based processors could have hardware support for executing Java bytecode through their Jazelle option, though support has mostly been dropped in current implementations of ARM.

Automatic memory management
Java uses an automatic garbage collector to manage memory in the object lifecycle . The programmer determines when objects are created, and the Java runtime is responsible for recovering the memory once objects are no longer in use. Once no references to an object remain, the unreachable memory becomes eligible to be freed automatically by the garbage collector. Something similar to a memory leak may still occur if a programmer's code holds a reference to an object that is no longer needed, typically when objects that are no longer needed are stored in containers that are still in use. If methods for a nonexistent object are called, a "null pointer exception" is thrown. [44] [45]
One of the ideas behind Java's automatic memory management model is that programmers can be spared the burden of having to perform manual memory management. In some languages, memory for the creation of objects is implicitly allocated on the stack or explicitly allocated and deallocated from the heap . In the latter case, the responsibility of managing memory resides with the programmer. If the program does not deallocate an object, a memory leak occurs. If the program attempts to access or deallocate memory that has already been deallocated, the result is undefined and difficult to predict, and the program is likely to become unstable and/or crash. This can be partially remedied by the use of smart pointers , but these add overhead and complexity. Note that garbage collection does not prevent "logical" memory leaks, i.e. , those where the memory is still referenced but never used.
Garbage collection may happen at any time. Ideally, it will occur when a program is idle. It is guaranteed to be triggered if there is insufficient free memory on the heap to allocate a new object; this can cause a program to stall momentarily. Explicit memory management is not possible in Java.
Java does not support C/C++ style pointer arithmetic , where object addresses and unsigned integers (usually long integers) can be used interchangeably. This allows the garbage collector to relocate referenced objects and ensures type safety and security.
As in C++ and some other object-oriented languages, variables of Java's primitive data types are either stored directly in fields (for objects) or on the stack (for methods) rather than on the heap, as is commonly true for non-primitive data types (but see escape analysis ). This was a conscious decision by Java's designers for performance reasons.
Java contains multiple types of garbage collectors. By default, HotSpot uses the parallel scavenge garbage collector . [46] However, there are also several other garbage collectors that can be used to manage the heap. For 90% of applications in Java, the Concurrent Mark-Sweep (CMS) garbage collector is sufficient. [47] Oracle aims to replace CMS with the Garbage-First collector (G1). [48]

Syntax
The syntax of Java is largely influenced by C++ . Unlike C++, which combines the syntax for structured, generic, and object-oriented programming, Java was built almost exclusively as an object-oriented language. [16] All code is written inside classes, and every data item is an object, with the exception of the primitive data types, ( i.e. integers, floating-point numbers, boolean values , and characters), which are not objects for performance reasons. Java reuses some popular aspects of C++ (such as printf() method).
Unlike C++, Java does not support operator overloading [49] or multiple inheritance for classes , though multiple inheritance is supported for interfaces . [50] This simplifies the language and aids in preventing potential errors and anti-pattern design. [ citation needed ]
Java uses comments similar to those of C++. There are three different styles of comments: a single line style marked with two slashes ( // ), a multiple line style opened with /* and closed with */ , and the Javadoc commenting style opened with /** and closed with */ . The Javadoc style of commenting allows the user to run the Javadoc executable to create documentation for the program and can be read by some integrated development environments (IDEs) such as Eclipse to allow developers to access documentation within the IDE.
Example:

"Hello world" example
The traditional "Hello, world!" program can be written in Java as: [51]
Source files must be named after the public class they contain, appending the suffix .java , for example, HelloWorldApp.java . It must first be compiled into bytecode, using a Java compiler , producing a file named HelloWorldApp.class . Only then can it be executed, or "launched". The Java source file may only contain one public class, but it can contain multiple classes with other than public access and any number of public inner classes . When the source file contains multiple classes, make one class "public" and name the source file with that public class name.
A class that is not declared public may be stored in any .java file. The compiler will generate a class file for each class defined in the source file. The name of the class file is the name of the class, with .class appended. For class file generation, anonymous classes are treated as if their name were the concatenation of the name of their enclosing class, a $ , and an integer.
The keyword public denotes that a method can be called from code in other classes, or that a class may be used by classes outside the class hierarchy. The class hierarchy is related to the name of the directory in which the .java file is located. This is called an access level modifier. Other access level modifiers include the keywords private and protected .
The keyword static in front of a method indicates a static method , which is associated only with the class and not with any specific instance of that class. Only static methods can be invoked without a reference to an object. Static methods cannot access any class members that are not also static. Methods that are not designated static are instance methods and require a specific instance of a class to operate.
The keyword void indicates that the main method does not return any value to the caller. If a Java program is to exit with an error code, it must call System.exit() explicitly.
The method name " main " is not a keyword in the Java language. It is simply the name of the method the Java launcher calls to pass control to the program. Java classes that run in managed environments such as applets and Enterprise JavaBeans do not use or need a main() method. A Java program may contain multiple classes that have main methods, which means that the VM needs to be explicitly told which class to launch from.
The main method must accept an array of String objects. By convention, it is referenced as args although any other legal identifier name can be used. Since Java 5, the main method can also use variable arguments , in the form of public static void main(String... args) , allowing the main method to be invoked with an arbitrary number of String arguments. The effect of this alternate declaration is semantically identical (the args parameter is still an array of String objects), but it allows an alternative syntax for creating and passing the array.
The Java launcher launches Java by loading a given class (specified on the command line or as an attribute in a JAR ) and starting its public static void main(String[]) method. Stand-alone programs must declare this method explicitly. The String[] args parameter is an array of String objects containing any arguments passed to the class. The parameters to main are often passed by means of a command line .
Printing is part of a Java standard library: The System class defines a public static field called out . The out object is an instance of the PrintStream class and provides many methods for printing data to standard out , including println(String) which also appends a new line to the passed string.
The string "Hello World!" is automatically converted to a String object by the compiler.

Special classes

Applet
Java applets are programs that are embedded in other applications, typically in a Web page displayed in a web browser.
The import statements direct the Java compiler to include the javax.swing.JApplet and java.awt.Graphics classes in the compilation. The import statement allows these classes to be referenced in the source code using the simple class name (i.e. JApplet ) instead of the fully qualified class name ( FQCN , i.e. javax.swing.JApplet ).
The Hello class extends ( subclasses ) the JApplet (Java Applet) class; the JApplet class provides the framework for the host application to display and control the lifecycle of the applet. The JApplet class is a JComponent (Java Graphical Component) which provides the applet with the capability to display a graphical user interface (GUI) and respond to user events .
The Hello class overrides the paintComponent(Graphics) method (additionally indicated with the annotation , supported as of JDK 1.5, Override ) inherited from the Container superclass to provide the code to display the applet. The paintComponent() method is passed a Graphics object that contains the graphic context used to display the applet. The paintComponent() method calls the graphic context drawString(String, int, int) method to display the "Hello, world!" string at a pixel offset of ( 65, 95 ) from the upper-left corner in the applet's display.
An applet is placed in an HTML document using the <applet> HTML element . The applet tag has three attributes set: code="Hello" specifies the name of the JApplet class and width="200" height="200" sets the pixel width and height of the applet. Applets may also be embedded in HTML using either the object or embed element, [52] although support for these elements by web browsers is inconsistent. [53] However, the applet tag is deprecated, so the object tag is preferred where supported.
The host application, typically a Web browser, instantiates the Hello applet and creates an AppletContext for the applet. Once the applet has initialized itself, it is added to the AWT display hierarchy. The paintComponent() method is called by the AWT event dispatching thread whenever the display needs the applet to draw itself.

Servlet
Java Servlet technology provides Web developers with a simple, consistent mechanism for extending the functionality of a Web server and for accessing existing business systems. Servlets are server-side Java EE components that generate responses (typically HTML pages) to requests (typically HTTP requests) from clients . A servlet can almost be thought of as an applet that runs on the server side—without a face.
The import statements direct the Java compiler to include all the public classes and interfaces from the java.io and javax.servlet packages in the compilation. Packages make Java well suited for large scale applications.
The Hello class extends the GenericServlet class; the GenericServlet class provides the interface for the server to forward requests to the servlet and control the servlet's lifecycle.
The Hello class overrides the service(ServletRequest, ServletResponse) method defined by the Servlet interface to provide the code for the service request handler. The service() method is passed: a ServletRequest object that contains the request from the client and a ServletResponse object used to create the response returned to the client. The service() method declares that it throws the exceptions ServletException and IOException if a problem prevents it from responding to the request.
The setContentType(String) method in the response object is called to set the MIME content type of the returned data to "text/html" . The getWriter() method in the response returns a PrintWriter object that is used to write the data that is sent to the client. The println(String) method is called to write the "Hello, world!" string to the response and then the close() method is called to close the print writer, which causes the data that has been written to the stream to be returned to the client.

JavaServer Pages
JavaServer Pages (JSP) are server-side Java EE components that generate responses, typically HTML pages, to HTTP requests from clients . JSPs embed Java code in an HTML page by using the special delimiters <% and %> . A JSP is compiled to a Java servlet , a Java application in its own right, the first time it is accessed. After that, the generated servlet creates the response.

Swing application
Swing is a graphical user interface library for the Java SE platform. It is possible to specify a different look and feel through the pluggable look and feel system of Swing. Clones of Windows , GTK+ , and Motif are supplied by Sun. Apple also provides an Aqua look and feel for macOS . Where prior implementations of these looks and feels may have been considered lacking, Swing in Java SE 6 addresses this problem by using more native GUI widget drawing routines of the underlying platforms.
This example Swing application creates a single window with "Hello, world!" inside:
The first import includes all the public classes and interfaces from the javax.swing package.
The Hello class extends the JFrame class; the JFrame class implements a window with a title bar and a close control .
The Hello() constructor initializes the frame by first calling the superclass constructor, passing the parameter "hello" , which is used as the window's title. It then calls the setDefaultCloseOperation(int) method inherited from JFrame to set the default operation when the close control on the title bar is selected to WindowConstants.EXIT_ON_CLOSE –  this causes the JFrame to be disposed of when the frame is closed (as opposed to merely hidden), which allows the Java virtual machine to exit and the program to terminate. Next, a JLabel is created for the string "Hello, world!" and the add(Component) method inherited from the Container superclass is called to add the label to the frame. The pack() method inherited from the Window superclass is called to size the window and lay out its contents.
The main() method is called by the Java virtual machine when the program starts. It instantiates a new Hello frame and causes it to be displayed by calling the setVisible(boolean) method inherited from the Component superclass with the boolean parameter true . Once the frame is displayed, exiting the main method does not cause the program to terminate because the AWT event dispatching thread remains active until all of the Swing top-level windows have been disposed.

Generics
In 2004, generics were added to the Java language, as part of J2SE 5.0. Prior to the introduction of generics, each variable declaration had to be of a specific type. For container classes, for example, this is a problem because there is no easy way to create a container that accepts only specific types of objects. Either the container operates on all subtypes of a class or interface, usually Object , or a different container class has to be created for each contained class. Generics allow compile-time type checking without having to create many container classes, each containing almost identical code. In addition to enabling more efficient code, certain runtime exceptions are prevented from occurring, by issuing compile-time errors. If Java prevented all runtime type errors ( ClassCastException 's) from occurring, it would be type safe .
In 2016, the type system was shown not to be safe at all, it was proven unsound . [54]

Criticism
Criticisms directed at Java include the implementation of generics, [55] speed, [56] the handling of unsigned numbers, [57] the implementation of floating-point arithmetic, [58] and a history of security vulnerabilities in the primary Java VM implementation HotSpot . [59]

Use outside of the Java platform
The Java programming language requires the presence of a software platform in order for compiled programs to be executed. Oracle supplies the Java platform for use with Java. The Android SDK is an alternative software platform, used primarily for developing Android applications .

Android
The Java language is a key pillar in Android , an open source mobile operating system . Although Android, built on the Linux kernel , is written largely in C, the Android SDK uses the Java language as the basis for Android applications. The bytecode language supported by the Android SDK is incompatible with Java bytecode and runs on its own virtual machine, optimized for low-memory devices such as smartphones and tablet computers . Depending on the Android version, the bytecode is either interpreted by the Dalvik virtual machine or compiled into native code by the Android Runtime .
Android does not provide the full Java SE standard library, although the Android SDK does include an independent implementation of a large subset of it. It supports Java 6 and some Java 7 features, offering an implementation compatible with the standard library ( Apache Harmony ).

Controversy
The use of Java-related technology in Android led to a legal dispute between Oracle and Google. On May 7, 2012, a San Francisco jury found that if APIs could be copyrighted, then Google had infringed Oracle's copyrights by the use of Java in Android devices. [60] District Judge William Haskell Alsup ruled on May 31, 2012, that APIs cannot be copyrighted, [61] but this was reversed by the United States Court of Appeals for the Federal Circuit in May 2014. [62] On May 26, 2016, the district court decided in favor of Google, ruling the copyright infringement of the Java API in Android constitutes fair use. [63]

Class libraries
The Java Class Library is the standard library , developed to support application development in Java. It is controlled by Sun Microsystems in cooperation with others through the Java Community Process program. Companies or individuals participating in this process can influence the design and development of the APIs. This process has been a subject of controversy. [ when? ] The class library contains features such as:

Documentation
Javadoc is a comprehensive documentation system, created by Sun Microsystems , used by many Java developers [ by whom? ] . It provides developers with an organized system for documenting their code. Javadoc comments have an extra asterisk at the beginning, i.e. the delimiters are /** and */ , whereas the normal multi-line comments in Java are set off with the delimiters /* and */ . [67]

Editions
Sun has defined and supports four editions of Java targeting different application environments and segmented many of its APIs so that they belong to one of the platforms. The platforms are:
The classes in the Java APIs are organized into separate groups called packages . Each package contains a set of related interfaces , classes, and exceptions . Refer to the separate platforms for a description of the packages available. [ relevant to this section? – discuss ]
Sun also provided an edition called PersonalJava that has been superseded by later, standards-based Java ME configuration-profile pairings.

See also

Comparison of Java with other languages

Notes
WebPage index: 00075
Social group
In the social sciences , a social group has been defined as two or more people who interact with one another, share similar characteristics, and collectively have a sense of unity. Other theorists disagree however, and are wary of definitions which stress the importance of interdependence or objective similarity. [1] [2] Instead, researchers within the social identity tradition generally define it as "a group is defined in terms of those who identify themselves as members of the group". [3] Regardless, social groups come in a myriad of sizes and varieties. For example, a society can be viewed as a large social group.

Definition

Social cohesion approach
A social group exhibits some degree of social cohesion and is more than a simple collection or aggregate of individuals, such as people waiting at a bus stop, or people waiting in a line. Characteristics shared by members of a group may include interests , values , representations , ethnic or social background, and kinship ties. Kinship ties being a social bond based on common ancestry, marriage, or adoption. [4] In a similar vein, some researchers consider the defining characteristic of a group as social interaction . [5] According to Dunbar's number , on average , people cannot maintain stable social relationships with more than 150 individuals. [6]
Social psychologist Muzafer Sherif proposed to define a social unit as a number of individuals interacting with each other with respect to:
This definition is long and complex, but it is also precise. It succeeds at providing the researcher with the tools required to answer three important questions:

Significance of that definition
The attention of those who use, participate in, or study groups has focused on functioning groups, on larger organizations, or on the decisions made in these organizations . [8] Much less attention has been paid to the more ubiquitous and universal social behaviors that do not clearly demonstrate one or more of the five necessary elements described by Sherif.
Some of the earliest efforts to understand these social units have been the extensive descriptions of urban street gangs in the 1920s and 1930s, continuing through the 1950s, which understood them to be largely reactions to the established authority. [9] The primary goal of gang members was to defend gang territory, and to define and maintain the dominance structure within the gang. There remains in the popular media and urban law enforcement agencies an avid interest in gangs, reflected in daily headlines which emphasize the criminal aspects of gang behavior. However, these studies and the continued interest have not improved the capacity to influence gang behavior or to reduce gang related violence.
The relevant literature on animal social behaviors , such as work on territory and dominance, has been available since the 1950s. Also, they have been largely neglected by policy makers, sociologists and anthropologists. Indeed, vast literature on organization, property, law enforcement, ownership, religion, warfare, values, conflict resolution, authority, rights, and families have grown and evolved without any reference to any analogous social behaviors in animals. This disconnect may be the result of the belief that social behavior in humankind is radically different from the social behavior in animals because of the human capacity for language use and rationality. Of course, while this is true, it is equally likely that the study of the social (group) behaviors of other animals might shed light on the evolutionary roots of social behavior in people.
Territorial and dominance behaviors in humans are so universal and commonplace that they are simply taken for granted (though sometimes admired, as in home ownership, or deplored, as in violence). But these social behaviors and interactions between human individuals play a special role in the study of groups: they are necessarily prior to the formation of groups . [ citation needed ] The psychological internalization of territorial and dominance experiences in conscious and unconscious memory are established through the formation of social identity , personal identity , body concept, or self concept . An adequately functioning individual identity is necessary before an individual can function in a division of labor (role), and hence, within a cohesive group. Coming to understand territorial and dominance behaviors may thus help to clarify the development, functioning, and productivity of groups.

Social identification approach
Explicitly contrasted against a social cohesion based definition for social groups is the social identity perspective , which draws on insights made in social identity theory . [10] Here, rather than defining a social group based on expressions of cohesive social relationships between individuals, the social identity model assumes that "psychological group membership has primarily a perceptual or cognitive basis". [1] It posits that the necessary and sufficient condition for individuals to act as group members is "awareness of a common category membership" and that a social group can be "usefully conceptualized as a number of individuals who have internalized the same social category membership as a component of their self concept". [1] Stated otherwise, while the social cohesion approach expects group members to ask "who am I attracted to?", the social identity perspective expects group members to simply ask "who am I?"
Empirical support for the social identity perspective on groups was initially drawn from work using the minimal group paradigm . For example, it has been shown that the mere act of allocating individuals to explicitly random categories is sufficient to lead individuals to act in an ingroup favouring fashion (even where no individual self-interest is possible). [11] Also problematic for the social cohesion account is recent research showing that seemingly meaningless categorization can be an antecedent of perceptions of interdependence with fellow category members. [2]
While the roots of this approach to social groups had its foundations in social identity theory, more concerted exploration of these ideas occurred later in the form of self-categorization theory . [12] Whereas social identity theory was directed initially at the explanation of intergroup conflict in the absence of any conflict of interests, self-categorization theory was developed to explain how individuals come to perceive themselves as members of a group in the first place, and how this self-grouping process underlies and determines all problems subsequent aspects of group behaviour. [13]

Defining characteristics of groups
In his text, Group Dynamics, Forsyth (2010) discuses several common characteristics of groups that can help to define them. [14]

1) Interaction
This group component varies greatly, including verbal or non-verbal communication, social loafing, networking, forming bonds, etc. Research by Bales (cite, 1950, 1999) determine that there are two main types of interactions; relationship interactions and task interactions.

2) Goals
Most groups have a reason for their existence, be it increasing the education and knowledge, receiving emotional support, or experiencing spirituality or religion. Groups can facilitate the achievement of these goals. [14] The circumplex model of group tasks , by Joseph McGrath [15] organizes group related tasks and goals. Groups may focus on several of these goals, or one area at a time. The model divides group goals into four main types, which are further sub-categorized

3) Interdependence in relation
“The state of being dependent, to some degree, on other people, as when one’s outcomes, actions, thoughts, feelings, and experiences are determined in whole or part by others." [14] It is obvious that some groups are more interdependent than others. For example, a sports team would have a relatively high level of interdependence as compared to a group of people watching a movie at the movie theater. Also, interdependence may be mutual (flowing back and forth between members) or more linear/unilateral. For example, some group members may be more dependent on their boss than the boss is on each of the individuals.

4) Structure
Group structure involves the emergence or regularities, norms, roles and relations that form within a group over time. Roles involve the expected performance and conduct of people within the group depending on their status or position within the group. Norms are the ideas adopted by the group pertaining to acceptable and unacceptable conduct by members. Group structure is a very important part of a group. If people fail to meet their expectations within to groups, and fulfil their roles, they may not accept the group, or be accepted by other group members.

5) Unity
When viewed holistically, a group is greater than the sum of its individual parts. When people speak of groups, they speak of the group as a whole, or an entity, rather than speaking of it in terms of individuals. For example, it would be said that “The band played beautifully.” Several factors play a part in this image of unity, including group cohesiveness, and entitativity (appearance of cohesion by outsiders). [14]

Types
According to Charles Horton Cooley (1864–1929), a primary group is a small social group whose members share personal and lasting relationships. People joined in primary relationships spend a great deal of time together, engage in a wide range of activities, and feel that they know one another well. In short, they show real concern for one another. In every society, the family is the most important primary group. Groups based on lasting friendships are also primary groups. [4] :149
Secondary groups , in contrast to primary groups, are large groups involving formal and institutional relationships. Secondary relationships involve weak emotional ties and little personal knowledge of one another. Most secondary groups are short term, beginning and ending without particular significance. [4] :149 They may last for years or may disband after a short time. The formation of primary groups happens within secondary groups.
Primary groups can be present in secondary settings. For example, attending a university exemplifies membership of a secondary group, while the friendships that are made there would be considered a primary group that you belong to. Likewise, some businesses care deeply about the well being of one another, while some immediate families have hostile relations within it.
Individuals almost universally have a bond toward what sociologists call reference groups . A reference group is a social group that serves as a point of reference in making evaluations and decisions. [4] :152
Some examples of types of groups include the following:
Groups can also be categorized according to the number of people present within the group. This makes sense if the size of the group has consequences for the way group members relate with each other. In a small group, for example, "each member receives some impression ... of each other member distinct enough so that he or she ... can give some reaction to each of the others as an individual person." [17] This personal interaction is not possible in larger groups.

Health
The social groups people are involved with in the workplace directly affect their health. No matter where you work or what the occupation is, feeling a sense of belonging in a peer group is a key to overall success. [18] Part of this is the responsibility of the leader (manager, supervisor, etc.). If the leader helps everyone feel a sense of belonging within the group, it can help boost morale and productivity. According to Dr. Niklas Steffens "Social identification contributes to both psychological and physiological health, but the health benefits are stronger for psychological health". [19] The social relationships people have can be linked to different health conditions. Lower quantity or quality social relationships have been connected to issues such as: development of cardiovascular disease , recurrent myocardial infarction , atherosclerosis , autonomic dysregulation, high blood pressure , cancer and delayed cancer recovery, and slower wound healing as well as inflammatory biomarkers and impaired immune function, factors associated with adverse health outcomes and mortality. The social relationship of marriage is the most studied of all, the marital history over the course of one's life can form differing health outcomes such as cardiovascular disease, chronic conditions, mobility limitations, self-rated health, and depressive symptoms. Social connectedness also plays a large part in overcoming mental afflictions such as drug, alcohol, or substance abuse. With these types of issues, a person's peer group play a big role in helping them stay sober. Conditions do not need to be life-threatening, one's social group can help deal with work anxiety as well. When people are more socially connected have access to more support. [20] Some of the health issues people have may also stem from their uncertainty about just where they stand among their colleagues. It has been shown that being well socially connected has a significant impact on a person as they age, according to a 10-year study by the MacArthur Foundation, which was published in the book 'Successful Aging' [21] the support, love, and care we feel through our social connections can help to counteract some of the health-related negatives of aging. Older people who were more active in social circles tended to be better off health-wise. [22]

Recruitment
Social groups acquire and renew their members via recruitment . [23] [24] Compare proselytism .
In the initial stages of expansion, the groups usually do not accept every applicant. One of the ways to build a reasonably closed group is to accept new members after one or more existing members propose and recommend them. Such group expands along the lines of other existing social networks. Other approach is to use existing members to evaluate the applicant, like in Microsoft interview . Member evaluation can also be delegated to some team that is not part of the group itself (like in high IQ societies ). Some groups may choose to easily accept a lot of people but only leave the most efficient new members after probation (discarding others).

Development
If one brings a small collection of strangers together in a restricted space and environment, provides a common goal and maybe a few ground rules, then a highly probable course of events will follow. Interaction between individuals is the basic requirement. At first, individuals will differentially interact in sets of twos or threes while seeking to interact with those with whom they share something in common: i.e., interests, skills, and cultural background. Relationships will develop some stability in these small sets, in that individuals may temporarily change from one set to another, but will return to the same pairs or trios rather consistently and resist change. Particular twosomes and threesomes will stake out their special spots within the overall space.
Again depending on the common goal, eventually twosomes and threesomes will integrate into larger sets of six or eight, with corresponding revisions of territory, dominance-ranking, and further differentiation of roles. All of this seldom takes place without some conflict or disagreement: for example, fighting over the distribution of resources, the choices of means and different subgoals, the development of what are appropriate norms, rewards and punishments. Some of these conflicts will be territorial in nature: i.e., jealousy over roles, or locations, or favored relationships. But most will be involved with struggles for status, ranging from mild protests to serious verbal conflicts and even dangerous violence.
By analogy to animal behavior, sociologists may term these behaviors territorial behaviors and dominance behaviors . Depending on the pressure of the common goal and on the various skills of individuals, differentiations of leadership, dominance, or authority will develop. Once these relationships solidify, with their defined roles, norms, and sanctions, a productive group will have been established. [25] [26] [27]
Aggression is the mark of unsettled dominance order. Productive group cooperation requires that both dominance order and territorial arrangements (identity, self-concept) be settled with respect to the common goal and within the particular group. Some individuals may withdraw from interaction or be excluded from the developing group. Depending on the number of individuals in the original collection of strangers, and the number of "hangers-on" that are tolerated, one or more competing groups of ten or less may form, and the competition for territory and dominance will then also be manifested in the inter group transactions.

Dispersal and transformation
Two or more people in interacting situations will over time develop stable territorial relationships. As described above, these may or may not develop into groups. But stable groups can also break up in to several sets of territorial relationships. There are numerous reasons for stable groups to "malfunction" or to disperse, but essentially this is because of loss of compliance with one or more elements of the definition of group provided by Sherif [ citation needed ] . The two most common causes of a malfunctioning group are the addition of too many individuals, and the failure of the leader to enforce a common purpose, though malfunctions may occur due to a failure of any of the other elements (i.e., confusions status or of norms).
In a society, there is an obvious need for more people to participate in cooperative endeavors than can be accommodated by a few separate groups. [ citation needed ] The military has been the best example as to how this is done in its hierarchical array of squads, platoons, companies, battalions, regiments, and divisions. Private companies, corporations, government agencies, clubs, and so on have all developed comparable (if less formal and standardized) systems when the number of members or employees exceeds the number that can be accommodated in an effective group. Not all larger social structures require the cohesion that may be found in the small group. Consider the neighborhood, the country club , or the megachurch , which are basically territorial organizations who support large social purposes. Any such large organizations may need only islands of cohesive leadership.
For a functioning group to attempt to add new members in a casual way is a certain prescription for failure, loss of efficiency, or disorganization. The number of functioning members in a group can be reasonably flexible between five and ten, and a long-standing cohesive group may be able to tolerate a few hangers on. The key concept is that the value and success of a group is obtained by each member maintaining a distinct, functioning identity in the minds of each of the members. The cognitive limit to this span of attention in individuals is often set at seven. Rapid shifting of attention can push the limit to about ten. After ten, subgroups will inevitably start to form with the attendant loss of purpose, dominance-order, and individuality, with confusion of roles and rules. The standard classroom with twenty to forty pupils and one teacher offers a rueful example of one supposed leader juggling a number of subgroups.
Weakening of the common purpose once a group is well established can be attributed to: adding new members; unsettled conflicts of identities (i.e., territorial problems in individuals); weakening of a settled dominance-order; and weakening or failure of the leader to tend to the group. The actual loss of a leader is frequently fatal to a group, unless there was lengthy preparation for the transition. The loss of the leader tends to dissolve all dominance relationships, as well as weakening dedication to common purpose, differentiation of roles, and maintenance of norms. The most common symptoms of a troubled group are loss of efficiency, diminished participation, or weakening of purpose, as well as an increase in verbal aggression. Often, if a strong common purpose is still present, a simple reorganization with a new leader and a few new members will be sufficient to re-establish the group, which is somewhat easier than forming an entirely new group. This is the most common factor.

See also
WebPage index: 00076
Computer cluster
A computer cluster consists of a set of loosely or tightly connected computers that work together so that, in many respects, they can be viewed as a single system. Unlike grid computers , computer clusters have each node set to perform the same task, controlled and scheduled by software.
The components of a cluster are usually connected to each other through fast local area networks , with each node (computer used as a server) running its own instance of an operating system . In most circumstances, all of the nodes use the same hardware [1] and the same operating system, although in some setups (i.e. using Open Source Cluster Application Resources (OSCAR)), different operating systems can be used on each computer, and/or different hardware. [2]
They are usually deployed to improve performance and availability over that of a single computer, while typically being much more cost-effective than single computers of comparable speed or availability. [3]
Computer clusters emerged as a result of convergence of a number of computing trends including the availability of low-cost microprocessors, high speed networks, and software for high-performance distributed computing . [ citation needed ] They have a wide range of applicability and deployment, ranging from small business clusters with a handful of nodes to some of the fastest supercomputers in the world such as IBM's Sequoia . [4]

Basic concepts
The desire to get more computing power and better reliability by orchestrating a number of low-cost commercial off-the-shelf computers has given rise to a variety of architectures and configurations.
The computer clustering approach usually (but not always) connects a number of readily available computing nodes (e.g. personal computers used as servers) via a fast local area network . [5] The activities of the computing nodes are orchestrated by "clustering middleware", a software layer that sits atop the nodes and allows the users to treat the cluster as by and large one cohesive computing unit, e.g. via a single system image concept. [5]
Computer clustering relies on a centralized management approach which makes the nodes available as orchestrated shared servers. It is distinct from other approaches such as peer to peer or grid computing which also use many nodes, but with a far more distributed nature . [5]
A computer cluster may be a simple two-node system which just connects two personal computers, or may be a very fast supercomputer . A basic approach to building a cluster is that of a Beowulf cluster which may be built with a few personal computers to produce a cost-effective alternative to traditional high performance computing . An early project that showed the viability of the concept was the 133-node Stone Soupercomputer . [6] The developers used Linux , the Parallel Virtual Machine toolkit and the Message Passing Interface library to achieve high performance at a relatively low cost. [7]
Although a cluster may consist of just a few personal computers connected by a simple network, the cluster architecture may also be used to achieve very high levels of performance. The TOP500 organization's semiannual list of the 500 fastest supercomputers often includes many clusters, e.g. the world's fastest machine in 2011 was the K computer which has a distributed memory , cluster architecture. [8] [9]

History
Greg Pfister has stated that clusters were not invented by any specific vendor but by customers who could not fit all their work on one computer, or needed a backup. [10] Pfister estimates the date as some time in the 1960s. The formal engineering basis of cluster computing as a means of doing parallel work of any sort was arguably invented by Gene Amdahl of IBM , who in 1967 published what has come to be regarded as the seminal paper on parallel processing: Amdahl's Law .
The history of early computer clusters is more or less directly tied into the history of early networks, as one of the primary motivations for the development of a network was to link computing resources, creating a de facto computer cluster.
The first production system designed as a cluster was the Burroughs B5700 in the mid-1960s. This allowed up to four computers, each with either one or two processors, to be tightly coupled to a common disk storage subsystem in order to distribute the workload. Unlike standard multiprocessor systems, each computer could be restarted without disrupting overall operation.
The first commercial loosely coupled clustering product was Datapoint Corporation's "Attached Resource Computer" (ARC) system, developed in 1977, and using ARCnet as the cluster interface. Clustering per se did not really take off until Digital Equipment Corporation released their VAXcluster product in 1984 for the VAX/VMS operating system (now named as OpenVMS). The ARC and VAXcluster products not only supported parallel computing, but also shared file systems and peripheral devices. The idea was to provide the advantages of parallel processing, while maintaining data reliability and uniqueness. Two other noteworthy early commercial clusters were the Tandem Himalayan (a circa 1994 high-availability product) and the IBM S/390 Parallel Sysplex (also circa 1994, primarily for business use).
Within the same time frame, while computer clusters used parallelism outside the computer on a commodity network, supercomputers began to use them within the same computer. Following the success of the CDC 6600 in 1964, the Cray 1 was delivered in 1976, and introduced internal parallelism via vector processing . [11] While early supercomputers excluded clusters and relied on shared memory , in time some of the fastest supercomputers (e.g. the K computer ) relied on cluster architectures.

Attributes of clusters
Computer clusters may be configured for different purposes ranging from general purpose business needs such as web-service support, to computation-intensive scientific calculations. In either case, the cluster may use a high-availability approach. Note that the attributes described below are not exclusive and a "computer cluster" may also use a high-availability approach, etc.
" Load-balancing " clusters are configurations in which cluster-nodes share computational workload to provide better overall performance. For example, a web server cluster may assign different queries to different nodes, so the overall response time will be optimized. [12] However, approaches to load-balancing may significantly differ among applications, e.g. a high-performance cluster used for scientific computations would balance load with different algorithms from a web-server cluster which may just use a simple round-robin method by assigning each new request to a different node. [12]
Computer clusters are used for computation-intensive purposes, rather than handling IO-oriented operations such as web service or databases. [13] For instance, a computer cluster might support computational simulations of vehicle crashes or weather. Very tightly coupled computer clusters are designed for work that may approach " supercomputing ".
" High-availability clusters " (also known as failover clusters, or HA clusters) improve the availability of the cluster approach. They operate by having redundant nodes , which are then used to provide service when system components fail. HA cluster implementations attempt to use redundancy of cluster components to eliminate single points of failure . There are commercial implementations of High-Availability clusters for many operating systems. The Linux-HA project is one commonly used free software HA package for the Linux operating system.

Benefits
Clusters are primarily designed with performance in mind, but installations are based on many other factors; fault tolerance ( the ability for a system to continue working with a malfunctioning node ) also allows for simpler scalability, and in high performance situations, low frequency of maintenance routines, resource consolidation [ clarification needed ] , and centralized management. Other advantages include enabling data recovery in the event of a disaster and providing parallel data processing and high processing capacity . [14] [15]

Design and configuration
One of the issues in designing a cluster is how tightly coupled the individual nodes may be. For instance, a single computer job may require frequent communication among nodes: this implies that the cluster shares a dedicated network, is densely located, and probably has homogeneous nodes. The other extreme is where a computer job uses one or few nodes, and needs little or no inter-node communication, approaching grid computing .
In a Beowulf system, the application programs never see the computational nodes (also called slave computers) but only interact with the "Master" which is a specific computer handling the scheduling and management of the slaves. [13] In a typical implementation the Master has two network interfaces, one that communicates with the private Beowulf network for the slaves, the other for the general purpose network of the organization. [13] The slave computers typically have their own version of the same operating system, and local memory and disk space. However, the private slave network may also have a large and shared file server that stores global persistent data, accessed by the slaves as needed. [13]
By contrast, the special purpose 144-node DEGIMA cluster is tuned to running astrophysical N-body simulations using the Multiple-Walk parallel treecode, rather than general purpose scientific computations. [16]
Due to the increasing computing power of each generation of game consoles , a novel use has emerged where they are repurposed into High-performance computing (HPC) clusters. Some examples of game console clusters are Sony PlayStation clusters and Microsoft Xbox clusters. Another example of consumer game product is the Nvidia Tesla Personal Supercomputer workstation, which uses multiple graphics accelerator processor chips. Besides game consoles, high-end graphics cards too can be used instead. The use of graphics cards (or rather their GPU's) to do calculations for grid computing is vastly more economical than using CPU's, despite being less precise. However, when using double-precision values, they become as precise to work with as CPU's, and still be much less costly (purchase cost). [17]
Computer clusters have historically run on separate physical computers with the same operating system . With the advent of virtualization , the cluster nodes may run on separate physical computers with different operating systems which are painted above with a virtual layer to look similar. [18] [ citation needed ] [ clarification needed ] The cluster may also be virtualized on various configurations as maintenance takes place. An example implementation is Xen as the virtualization manager with Linux-HA . [19]

Data sharing and communication

Data sharing
As the computer clusters were appearing during the 1980s, so were supercomputers . One of the elements that distinguished the three classes at that time was that the early supercomputers relied on shared memory . To date clusters do not typically use physically shared memory, while many supercomputer architectures have also abandoned it.
However, the use of a clustered file system is essential in modern computer clusters. [ citation needed ] Examples include the IBM General Parallel File System , Microsoft's Cluster Shared Volumes or the Oracle Cluster File System .

Message passing and communication
Two widely used approaches for communication between cluster nodes are MPI, the Message Passing Interface and PVM, the Parallel Virtual Machine . [20]
PVM was developed at the Oak Ridge National Laboratory around 1989 before MPI was available. PVM must be directly installed on every cluster node and provides a set of software libraries that paint the node as a "parallel virtual machine". PVM provides a run-time environment for message-passing, task and resource management, and fault notification. PVM can be used by user programs written in C, C++, or Fortran, etc. [20] [21]
MPI emerged in the early 1990s out of discussions among 40 organizations. The initial effort was supported by ARPA and National Science Foundation . Rather than starting anew, the design of MPI drew on various features available in commercial systems of the time. The MPI specifications then gave rise to specific implementations. MPI implementations typically use TCP/IP and socket connections. [20] MPI is now a widely available communications model that enables parallel programs to be written in languages such as C , Fortran , Python , etc. [21] Thus, unlike PVM which provides a concrete implementation, MPI is a specification which has been implemented in systems such as MPICH and Open MPI . [21] [22]

Cluster management
One of the challenges in the use of a computer cluster is the cost of administrating it which can at times be as high as the cost of administrating N independent machines, if the cluster has N nodes. [23] In some cases this provides an advantage to shared memory architectures with lower administration costs. [23] This has also made virtual machines popular, due to the ease of administration. [23]

Task scheduling
When a large multi-user cluster needs to access very large amounts of data, task scheduling becomes a challenge. In a heterogeneous CPU-GPU cluster with a complex application environment, the performance of each job depends on the characteristics of the underlying cluster. Therefore, mapping tasks onto CPU cores and GPU devices provides significant challenges. [24] This is an area of ongoing research; algorithms that combine and extend MapReduce and Hadoop have been proposed and studied. [24]

Node failure management
When a node in a cluster fails, strategies such as " fencing " may be employed to keep the rest of the system operational. [25] [26] Fencing is the process of isolating a node or protecting shared resources when a node appears to be malfunctioning. There are two classes of fencing methods; one disables a node itself, and the other disallows access to resources such as shared disks. [25]
The STONITH method stands for "Shoot The Other Node In The Head", meaning that the suspected node is disabled or powered off. For instance, power fencing uses a power controller to turn off an inoperable node. [25]
The resources fencing approach disallows access to resources without powering off the node. This may include persistent reservation fencing via the SCSI3 , fibre channel fencing to disable the fibre channel port, or global network block device (GNBD) fencing to disable access to the GNBD server.

Software development and administration

Parallel programming
Load balancing clusters such as web servers use cluster architectures to support a large number of users and typically each user request is routed to a specific node, achieving task parallelism without multi-node cooperation, given that the main goal of the system is providing rapid user access to shared data. However, "computer clusters" which perform complex computations for a small number of users need to take advantage of the parallel processing capabilities of the cluster and partition "the same computation" among several nodes. [27]
Automatic parallelization of programs continues to remain a technical challenge, but parallel programming models can be used to effectuate a higher degree of parallelism via the simultaneous execution of separate portions of a program on different processors. [27] [28]

Debugging and monitoring
The development and debugging of parallel programs on a cluster requires parallel language primitives as well as suitable tools such as those discussed by the High Performance Debugging Forum (HPDF) which resulted in the HPD specifications. [21] [29] Tools such as TotalView were then developed to debug parallel implementations on computer clusters which use MPI or PVM for message passing.
The Berkeley NOW (Network of Workstations) system gathers cluster data and stores them in a database, while a system such as PARMON, developed in India, allows for the visual observation and management of large clusters. [21]
Application checkpointing can be used to restore a given state of the system when a node fails during a long multi-node computation. [30] This is essential in large clusters, given that as the number of nodes increases, so does the likelihood of node failure under heavy computational loads. Checkpointing can restore the system to a stable state so that processing can resume without having to recompute results. [30]

Some implementations
The GNU/Linux world supports various cluster software; for application clustering, there is distcc , and MPICH . Linux Virtual Server , Linux-HA - director-based clusters that allow incoming requests for services to be distributed across multiple cluster nodes. MOSIX , LinuxPMI , Kerrighed , OpenSSI are full-blown clusters integrated into the kernel that provide for automatic process migration among homogeneous nodes. OpenSSI, openMosix and Kerrighed are single-system image implementations.
Microsoft Windows computer cluster Server 2003 based on the Windows Server platform provides pieces for High Performance Computing like the Job Scheduler, MSMPI library and management tools.
gLite is a set of middleware technologies created by the Enabling Grids for E-sciencE (EGEE) project.
slurm is also used to schedule and manage some of the largest supercomputer clusters (see top500 list).

Other approaches
Although most computer clusters are permanent fixtures, attempts at flash mob computing have been made to build short-lived clusters for specific computations. However, larger scale volunteer computing systems such as BOINC -based systems have had more followers.

See also
WebPage index: 00077
Ashburn, Virginia
Ashburn is a census-designated place (CDP) in Loudoun County , Virginia . As of the 2010 United States Census , its population was 43,511. [3] [6] It is 30 miles (48 km) northwest of Washington, D.C. and part of the Washington metropolitan area .

History
Ashburn was originally called Farmwell (variant names include Old Farmwell and Farmwell Station ) after a nearby mansion of that name owned by George Lee III. The name "Farmwell" first appeared in George Lee's October 1802 will and was used to describe the 1,236 acre (5.0 km²) plantation he inherited from his father, Thomas Ludwell Lee II. A section of Farmwell plantation west of Ashburn Road, a 580-acre (2.3 km²) tract, was purchased in 1841 as a summer home by John Janney , a Quaker lawyer who nearly became Vice President of the United States . Janney called the property Ashburn Farm ; the name's first known appearance in writing is 1870, when he sold the property. It is likely he named the farm after family friends whose name was "Ashburn". [7]
The Belmont Manor House and Janelia are listed on the National Register of Historic Places . [8]

Geography
Ashburn is located at 39°02′37″N 077°29′15″W ﻿ / ﻿ 39.04361°N 77.48750°W ﻿ / 39.04361; -77.48750 (39.0437192, −77.4874899) and its average elevation is 295 feet (90 m) above sea level . [1] According to the 2010 United States Census , the CDP has a total area of 17.287 square miles (44.77 km 2 ), of which 17.025 square miles (44.09 km 2 ) is land and 0.262 square miles (0.68 km 2 ) is water. [2] Ashburn is located between Washington Dulles International Airport and Leesburg , the county seat of Loudoun County.

Subdivisions
The Ashburn area consists of many major and minor subdivisions such as Ashbrook, Ashburn Farm , Ashburn Village , the Courts and Ridges at Ashburn, Belmont Greene , Belmont Country Club, Brambleton, Broadlands and the Village of Waxpool.

Demographics
The United States Census Bureau defines Ashburn as a census-designated place (CDP). As of the 2010 census , the CDP had a population of 43,511 residents, [3] while the larger ZIP Code Tabulation Area (ZCTA) for Ashburn's 20147 ZIP code contained 54,086 people. [9]
Many of its residents commute into Washington, D.C. and the surrounding suburbs such as Tysons Corner and Reston to their places of employment. [10] The median household income as of 2009 was $100,719. [11] Median age in Ashburn is 31.6. [11] Ashburn's population is made up of 49% males and 51% females. [11] The racial makeup of the CDP is White (71%), Asian/Pacific Islander (14%), African American (8%), Hispanic (7%), and Other race (7%). [11] The total number of households accounted for in Ashburn was 22,555. [11] The median household size is 2.9 persons. [11] 98% percent of Ashburn residents have a high school degree. [11] Some 42 percent of Ashburn's population holds a four-year bachelor's degree; [11] 18 percent holds graduate degrees. [11]
Homeowners formed 80 percent of the population. [11] In addition, renters made up 13% of the population. [11] There were 7% properties available as vacancies. [11] The median age of housing was 5.0 years. [11] The median housing value is at $345,000. [12]

Economy
Located within the Dulles Technology Corridor , Ashburn is home to many high-tech businesses. World Trade Center Dulles Airport is currently [ when? ] under construction and will be the second World Trade Center in the state. [13] Verizon Business has a major office in Ashburn at the location replacing MCI WorldCom 's headquarters after its acquisition. [14] [15] Ashburn is also home to government contractor Telos .
The George Washington University 's Virginia Science and Technology Campus and the Howard Hughes Medical Institute 's Janelia Research Campus are located in Ashburn. Redskins Park, the training camp for the Washington Redskins football team of the National Football League , is also located in Ashburn. [16] The Wikimedia Foundation (parent of Wikipedia) has its primary data center in Ashburn. [17]
EADS North America (the European Aeronautic Defense and Space Company), renamed Airbus Group, Inc. , a defense contractor headed by former NASA administrator Sean O'Keefe , has a second location in Ashburn in addition to the main office in Herndon , Virginia.

Government

Federal
The United States Postal Service operates the Ashburn Post Office. [18] The National Transportation Safety Board operates the Ashburn Aviation Field Office in Ashburn; it is the regional headquarters of the NTSB Aviation Eastern Region. [19]

Education

Colleges and universities
George Washington University and Strayer University have campuses in Ashburn. In December 2009, it was announced that George Mason University is planning to set up a campus in Ashburn, to be located at Exit 6 off the Dulles Greenway . [20]

Primary and secondary schools
Educational institutions in Ashburn are operated by the Loudoun County Public Schools .
Ashburn's elementary schools include Ashburn Elementary School, Belmont Station Elementary School, Cedar Lane Elementary School, Discovery Elementary School, Dominion Trail Elementary School, Hillside Elementary School, Legacy Elementary School,Creighton's Corner Elementary, Mill Run Elementary School, Moorefield Station Elementary School, Newton-Lee Elementary School, Rosa Lee Carter Elementary School, Sanders Corner Elementary School, and Steuart W. Weller Elementary School. Ashburn's public middle schools include Eagle Ridge Middle School , Farmwell Station Middle School , Stone Hill Middle School, and Trailside Middle School. Public high schools in Ashburn include Briar Woods High School , Broad Run High School , Stone Bridge High School , Belmont Ridge Middle School, and Rock Ridge High School . [21]
There are five private schools in Ashburn: Ideal Schools High School , St. Theresa Catholic School, Virginia Academy, Boyd School, and County Christian School.

Media
Media covering Ashburn include Leesburg Today , and the Loudoun Times-Mirror .

Infrastructure

Emergency services
Ashburn's fire and emergency medical services are provided by a combination of the volunteers of Ashburn Volunteer Fire-Rescue Department and the Loudoun County Department of Fire, Rescue & Emergency Management . AVFRD is a company under LCFR, and serves Ashburn with Stations 6 and 22, which is located next to Loudoun Hospital. LCFR operates the 24-7 career Moorefield station 23, the first of its kind in the county. The Ashburn area is served by the Inova Ashburn Healthplex Emergency Room at the corner of the Dulles Greenway and Loudoun County Parkway as well as Inova Loudoun Hospital, located less than 2 miles (3.2 km) from Ashburn in neighboring Lansdowne, Virginia , and by larger hospitals in the Washington suburbs and city.

Sports and entertainment center
One Loudoun, a new multimillion-dollar residential, sports, and entertainment development designed to be the downtown area of Loudoun County, and contains the Alamo Drafthouse Cinema , restaurants, and housing, as well as the Edelman Financial Field , a planned baseball stadium designed to be the centerpiece of the area. [22]

Notable people

See also
WebPage index: 00078
Creative Commons license
A Creative Commons ( CC ) license is one of several public copyright licenses that enable the free distribution of an otherwise copyrighted work. A CC license is used when an author wants to give people the right to share, use, and build upon a work that he/she has created. CC provides an author flexibility (for example, he/she might choose to allow only non-commercial uses of his/her own work) and protects the people who use or redistribute an author's work from concerns of copyright infringement as long as they abide by the conditions that are specified in the license by which the author distributes the work.
There are several types of CC licenses. The licenses differ by several combinations that condition the terms of distribution. They were initially released on December 16, 2002 by Creative Commons , a U.S. non-profit corporation founded in 2001. There have also been five versions of the suite of licenses, numbered 1.0 through 4.0. [1] As of 2016 [update] , the 4.0 license suite is the most current.
In October 2014 the Open Knowledge Foundation approved the Creative Commons CC BY , CC BY-SA , and CC0 licenses as conformant with the " Open Definition " for content and data. [2] [3] [4]

Applicable works
Work licensed under a Creative Commons license is governed by applicable copyright law. [5] This allows Creative Commons licenses to be applied to all work falling under copyright, including: books, plays, movies, music, articles, photographs, blogs, and websites. Creative Commons does not recommend the use of Creative Commons licenses for software. [6]
There are over 35,000 works that are available in hardcopy and have a registered ISBN number. Creative Commons splits these works into two categories, one of which encompasses self-published books. [7]
However, application of a Creative Commons license may not modify the rights allowed by fair use or fair dealing or exert restrictions which violate copyright exceptions. [8] Furthermore, Creative Commons licenses are non-exclusive and non-revocable. [9] Any work or copies of the work obtained under a Creative Commons license may continue to be used under that license. [10]
In the case of works protected by multiple Creative Common licenses, the user may choose either. [11]

Types of licenses
The CC licenses all grant the "baseline rights", such as the right to distribute the copyrighted work worldwide for non-commercial purposes, and without modification. [12] The details of each of these licenses depend on the version, and comprises a selection out of four conditions:
The last two clauses are not free content licenses, according to definitions such as DFSG or the Free Software Foundation 's standards, and cannot be used in contexts that require these freedoms, such as Wikipedia . For software , Creative Commons includes three free licenses created by other institutions: the BSD License , the GNU LGPL , and the GNU GPL . [14]
Mixing and matching these conditions produces sixteen possible combinations, of which eleven are valid Creative Commons licenses and five are not. Of the five invalid combinations, four include both the "nd" and "sa" clauses, which are mutually exclusive; and one includes none of the clauses. Of the eleven valid combinations, the five that lack the "by" clause have been retired because 98% of licensors requested attribution, though they do remain available for reference on the website. [15] [16] [17] This leaves six regularly used licenses + the CC0 public domain waiver :

Seven regularly used licenses
[17] [18]
For example, the Creative Commons Attribution (BY) license allows one to share and remix (create derivative works), even for commercial use, so long as attribution is given. [19]

Version 4.0 and international use
The original non-localized Creative Commons licenses were written with the U.S. legal system in mind, therefore the wording may be incompatible with local legislation in other jurisdictions , rendering the licenses unenforceable there. To address this issue, Creative Commons asked its affiliates to translate the various licenses to reflect local laws in a process called " porting ." [20] As of July 2011, Creative Commons licenses have been ported to over 50 jurisdictions worldwide. [21]
The latest version 4.0 of the Creative Commons licenses, released on November 25, 2013, are generic licenses that are applicable to most jurisdictions and do not usually require ports. [22] [23] [24] [25] No new ports have been implemented in version 4.0 of the license. [26] Version 4.0 discourages using ported versions and instead acts as a single global license. [27]

Rights

Attribution
Since 2004, all current licenses (beside the CC0 waiver) require attribution of the original author, the BY component. [16] The attribution must be given to "the best of [one's] ability using the information available". [28] Generally this implies the following:

Non-commercial licenses
The "non-commercial" option included in some Creative Commons licenses is controversial in definition, [29] as it is sometimes unclear what can be considered a non-commercial setting, and application, since its restrictions differ from the principles of open content promoted by other permissive licenses . [30] In 2014 Wikimedia Deutschland published a guide to using Creative Commons licenses as wiki pages for translations and as PDF. [31]

Zero / public domain
Besides licenses, Creative Commons also offers through CC0 a way to release material worldwide into the public domain . [18] CC0 is a legal tool for waiving as many rights as legally possible. [33] Or, when not legally possible, CC0 acts as fallback as public domain equivalent license . [33] Development of CC0 began in 2007 [34] and the tool was released in 2009. [35] [36] A major target of the license was the scientific data community. [37]
In 2010, Creative Commons announced its Public Domain Mark , [38] a tool for labeling works already in the public domain. Together, CC0 and the Public Domain Mark replace the Public Domain Dedication and Certification, [39] which took a U.S.-centric approach and co-mingled distinct operations.
In 2011, the Free Software Foundation added CC0 to its free software licenses , [40] and currently recommends CC0 as the preferred method of releasing software into the public domain . [41]
In February 2012 CC0 was submitted to Open Source Initiative (OSI) for their approval. [42] However, controversy arose over its clause which excluded from the scope of the license any relevant patents held by the copyright holder. This clause was added with scientific data in mind rather than software, but some members of the OSI believed it could weaken users' defenses against software patents . As a result, Creative Commons withdrew their submission, and the license is not currently approved by the OSI. [37] [43]
In 2013, Unsplash began using the CC0 license to distribute free stock photography . [44] [45] It now distributes several million photos a month [46] and has inspired a host of similar sites, including CC0 photography companies and CC0 blogging companies. [47] Lawrence Lessig , the founder of Creative Commons, has contributed to the site. [48] [ dead link ]
In October 2014 the Open Knowledge Foundation approved the Creative Commons CC0 as conformant with the "Open Definition" and recommend the license to dedicate content to the public domain. [3] [4]

Adaptation
Rights in an adaptation can be expressed by a CC license that is compatible with the status or licensing of the original work or works on which the adaptation is based. [49]

Legal aspects
The legal implications of large numbers of works having Creative Commons licensing are difficult to predict, and there is speculation that media creators often lack insight to be able to choose the license which best meets their intent in applying it. [50]
Some works licensed using Creative Commons licenses have been involved in several court cases. [51] Creative Commons itself was not a party to any of these cases; they only involved licensors or licensees of Creative Commons licenses. When the cases went as far as decisions by judges (that is, they were not dismissed for lack of jurisdiction or were not settled privately out of court), they have all validated the legal robustness of Creative Commons public licenses. Here are some notable cases:

Dutch tabloid
In early 2006, podcaster Adam Curry sued a Dutch tabloid who published photos from Curry's Flickr page without Curry's permission. The photos were licensed under the Creative Commons Non-Commercial license. While the verdict was in favor of Curry, the tabloid avoided having to pay restitution to him as long as they did not repeat the offense. Professor Bernt Hugenholtz, main creator of the Dutch CC license and director of the Institute for Information Law of the University of Amsterdam, commented, "The Dutch Court's decision is especially noteworthy because it confirms that the conditions of a Creative Commons license automatically apply to the content licensed under it, and binds users of such content even without expressly agreeing to, or having knowledge of, the conditions of the license." [52] [53] [54] [55]

Virgin Mobile
In 2007, Virgin Mobile Australia launched an Australian bus stop ad campaign promoting their cellphone text messaging service using the work of amateur photographers who uploaded their work to Flickr using a Creative Commons-BY (Attribution) license. Users licensing their images this way freed their work for use by any other entity, as long as the original creator was attributed credit, without any other compensation required. Virgin upheld this single restriction by printing a URL leading to the photographer's Flickr page on each of their ads. However, one picture, depicting 15-year-old Alison Chang at a fund-raising carwash for her church, [56] caused some controversy when she sued Virgin Mobile. The photo was taken by Alison's church youth counselor, Justin Ho-Wee Wong, who uploaded the image to Flickr under the Creative Commons license. [56] In 2008, the case (concerning personality rights rather than copyright as such) was thrown out of a Texas court for lack of jurisdiction. [57] [58]

SGAE vs Fernández
In the fall of 2006, the collecting society Sociedad General de Autores y Editores ( SGAE ) in Spain sued Ricardo Andrés Utrera Fernández, owner of a disco bar located in Badajoz who played CC-licensed music. SGAE argued that Fernández should pay royalties for public performance of the music between November 2002 and August 2005. The Lower Court rejected the collecting society's claims because the owner of the bar proved that the music he was using was not managed by the society. [59]
In February 2006, the Cultural Association Ladinamo (based in Madrid, and represented by Javier de la Cueva ) was granted the use of copyleft music in their public activities. The sentence said: "Admitting the existence of music equipment, a joint evaluation of the evidence practiced, this court is convinced that the defendant prevents communication of works whose management is entrusted to the plaintiff [SGAE], using a repertoire of authors who have not assigned the exploitation of their rights to the SGAE, having at its disposal a database for that purpose and so it is manifested both by the legal representative of the Association and by Manuela Villa Acosta, in charge of the cultural programming of the association, which is compatible with the alternative character of the Association and its integration in the movement called ' copy left '". [60]

GateHouse Media, Inc. vs. That's Great News, LLC
On June 30, 2010 GateHouse Media filed a lawsuit against That's Great News . GateHouse Media owns a number of local newspapers, including Rockford Register Star , which is based in Rockford, Illinois. That's Great News makes plaques out of newspaper articles and sells them to the people featured in the articles. [61] GateHouse sued That's Great News for copyright infringement and breach of contract. GateHouse claimed that TGN violated the non-commercial and no-derivative works restrictions on GateHouse Creative Commons licensed work when TGN published the material on its website. The case was settled on August 17, 2010, though the settlement was not made public. [61] [62]

Drauglis v. Kappa Map Group, LLC
The plaintiff was photographer Art Drauglis, who uploaded several pictures to the photo-sharing website Flickr using Creative Commons Attribution-ShareAlike 2.0 Generic License (CC BY-SA), including one entitled "Swain's Lock, Montgomery Co., MD.". The defendant was Kappa Map Group, a map-making company, which downloaded the image and used it in a compilation entitled "Montgomery Co. Maryland Street Atlas". Though there was nothing on the cover that indicated the origin of the picture, the text " Photo: Swain's Lock, Montgomery Co., MD Photographer: Carly Lesser & Art Drauglis, Creative Commoms [ sic ] , CC-BY-SA-2.0 " appeared at the bottom of the back cover.
The validity of the CC BY-SA 2.0 as a license was not in dispute. The CC BY-SA 2.0 requires that the licensee to use nothing less restrictive than the CC BY-SA 2.0 terms. The atlas was sold commercially and not for free reuse by others. The dispute was whether Drauglis' license terms that would apply to "derivative works" applied to the entire atlas. Drauglis sued the defendants on June 2014 for copyright infringement and license breach, seeking declaratory and injunctive relief, damages, fees, and costs. Drauglis asserted, among other things, that Kappa Map Group "exceeded the scope of the License because defendant did not publish the Atlas under a license with the same or similar terms as those under which the Photograph was originally licensed." [63] The judge dismissed the case on that count, ruling that the atlas was not a derivative work of the photograph in the sense of the license. Since the atlas was not a derivative work of the photograph, Kappa Map Group did not need to license the entire atlas under the CC BY-SA 2.0 license. The judge also determined that the work had been properly attributed. [64]

Verband zum Schutz geistigen Eigentums im Internet (VGSE)
This incident has not been tested in court, but it highlights a potentially disturbing practice. In July 2016, German computer magazine LinuxUser reports that a German blogger Christoph Langner used two CC-BY licensed photographs from Berlin photographer Dennis Skley on his private blog Linuxundich.de . Langner duly mentioned the author and the license and added a link to the original. Langner was later contacted by the Verband zum Schutz geistigen Eigentums im Internet (VGSE) (Association for the Protection of Intellectual Property in the Internet) with a demand for €2300 for failing to provide the full name of the work, the full name of the author, the license text, and a source link, as is apparently required by the fine print in the license. Of this sum, €40 goes to the photographer and remainder is retained by VGSE. [65] [66]

Works with a Creative Commons license
Creative Commons maintains a content directory wiki of organizations and projects using Creative Commons licenses. [67] On its website CC also provides case studies of projects using CC licenses across the world. [68] CC licensed content can also be accessed through a number of content directories and search engines (see CC licensed content directories ).

Retired licenses
Due to either disuse or criticism, a number of previously offered Creative Commons licenses have since been retired, [15] [69] and are no longer recommended for new works. The retired licenses include all licenses lacking the Attribution element other than CC0, as well as the following four licenses:

See also
WebPage index: 00079
Reference.com
Reference.com is an online encyclopedia , [2] thesaurus , [3] and dictionary . [4] The site also provides machine translation [5] and web search .
Reference.com was launched by InReference, Inc in February, 1997. [6] The site was later acquired by Lexico Publishing Group, LLC. In 2005, Lexico announced that Reference.com would begin offering searches of Wikipedia content. [7] In mid-2007, the site typically ranked in the mid-200s among the most popular websites on the Internet. [8] The popularity of Dictionary.com had been greatly boosted by Google's practice of offering a link at the top of their search results that go to the Dictionary.com definition. This exclusive relationship was terminated without explanation to the public when the Google links were redirected to definitions at Answers.com . (In December 2009, the Answers.com links were replaced with Google's own dictionary.) Google additionally added a Dictionary.com definition link for certain search words in a non-exclusive relationship (along with links to definitions from a few other commercial reference websites). On 3 July 2008, IAC acquired Lexico Publishing Group, LLC and its three properties: Thesaurus.com, Reference.com, and Dictionary.com. [9] [10]
Reference.com reproduces content from external sources. [11] The site's sources include other online dictionaries, encyclopedias, and a search of terms found on other websites such as Wikipedia and the CIA World Factbook . The site can also search Usenet groups and other mailing lists . [12] [13]
Reference.com in 2010 topped the list compiled by The Wall Street Journal ranking websites by how many third-party tracking cookies were added to the user's computer. Reference.com added 234 tracking cookies when encountering a first-time user. [14]
WebPage index: 00080
iOS
iOS (formerly iPhone OS ) is a mobile operating system created and developed by Apple Inc. exclusively for its hardware . It is the operating system that presently powers many of the company's mobile devices, including the iPhone , iPad , and iPod Touch . It is the second most popular mobile operating system globally after Android . iPad tablets are also the second most popular, by sales, against Android since 2013. [7]
Originally unveiled in 2007 for the iPhone , iOS has been extended to support other Apple devices such as the iPod Touch (September 2007) and the iPad (January 2010). As of January 2017 [update] , Apple's App Store contains more than 2.2 million iOS applications, 1 million of which are native for iPads. These mobile apps have collectively been downloaded more than 130 billion times.
The iOS user interface is based upon direct manipulation , using multi-touch gestures. Interface control elements consist of sliders, switches, and buttons. Interaction with the OS includes gestures such as swipe , tap , pinch , and reverse pinch , all of which have specific definitions within the context of the iOS operating system and its multi-touch interface. Internal accelerometers are used by some applications to respond to shaking the device (one common result is the undo command) or rotating it in three dimensions (one common result is switching between portrait and landscape mode). Apple has been significantly praised for incorporating thorough accessibility functions into iOS, enabling users with vision and hearing disabilities to properly use its products.
Major versions of iOS are released annually. The current version, iOS 10 , was released on September 13, 2016. It is available for the iPhone 5 and later iPhone models, the fourth-generation iPad , the iPad Air and iPad Air 2 , the iPad Pro , the iPad Mini 2 and later iPad Mini models, and the sixth-generation iPod Touch . In iOS, there are four abstraction layers : the Core OS, Core Services , Media, and Cocoa Touch layers.

History
In 2005, when Steve Jobs began planning the iPhone , he had a choice to either "shrink the Mac, which would be an epic feat of engineering, or enlarge the iPod". Jobs favored the former approach but pitted the Macintosh and iPod teams, led by Scott Forstall and Tony Fadell , respectively, against each other in an internal competition, with Forstall winning by creating the iPhone OS. The decision enabled the success of the iPhone as a platform for third-party developers: using a well-known desktop operating system as its basis allowed the many third-party Mac developers to write software for the iPhone with minimal retraining. Forstall was also responsible for creating a software development kit for programmers to build iPhone apps, as well as an App Store within iTunes . [8] [9]
The operating system was unveiled with the iPhone at the Macworld Conference & Expo on January 9, 2007, and released in June of that year. [10] [11] [12] At the time of its unveiling in January, Steve Jobs claimed: "iPhone runs OS X" and runs "desktop applications", [13] [14] but at the time of the iPhone's release, the operating system was renamed "iPhone OS". [15] Initially, third-party native applications were not supported. Steve Jobs' reasoning was that developers could build web applications through the Safari web browser that "would behave like native apps on the iPhone". [16] [17] In October 2007, Apple announced that a native Software Development Kit (SDK) was under development and that they planned to put it "in developers' hands in February". [18] [19] [20] On March 6, 2008, Apple held a press event, announcing the iPhone SDK. [21] [22]
The iOS App Store was opened on July 10, 2008 with an initial 500 applications available. [23] This quickly grew to 3,000 in September 2008, [24] 15,000 in January 2009, [25] 50,000 in June 2009, [26] 100,000 in November 2009, [27] [28] 250,000 in August 2010, [29] [30] 650,000 in July 2012, [31] 1 million in October 2013, [32] [33] 2 million in June 2016, [34] [35] [36] and 2.2 million in January 2017. [37] [38] As of March 2016 [update] , 1 million apps are natively compatible with the iPad tablet computer. [39] These apps have collectively been downloaded more than 130 billion times. [34] App intelligence firm Sensor Tower has estimated that the App Store will reach 5 million apps by the year 2020. [40]
On September 5, 2007, Apple released the iPod Touch, which had most of the non-phone capabilities of the iPhone. Apple also sold more than one million iPhones during the 2007 holiday season. [41] On January 27, 2010, Apple announced the iPad , featuring a larger screen than the iPhone and iPod Touch, and designed for web browsing, media consumption, and reading. [42]
In June 2010, Apple rebranded iPhone OS as "iOS". The trademark "IOS" had been used by Cisco for over a decade for its operating system, IOS , used on its routers. To avoid any potential lawsuit, Apple licensed the "IOS" trademark from Cisco. [43]
In October 2016, Apple opened its first iOS Developer Academy in Naples inside University of Naples Federico II 's new campus. [44] [45]

Software updates
Apple provides major updates to the iOS operating system annually via iTunes and also, for iOS 5 and later, over the air . The latest version is iOS 10 , released on September 13, 2016. [46] It is available for iPhone 5 and later, fourth-generation iPad , first- and second-generation iPad Air , iPad Pro , iPad Mini 2 and later, and sixth-generation iPod Touch . [47]
Before the iOS 4 release in 2010, iPod Touch users had to pay for system software updates. Apple claimed that this was the case because the iPod Touch was not a 'subscription device' like the iPhone (i.e., it was a one-off purchase). [48] Apple said it had 'found a way' to deliver software updates for free to iPod Touch users at WWDC 2010 when iOS 4 was unveiled. [49]

Platform usage
Charts in this section provide breakdowns of iOS versions, based on devices accessing the App Store as of February 23, 2017 [update] . [50]

Features

Home screen
The home screen, rendered by SpringBoard , displays application icons and a dock at the bottom where users can pin their most frequently used apps. The home screen appears whenever the user unlocks the device or presses the physical "Home" button whilst in another app. [51] Before iOS 4 on the iPhone 3GS (or later), the screen's background could be customized only through jailbreaking , but can now be changed out-of-the-box. The screen has a status bar across the top to display data, such as time, battery level, and signal strength. The rest of the screen is devoted to the current application. When a passcode is set and a user switches on the device, the passcode must be entered at the Lock Screen before access to the Home screen is granted. [52]
In iPhone OS 3, Spotlight was introduced, allowing users to search media, apps, emails, contacts, messages, reminders, calendar events, and similar content. In iOS 7 and later, Spotlight is accessed by pulling down anywhere on the home screen (except for the top and bottom edges that open Notification Center and Control Center). [53] [54] In iOS 9, there are two ways to access Spotlight. As with iOS 7 and 8, pulling down on any homescreen will show Spotlight. However, it can also be accessed as it was in iOS 3 – 6. This gives a Spotlight endowed with Siri suggestions, which include app suggestions, contact suggestions and news. [55] In iOS 10, Spotlight is at the top of the now-dedicated "Today" panel. [56]
Since iOS 3.2, users are able to set a background image for the Home screen. This feature is only available on third-generation devices or newer – iPhone 3GS +, iPod Touch 3rd generation+ (iOS 4.0+), and all iPad models (iOS 3.2+).
Researchers found that users organize icons on their homescreens based on usage-frequency and relatedness of the applications, as well as for reasons of usability and aesthetics. [57]

System font
iOS originally used Helvetica as the system font. With the release of the iPhone 4 and iOS 4 , iOS switched to Helvetica Neue with Retina Displays , but retained Helvetica as the system font for older devices. [58] iOS 7 provided the ability to scale text or switch to Neue Bold as the default system font, as accessibility options. iOS 9 changed the font to San Francisco , a Apple-designed font for maximum legibility on computer and mobile displays, originally introduced as the system font for the Apple Watch . [59]

Folders
iOS 4 introduced folders, which were created when two applications are in "jiggle mode"(with the exception of Newsstand in iOS 5 - 6 [60] ) are dragged together to create it, and from then on, more can be added using the same procedure. It can be up to 12 on iPhone 4S and earlier and iPod Touch, 16 on iPhone 5, and 20 on iPad. A title for the folder is automatically selected by the category of applications inside, but the name can also be edited by the user. When apps inside folders receive badges, the numbers shown by the badges is added up and shown on the folder. Folders cannot be put into other folders, though an unofficial workaround exists that enables folders to be nested within folders. [61] iOS 7 updated the folders with pages like on the SpringBoard. Each page can hold nine apps, and the Newsstand app is now able to be placed into a folder.

Notification Center
Before iOS 5, notifications were delivered in a modal window and couldn't be viewed after being dismissed. In iOS 5, Apple introduced Notification Center , which allows users to view a history of notifications. The user can tap a notification to open its corresponding app, or clear it. [62] Notifications are now delivered in banners that appear briefly at the top of the screen. If a user taps a received notification, the application that sent the notification will be opened. Users can also choose to view notifications in modal alert windows by adjusting the application's notification settings. Introduced with iOS 8, widgets are now accessible through the Notification Center, defined by 3rd parties.
When an app sends a notification while closed, a red badge appears on its icon. This badge tells the user, at a glance, how many notifications that app has sent. Opening the app clears the badge.

Accessibility
iOS offers various accessibility features to help users with vision and hearing disabilities. One major feature, VoiceOver , provides a voice reading information on the screen, including contextual buttons, icons, links and other user interface elements, and allows the user to navigate the operating system through gestures. Any apps with default controls and developed with a UIKit framework gets VoiceOver functionality built in. [63] One example includes holding up the iPhone to take a photo, with VoiceOver describing the photo scenery. [64] As part of a "Made for iPhone" program, introduced with the release of iOS 7 in 2013, Apple has developed technology to use Bluetooth and a special technology protocol to let compatible third-party equipment connect with iPhones and iPads for streaming audio directly to a user's ears. Additional customization available for Made for iPhone products include battery tracking and adjustable sound settings for different environments. [65] [66] Apple made further efforts for accessibility for the release of iOS 10 in 2016, adding a new pronunciation editor to VoiceOver, adding a Magnifier setting to enlarge objects through the device's camera, software TTY support for deaf people to make phone calls from the iPhone, and giving tutorials and guidelines for third-party developers to incorporate proper accessibility functions into their apps. [67]
In 2012, Liat Kornowski from The Atlantic wrote that "the iPhone has turned out to be one of the most revolutionary developments since the invention of Braille ", [68] and in 2016, Steven Aquino of TechCrunch described Apple as "leading the way in assistive technology", with Sarah Herrlinger, Senior Manager for Global Accessibility Policy and Initiatives at Apple, stating that "We see accessibility as a basic human right. Building into the core of our products supports a vision of an inclusive world where opportunity and access to information are barrier-free, empowering individuals with disabilities to achieve their goals". [69]

Multitasking
Multitasking for iOS was first released in June 2010 along with the release of iOS 4 . [70] [71] Only certain devices— iPhone 4 , iPhone 3GS , and iPod Touch 3rd generation—were able to multitask. [72] The iPad did not get multitasking until iOS 4.2.1 in November. [73] Currently, multitasking is supported on iPhone 3GS+, iPod Touch 3rd generation+, and all iPad models. [74]
Implementation of multitasking in iOS has been criticized for its approach, which limits the work that applications in the background can perform to a limited function set and requires application developers to add explicit support for it. [72] [75]
Before iOS 4, multitasking was limited to a selection of the applications Apple included on the device. Users could, however "jailbreak" their device in order to unofficially multitask. [76] Starting with iOS 4, on third-generation and newer iOS devices, multitasking is supported through seven background APIs : [77]
In iOS 5, three new background APIs were introduced:
In iOS 7, Apple introduced a new multitasking feature, providing all apps with the ability to perform background updates. This feature prefers to update the user's most frequently used apps and prefers to use WiFi networks over a cellular network, without markedly reducing the device's battery life.

Switching applications
In iOS 4.0 to iOS 6.x, double-clicking the home button activates the application switcher. A scrollable dock-like interface appears from the bottom, moving the contents of the screen up. Choosing an icon switches to an application. To the far left are icons which function as music controls, a rotation lock, and on iOS 4.2 and above, a volume controller.
With the introduction of iOS 7, double clicking the home button also activates the application switcher. However, unlike previous versions it displays screenshots of open applications on top of the icon and horizontal scrolling allows for browsing through previous apps, and it is possible to close applications by dragging them up, similar to how WebOS handled multiple cards. [79]
With the introduction of iOS 9, the application switcher received a significant visual change; whilst still retaining the card metaphor introduced in iOS 7, the application icon is smaller, and appears above the screenshot (which is now larger, due to the removal of "Recent and Favorite Contacts"), and each application "card" overlaps the other, forming a rolodex effect as the user scrolls. Now, instead of the home screen appearing at the leftmost of the application switcher, it appears rightmost. [80]

Ending tasks
In iOS 4.0 to iOS 6.x, briefly holding the icons in the application switcher makes them "jiggle" (similarly to the homescreen) and allows the user to force quit the applications by tapping the red minus circle that appears at the corner of the app's icon. [81] Clearing applications from multitasking stayed the same from iOS 4.0 through 6.1.6, the last version of iOS 6.
As of iOS 7, the process has become faster and easier. In iOS 7, instead of holding the icons to close them, they are closed by simply swiping them upwards off the screen. Up to three apps can be cleared at a time compared to one in versions up to iOS 6.1.6. [82]

Task completion
Task completion allows apps to continue a certain task after the app has been suspended. [83] [84] As of iOS 4.0, apps can request up to ten minutes to complete a task in the background. [85] This doesn't extend to background up- and downloads though (e.g. if you start a download in one application, it won't finish if you switch away from the application).

Siri
Siri is a personal assistant and knowledge navigator which works as an application on supported devices. The service, directed by the user's spoken commands, can do a variety of different tasks, such as call or text someone, open an app, search the web, lookup sports information, find directions or locations, and answer general knowledge questions (e.g. "How many cups are in a gallon?"). [86] Siri was updated in iOS 7 with a new interface, faster answers, Wikipedia, Twitter, and Bing support and the voice was changed to sound more human. Siri is currently only available on the iPhone 4S and later iPhones, the fifth and sixth generation iPod Touch , all of the models of the iPad Mini , and the third-generation and later iPads.

Game Center
Game Center is an online multiplayer "social gaming network" [87] released by Apple. [88] It allows users to "invite friends to play a game, start a multiplayer game through matchmaking, track their achievements , and compare their high scores on a leaderboard ." iOS 5 and above adds support for profile photos. [87]
Game Center was announced during an iOS 4 preview event hosted by Apple on April 8, 2010. A preview was released to registered Apple developers in August. [87] It was released on September 8, 2010 with iOS 4.1 on iPhone 4 , iPhone 3GS, and iPod Touch 2nd generation through 4th generation. [89] Game Center made its public debut on the iPad with iOS 4.2.1. [90] There is no support for the iPhone 3G , original iPhone and the first-generation iPod Touch (the latter two devices did not have Game Center because they did not get iOS 4). However, Game Center is unofficially available on the iPhone 3G via a hack. [91]

Development
Authorized third-party native applications are available through Apple's App Store for devices running iPhone OS 2.0 and higher. Native apps must be written in Swift or Objective-C (with some elements optionally in C or C++ ) and compiled specifically for iOS and the 64-bit ARM architecture or previous 32-bit one (typically using Xcode ). Third-party attempts have been made to allow apps written with Java , .NET , and Adobe Flash to run on iOS devices, but due to Apple restrictions these are generally not available in the iOS App Store.
The Safari web browser supports web applications as with other web browsers. Hybrid apps embed a mobile web site inside a native app, possibly using a hybrid framework like Apache Cordova or React Native .
iOS shares some frameworks with Apple's desktop operating system macOS , such as Core Foundation and Foundation Kit ; however, its UI toolkit is Cocoa Touch rather than macOS' Cocoa , providing the UIKit rather than the AppKit framework, preventing source compatibility with desktop applications. Also, Unix-like shell access is strictly apps-only, preventing it from being fully Unix despite its Darwin foundation from macOS itself.

SDK
On October 17, 2007, in an open letter posted to Apple's "Hot News" weblog, Steve Jobs announced that a software development kit (SDK) would be made available to third-party developers in February 2008. [92] The SDK was released on March 6, 2008, and allows developers to make applications for the iPhone and iPod Touch, as well as test them in an "iPhone simulator". However, loading an application onto the devices is only possible after paying an iPhone Developer Program fee.
The fees to join the respective developer programs for iOS and macOS were each set at US$99.00 per year. As of July 20, 2011, Apple released Xcode on its Mac App Store free to download for all Mac OS X Lion users, instead of as a standalone download. Users can create and develop iOS and macOS applications using a free copy of Xcode; however, they cannot test their applications on a physical iOS device, or publish them to the App store, without first paying the yearly $99.00 iPhone Developer or Mac Developer Program fee. [93]
Since the release of Xcode 3.1, Xcode is the development environment for the iOS SDK.
Developers are able to set any price above a set minimum for their applications to be distributed through the App Store , keeping 70% for the developer, and leaving 30% for Apple. Alternatively, they may opt to release the application for free and need not pay any costs to release or distribute the application except for the membership fee. [94]

Market share
iOS is the second most popular mobile operating system in the world, after Android . Sales of iPads in recent years are also behind Android, while, by web use (a proxy for all use), iPads (using iOS) are still most popular. [95]
By the middle of 2012, there were 410 million devices activated. [96] At WWDC 2014, Tim Cook said 800 million devices had been sold by June 2014. [97]
During Apple's quarterly earnings call in January 27, 2015, Apple announced that they have now sold one billion iOS devices since 2007 [98] (a little less than Android sold in 2014 only). [99]
By late 2011, iOS accounted for 60% of the market share for smartphones and tablets. [100] By the end of 2014, iOS accounted for 14.8% of the smartphone market [101] and 27.6% of the tablet and two-in-one market. [102] In February 2015, StatCounter reported iOS was used on 23.18% of smartphones and 66.25% of tablets worldwide, measured by internet usage instead of sales. [103]
In the third quarter of 2015, research from Strategy Analytics showed that iOS adoption of the worldwide smartphone market was at a record-low 12.1%, attributed to lackluster performance in China and Africa. Android accounted for 87.5% of the market, with Windows Phone and BlackBerry accounting for the rest. [104] [105]

Jailbreaking
Since its initial release, iOS has been subject to a variety of different hacks centered around adding functionality not allowed by Apple. [106] Prior to the 2008 debut of Apple's native iOS App Store , the primary motive for jailbreaking was to bypass Apple's purchase mechanism for installing the App Store's native applications. [107] Apple claimed that it will not release iOS software updates designed specifically to break these tools (other than applications that perform SIM unlocking ); however, with each subsequent iOS update, previously un-patched jailbreak exploits are usually patched. [108]
Since the arrival of Apple's native iOS App Store, and—along with it—third-party applications, the general motives for jailbreaking have changed. [109] People jailbreak for many different reasons, including gaining filesystem access, installing custom device themes, and modifying SpringBoard. An additional motivation is that it may enable the installation of pirated apps. On some devices, jailbreaking also makes it possible to install alternative operating systems, such as Android and the Linux kernel. Primarily, users jailbreak their devices because of the limitations of iOS. Depending on the method used, the effects of jailbreaking may be permanent or temporary. [110]
In 2010, the Electronic Frontier Foundation (EFF) successfully convinced the U.S. Copyright Office to allow an exemption to the general prohibition on circumvention of copyright protection systems under the Digital Millennium Copyright Act (DMCA). The exemption allows jailbreaking of iPhones for the sole purpose of allowing legally obtained applications to be added to the iPhone. [111] The exemption does not affect the contractual relations between Apple and an iPhone owner, for example, jailbreaking voiding the iPhone warranty; however, it is solely based on Apple's discretion on whether they will fix jailbroken devices in the event that they need to be repaired. At the same time, the Copyright Office exempted unlocking an iPhone from DMCA's anticircumvention prohibitions. [112] Unlocking an iPhone allows the iPhone to be used with any wireless carrier using the same GSM or CDMA technology for which the particular phone model was designed to operate. [113]

Unlocking
Initially most wireless carriers in the US did not allow iPhone owners to unlock it for use with other carriers. However AT&T allowed iPhone owners who have satisfied contract requirements to unlock their iPhone. [114] Instructions to unlock the device are available from Apple, [115] but it is ultimately the sole discretion of the carrier to authorize the device to be unlocked. [116] This allows the use of a carrier-sourced iPhone on other networks. However, because T-Mobile primarily uses a different band than AT&T for its 3G, the iPhone will only work at 3G speeds on the T-Mobile 1900 MHz network. [117] There are programs to break these restrictions, but are not supported by Apple and most often not a permanent unlock - a soft-unlock. [118]

Digital rights management
The closed and proprietary nature of iOS has garnered criticism, particularly by digital rights advocates such as the Electronic Frontier Foundation , computer engineer and activist Brewster Kahle , Internet-law specialist Jonathan Zittrain , and the Free Software Foundation who protested the iPad's introductory event and have targeted the iPad with their " Defective by Design " campaign. [119] [120] [121] [122] Competitor Microsoft , via a PR spokesman, criticized Apple's control over its platform. [123]
At issue are restrictions imposed by the design of iOS, namely digital rights management (DRM) intended to lock purchased media to Apple's platform, the development model (requiring a yearly subscription to distribute apps developed for the iOS), the centralized approval process for apps, as well as Apple's general control and lockdown of the platform itself. Particularly at issue is the ability for Apple to remotely disable or delete apps at will.
Some in the tech community have expressed concern that the locked-down iOS represents a growing trend in Apple's approach to computing, particularly Apple's shift away from machines that hobbyists can "tinker with" and note the potential for such restrictions to stifle software innovation. [124] [125] Former Facebook developer Joe Hewitt protested against Apple's control over its hardware as a "horrible precedent" but praised iOS's sandboxing of apps. [126]

Kernel
The iOS kernel is the XNU kernel of Darwin . The original iPhone OS (1.0) up to iPhone OS 3.1.3 used Darwin 9.0.0d1. iOS 4 was based on Darwin 10. iOS 5 was based on Darwin 11. iOS 6 was based on Darwin 13. iOS 7 and iOS 8 are based on Darwin 14. iOS 9 is based on Darwin 15. iOS 10 is based on Darwin 16. [127]

Security
iOS utilizes many security features in both hardware and software. Below are summaries of the most prominent features.

Secure Boot
Before fully booting into iOS, there is low-level code that runs from the Boot ROM . Its task is to verify that the Low-Level Bootloader is signed by the Apple Root CA public key before running it. This process is to ensure that no malicious or otherwise unauthorized software can be run on an iOS device. After the Low-Level Bootloader finishes its tasks, it runs the higher level bootloader, known as iBoot . If all goes well, iBoot will then proceed to load the iOS kernel as well as the rest of the operating system. [128]

Secure Enclave
The Secure Enclave is a coprocessor found in iOS devices that contain Touch ID . It has its own secure boot process to ensure that it is completely secure. A hardware random number generator is also included as a part of this coprocessor. Each device's Secure Enclave has a unique ID that is given to it when it is made and cannot be changed. This identifier is used to create a temporary key that encrypts the memory in this portion of the system. The Secure Enclave also contains an anti-replay counter to prevent brute force attacks . [128]

Passcode
iOS devices can have a passcode that is used to unlock the device, make changes to system settings, and encrypt the device's contents. Until recently, these were typically four numerical digits long. However, since unlocking the devices with a fingerprint by using Touch ID has become more widespread, six-digit passcodes are now the default on iOS with the option to switch back to four or use an alphanumeric passcode. [128]

Touch ID
Touch ID is a fingerprint scanner that is embedded in the home button and can be used to unlock the device, make purchases, and log into applications among other functions. When used, Touch ID only temporarily stores the fingerprint data in encrypted memory in the Secure Enclave, as described above. There is no way for the device's main processor or any other part of the system to access the raw fingerprint data that is obtained from the Touch ID sensor. [128]

Address Space Layout Randomization
Address Space Layout Randomization (ASLR) is a low-level technique of preventing memory corruption attacks such as buffer overflows . It involves placing data in randomly selected locations in memory in order to make it harder to predict ways to corrupt the system and create exploits. ASLR makes app bugs more likely to crash the app than to silently overwrite memory, regardless of whether the behavior is accidental or malicious. [129]

Non-Executable Memory
iOS utilizes the ARM architecture's Execute Never (XN) feature. This allows some portions of the memory to be marked as non-executable, working alongside ASLR to prevent buffer overflow attacks including return-to-libc attacks . [128]

Encryption
As mentioned above, one use of encryption in iOS is in the memory of the Secure Enclave. When a passcode is utilized on an iOS device, the contents of the device are encrypted. This is done by using a hardware AES 256 implementation that is very efficient because it is placed directly between the flash storage and RAM. [128]

Keychain
The iOS keychain is a database of login information that can be shared across apps written by the same person or organization. [128] This service is often used for storing passwords for web applications. [130]

App Security
Third-party applications such as those distributed through the App Store must be code signed with an Apple-issued certificate . This continues the chain of trust all the way from the Secure Boot process as mentioned above to the actions of the applications installed on the device by users. Applications are also sandboxed , meaning that they can only modify the data within their individual home directory unless explicitly given permission to do otherwise. For example, they cannot access data that is owned by other user-installed applications on the device. There is a very extensive set of privacy controls contained within iOS with options to control apps' ability to access a wide variety of permissions such as the camera, contacts, background app refresh, cellular data, and access to other data and services. Most of the code in iOS, including third-party applications, run as the "mobile" user which does not have root privileges . This ensures that system files and other iOS system resources remain hidden and inaccessible to user-installed applications. [128]

Network Security
iOS supports TLS with both low- and high-level APIs for developers. By default, the App Transport Security framework requires that servers use at least TLS 1.2. However, developers are free to override this framework and utilize their own methods of communicating over networks. When Wi-Fi is enabled, iOS uses a randomized MAC address so that devices cannot be tracked by anyone sniffing wireless traffic. [128]

Two-Factor Authentication
Two-factor authentication is an option in iOS to ensure that even if an unauthorized person knows an Apple ID and password combination, they cannot gain access to the account. It works by requiring not only the Apple ID and password, but also a verification code that is sent to a device that is already known to be trusted. [128] If an unauthorized user attempts to sign in using another user's Apple ID, the owner of the Apple ID receives a notification that allows them to deny access to the unrecognized device. [131]

Devices

See also
WebPage index: 00081
Wikipedia: Wikipedia for Schools
Wikipedia for Schools is a selection of articles from Wikipedia produced by international children's charity SOS Children and most recently updated in 2013. It was originally produced as a learning resource for schools in countries where Internet access is limited, though it has also enjoyed significant success in the developed world. While previous version have been released onto CD and then DVD, the current version is available online as well as by download and on USB memory stick. When the first version was released in April 2006, it was the only version of Wikipedia available offline on CD.
The 2013 edition of Wikipedia for Schools contains 6,000 articles comprising 26 million words, as well as 50,000 images. Taking the UK National Curriculum as its starting point, articles are organised by school subject, from Art and Citizenship , to Geography and Mathematics . All pages were selected from the English Wikipedia by staff and volunteers at SOS Children, before being checked to ensure suitability for children, and any inappropriate content removed before release. This additional step was designed to remove a key problem with Wikipedia as perceived by many teachers and parents. [1]

Distribution
When Wikipedia for Schools was first released in April 2006, copies were distributed on CD. Distribution was largely carried out by SOS Children with the help of its umbrella organisation , SOS Children's Villages international. However, in South Africa and India, SOS Children benefited from the help of partners such as the Shuttleworth Foundation and the Hole in the Wall . [2] The 2013 version of Wikipedia for Schools was released onto USB memory stick, to accommodate the increased size of the new edition, as well as to improve durability and portability.
Wikipedia for Schools can also be accessed at http://schools-wikipedia.org . This online version gets around 7,000 unique IP visitors a day rising to over 20,000 in the run up to new editions. [3] A Plucker database version of the 2007 can be carried on SD card for Palm Pilot . [4]

History of the project
Because this distribution was not initially an official Wikimedia project, some changes had to be made for legal reasons.

Logo
SOS Children did not have permission to use the Wikipedia puzzle-globe logo in the 2006 version. However, when the Wikimedia Foundation endorsed the project roughly one year later, the puzzle-globe was adopted for the 2007 edition as well as the 2008/9 release.
The 2013 version uses a new logo designed by SOS Children, which can be seen above.

Content changes
Wikipedia content remains substantially the same, although material deemed unsuitable for school-age children during checking is removed. This includes strong language and sexual references which are not justified by the context. [5] Though editing may seem conservative to some users, SOS Children attempts to bear in mind the various cultural settings in which Wikipedia for Schools is intended for use. As far as is reasonable in an educational resource, Wikipedia for Schools endeavours to accommodate all of these preferences.

See also

References and notes

Further reading

See also

External links
WebPage index: 00082
Mauritius
Coordinates : 20°12′S 57°30′E ﻿ / ﻿ 20.2°S 57.5°E ﻿ / -20.2; 57.5
Mauritius ( i / m ə ˈ r ɪ ʃ ə s / ; French: Maurice ), officially the Republic of Mauritius (French: République de Maurice ), is an island nation in the Indian Ocean about 2,000 kilometres (1,200 mi) off the southeast coast of the African continent. The country includes the islands of Mauritius and Rodrigues [560 kilometres (350 mi) east of Mauritius], and the outer islands ( Agaléga , St. Brandon and two disputed territories). The islands of Mauritius and Rodrigues form part of the Mascarene Islands , along with nearby Réunion , a French overseas department. The area of the country is 2,040 km 2 (790 sq mi). The capital and largest city is Port Louis . Formerly a Dutch colony (1638–1710) and a French colony (1715–1810), Mauritius became a British colonial possession in 1810 and remained so until 1968, the year in which it attained independence. The government uses English as its main language.
The sovereignty over the Chagos Archipelago is disputed between Mauritius and the United Kingdom (UK). The UK excised the archipelago from Mauritian territory in 1965, three years prior to Mauritian independence. The UK gradually depopulated the archipelago's indigenous population and leased its biggest island, Diego Garcia , to the United States. Access to the archipelago is prohibited to casual tourists, the media, and its former inhabitants. Mauritius also claims sovereignty over Tromelin Island from France.
The people of Mauritius are multiethnic , multi-religious, multicultural and multilingual. The island's government is closely modelled on the Westminster parliamentary system , and Mauritius is highly ranked for democracy and for economic and political freedom . Along with the other Mascarene Islands, Mauritius is known for its varied flora and fauna , with many species endemic to the island. The island is widely known as the only known home of the dodo , which, along with several other avian species, was made extinct by human activities relatively shortly after the island's settlement. Mauritius is the only country in Africa where Hinduism is the largest religion.

Etymology
The first historical evidence of the existence of an island now known as Mauritius is on a map produced by the Italian cartographer Alberto Cantino in 1502. [18] From this, it appears that Mauritius was first named Dina Arobi around 975 by Arab sailors, the first people to visit the island.
In 1507 Portuguese sailors visited the uninhabited island. The island appears with a Portuguese name Cirne on early Portuguese maps, probably from the name of a ship in the 1507 expedition. Another Portuguese sailor, Dom Pedro Mascarenhas , gave the name Mascarenes to the Archipelago.
In 1598 a Dutch squadron under Admiral Wybrand van Warwyck landed at Grand Port and named the island Mauritius , in honour of Prince Maurice van Nassau , stadholder of the Dutch Republic . Later the island became a French colony and was renamed Isle de France . On 3 December 1810 the French surrendered the island to Great Britain during the Napoleonic Wars . Under British rule, the island's name reverted to Mauritius i / m ə ˈ r ɪ ʃ ə s / . Mauritius is also commonly known as Maurice ( pronounced: [mɔˈʁis] ) and Île Maurice in French, Moris in Mauritian Creole .

History
The island of Mauritius was uninhabited before its first recorded visit during the Middle Ages by Arab sailors, who named it Dina Arobi. However, the island might have been visited well before by sailors of ancient times; wax tablets were found on the shores of Mauritius by the Dutch, but since the tablets were not preserved, it cannot be said whether they were of Greek , Phoenician or Arab origin. [19]
In 1507 Portuguese sailors came to the uninhabited island and established a visiting base. Diogo Fernandes Pereira , a Portuguese navigator, was the first European known to land in Mauritius. He named the island "Ilha do Cirne". The Portuguese did not stay long as they were not interested in these islands. [20]

Dutch Mauritius (1638–1710)
In 1598 a Dutch squadron under Admiral Wybrand Van Warwyck landed at Grand Port and named the island "Mauritius" after Prince Maurice van Nassau of the Dutch Republic , the ruler of his country. The Dutch established a small colony on the island in 1638, from which they exploited ebony trees and introduced sugar cane , domestic animals and deer . It was from here that Dutch navigator Abel Tasman set out to discover the western part of Australia. The first Dutch settlement lasted twenty years. Several attempts were subsequently made, but the settlements never developed enough to produce dividends, causing the Dutch to abandon Mauritius in 1710. [20] [21]

French Mauritius (1715–1810)
France, which already controlled neighbouring Île Bourbon (now Réunion ), took control of Mauritius in 1715 and renamed it Isle de France . In 1723, the Code Noir was established to categorise one group of human beings as "goods", in order for the owner of these goods to be able to obtain insurance money and compensation in case of loss of his "goods". [22] The 1735 arrival of French governor Bertrand-François Mahé de La Bourdonnais coincided with development of a prosperous economy based on sugar production. Mahé de La Bourdonnais established Port Louis as a naval base and a shipbuilding centre. [20]
Under his governorship, numerous buildings were erected, a number of which are still standing. These include part of Government House, the Château de Mon Plaisir , and the Line Barracks, the headquarters of the police force . The island was under the administration of the French East India Company which maintained its presence until 1767. [20]
From 1767 to 1810, except for a brief period during the French Revolution when the inhabitants set up a government virtually independent of France, the island was controlled by officials appointed by the French Government . Jacques-Henri Bernardin de Saint-Pierre lived on the island from 1768 to 1771, then went back to France, where he wrote Paul et Virginie , a love story, which made the Isle de France famous wherever the French language was spoken. Two famous French governors were the Vicomte de Souillac (who constructed the Chaussée in Port Louis [23] and encouraged farmers to settle in the district of Savanne), and Antoine Bruni d'Entrecasteaux (who saw to it that the French in the Indian Ocean should have their headquarters in Mauritius instead of Pondicherry in India). [19]
Charles Mathieu Isidore Decaen was a successful general in the French Revolutionary Wars and, in some ways, a rival of Napoléon I . He ruled as Governor of Isle de France and Réunion from 1803 to 1810. British naval cartographer and explorer Matthew Flinders was arrested and detained by General Decaen on the island, in contravention of an order from Napoléon. During the Napoleonic Wars , Mauritius became a base from which French corsairs organised successful raids on British commercial ships. The raids continued until 1810, when a Royal Navy expedition led by Commodore Josias Rowley , R.N. , an Anglo-Irish aristocrat , was sent to capture the island. Despite winning the Battle of Grand Port , the only French naval victory over the British during these wars, the French could not prevent the British from landing at Cap Malheureux three months later. They formally surrendered the island on the fifth day of the invasion, 3 December 1810, [19] on terms allowing settlers to keep their land and property and to use the French language and law of France in criminal and civil matters. Under British rule, the island's name reverted to Mauritius. [20]

British Mauritius (1810–1968)
The British administration, which began with Sir Robert Farquhar as Governor , led to rapid social and economic changes. However, it was tainted by the Ratsitatane episode. Ratsitatane, nephew of King Radama of Madagascar, was brought to Mauritius as a political prisoner. He managed to escape from prison and plotted a rebellion that would free the island's slaves. He was betrayed by an associate and was caught by the British forces, summarily judged, and condemned to death. He was beheaded at Plaine Verte on 15 April 1822, and his head was displayed as a deterrent against future uprisings among the slaves. [24]
In 1832, Adrien d'Épinay launched the first Mauritian newspaper ( Le Cernéen ) which was not controlled by the government. In the same year, there was a move by the procureur-general to abolish slavery without compensation to the slave owners. This gave rise to discontent, and to check an eventual rebellion, the government ordered all the inhabitants to surrender their arms. Furthermore, a stone fortress, Fort Adelaide, was built on a hill (now known as the Citadel hill) in the centre of Port Louis to quell any uprising. [23]
Slavery was abolished in 1835, and the planters ultimately received two million pounds sterling in compensation for the loss of their slaves who had been imported from Africa and Madagascar during the French occupation. The abolition of slavery had important impacts on Mauritius' society, economy and population. The planters brought a large number of indentured labourers from India to work in the sugar cane fields. Between 1834 and 1921, around half a million indentured labourers were present on the island. They worked on sugar estates, factories, in transport and on construction sites. Additionally, the British brought 8,740 Indian soldiers to the island. [20] Aapravasi Ghat , in the bay at Port Louis and now a UNESCO site, was the first British colony to serve as a major reception centre for slaves and indentured servants for British plantation labour. [ clarification needed ]
An important figure of the 19th century was Rémy Ollier , a journalist of mixed origin. In 1828, the colour bar was officially abolished in Mauritius but British governors gave little power to coloured persons, and appointed only whites as leading officials. Rémy Ollier petitioned to Queen Victoria to allow coloureds in the council of government, and this became possible a few years later. He also made Port Louis become a municipality so that the citizens could administer the town through their own elected representatives. A street has been named after him in Port Louis, and his bust was erected in the Jardin de la Compagnie in 1906. [19] In 1885 a new constitution was introduced to Mauritius. It created elected positions on the governing council, but the franchise was restricted mainly to the French and Creole classes.
The labourers brought from India were not always fairly treated and a German, Adolph von Plevitz, made himself the unofficial protector of these immigrants. He mixed with many of the labourers, and in 1871 helped them to write a petition which was sent to Governor Gordon . A commission was appointed to look into the complaints made by the Indian immigrants, and in 1872 two lawyers, appointed by the British Crown, were sent from England to make an inquiry. This Royal Commission recommended several measures that would affect the lives of Indian labourers during the next fifty years. [19]
In November 1901, Mahatma Gandhi visited Mauritius, on his way from South Africa to India. He stayed on the island for two weeks, and urged the Indo-Mauritian community to take an interest in education and to play a more active role in politics. Back in India, he sent over a young lawyer, Manilal Doctor , to improve the plight of the Indo-Mauritians. During the same year, faster links were established with the island of Rodrigues thanks to the wireless. [25]
In 1903, motorcars were introduced in Mauritius, and in 1910 the first taxis, operated by Joseph Merven, came into service. The electrification of Port Louis took place in 1909, and in the same decade the Mauritius Hydro Electric Company (managed by the Atchia Brothers) was authorised to provide power to the towns of upper Plaines Wilhems.
The 1910s were a period of political agitation. The rising middle class (made up of doctors, lawyers, and teachers) began to challenge the political power of the sugar cane landowners. Dr. Eugène Laurent, mayor of Port Louis, was the leader of this new group; his party, Action Libérale, demanded that more people should be allowed to vote in the elections. Action Libérale was opposed by the Parti de l'Ordre, led by Henri Leclézio, the most influential of the sugar magnates. [19] In 1911 there were riots in Port Louis due to a false rumour that Dr. Eugène Laurent had been murdered by the oligarchs in Curepipe. Shops and offices were damaged in the capital and one person was killed. In the same year, 1911, the first public cinema shows took place in Curepipe and, in the same town, a stone building was erected to house the Royal College. [25] In 1912, a wider telephone network came into service and it was used by the government, business firms, and a few private households.
World War I broke out in August 1914. Many Mauritians volunteered to fight in Europe against the Germans, and in Mesopotamia against the Turks. But the war affected Mauritius much less than the wars of the eighteenth century. On the contrary, the 1914–18 war was a period of great prosperity because of a boom in sugar prices. In 1919 the Mauritius Sugar Syndicate came into being, and it included 70% of all sugar producers.
The 1920s saw the rise of a "retrocessionism" movement which favoured the retrocession of Mauritius to France. The movement rapidly collapsed because none of the candidates who wanted Mauritius to be given back to France was elected in the 1921 elections. Due to the post-war recession, there was a sharp drop in sugar prices. Many sugar estates closed down, and it marked the end of an era for the sugar magnates who had not only controlled the economy, but also the political life of the country. Raoul Rivet, the editor of Le Mauricien newspaper, campaigned for a revision of the constitution that would give the emerging middle class a greater role in the running of the country. The principles of Arya Samaj began to infiltrate the Hindu community, who clamoured for more social justice. [25]
The 1930s saw the birth of the Labour Party , launched by Dr. Maurice Curé. Emmanuel Anquetil rallied the urban workers while Pandit Sahadeo concentrated on the rural working class. Labour Day was celebrated for the first time in 1938. More than 30,000 workers sacrificed a day's wage and came from all over the island to attend a giant meeting at the Champ de Mars. [26]
At the outbreak of World War II in 1939, many Mauritians volunteered to serve under the British flag in Africa and the Near East, fighting against the German and Italian armies. Some went to England to become pilots and ground staff in the Royal Air Force . Mauritius was never really threatened, but several British ships were sunk outside Port Louis by German submarines in 1943.
During World War II conditions were hard in the country; the prices of commodities doubled but the salaries of workers increased only by 10 to 20 percent. There was civil unrest, and the colonial government crushed all trade union activities. However, the labourers of Belle Vue Harel Sugar Estate went on strike on 27 September 1943. Police officers eventually fired on the crowd, and killed three labourers including a boy of ten and a pregnant woman, Anjaly Coopen. [27] [28]
The first general elections were held on 9 August 1948 and were won by the Labour Party. This party, led by Guy Rozemont, bettered its position in 1953, and, on the strength of the election results, demanded universal suffrage . Constitutional conferences were held in London in 1955 and 1957, and the ministerial system was introduced. Voting took place for the first time on the basis of universal adult suffrage on 9 March 1959. The general election was again won by the Labour Party, led this time by Sir Seewoosagur Ramgoolam . [29]
A Constitutional Review Conference was held in London in 1961 and a programme of further constitutional advance was established. The 1963 election was won by the Labour Party and its allies. The Colonial Office noted that politics of a communal nature was gaining ground in Mauritius and that the choice of candidates (by parties) and the voting behaviour (of electors) were governed by ethnic and caste considerations. [29] Around that time, two eminent British academics, Richard Titmuss and James Meade , published a report of the island's social problems caused by overpopulation and the monoculture of sugar cane. This led to an intense campaign to halt the population explosion, and the decade registered a sharp decline in population growth.

Independence (since 1968)
At the Lancaster Conference of 1965, it became clear that Britain wanted to relieve itself of the colony of Mauritius. In 1959, Harold Macmillan had made his famous Winds of Change Speech where he acknowledged that the best option for Britain was to give complete independence to its colonies. Thus, since the late Fifties, the way was paved for independence. [30]
Later in 1965, after the Lancaster Conference, the Chagos Archipelago was excised from the territory of Mauritius to form the British Indian Ocean Territory (BIOT). A general election took place on 7 August 1967, and the Labour Party and its two allies obtained the majority of seats. Mauritius adopted a new constitution and independence was proclaimed on 12 March 1968. Sir Seewoosagur Ramgoolam became the first prime minister of an independent Mauritius with Queen Elizabeth II remaining head of state as Queen of Mauritius. In 1969, the opposition party Mauritian Militant Movement (MMM) led by Paul Bérenger was founded. Later in 1971, the MMM, backed by unions, called a series of strikes in the port which caused a state of emergency in the country. [31] The coalition government of the Labour Party and the PMSD (Parti Mauricien Social Democrate) reacted by curtailing civil liberties and curbing freedom of the press. [25] Two unsuccessful assassination attempts were made against Paul Bérenger. The second one led to the death of Azor Adélaïde, a dock worker and activist, on 25 November 1971. [32] General elections were postponed and public meetings were prohibited. Members of the MMM including Paul Bérenger were imprisoned on 23 December 1971. The MMM leader was released a year later. [33]
In May 1975, a student revolt that started at the University of Mauritius swept across the country. [34] The students were unsatisfied with an education system that did not meet their aspirations and gave limited prospects for future employment. On 20 May, thousands of students tried to enter Port-Louis over the Grand River North West bridge and clashed with police. An act of Parliament was passed on 16 December 1975 to extend the right to vote to 18-year-olds. This was seen as an attempt to appease the frustration of the younger generation. [24]
The next general election took place on 20 December 1976. The Labour Party won 28 seats out of 62 [35] but Prime Minister Sir Seewoosagur Ramgoolam managed to remain in office, with a two-seat majority, after striking an alliance with the PMSD of Gaetan Duval.
In 1982 an MMM government led by Prime Minister Anerood Jugnauth and Paul Bérenger as Minister of Finance was elected. However, ideological and personality differences emerged within the MMM leadership. The power struggle between Bérenger and Jugnauth peaked in March 1983. Jugnauth travelled to New Delhi to attend a Non-Aligned Movement summit; on his return, Bérenger proposed constitutional changes that would strip power from the Prime Minister. At Jugnauth's request, PM Indira Gandhi of India planned an armed intervention involving the Indian Navy and Indian Army to prevent a coup under the code name Operation Lal Dora . [36] [37] [38]
The MMM government split up nine months after the June 1982 election. According to an Information Ministry official the nine months was a "socialist experiment". [39] The new MSM party, led by Aneerood Jugnauth, was elected in 1983. Gaëtan Duval became the vice-prime minister. Throughout the decade, Aneerood Jugnauth ruled the country with the help of the PMSD and the Labour Party.
That period saw a growth in the EPZ (Export Processing Zone) sector. Industrialisation began to spread to villages as well, and attracted young workers from all ethnic communities. As a result, the sugar industry began to lose its hold on the economy. Large retail chains began opening stores opened in 1985 and offered credit facilities to low income earners, thus allowing them to afford basic household appliances. There was also a boom in the tourism industry, and new hotels sprang up throughout the island. In 1989 the stock exchange opened its doors and in 1992 the freeport began operation. [25] In 1990, the Prime Minister lost the vote on changing the Constitution to make the country a republic with Bérenger as President. [40]

Republic (since 1992)
On 12 March 1992, twenty-four years after independence, Mauritius was proclaimed a republic within the Commonwealth of Nations . [20] The last Governor General, Sir Veerasamy Ringadoo became the first President . [41] This was under a transitional arrangement, in which he was replaced by Cassam Uteem later that year. [42] Political power remained with the Prime Minister.
Despite an improvement in the economy, which coincided with a fall in the price of petrol and a favourable dollar exchange rate, the government did not enjoy full popularity. As early as 1984, there was discontent. Through the Newspapers and Periodicals Amendment Act, the government tried to make every newspaper provide a bank guarantee of half a million rupees. Forty-three journalists protested by participating in a public demonstration in Port Louis, in front of Parliament. They were arrested and freed on bail. This caused a public outcry and the government had to review its policy. [25]
There was also dissatisfaction in the education sector. There were not enough high-quality secondary colleges to answer the growing demand of primary school leavers who had got through their CPE (Certificate of Primary Education). In 1991, a master plan for education failed to get national support and contributed to the government's downfall. [25]
Dr Navin Chandra Ramgoolam was elected as Prime Minister in the 1995 election. The landslide victory of 60–0 was a repeat of the 1982 score, but this time it was on the side of the Labour–MMM alliance. [ citation needed ]
In February 1999, the country experienced a brief period of civil unrest. Riots flared after the popular singer Kaya , arrested for smoking marijuana at a public concert, was found dead in his prison cell. President Cassam Uteem and Cardinal Jean Margéot toured the country and, after four days of turmoil, calm was restored. [43] A commission of enquiry was set up to investigate the root causes of the social disturbance. The resulting report delved into the cause of poverty and qualified many tenacious beliefs as perceptions. [44]
Aneerood Jugnauth of the MSM returned to power in 2000 after making an alliance with the MMM, which included prominent figures such as Anil Bachoo , Pravind Jugnauth and Sangeet Fowdar [ clarification needed ] amongst others. In 2002, the island of Rodrigues became an autonomous entity within the republic and was thus able to elect its own representatives to administer the island. In 2003, the prime ministership was transferred to Paul Bérenger of the MMM, and Aneerood Jugnauth went to Le Réduit to serve as president. [ citation needed ]
In the 2005 election, Navin Ramgoolam, leader of the Labour Party, was brought to power after making an alliance with the Parti Mauricien Xavier-Luc Duval (PMXD) and other minor parties. Navin Ramgoolam was again elected in May 2010. This time the Labour Party joined forces with the PMSD and the MSM . Under the new government, the country continued with its MID ( Maurice Ile Durable ) project, started in 2008, to make the economy less dependent on fossil fuels. The political landscape stayed rather confused. The Labour Party did away with the MSM, and then with the PMSD, whose leader had acted as Finance minister. The MMM made an alliance (known as Remake) with the MSM but broke off with the latter to become the ally of Labour Party. Parliament remained closed for most of 2014. A second republic was proposed (by the leaders of Labour and MMM) whereby a president, elected by the population, would hold more power and rule the country in joint collaboration with the PM. Nomination day took place on 24 November 2014 and, for the first time, electoral candidates had the option of not proclaiming their ethnic group. Only a few chose to do so. General elections were held on 10 December 2014, and the Lepep alliance made up of the MSM, PMSD, and Mouvement Liberater (led by an MMM dissident) was elected to power by reaping 47 seats out of 60. The Westminster system was thus maintained and Aneerood Jugnauth became the PM for the sixth time. [ citation needed ]
Shortly after the new government took office, the ex-PM was lengthily interrogated by the police on charges related to money laundering . The license of the Bramer Bank was revoked due to alleged lack of liquidity, and the BAI ( British-American Insurance ) was suspended from trading and placed in receivership. A United Nations tribunal ruled that Britain had acted illegally when it created a marine protected area around the Chagos without the consent of Mauritius, thereby depriving this country of its fishing rights. Fresh negotiations began with Jin Fei in view of reviving the project started in 2006. Mauritius will henceforth detain 80% of the shares while the rest would go to the Chinese promoters.
Tourism continued to be the main source for foreign exchange, and the number of visitors to the island reached 1.1 million in 2015. Despite this boom in the tourism industry, Tourism Minister Xavier-Luc Duval placed a two-year moratorium on the construction of new hotels. [ citation needed ]
On 21 January 2017, Anerood Jugnauth announced that in two days time he would resign in favor of his son, Finance Minister Pravind Jugnauth, who would assume the office of prime minister. [45] The transition took place as planned on 23 January. [46]

Truth and Justice Commission
Operating from 2009 to 2011 the Truth and Justice Commission was established to explore the impact of slavery and indentured servitude in Mauritius. The Commission was tasked to investigate the dispossession of land and "determine appropriate measures to be extended to descendants of slaves and indentured laborers." [47] [48] It was "unique in that it [dealt] with socio-economic class abuses" and explored the possibility of reparations. [47] The Commission attempted to cover more than 370 years, the longest period of time that a truth commission has ever covered. [47] Published 25 November 2011, the report outlined over 300 recommendations detailing ways to bring those affected by slavery and indentured labour out of poverty. [49]

Politics
The politics of Mauritius take place in a framework of a parliamentary representative democratic republic, in which the President is the head of state and the Prime Minister is the head of government , assisted by a Council of Ministers . Mauritius has a multi-party system . Executive power is exercised by the Government. Legislative power is vested in both the Government and the National Assembly .

Parliament
The National Assembly is Mauritius' unicameral parliament, which was called the Legislative Assembly until 1992, when the country became a republic. It consists of 70 members, 62 elected for four-year terms in multi-member constituencies and eight additional members, known as "best losers", appointed by the Supreme Court to ensure that ethnic and religious minorities are equitably represented. The UN Human Rights Committee (UNHRC), which monitors member states' compliance with the International Covenant on Political and Civil Rights (ICPCR), has criticised the country's Best Loser System following a complaint by a local youth and trade union movement. [50] The president is elected for a five-year term by the Parliament.
The island of Mauritius is divided into 20 constituencies that return three members each, while Rodrigues is a single constituency that returns two members. After a general election, the Electoral Supervisory Commission may nominate up to eight additional members with a view to correct any imbalance in the representation of ethnic minorities in Parliament. This system of nominating members is commonly called the best loser system.
The political party or party alliance that wins the majority of seats in Parliament forms the government. Its leader becomes the Prime Minister, who selects the Cabinet from elected members of the Assembly, except for the Attorney General, who may not be an elected member of the Assembly. The political party or alliance which has the second largest majority forms the Official Opposition and its leader is normally nominated by the President of the Republic as the Leader of the Opposition. The Assembly elects a Speaker, a Deputy Speaker and a Deputy Chairman of Committees as some of its first tasks.

Government
Mauritius is a democracy with a government elected every five years. The most recent National Assembly Election was held on 10 December 2014 in all the 20 mainland constituencies, and in the constituency covering the island of Rodrigues. Elections have tended to be a contest between two major coalitions of parties.
The 2006–2014 Ibrahim Index of African Governance ranked Mauritius first in good governance. [51] According to the 2015 Democracy Index compiled by the Economist Intelligence Unit that measures the state of democracy in 167 countries, Mauritius ranks 18th worldwide and is the only African-related country with "full democracy". [52]

Rule of law
Laws governing the Mauritian penal system are derived partly from French civil law and British common law . [55] The crime rate reduced from 4.3 per 1,000 population in 2009 to 3.6 per 1,000 population in 2010. [56] The Constitution of Mauritius states that for purposes of separation of powers, the judiciary is independent. According to Justice E. Balancy, public opinion is characterised by excessive emotional reaction to crimes arousing the moral indignation of the community. The result is a reluctance to give due weight to the liberty of the citizen and the presumption of innocence. [57]
The provisional charge, part of criminal procedure law since 1852, is a practice that allows anyone suspected of a crime to be detained – sometimes for up to two years – before being charged. [58] In 1994, the police detained the editor-in-chief and a journalist of a weekly magazine for having "unlawfully published secret news". The chairman of the company was also arrested. The Supreme Court found the provisional charge to be null and void, as the offence set out on the provisional charge "publishing secret news" was not known to the law. [59]

Foreign relations
Mauritius has strong and friendly relations with various African, American, Asian, European and Oceania countries. Considered part of Africa geographically, Mauritius has friendly relations with African states in the region, particularly South Africa, by far its largest continental trading partner. Mauritian investors are gradually entering African markets, notably Madagascar, Mozambique and Zimbabwe. The country's political heritage and dependence on Western markets have led to close ties with the European Union and its member states, particularly France. It also depends on the United Kingdom as a trading partner. Relations with China and India are strong for both historical and commercial reasons.
Mauritius is a member of the World Trade Organization , the Commonwealth of Nations , La Francophonie , the African Union , the Southern Africa Development Community (SADC), the Indian Ocean Commission , COMESA , and formed the Indian Ocean Rim Association .

Military
All military, police, and security functions in Mauritius are carried out by 10,000 active-duty personnel under the Commissioner of Police. The 8,000-member National Police Force is responsible for domestic law enforcement. The 1,400-member Special Mobile Force (SMF) and the 688-member National Coast Guard are the only two paramilitary units in Mauritius. Both units are composed of police officers on lengthy rotations to those services. [60]

Geography
The total land area of the country is 2,040 km 2 (790 sq mi) (about 80% the size of Luxembourg ). It is the 169th largest nation in the world by size. The Republic of Mauritius is constituted of the main island of Mauritius and several outlying islands. The second largest island is Rodrigues with an area of 108 km 2 (42 sq mi) and situated 560 km (350 mi) to the east of Mauritius, the twin island of Agalega with a total land area of 2,600 hectares (26 km 2 ; 10 sq mi) and situated some 1,000 km (620 mi) north of Mauritius. Saint Brandon is an archipelago comprising a number of sand-banks, shoals and islets. It is situated some 430 km (270 mi) north-east of Mauritius and is mostly used as a fishing base. [61] The nation's exclusive economic zone (EEZ) covers about 2.3 million square kilometres (890,000 sq mi) of the Indian Ocean, including approximately 400,000 km 2 (150,000 sq mi) jointly managed with the Seychelles . [62] [63] [64]

Mauritius island
Mauritius is some 2,000 km (1,200 mi) off the southeast coast of Africa, between latitudes 19°58.8' and 20°31.7' south and longitudes 57°18.0' and 57°46.5' east. It is 65 km (40 mi) long and 45 km (30 mi) wide. Its land area is 1,864.8 km 2 (720.0 sq mi). [65] [66] The island is surrounded by more than 150 km (100 mi) of white sandy beaches, and the lagoons are protected from the open sea by the world's third largest coral reef, which surrounds the island. [67] Just off the Mauritian coast lie some 49 uninhabited islands and islets , several used as natural reserves for endangered species.
The island of Mauritius is relatively young geologically, having been created by volcanic activity some 8 million years ago. Together with Saint Brandon, Réunion, and Rodrigues, the island is part of the Mascarene Islands . These islands have emerged as a result of gigantic underwater volcanic eruptions that happened thousands of kilometres to the east of the continental block made up of Africa and Madagascar. [61] They are no longer volcanically active and the hotspot now rests under Réunion Island. Mauritius is encircled by a broken ring of mountain ranges, varying in height from 300–800 m (1,000–2,600 ft) above sea level. The land rises from coastal plains to a central plateau where it reaches a height of 670 m (2,200 ft); the highest peak is in the southwest, Piton de la Petite Rivière Noire at 828 metres (2,717 ft). Streams and rivers speckle the island, many formed in the cracks created by lava flows.

Territorial dispute

Chagos Archipelago
Mauritius has long sought sovereignty over the Chagos Archipelago , located 1,287 km to the northeast. Chagos was administratively part of Mauritius from the 18th century when the French first settled the islands. All of the islands forming part of the French colonial territory of Isle de France (as Mauritius was then known) were ceded to the British in 1810 under the Act of Capitulation signed between the two powers. [68] In 1965, three years before the independence of Mauritius, the United Kingdom split the Chagos Archipelago from Mauritius and the islands of Aldabra , Farquhar and Desroches from the Seychelles to form the British Indian Ocean Territory (BIOT). The islands were formally established as an overseas territory of the United Kingdom on 8 November 1965. On 23 June 1976, Aldabra, Farquhar and Desroches were returned to Seychelles as a result of its attaining independence. The BIOT now comprises the Chagos Archipelago only. The UK leased the main island of the archipelago Diego Garcia to the United States under a 50-year lease (which expires in 2016 [ needs update ] ) to establish a military base. [68] [69] Mauritius has repeatedly asserted that the separation of its territories is a violation of United Nations resolutions banning the dismemberment of colonial territories before independence and claims that the Chagos Archipelago, including Diego Garcia, forms an integral part of the territory of Mauritius under both Mauritian law and international law. [70] After initially denying that the islands were inhabited, British officials forcibly expelled to the mainland approximately 2,000 Chagossians who had lived on those islands for a century. Since 1971, only the atoll of Diego Garcia is inhabited, home to some 3,000 UK and US military and civilian contracted personnel. Chagossians have since engaged in activism to return to the archipelago, claiming that their forced expulsion and dispossession were illegal. [71] [72]

MPA ruling
On 20 December 2010, Mauritius initiated proceedings against the United Kingdom (UK) under the United Nations Convention on the Law of the Sea (UNCLOS) to challenge the legality of the Chagos Marine Protected Area (MPA), which the UK purported to declare around the Chagos Archipelago in April 2010. The dispute was arbitrated by the Permanent Court of Arbitration .
After lengthy written pleadings by the Parties and a hearing from 22 April to 9 May 2014 in Istanbul , Turkey, the Arbitral Tribunal ruled unanimously on 18 March 2015 that the ‘marine protected area' which the United Kingdom had declared around the Chagos Archipelago in April 2010 violates international law. It is the first time that UK's conduct with regard to the Chagos Archipelago has been considered and condemned by any international court or tribunal. [73]
The Tribunal held unanimously that, in declaring the ‘MPA', UK violated international law. It ruled that UK breached its obligations under Articles 2(3), 56(2), and 194(4) of UNCLOS. In reaching these conclusions, the Tribunal made several findings. It considered the undertakings given by UK to the Mauritian Ministers at the Lancaster House talks in September 1965. UK argued that those undertakings were not binding and had no status in international law. The Tribunal rejected that argument, holding that those undertakings became a binding international agreement upon the independence of Mauritius, and have bound UK since then. It found that UK's commitments to Mauritius in relation to fishing rights and oil and mineral rights in the Chagos Archipelago are legally binding. The Tribunal also found that UK's undertaking to return the Chagos Archipelago to Mauritius when no longer needed for defence purposes is legally binding. [73]
The Tribunal held that UK had not respected Mauritius' legal rights over the Chagos Archipelago. It considered the events from February 2009 to April 2010, during which time the ‘MPA' proposal came into being and was then imposed on Mauritius. [73]
The Tribunal observed that UK's failure to balance its rights and interests with those of Mauritius is to be contrasted with the approach adopted by UK with respect to the United States. It noted that the record demonstrates a conscious balancing of rights and interests, suggestions of compromise and willingness to offer assurances by UK, and an understanding of the United States' concerns in connection with the proposed ‘MPA'. Those elements were noticeably absent in UK's approach to Mauritius. Accordingly, the Tribunal found that, in declaring the ‘MPA', UK had acted unlawfully and in disregard of Mauritius' rights. [73]
The parties differ on the characterization of the dispute. Mauritius states that its case is that the MPA is unlawful under the Convention. UK argued that the dispute concerns sovereignty over the Chagos Archipelago. Mauritius requested the Tribunal to adjudge and declare that UK is not entitled to declare an "MPA" or other maritime zones because it is not the "coastal State within the meaning of inter alia Articles 2, 55, 56 and 76 of the Convention." [74]
The sovereignty of Mauritius was explicitly recognised by two of the arbitrators and denied by none of the other three. Three members of the Tribunal found that they did not have jurisdiction to rule on that question; they expressed no view as to which of the two States has sovereignty over the Chagos Archipelago. Tribunal Judges Rüdiger Wolfrum and James Kateka held that the Tribunal did have jurisdiction to decide this question, and concluded that UK does not have sovereignty over the Chagos Archipelago. They found that; [73] [75]
The Tribunal's decision determined that UK's undertaking to return the Chagos Archipelago to Mauritius gives Mauritius an interest in significant decisions that bear upon possible future uses of the Archipelago. The result of the Tribunal's decision is that, it is now open to the Parties to enter into the negotiations that the Tribunal would have expected prior to the proclamation of the MPA, with a view to achieving a mutually satisfactory arrangement for protecting the marine environment, to the extent necessary under a "sovereignty umbrella". [73]

Tromelin
Mauritius also claims sovereignty over Tromelin island from France, a small island that lies 430 km north-east of Mauritius. [76] [77]

Environment and climate
The environment in Mauritius is typically tropical in the coastal regions with forests in the mountainous areas. Seasonal cyclones are destructive to its flora and fauna, although they recover quickly. Mauritius ranked second in an air quality index released by the World Health Organization in 2011. [78]
Situated near the Tropic of Capricorn , Mauritius has a tropical climate . There are 2 seasons: a warm humid summer from November to April, with a mean temperature of 24.7 °C (76.5 °F) and a relatively cool dry winter from June to September with a mean temperature of 20.4 °C (68.7 °F). The temperature difference between the seasons is only 4.3 °C (39.7 °F). The warmest months are January and February with average day maximum temperature reaching 29.2 °C (84.6 °F) and the coolest months are July and August with average overnight minimum temperatures of 16.4 °C (61.5 °F). Annual rainfall ranges from 900 mm (35 in) on the coast to 1,500 mm (59 in) on the central plateau. Although there is no marked rainy season, most of the rainfall occurs in summer months. Sea temperature in the lagoon varies from 22–27 °C (72–81 °F) The central plateau is much cooler than the surrounding coastal areas and can experience as much as double the rainfall. The prevailing trade winds keep the east side of the island cooler and bring more rain. There can also be a marked difference in temperature and rainfall from one side of the island to the other. Occasional tropical cyclones generally occur between January to March and tend to disrupt the weather for only about three days, bringing heavy rain. [79]

Biodiversity
The country is home to some of the world's rarest plants and animals, but human habitation and the introduction of non-native species have threatened its indigenous flora and fauna. [71] Due to its volcanic origin, age, isolation, and its unique terrain, Mauritius is home to a diversity of flora and fauna not usually found in such a small area. Before the Portuguese arrival in 1507, there were no terrestrial mammals on the island. This allowed the evolution of a number of flightless birds and large reptile species. The arrival of man saw the introduction of invasive alien species and the rapid destruction of habitat and the loss of much of the endemic flora and fauna. Less than 2% of the native forest now remains, concentrated in the Black River Gorges National Park in the southwest, the Bambous Mountain Range in the southeast, and the Moka-Port Louis Ranges in the northwest. There are some isolated mountains, Corps de Garde , Le Morne Brabant , and several offshore islands with remnants of coastal and mainland diversity. Over 100 species of plants and animals have become extinct and many more are threatened. Conservation activities began in the 1980s with the implementation of programmes for the reproduction of threatened bird and plant species as well as habitat restoration in the national parks and nature reserves. [80]
When it was discovered, Mauritius was the home of a previously unknown species of bird, the dodo , descendants of a type of pigeon which settled in Mauritius over four million years ago. [81] With no predators to attack them, they had lost their ability to fly. Arabs became the first humans to set foot on Mauritius, followed by Portuguese around 1505. The island quickly became a stopover for ships engaged in the spice trade. Weighing up to 50 pounds, the dodo was a welcome source of fresh meat for the sailors. Large numbers of dodos were killed for food. Later, when the Dutch used the island as a penal colony, new species were introduced to the island. Rats , pigs, and monkeys ate dodo eggs in the ground nests. The combination of human exploitation and introduced species significantly reduced the dodo population. Within 100 years of the arrival of humans on Mauritius, the once abundant dodo became a rare bird. The last one was killed in 1681. [82] The dodo is prominently featured as a (heraldic) supporter of the national coat of arms of Mauritius .

Districts
Mauritius is divided into nine districts which consist of different cities, towns and villages .

Demographics
The estimated resident population of the Republic of Mauritius was 1,264,000 as of December 2016. The female population was 637,032 compared to a male population of 624,176. The population on the island of Mauritius is 1,219,265, and that of Rodrigues island is 41,669; Agalega and Saint Brandon had an estimated total population of 274. [83] Mauritius has the highest population density in Africa.

Ethnic groups
Official statistics on ethnicity are not available, as such questions were removed from the population census in 1972. [3] [84] Mauritius is a multiethnic society, drawn from Indian , African , European (mostly French ) and Chinese origin. According to a U.S. Ambassador to Mauritius, Mauritians "remain very conscious of their ethnic/communal identities". [85]

Religion
According to the 2011 census conducted by Statistics Mauritius , Hinduism is the major religion at 51.9%, followed by Christianity (31.4%), Islam (15.3%) and Buddhism (0.4%). Those of other religions accounted for 0.2% of the population, and 0.7% reported themselves as non-religious and 0.1% did not answer. [86] Mauritius is the only country in Africa to have a Hindu majority.
An officially secular state, Mauritius is a religiously diverse nation, with freedom of religion being enshrined as a constitutional right. [87] The culture of the Mauritian people is reflected in the various religious festivities that are celebrated throughout the year, some of which are recognized as public holidays. According to one estimate Mauritians spend an average of more than 700 hours per year engaging in religious activities. [88]

Language
As both an English-speaking and French-speaking nation, Mauritius is a member of both the Commonwealth of Nations and the Francophonie . The Mauritian constitution makes no mention of an official language . In Parliament, the official language is English; however, any member of the National Assembly can also address the chair in French. [8] English and French are generally accepted as the official languages of Mauritius and as the languages of government administration, courts, and business. [9] The constitution of Mauritius is written in English, while some laws, such as the Civil code , are in French.
The Mauritian population is multilingual ; while Mauritian Creole is the mother tongue of most Mauritians, most people are also fluent in English and French, they tend to switch languages according to the situation. [89] French and English are favoured in educational and professional settings while Asian languages are used mainly in music, religious and cultural activities. The media and literature are primarily in French.
The Creole language, derived mainly from French (a French-based Creole ) with influences from the other dialects, is spoken by the majority of the population and is the country's native language. [90] The Creole languages which are spoken in different islands of the country are more or less similar: Mauritian Creole , Rodriguan Creole , Agalega Creole and Chagossian Creole are spoken by people from the islands of Mauritius, Rodrigues , Agalega and Chagos . Bhojpuri which was widely spoken as mother tongue, has been decreasing over the years. According to the 2011 census, there was a decrease in the use of Bhojpuri at home, it was spoken by 5% of the population compared to 12% in 2000. [1]
Some ancestral languages that are also spoken in Mauritius include Bhojpuri , [91] Chinese , [11] Hindi , [12] Marathi , [13] Tamil , [15] Telugu [16] and Urdu . [17] School students must learn English and French; they also have the option to study Asian languages and Creole. The medium of instruction varies from school to school but is usually Creole, French and English.

Health
Mauritius had a life expectancy of 75.17 years in 2014. [92] 39% of Mauritian men smoked in 2014. [93] 12.9% of men and 23% of women were obese in 2008. [93]
Heroin use has a high prevalence rate of 0.91% (2011 UN figure); [94] see also Drugs in Mauritius .

Education
The government of Mauritius provides free education to its citizens from pre-primary to tertiary level. In 2013 government expenditure on education was estimated at about Rs 13,584 million, representing 13% of total expenditure. [95]
The adult literacy rate was estimated at 89.8% in 2011. [96] Male literacy was 92.3% and female literacy 87.3%. [96]
The education system in Mauritius consists of pre-primary, primary, secondary and tertiary sectors. The education structure consists of three years of pre-primary school, six years of primary schooling leading to the Certificate of Primary Education, five years of secondary education leading to the School Certificate, and two years of higher secondary ending with the Higher School Certificate. [97] Secondary schools have "college" as part of their title.
The O-Level and A-Level examinations are carried out by the University of Cambridge through University of Cambridge International Examinations . The Tertiary Education sector includes universities and other technical institutions in Mauritius. The country's two main public universities are the University of Mauritius and the University of Technology . The Tertiary Education Commission's Strategic Plan envisages Mauritius as a regional knowledge hub and a centre for higher learning and excellence. It promotes open and distance learning to increase access to post-secondary education and lifelong learning locally and regionally. [97]

Economy
Since independence in 1968, Mauritius has developed from a low-income, agriculture-based economy to a middle-income diversified economy, based on tourism , textiles, sugar, and financial services. In recent years, information and communication technology, seafood, hospitality and property development, healthcare, renewable energy, and education and training have emerged as important sectors, attracting substantial investment from both local and foreign investors. [98]
Mauritius has no exploitable natural resources and therefore depends on imported petroleum products to meet most of its energy requirements. Local and renewable energy sources are biomass, hydro, solar and wind energy. [99] Mauritius has one of the largest Exclusive Economic Zones in the world, and in 2012 the government announced its intention to develop the marine economy. [100]
Mauritius is ranked high in terms of economic competitiveness, a friendly investment climate, good governance and a free economy. [4] [51] [101] [102] [103] The Gross Domestic Product (PPP) was estimated at US$22.025 billion in 2014, and GDP (PPP) per capita was over US$16,820, one of the highest in Africa. [4] [51] [101] [102] [103]
Mauritius has an upper middle income economy , according to the World Bank in 2011. [104] The World Bank's 2016 Ease of Doing Business Index ranks Mauritius 49th worldwide out of 189 economies in terms of ease of doing business. [103] [105] According to the Mauritian Ministry of Foreign Affairs, the country's challenges are heavy reliance on a few industry sectors, high brain drain, scarcity of skilled labour, ageing population and inefficient public companies and para-statal bodies. [106]
Mauritius has built its success on a free market economy. According to the 2013 Index of Economic Freedom , Mauritius is ranked as having the 8th most free economy in the world, and the highest score in investment freedom. [107] The report's ranking of 183 countries is based on measures of economic openness, regulatory efficiency, rule of law, and competitiveness.

Tourism
Mauritius is a major tourist destination, ranking 3rd in the region and 56th globally. [108] It enjoys a tropical climate with clear warm sea waters, beaches, tropical fauna and flora complemented by a multi-ethnic and cultural population. [109] [ better source needed ]
Mauritius received the World's Leading Island Destination award for the third time and World's Best Beach at the World Travel Awards in January 2012. [110]
Issues often encountered by foreign tourists include scams, overcharging and dual pricing. [111] [112] [113] [114]

Transportation
Since 2005 public bus transport in Mauritius is free of charge for students, people with disabilities and senior citizens. [115] There are currently no railways in Mauritius, former privately owned industrial railways having been abandoned. To cope with increasing road traffic congestion, a Light Rail Transit system has been proposed between Curepipe and Port Louis.
The harbour of Port Louis handles international trade as well as a cruise terminal. The sole international airport for civil aviation is Sir Seewoosagur Ramgoolam International Airport , which also serves as the home operating base for the national airline Air Mauritius ; the airport authority inaugurated a new passenger terminal in September 2013. [116] Another airport is the Sir Gaëtan Duval Airport in Rodrigues .

Culture

Music
The major musical genre of Mauritius is Sega music, other musical genres are its fusion genre , Seggae and Bhojpuri songs.

Cuisine
The cuisine of Mauritius is a combination of Creole, French, Chinese and Indian, with many dishes unique to the island. Spices are also a big part of Mauritian cuisine.

Holidays and festivals
The public holidays of Mauritius involve the blending of several cultures from Mauritius' history. There are Hindu festivals , Chinese festivals , Muslim festivals , as well as Christian festivals .
There are 15 annual public holidays in Mauritius. Seven of these are fixed holidays: 1 and 2 January; 1 February; 12 March; 1 May; 2 November; and 25 December. The remaining public holidays are religious festivals with dates that vary from year to year. However these are public holidays, many other festivals such as Holi , Raksha Bandhan , Père Laval Pilgrimage also exist in Mauritius.

Sports
The most popular sport in Mauritius is football [117] and the national team is the Club M . Other popular sports in Mauritius include cycling, table tennis, badminton, volleyball, basketball, handball, boxing, judo, karate, taekwondo, weightlifting, bodybuilding and athletics. Water sports include swimming, sailing, scuba diving, windsurfing and kitesurfing .
Horseracing , which dates from 1812 when the Champ de Mars Racecourse was inaugurated, remains popular. The country hosted the second (1985) and fifth editions (2003) of the Indian Ocean Island Games . Mauritius won its first Olympic medal at the 2008 Summer Olympics in Beijing when boxer Bruno Julie won the bronze medal.
In golf, the former Mauritius Open and the current AfrAsia Bank Mauritius Open have been part of the European Tour .

See also
WebPage index: 00083
Resource Description Framework
The Resource Description Framework ( RDF ) is a family of World Wide Web Consortium (W3C) specifications [1] originally designed as a metadata data model . It has come to be used as a general method for conceptual description or modeling of information that is implemented in web resources , using a variety of syntax notations and data serialization formats. It is also used in knowledge management applications.
RDF was adopted as a W3C recommendation in 1999. The RDF 1.0 specification was published in 2004, the RDF 1.1 specification in 2014.

Overview
The RDF data model [2] is similar to classical conceptual modeling approaches (such as entity–relationship or class diagrams ). It is based upon the idea of making statements about resources (in particular web resources ) in the form of subject – predicate – object expressions, known as triples . The subject denotes the resource, and the predicate denotes traits or aspects of the resource, and expresses a relationship between the subject and the object .
For example, one way to represent the notion "The sky has the color blue" in RDF is as the triple: a subject denoting "the sky", a predicate denoting "has the color", and an object denoting "blue". Therefore, RDF uses subject instead of object (or entity ) in contrast to the typical approach of an entity–attribute–value model in object-oriented design : entity (sky), attribute (color), and value (blue).
RDF is an abstract model with several serialization formats (i.e. file formats), so the particular encoding for resources or triples varies from format to format.
This mechanism for describing resources is a major component in the W3C's Semantic Web activity: an evolutionary stage of the World Wide Web in which automated software can store, exchange, and use machine-readable information distributed throughout the Web, in turn enabling users to deal with the information with greater efficiency and certainty . RDF's simple data model and ability to model disparate, abstract concepts has also led to its increasing use in knowledge management applications unrelated to Semantic Web activity.
A collection of RDF statements intrinsically represents a labeled, directed multi-graph . This theoretically makes an RDF data model better suited to certain kinds of knowledge representation than other relational or ontological models. However, in practice, RDF data is often persisted in relational database or native representations (also called Triplestores —or Quad stores, if context (i.e. the named graph ) is also persisted for each RDF triple). [3]
As RDFS and OWL demonstrate, one can build additional ontology languages upon RDF.

History
The initial RDF design, intended to "build a vendor-neutral and operating system-independent system of metadata," [4] derived from the W3C's Platform for Internet Content Selection (PICS), an early web content labelling system, [5] but the project was also shaped by ideas from Dublin Core , and from the Meta Content Framework (MCF), [4] which had been developed during 1995–1997 by Ramanathan V. Guha at Apple and Tim Bray at Netscape . [6]
A first public draft of RDF appeared in October 1997, [7] [8] issued by a W3C working group that included representatives from IBM , Microsoft , Netscape , Nokia , Reuters , SoftQuad , and the University of Michigan . [5]
The W3C published a specification of RDF's data model and an XML serialization as a recommendation in February 1999. [9]
Two persistent misunderstandings developed around RDF at this time: firstly, from the MCF influence and the RDF "Resource Description" acronym, the idea that RDF was specifically for use in representing metadata. Secondly that RDF was an XML format, rather than RDF being a data model and only the RDF/XML serialisation being XML-based. RDF saw little take-up in this period, but there was significant work carried out in Bristol , around ILRT at Bristol University and HP Labs , and also in Boston at MIT . RSS 1.0 and FOAF became exemplar applications for RDF in this period.
The recommendation of 1999 was replaced in 2004 by a set of six specifications: "The RDF Primer", [10] "RDF Concepts and Abstract", [11] "RDF/XML Syntax Specification (revised)", [12] "RDF Semantics", [13] "RDF Vocabulary Description Language 1.0", [14] and "The RDF Test Cases". [15]
This series was superseded in 2014 by the following six "RDF 1.1" documents: "RDF 1.1 Primer," [16] "RDF 1.1 Concepts and Abstract Syntax," [17] "RDF 1.1 XML Syntax," [18] "RDF 1.1 Semantics," [19] "RDF Schema 1.1," [20] and "RDF 1.1 Test Cases". [21]

RDF topics

RDF vocabulary
The vocabulary defined by the RDF specification is as follows: [22]

Classes

rdf

rdfs

Properties

rdf
rdf:Statement , rdf:subject , rdf:predicate , rdf:object are used for reification (see below ).

rdfs
This vocabulary is used as a foundation for RDF Schema where it is extended.

Serialization formats
Several common serialization formats are in use, including:
RDF/XML is sometimes misleadingly called simply RDF because it was introduced among the other W3C specifications defining RDF and it was historically the first W3C standard RDF serialization format. However, it is important to distinguish the RDF/XML format from the abstract RDF model itself. Although the RDF/XML format is still in use, other RDF serializations are now preferred by many RDF users, both because they are more human-friendly, [31] and because some RDF graphs are not representable in RDF/XML due to restrictions on the syntax of XML QNames .
With a little effort, virtually any arbitrary XML may also be interpreted as RDF using GRDDL (pronounced 'griddle'), Gleaning Resource Descriptions from Dialects of Languages.
RDF triples may be stored in a type of database called a triplestore .

Resource identification
The subject of an RDF statement is either a uniform resource identifier (URI) or a blank node , both of which denote resources . Resources indicated by blank nodes are called anonymous resources. They are not directly identifiable from the RDF statement. The predicate is a URI which also indicates a resource, representing a relationship. The object is a URI, blank node or a Unicode string literal . As of RDF 1.1 resources are identified by IRI's. IRI is a generalization of URI. [32]
In Semantic Web applications, and in relatively popular applications of RDF like RSS and FOAF (Friend of a Friend), resources tend to be represented by URIs that intentionally denote, and can be used to access, actual data on the World Wide Web. But RDF, in general, is not limited to the description of Internet-based resources. In fact, the URI that names a resource does not have to be dereferenceable at all. For example, a URI that begins with "http:" and is used as the subject of an RDF statement does not necessarily have to represent a resource that is accessible via HTTP , nor does it need to represent a tangible, network-accessible resource — such a URI could represent absolutely anything. However, there is broad agreement that a bare URI (without a # symbol) which returns a 300-level coded response when used in an HTTP GET request should be treated as denoting the internet resource that it succeeds in accessing.
Therefore, producers and consumers of RDF statements must agree on the semantics of resource identifiers. Such agreement is not inherent to RDF itself, although there are some controlled vocabularies in common use, such as Dublin Core Metadata, which is partially mapped to a URI space for use in RDF. The intent of publishing RDF-based ontologies on the Web is often to establish, or circumscribe, the intended meanings of the resource identifiers used to express data in RDF. For example, the URI:
is intended by its owners to refer to the class of all Merlot red wines by vintner (i.e., instances of the above URI each represent the class of all wine produced by a single vintner), a definition which is expressed by the OWL ontology — itself an RDF document — in which it occurs. Without careful analysis of the definition, one might erroneously conclude that an instance of the above URI was something physical, instead of a type of wine.
Note that this is not a 'bare' resource identifier, but is rather a URI reference , containing the '#' character and ending with a fragment identifier .

Statement reification and context
The body of knowledge modeled by a collection of statements may be subjected to reification , in which each statement (that is each triple subject-predicate-object altogether) is assigned a URI and treated as a resource about which additional statements can be made, as in " Jane says that John is the author of document X". Reification is sometimes important in order to deduce a level of confidence or degree of usefulness for each statement.
In a reified RDF database, each original statement, being a resource, itself, most likely has at least three additional statements made about it: one to assert that its subject is some resource, one to assert that its predicate is some resource, and one to assert that its object is some resource or literal. More statements about the original statement may also exist, depending on the application's needs.
Borrowing from concepts available in logic (and as illustrated in graphical notations such as conceptual graphs and topic maps ), some RDF model implementations acknowledge that it is sometimes useful to group statements according to different criteria, called situations , contexts , or scopes , as discussed in articles by RDF specification co-editor Graham Klyne . [33] [34] For example, a statement can be associated with a context, named by a URI, in order to assert an "is true in" relationship. As another example, it is sometimes convenient to group statements by their source, which can be identified by a URI, such as the URI of a particular RDF/XML document. Then, when updates are made to the source, corresponding statements can be changed in the model, as well.
Implementation of scopes does not necessarily require fully reified statements. Some implementations allow a single scope identifier to be associated with a statement that has not been assigned a URI, itself. [35] [36] Likewise named graphs in which a set of triples is named by a URI can represent context without the need to reify the triples. [37]

Query and inference languages
The predominant query language for RDF graphs is SPARQL . SPARQL is an SQL -like language, and a recommendation of the W3C as of January 15, 2008.
An example of a SPARQL query to show country capitals in Africa, using a fictional ontology.
Other non-standard ways to query RDF graphs include:

Validation and description
There are several proposals to validate and describe RDF:

Examples

Example 1: RDF Description of a person named Eric Miller
The following example is taken from the W3C website [41] describing a resource with statements "there is a Person identified by http://www.w3.org/People/EM/contact#me, whose name is Eric Miller, whose email address is e.miller123(at)example (changed for security purposes), and whose title is Dr.
The resource "http://www.w3.org/People/EM/contact#me" is the subject.
The objects are:
The subject is a URI.
The predicates also have URIs. For example, the URI for each predicate:
In addition, the subject has a type (with URI http://www.w3.org/1999/02/22-rdf-syntax-ns#type), which is person (with URI http://www.w3.org/2000/10/swap/pim/contact#Person).
Therefore, the following "subject, predicate, object" RDF triples can be expressed:
In standard N-Triples format, this RDF can be written as:
Equivalently, it can be written in standard Turtle (syntax) format as:
Or, it can be written in RDF/XML format as:

Example 2: The postal abbreviation for New York
Certain concepts in RDF are taken from logic and linguistics , where subject-predicate and subject-predicate-object structures have meanings similar to, yet distinct from, the uses of those terms in RDF. This example demonstrates:
In the English language statement 'New York has the postal abbreviation NY' , 'New York' would be the subject, 'has the postal abbreviation' the predicate and 'NY' the object.
Encoded as an RDF triple, the subject and predicate would have to be resources named by URIs. The object could be a resource or literal element. For example, in the N-Triples form of RDF, the statement might look like:
In this example, "urn:x-states:New%20York" is the URI for a resource that denotes the US state New York , "http://purl.org/dc/terms/alternative" is the URI for a predicate (whose human-readable definition can be found at here [42] ), and "NY" is a literal string. Note that the URIs chosen here are not standard, and don't need to be, as long as their meaning is known to whatever is reading them.

Example 3: A Wikipedia article about Tony Benn
In a like manner, given that "http://en.wikipedia.org/wiki/Tony_Benn" identifies a particular resource (regardless of whether that URI could be traversed as a hyperlink, or whether the resource is actually the Wikipedia article about Tony Benn ), to say that the title of this resource is "Tony Benn" and its publisher is "Wikipedia" would be two assertions that could be expressed as valid RDF statements. In the N-Triples form of RDF, these statements might look like the following:
To an English-speaking person, the same information could be represented simply as:
However, RDF puts the information in a formal way that a machine can understand. The purpose of RDF is to provide an encoding and interpretation mechanism so that resources can be described in a way that particular software can understand it; in other words, so that software can access and use information that it otherwise couldn't use.
Both versions of the statements above are wordy because one requirement for an RDF resource (as a subject or a predicate) is that it be unique. The subject resource must be unique in an attempt to pinpoint the exact resource being described. The predicate needs to be unique in order to reduce the chance that the idea of Title or Publisher will be ambiguous to software working with the description. If the software recognizes http://purl.org/dc/elements/1.1/title (a specific definition for the concept of a title established by the Dublin Core Metadata Initiative), it will also know that this title is different from a land title or an honorary title or just the letters t-i-t-l-e put together.
The following example, written in Turtle, shows how such simple claims can be elaborated on, by combining multiple RDF vocabularies. Here, we note that the primary topic of the Wikipedia page is a "Person" whose name is "Tony Benn":

Applications
Some uses of RDF include research into social networking. It will also help people in business fields understand better their relationships with members of industries that could be of use for product placement. [50] It will also help scientists understand how people are connected to one another.
RDF is being used to have a better understanding of road traffic patterns. This is because the information regarding traffic patterns is on different websites, and RDF is used to integrate information from different sources on the web. Before, the common methodology was using keyword searching, but this method is problematic because it does not consider synonyms. This is why ontologies are useful in this situation. But one of the issues that comes up when trying to efficiently study traffic is that to fully understand traffic, concepts related to people, streets, and roads must be well understood. Since these are human concepts, they require the addition of fuzzy logic . This is because values that are useful when describing roads, like slipperiness, are not precise concepts and cannot be measured. This would imply that the best solution would incorporate both fuzzy logic and ontology. [51]

See also
WebPage index: 00084
Internet access
Internet access is ability of individuals and organisations to connect to the Internet using computer terminals , computers , mobile devices ; and to access services such as email and the World Wide Web . Various technologies, at a wide range of speeds have been used by Internet service providers (ISPs) to provide this service.
Internet access was once rare, but has grown rapidly. In 1995, only .04 percent of the world's population had access, with well over half of those living in the United States, [1] and consumer use was through dial-up . By the first decade of the 21st century, many consumers in developed nations used faster broadband technology, and by 2014, 41 percent of the world's population had access, [2] broadband was almost ubiquitous worldwide, and global average connection speeds exceeded 4 Mbit/s. [3]

History
The Internet developed from the ARPANET , which was funded by the US government to support projects within the government and at universities and research laboratories in the US – but grew over time to include most of the world's large universities and the research arms of many technology companies. [4] [5] [6] Use by a wider audience only came in 1995 when restrictions on the use of the Internet to carry commercial traffic were lifted. [7]
In the early to mid-1980s, most Internet access was from personal computers and workstations directly connected to local area networks or from dial-up connections using modems and analog telephone lines . LANs typically operated at 10 Mbit/s, while modem data-rates grew from 1200 bit/s in the early 1980s, to 56 kbit/s by the late 1990s. Initially, dial-up connections were made from terminals or computers running terminal emulation software to terminal servers on LANs. These dial-up connections did not support end-to-end use of the Internet protocols and only provided terminal to host connections. The introduction of network access servers supporting the Serial Line Internet Protocol (SLIP) and later the point-to-point protocol (PPP) extended the Internet protocols and made the full range of Internet services available to dial-up users; although slower, due to the lower data rates available using dial-up.
Broadband Internet access, often shortened to just broadband, is simply defined as "Internet access that is always on, and faster than the traditional dial-up access" [8] [9] and so covers a wide range of technologies. Broadband connections are typically made using a computer's built in Ethernet networking capabilities, or by using a NIC expansion card .
Most broadband services provide a continuous "always on" connection; there is no dial-in process required, and it does not interfere with voice use of phone lines. [10] Broadband provides improved access to Internet services such as:
In the 1990s, the National Information Infrastructure initiative in the U.S. made broadband Internet access a public policy issue. [11] In 2000, most Internet access to homes was provided using dial-up, while many businesses and schools were using broadband connections. In 2000 there were just under 150 million dial-up subscriptions in the 34 OECD countries [12] and fewer than 20 million broadband subscriptions. By 2004, broadband had grown and dial-up had declined so that the number of subscriptions were roughly equal at 130 million each. In 2010, in the OECD countries, over 90% of the Internet access subscriptions used broadband, broadband had grown to more than 300 million subscriptions, and dial-up subscriptions had declined to fewer than 30 million. [13]
The broadband technologies in widest use are ADSL and cable Internet access. Newer technologies include VDSL and optical fibre extended closer to the subscriber in both telephone and cable plants. Fibre-optic communication , while only recently being used in premises and to the curb schemes, has played a crucial role in enabling broadband Internet access by making transmission of information at very high data rates over longer distances much more cost-effective than copper wire technology.
In areas not served by ADSL or cable, some community organizations and local governments are installing Wi-Fi networks. Wireless and satellite Internet are often used in rural, undeveloped, or other hard to serve areas where wired Internet is not readily available.
Newer technologies being deployed for fixed (stationary) and mobile broadband access include WiMAX , LTE , and fixed wireless , e.g., Motorola Canopy .
Starting in roughly 2006, mobile broadband access is increasingly available at the consumer level using " 3G " and " 4G " technologies such as HSPA , EV-DO , HSPA+ , and LTE .

Availability
In addition to access from home, school, and the workplace Internet access may be available from public places such as libraries and Internet cafes , where computers with Internet connections are available. Some libraries provide stations for physically connecting users' laptops to local area networks (LANs).
Wireless Internet access points are available in public places such as airport halls, in some cases just for brief use while standing. Some access points may also provide coin-operated computers. Various terms are used, such as "public Internet kiosk ", "public access terminal", and "Web payphone ". Many hotels also have public terminals, usually fee based.
Coffee shops, shopping malls, and other venues increasingly offer wireless access to computer networks, referred to as hotspots , for users who bring their own wireless-enabled devices such as a laptop or PDA . These services may be free to all, free to customers only, or fee-based. A Wi-Fi hotspot need not be limited to a confined location since multiple ones combined can cover a whole campus or park, or even an entire city can be enabled.
Additionally, Mobile broadband access allows smart phones and other digital devices to connect to the Internet from any location from which a mobile phone call can be made, subject to the capabilities of that mobile network.

Speed
The bit rates for dial-up modems range from as little as 110 bit/s in the late 1950s, to a maximum of from 33 to 64 kbit/s ( V.90 and V.92 ) in the late 1990s. Dial-up connections generally require the dedicated use of a telephone line. Data compression can boost the effective bit rate for a dial-up modem connection to from 220 ( V.42bis ) to 320 ( V.44 ) kbit/s. [14] However, the effectiveness of data compression is quite variable, depending on the type of data being sent, the condition of the telephone line, and a number of other factors. In reality, the overall data rate rarely exceeds 150 kbit/s. [15]
Broadband technologies supply considerably higher bit rates than dial-up, generally without disrupting regular telephone use. Various minimum data rates and maximum latencies have been used in definitions of broadband, ranging from 64 kbit/s up to 4.0 Mbit/s. [16] In 1988 the CCITT standards body defined "broadband service" as requiring transmission channels capable of supporting bit rates greater than the primary rate which ranged from about 1.5 to 2 Mbit/s. [17] A 2006 Organization for Economic Co-operation and Development (OECD) report defined broadband as having download data transfer rates equal to or faster than 256 kbit/s. [18] And in 2015 the U.S. Federal Communications Commission (FCC) defined "Basic Broadband" as data transmission speeds of at least 25 Mbit/s downstream (from the Internet to the user’s computer ) and 3 Mbit/s upstream (from the user’s computer to the Internet). [19] The trend is to raise the threshold of the broadband definition as higher data rate services become available. [20]
The higher data rate dial-up modems and many broadband services are "asymmetric"—supporting much higher data rates for download (toward the user) than for upload (toward the Internet).
Data rates, including those given in this article, are usually defined and advertised in terms of the maximum or peak download rate. In practice, these maximum data rates are not always reliably available to the customer. [21] Actual end-to-end data rates can be lower due to a number of factors. [22] In late June 2016, internet connection speeds averaged about 6 Mbit/s globally. [23] Physical link quality can vary with distance and for wireless access with terrain, weather, building construction, antenna placement, and interference from other radio sources. Network bottlenecks may exist at points anywhere on the path from the end-user to the remote server or service being used and not just on the first or last link providing Internet access to the end-user.

Network congestion
Users may share access over a common network infrastructure. Since most users do not use their full connection capacity all of the time, this aggregation strategy (known as contended service ) usually works well and users can burst to their full data rate at least for brief periods. However, peer-to-peer (P2P) file sharing and high-quality streaming video can require high data-rates for extended periods, which violates these assumptions and can cause a service to become oversubscribed, resulting in congestion and poor performance. The TCP protocol includes flow-control mechanisms that automatically throttle back on the bandwidth being used during periods of network congestion . This is fair in the sense that all users that experience congestion receive less bandwidth, but it can be frustrating for customers and a major problem for ISPs. In some cases the amount of bandwidth actually available may fall below the threshold required to support a particular service such as video conferencing or streaming live video–effectively making the service unavailable.
When traffic is particularly heavy, an ISP can deliberately throttle back the bandwidth available to classes of users or for particular services. This is known as traffic shaping and careful use can ensure a better quality of service for time critical services even on extremely busy networks. However, overuse can lead to concerns about fairness and network neutrality or even charges of censorship , when some types of traffic are severely or completely blocked.

Outages
An Internet blackout or outage can be caused by local signaling interruptions. Disruptions of submarine communications cables may cause blackouts or slowdowns to large areas, such as in the 2008 submarine cable disruption . Less-developed countries are more vulnerable due to a small number of high-capacity links. Land cables are also vulnerable, as in 2011 when a woman digging for scrap metal severed most connectivity for the nation of Armenia. [24] Internet blackouts affecting almost entire countries can be achieved by governments as a form of Internet censorship , as in the blockage of the Internet in Egypt , whereby approximately 93% [25] of networks were without access in 2011 in an attempt to stop mobilization for anti-government protests . [26]
On April 25, 1997, due to a combination of human error and software bug, an incorrect routing table at MAI Network Service (a Virginia Internet Service Provider ) propagated across backbone routers and caused major disruption to Internet traffic for a few hours. [27]

Technologies
When the Internet is accessed using a modem , digital data is converted to analog for transmission over analog networks such as the telephone and cable networks. [10] A computer or other device accessing the Internet would either be connected directly to a modem that communicates with an Internet service provider (ISP) or the modem's Internet connection would be shared via a Local Area Network (LAN) which provides access in a limited area such as a home, school, computer laboratory, or office building.
Although a connection to a LAN may provide very high data-rates within the LAN, actual Internet access speed is limited by the upstream link to the ISP. LANs may be wired or wireless. Ethernet over twisted pair cabling and Wi-Fi are the two most common technologies used to build LANs today, but ARCNET , Token Ring , Localtalk , FDDI , and other technologies were used in the past.
Ethernet is the name of the IEEE 802.3 standard for physical LAN communication [28] and Wi-Fi is a trade name for a wireless local area network (WLAN) that uses one of the IEEE 802.11 standards. [29] Ethernet cables are interconnected via switches & routers. Wi-Fi networks are built using one or more wireless antenna called access points .
Many "modems" provide the additional functionality to host a LAN so most Internet access today is through a LAN [ citation needed ] , often a very small LAN with just one or two devices attached. And while LANs are an important form of Internet access, this raises the question of how and at what data rate the LAN itself is connected to the rest of the global Internet. The technologies described below are used to make these connections.

Hardwired broadband access
The term broadband includes a broad range of technologies, all of which provide higher data rate access to the Internet. The following technologies use wires or cables in contrast to wireless broadband described later.

Dial-up access
Dial-up Internet access uses a modem and a phone call placed over the public switched telephone network (PSTN) to connect to a pool of modems operated by an ISP. The modem converts a computer's digital signal into an analog signal that travels over a phone line's local loop until it reaches a telephone company's switching facilities or central office (CO) where it is switched to another phone line that connects to another modem at the remote end of the connection. [30]
Operating on a single channel, a dial-up connection monopolizes the phone line and is one of the slowest methods of accessing the Internet. Dial-up is often the only form of Internet access available in rural areas as it requires no new infrastructure beyond the already existing telephone network, to connect to the Internet. Typically, dial-up connections do not exceed a speed of 56 kbit/s , as they are primarily made using modems that operate at a maximum data rate of 56 kbit/s downstream (towards the end user) and 34 or 48 kbit/s upstream (toward the global Internet). [10]

Multilink dial-up
Multilink dial-up provides increased bandwidth by channel bonding multiple dial-up connections and accessing them as a single data channel. [31] It requires two or more modems, phone lines, and dial-up accounts, as well as an ISP that supports multilinking – and of course any line and data charges are also doubled. This inverse multiplexing option was briefly popular with some high-end users before ISDN, DSL and other technologies became available. Diamond and other vendors created special modems to support multilinking. [32]

Integrated Services Digital Network
Integrated Services Digital Network (ISDN) is a switched telephone service capable of transporting voice and digital data, is one of the oldest Internet access methods. ISDN has been used for voice, video conferencing, and broadband data applications. ISDN was very popular in Europe, but less common in North America. Its use peaked in the late 1990s before the availability of DSL and cable modem technologies. [33]
Basic rate ISDN, known as ISDN-BRI, has two 64 kbit/s "bearer" or "B" channels. These channels can be used separately for voice or data calls or bonded together to provide a 128 kbit/s service. Multiple ISDN-BRI lines can be bonded together to provide data rates above 128 kbit/s. Primary rate ISDN, known as ISDN-PRI, has 23 bearer channels (64 kbit/s each) for a combined data rate of 1.5 Mbit/s (US standard). An ISDN E1 (European standard) line has 30 bearer channels and a combined data rate of 1.9 Mbit/s.

Leased lines
Leased lines are dedicated lines used primarily by ISPs, business, and other large enterprises to connect LANs and campus networks to the Internet using the existing infrastructure of the public telephone network or other providers. Delivered using wire, optical fiber , and radio , leased lines are used to provide Internet access directly as well as the building blocks from which several other forms of Internet access are created. [34]
T-carrier technology dates to 1957 and provides data rates that range from 56 and 64 kbit/s ( DS0 ) to 1.5 Mbit/s ( DS1 or T1), to 45 Mbit/s ( DS3 or T3). A T1 line carries 24 voice or data channels (24 DS0s), so customers may use some channels for data and others for voice traffic or use all 24 channels for clear channel data. A DS3 (T3) line carries 28 DS1 (T1) channels. Fractional T1 lines are also available in multiples of a DS0 to provide data rates between 56 and 1,500 kbit/s. T-carrier lines require special termination equipment that may be separate from or integrated into a router or switch and which may be purchased or leased from an ISP. [35] In Japan the equivalent standard is J1/J3. In Europe, a slightly different standard, E-carrier , provides 32 user channels (64 kbit/s) on an E1 (2.0 Mbit/s) and 512 user channels or 16 E1s on an E3 (34.4 Mbit/s).
Synchronous Optical Networking (SONET, in the U.S. and Canada) and Synchronous Digital Hierarchy (SDH, in the rest of the world) are the standard multiplexing protocols used to carry high-data-rate digital bit-streams over optical fiber using lasers or highly coherent light from light-emitting diodes (LEDs). At lower transmission rates data can also be transferred via an electrical interface. The basic unit of framing is an OC-3c (optical) or STS-3c (electrical) which carries 155.520 Mbit/s. Thus an OC-3c will carry three OC-1 (51.84 Mbit/s) payloads each of which has enough capacity to include a full DS3. Higher data rates are delivered in OC-3c multiples of four providing OC-12c (622.080 Mbit/s), OC-48c (2.488 Gbit/s), OC-192c (9.953 Gbit/s), and OC-768c (39.813 Gbit/s). The "c" at the end of the OC labels stands for "concatenated" and indicates a single data stream rather than several multiplexed data streams. [34]
The 1, 10, 40, and 100 gigabit Ethernet ( GbE , 10 GbE , 40/100 GbE ) IEEE standards (802.3) allow digital data to be delivered over copper wiring at distances to 100 m and over optical fiber at distances to 40 km. [36]

Cable Internet access
Cable Internet provides access using a cable modem on hybrid fiber coaxial wiring originally developed to carry television signals. Either fiber-optic or coaxial copper cable may connect a node to a customer's location at a connection known as a cable drop. In a cable modem termination system , all nodes for cable subscribers in a neighborhood connect to a cable company's central office, known as the "head end." The cable company then connects to the Internet using a variety of means – usually fiber optic cable or digital satellite and microwave transmissions. [37] Like DSL, broadband cable provides a continuous connection with an ISP.
Downstream , the direction toward the user, bit rates can be as much as 400 Mbit/s for business connections, and 250 Mbit/s for residential service in some countries. Upstream traffic, originating at the user, ranges from 384 kbit/s to more than 20 Mbit/s. Broadband cable access tends to service fewer business customers because existing television cable networks tend to service residential buildings and commercial buildings do not always include wiring for coaxial cable networks. [38] In addition, because broadband cable subscribers share the same local line, communications may be intercepted by neighboring subscribers. Cable networks regularly provide encryption schemes for data traveling to and from customers, but these schemes may be thwarted. [37]

Digital subscriber line (DSL, ADSL, SDSL, and VDSL)
Digital Subscriber Line (DSL) service provides a connection to the Internet through the telephone network. Unlike dial-up, DSL can operate using a single phone line without preventing normal use of the telephone line for voice phone calls. DSL uses the high frequencies, while the low (audible) frequencies of the line are left free for regular telephone communication. [10] These frequency bands are subsequently separated by filters installed at the customer's premises.
DSL originally stood for "digital subscriber loop". In telecommunications marketing, the term digital subscriber line is widely understood to mean Asymmetric Digital Subscriber Line (ADSL), the most commonly installed variety of DSL. The data throughput of consumer DSL services typically ranges from 256 kbit/s to 20 Mbit/s in the direction to the customer (downstream), depending on DSL technology, line conditions, and service-level implementation. In ADSL, the data throughput in the upstream direction, (i.e. in the direction to the service provider) is lower than that in the downstream direction (i.e. to the customer), hence the designation of asymmetric. [39] With a symmetric digital subscriber line (SDSL), the downstream and upstream data rates are equal. [40]
Very-high-bit-rate digital subscriber line (VDSL or VHDSL, ITU G.993.1) [41] is a digital subscriber line (DSL) standard approved in 2001 that provides data rates up to 52 Mbit/s downstream and 16 Mbit/s upstream over copper wires [42] and up to 85 Mbit/s down- and upstream on coaxial cable. [43] VDSL is capable of supporting applications such as high-definition television, as well as telephone services ( voice over IP ) and general Internet access, over a single physical connection.
VDSL2 (ITU-T G.993.2) is a second-generation version and an enhancement of VDSL. [44] Approved in February 2006, it is able to provide data rates exceeding 100 Mbit/s simultaneously in both the upstream and downstream directions. However, the maximum data rate is achieved at a range of about 300 meters and performance degrades as distance and loop attenuation increases.

DSL Rings
DSL Rings (DSLR) or Bonded DSL Rings is a ring topology that uses DSL technology over existing copper telephone wires to provide data rates of up to 400 Mbit/s. [45]

Fiber to the home
Fiber-to-the-home (FTTH) is one member of the Fiber-to-the-x (FTTx) family that includes Fiber-to-the-building or basement (FTTB), Fiber-to-the-premises (FTTP), Fiber-to-the-desk (FTTD), Fiber-to-the-curb (FTTC), and Fiber-to-the-node (FTTN). [46] These methods all bring data closer to the end user on optical fibers. The differences between the methods have mostly to do with just how close to the end user the delivery on fiber comes. All of these delivery methods are similar to hybrid fiber-coaxial (HFC) systems used to provide cable Internet access .
The use of optical fiber offers much higher data rates over relatively longer distances. Most high-capacity Internet and cable television backbones already use fiber optic technology, with data switched to other technologies (DSL, cable, POTS ) for final delivery to customers. [47]
Australia began rolling out its National Broadband Network across the country using fiber-optic cables to 93 percent of Australian homes, schools, and businesses. [48] The project was abandoned by the subsequent LNP government, in favour of a hybrid FTTN design, which turned out to be more expensive and introduced delays. Similar efforts are underway in Italy, Canada, India, and many other countries (see Fiber to the premises by country ). [49] [50] [51] [52]

Power-line Internet
Power-line Internet , also known as Broadband over power lines (BPL), carries Internet data on a conductor that is also used for electric power transmission . [53] Because of the extensive power line infrastructure already in place, this technology can provide people in rural and low population areas access to the Internet with little cost in terms of new transmission equipment, cables, or wires. Data rates are asymmetric and generally range from 256 kbit/s to 2.7 Mbit/s. [54]
Because these systems use parts of the radio spectrum allocated to other over-the-air communication services, interference between the services is a limiting factor in the introduction of power-line Internet systems. The IEEE P1901 standard specifies that all power-line protocols must detect existing usage and avoid interfering with it. [54]
Power-line Internet has developed faster in Europe than in the U.S. due to a historical difference in power system design philosophies. Data signals cannot pass through the step-down transformers used and so a repeater must be installed on each transformer. [54] In the U.S. a transformer serves a small cluster of from one to a few houses. In Europe, it is more common for a somewhat larger transformer to service larger clusters of from 10 to 100 houses. Thus a typical U.S. city requires an order of magnitude more repeaters than in a comparable European city. [55]

ATM and Frame Relay
Asynchronous Transfer Mode (ATM) and Frame Relay are wide-area networking standards that can be used to provide Internet access directly or as building blocks of other access technologies. For example, many DSL implementations use an ATM layer over the low-level bitstream layer to enable a number of different technologies over the same link. Customer LANs are typically connected to an ATM switch or a Frame Relay node using leased lines at a wide range of data rates. [56] [57]
While still widely used, with the advent of Ethernet over optical fiber, MPLS , VPNs and broadband services such as cable modem and DSL , ATM and Frame Relay no longer play the prominent role they once did.

Wireless broadband access
Wireless broadband is used to provide both fixed and mobile Internet access with the following technologies.

Satellite broadband
Satellite Internet access provides fixed, portable, and mobile Internet access. [58] Data rates range from 2 kbit/s to 1 Gbit/s downstream and from 2 kbit/s to 10 Mbit/s upstream. In the northern hemisphere, satellite antenna dishes require a clear line of sight to the southern sky, due to the equatorial position of all geostationary satellites. In the southern hemisphere, this situation is reversed, and dishes are pointed north. [59] [60] Service can be adversely affected by moisture, rain, and snow (known as rain fade). [59] [60] [61] The system requires a carefully aimed directional antenna. [60]
Satellites in geostationary Earth orbit (GEO) operate in a fixed position 35,786 km (22,236 miles) above the Earth's equator. At the speed of light (about 300,000 km/s or 186,000 miles per second), it takes a quarter of a second for a radio signal to travel from the Earth to the satellite and back. When other switching and routing delays are added and the delays are doubled to allow for a full round-trip transmission, the total delay can be 0.75 to 1.25 seconds. This latency is large when compared to other forms of Internet access with typical latencies that range from 0.015 to 0.2 seconds. Long latencies negatively affect some applications that require real-time response, particularly online games, voice over IP , and remote control devices. [62] [63] TCP tuning and TCP acceleration techniques can mitigate some of these problems. GEO satellites do not cover the Earth's polar regions. [59] HughesNet , Exede , AT&T and Dish Network have GEO systems. [64] [65] [66] [67]
Satellites in low Earth orbit (LEO, below 2000 km or 1243 miles) and medium Earth orbit (MEO, between 2000 and 35,786 km or 1,243 and 22,236 miles) are less common, operate at lower altitudes, and are not fixed in their position above the Earth. Lower altitudes allow lower latencies and make real-time interactive Internet applications more feasible. LEO systems include Globalstar and Iridium . The O3b Satellite Constellation is a proposed MEO system with a latency of 125 ms. COMMStellation™ is a LEO system, scheduled for launch in 2015, that is expected to have a latency of just 7 ms.

Mobile broadband
Mobile broadband is the marketing term for wireless Internet access delivered through mobile phone towers to computers, mobile phones (called "cell phones" in North America and South Africa, and "hand phones" in Asia), and other digital devices using portable modems . Some mobile services allow more than one device to be connected to the Internet using a single cellular connection using a process called tethering . The modem may be built into laptop computers, tablets, mobile phones, and other devices, added to some devices using PC cards , USB modems , and USB sticks or dongles , or separate wireless modems can be used. [68]
New mobile phone technology and infrastructure is introduced periodically and generally involves a change in the fundamental nature of the service, non-backwards-compatible transmission technology, higher peak data rates, new frequency bands, wider channel frequency bandwidth in Hertz becomes available. These transitions are referred to as generations. The first mobile data services became available during the second generation (2G).
The download (to the user) and upload (to the Internet) data rates given above are peak or maximum rates and end users will typically experience lower data rates.
WiMAX was originally developed to deliver fixed wireless service with wireless mobility added in 2005. CDPD, CDMA2000 EV-DO, and MBWA are no longer being actively developed.
In 2011, 90% of the world's population lived in areas with 2G coverage, while 45% lived in areas with 2G and 3G coverage. [69]

WiMAX
Worldwide Interoperability for Microwave Access ( WiMAX ) is a set of interoperable implementations of the IEEE 802.16 family of wireless-network standards certified by the WiMAX Forum . WiMAX enables "the delivery of last mile wireless broadband access as an alternative to cable and DSL". [70] The original IEEE 802.16 standard, now called "Fixed WiMAX", was published in 2001 and provided 30 to 40 megabit-per-second data rates. [71] Mobility support was added in 2005. A 2011 update provides data rates up to 1 Gbit/s for fixed stations. WiMax offers a metropolitan area network with a signal radius of about 50 km (30 miles), far surpassing the 30-metre (100-foot) wireless range of a conventional Wi-Fi local area network (LAN). WiMAX signals also penetrate building walls much more effectively than Wi-Fi.

Wireless ISP
Wireless Internet service providers (WISPs) operate independently of mobile phone operators . WISPs typically employ low-cost IEEE 802.11 Wi-Fi radio systems to link up remote locations over great distances ( Long-range Wi-Fi ), but may use other higher-power radio communications systems as well.
Traditional 802.11a/b/g/n/ac is an unlicensed omnidirectional service designed to span between 100 and 150 m (300 to 500 ft). By focusing the radio signal using a directional antenna (where allowed by regulations), 802.11 can operate reliably over a distance of many km(miles), although the technology's line-of-sight requirements hamper connectivity in areas with hilly or heavily foliated terrain. In addition, compared to hard-wired connectivity, there are security risks (unless robust security protocols are enabled); data rates are usually slower (2 to 50 times slower); and the network can be less stable, due to interference from other wireless devices and networks, weather and line-of-sight problems. [72]
With the increasing popularity of unrelated consumer devices operating on the same 2.4GHz band, many providers have migrated to the 5GHz ISM band . If the service provider holds the necessary spectrum license, it could also reconfigure various brands of off the shelf Wi-Fi hardware to operate on its own band instead of the crowded unlicensed ones. Using higher frequencies carry various advantages:
Proprietary technologies like Motorola Canopy & Expedience can be used by a WISP to offer wireless access to rural and other markets that are hard to reach using Wi-Fi or WiMAX. There are a number of companies that provide this service. [73]

Local Multipoint Distribution Service
Local Multipoint Distribution Service (LMDS) is a broadband wireless access technology that uses microwave signals operating between 26 GHz and 29 GHz. [74] Originally designed for digital television transmission (DTV), it is conceived as a fixed wireless, point-to-multipoint technology for utilization in the last mile. Data rates range from 64 kbit/s to 155 Mbit/s. [75] Distance is typically limited to about 1.5 miles (2.4 km), but links of up to 5 miles (8 km) from the base station are possible in some circumstances. [76]
LMDS has been surpassed in both technological and commercial potential by the LTE and WiMAX standards.

Non-commercial alternatives for using Internet services

Grassroots wireless networking movements
Deploying multiple adjacent Wi-Fi access points is sometimes used to create city-wide wireless networks. [77] It is usually ordered by the local municipality from commercial WISPs.
Grassroots efforts have also led to wireless community networks widely deployed at numerous countries, both developing and developed ones. Rural wireless-ISP installations are typically not commercial in nature and are instead a patchwork of systems built up by hobbyists mounting antennas on radio masts and towers , agricultural storage silos , very tall trees, or whatever other tall objects are available.
Where radio spectrum regulation is not community-friendly, the channels are crowded or when equipment can not be afforded by local residents, free-space optical communication can also be deployed in a similar manner for point to point transmission in air (rather than in fiber optic cable).

Packet radio
Packet radio connects computers or whole networks operated by radio amateurs with the option to access the Internet. Note that as per the regulatory rules outlined in the HAM license, Internet access and e-mail should be strictly related to the activities of hardware amateurs.

Outernet
Outernet Inc is a global broadcast data company. Outernet's goal is to provide free access to content from the web through geostationary and Low Earth Orbit satellites, made available effectively to all parts of the world . The project currently uses datacasting conventional geostationary communications satellites in a satellite constellation network.
This is conceptually similar to Teletext , but with adequate buffering and a delay tolerant return channel, enables rich interactivity.

Sneakernet
The term, a tongue-in-cheek play on net(work) as in Internet or Ethernet , refers to the wearing of sneakers as the transport mechanism for the data.
For those who do not have access to or can not afford broadband at home, downloading large files and disseminating information is done by transmission through workplace or library networks, taken home and shared with neighbors by sneakernet.
There are various decentralized, delay tolerant peer to peer applications which aim to fully automate this using any available interface, including both wireless (Bluetooth, Wi-Fi mesh, P2P or hotspots) and physically connected ones (USB storage, ethernet, etc.).
Sneakernets may also be used in tandem with computer network data transfer to increase data security or overall throughput for big data use cases. Innovation continues in the area to this day, for example AWS has recently announced Snowball, and bulk data processing is also done in a similar fashion by many research institutes and government agencies.

Pricing and spending
Internet access is limited by the relation between pricing and available resources to spend. Regarding the latter, it is estimated that 40% of the world's population has less than US$20 per year available to spend on information and communications technology (ICT). [79] In Mexico, the poorest 30% of the society counts with an estimated US$35 per year (US$3 per month) and in Brazil, the poorest 22% of the population counts with merely US$9 per year to spend on ICT (US$0.75 per month). From Latin America it is known that the borderline between ICT as a necessity good and ICT as a luxury good is roughly around the “magical number” of US$10 per person per month, or US$120 per year. [79] This is the amount of ICT spending people esteem to be a basic necessity. Current Internet access prices exceed the available resources by large in many countries.
Dial-up users pay the costs for making local or long distance phone calls, usually pay a monthly subscription fee, and may be subject to additional per minute or traffic based charges, and connect time limits by their ISP. Though less common today than in the past, some dial-up access is offered for "free" in return for watching banner ads as part of the dial-up service. NetZero , BlueLight , Juno , Freenet (NZ) , and Free-nets are examples of services providing free access. Some Wireless community networks continue the tradition of providing free Internet access.
Fixed broadband Internet access is often sold under an "unlimited" or flat rate pricing model, with price determined by the maximum data rate chosen by the customer, rather than a per minute or traffic based charge. Per minute and traffic based charges and traffic caps are common for mobile broadband Internet access.
Internet services like Facebook , Wikipedia and Google have built special programs to partner with mobile network operators (MNO) to introduce zero-rating the cost for their data volumes as a means to provide their service more broadly into developing markets. [80]
With increased consumer demand for streaming content such as video on demand and peer-to-peer file sharing, demand for bandwidth has increased rapidly and for some ISPs the flat rate pricing model may become unsustainable. However, with fixed costs estimated to represent 80–90% of the cost of providing broadband service, the marginal cost to carry additional traffic is low. Most ISPs do not disclose their costs, but the cost to transmit a gigabyte of data in 2011 was estimated to be about $0.03. [81]
Some ISPs estimate that a small number of their users consume a disproportionate portion of the total bandwidth. In response some ISPs are considering, are experimenting with, or have implemented combinations of traffic based pricing, time of day or "peak" and "off peak" pricing, and bandwidth or traffic caps. Others claim that because the marginal cost of extra bandwidth is very small with 80 to 90 percent of the costs fixed regardless of usage level, that such steps are unnecessary or motivated by concerns other than the cost of delivering bandwidth to the end user. [82] [83] [84]
In Canada, Rogers Hi-Speed Internet and Bell Canada have imposed bandwidth caps . [82] In 2008 Time Warner began experimenting with usage-based pricing in Beaumont, Texas. [85] In 2009 an effort by Time Warner to expand usage-based pricing into the Rochester, New York area met with public resistance, however, and was abandoned. [86] On August 1, 2012 in Nashville, Tennessee and on October 1, 2012 in Tucson, Arizona Comcast began tests that impose data caps on area residents. In Nashville exceeding the 300 Gbyte cap mandates a temporary purchase of 50 Gbytes of additional data. [87]

Digital divide
Despite its tremendous growth, Internet access is not distributed equally within or between countries. [92] [93] The digital divide refers to “the gap between people with effective access to information and communications technology (ICT), and those with very limited or no access”. The gap between people with Internet access and those without is one of many aspects of the digital divide. [94] Whether someone has access to the Internet can depend greatly on financial status, geographical location as well as government policies. “Low-income, rural, and minority populations have received special scrutiny as the technological "have-nots." [95]
Government policies play a tremendous role in bringing Internet access to or limiting access for underserved groups, regions, and countries. For example, in Pakistan, which is pursuing an aggressive IT policy aimed at boosting its drive for economic modernization, the number of Internet users grew from 133,900 (0.1% of the population) in 2000 to 31 million (17.6% of the population) in 2011. [96] In North Korea there is relatively little access to the Internet due to the governments' fear of political instability that might accompany the benefits of access to the global Internet. [97] The U.S. trade embargo is a barrier limiting Internet access in Cuba . [98]
Access to computers is a dominant factor in determining the level of Internet access. In 2011, in developing countries, 25% of households had a computer and 20% had Internet access, while in developed countries the figures were 74% of households had a computer and 71% had Internet access. [69] The majority of people in developing countries do not have Internet access. [1] About 4 billion people do not have Internet access. [2] When buying computers was legalized in Cuba in 2007, the private ownership of computers soared (there were 630,000 computers available on the island in 2008, a 23% increase over 2007). [99] [100]
Internet access has changed the way in which many people think and has become an integral part of peoples economic, political, and social lives. The United Nations has recognized that providing Internet access to more people in the world will allow them to take advantage of the “political, social, economic, educational, and career opportunities” available over the Internet. [93] Several of the 67 principles adopted at the World Summit on the Information Society convened by the United Nations in Geneva in 2003, directly address the digital divide. [101] To promote economic development and a reduction of the digital divide , national broadband plans have been and are being developed to increase the availability of affordable high-speed Internet access throughout the world.

Growth in number of users
Access to the Internet grew from an estimated 10 million people in 1993, to almost 40 million in 1995, to 670 million in 2002, and to 2.7 billion in 2013. [105] With market saturation , growth in the number of Internet users is slowing in industrialized countries, but continues in Asia , [106] Africa , Latin America , the Caribbean , and the Middle East .
There were roughly 0.6 billion fixed broadband subscribers and almost 1.2 billion mobile broadband subscribers in 2011. [107] In developed countries people frequently use both fixed and mobile broadband networks. In developing countries mobile broadband is often the only access method available. [69]

Bandwidth divide
Traditionally the divide has been measured in terms of the existing numbers of subscriptions and digital devices ("have and have-not of subscriptions"). Recent studies have measured the digital divide not in terms of technological devices, but in terms of the existing bandwidth per individual (in kbit/s per capita). [91] [108] As shown in the Figure on the side, the digital divide in kbit/s is not monotonically decreasing, but re-opens up with each new innovation. For example, "the massive diffusion of narrow-band Internet and mobile phones during the late 1990s" increased digital inequality, as well as "the initial introduction of broadband DSL and cable modems during 2003–2004 increased levels of inequality". [108] This is because a new kind of connectivity is never introduced instantaneously and uniformly to society as a whole at once, but diffuses slowly through social networks. As shown by the Figure, during the mid-2000s, communication capacity was more unequally distributed than during the late 1980s, when only fixed-line phones existed. The most recent increase in digital equality stems from the massive diffusion of the latest digital innovations (i.e. fixed and mobile broadband infrastructures, e.g. 3G and fiber optics FTTH ). [109] As shown in the Figure, Internet access in terms of bandwidth is more unequally distributed in 2014 as it was in the mid-1990s.

In the United States
In the United States, billions of dollars have been invested in efforts to narrow the digital divide and bring Internet access to more people in low-income and rural areas of the United States. Internet availability varies widely state by state in the U.S. In 2011 for example, 87.1% of all New Hampshire residents lived in a household where Internet was available, ranking first in the nation. [110] Meanwhile, 61.4% of all Mississippi residents lived in a household where Internet was available, ranking last in the nation. [111] The Obama administration continued this commitment to narrowing the digital divide through the use of stimulus funding . [95] The National Center for Education Statistics reported that 98% of all U.S. classroom computers had Internet access in 2008 with roughly one computer with Internet access available for every three students. The percentage and ratio of students to computers was the same for rural schools (98% and 1 computer for every 2.9 students). [112]

Rural access
One of the great challenges for Internet access in general and for broadband access in particular is to provide service to potential customers in areas of low population density , such as to farmers, ranchers, and small towns. In cities where the population density is high, it is easier for a service provider to recover equipment costs, but each rural customer may require expensive equipment to get connected. While 66% of Americans had an Internet connection in 2010, that figure was only 50% in rural areas, according to the Pew Internet & American Life Project. [113] Virgin Media advertised over 100 towns across the United Kingdom "from Cwmbran to Clydebank " that have access to their 100 Mbit/s service. [21]
Wireless Internet Service Provider (WISPs) are rapidly becoming a popular broadband option for rural areas. [114] The technology's line-of-sight requirements may hamper connectivity in some areas with hilly and heavily foliated terrain. However, the Tegola project, a successful pilot in remote Scotland, demonstrates that wireless can be a viable option. [115]
The Broadband for Rural Nova Scotia initiative is the first program in North America to guarantee access to "100% of civic addresses" in a region. It is based on Motorola Canopy technology. As of November 2011, under 1000 households have reported access problems. Deployment of a new cell network by one Canopy provider ( Eastlink ) was expected to provide the alternative of 3G/4G service, possibly at a special unmetered rate, for areas harder to serve by Canopy. [116]
In New Zealand, a fund has been formed by the government to improve rural broadband, [117] and mobile phone coverage. Current proposals include: (a) extending fibre coverage and upgrading copper to support VDSL, (b) focussing on improving the coverage of cellphone technology, or (c) regional wireless. [118]

Access as a civil or human right
The actions, statements, opinions, and recommendations outlined below have led to the suggestion that Internet access itself is or should become a civil or perhaps a human right. [119] [120]
Several countries have adopted laws requiring the state to work to ensure that Internet access is broadly available and/or preventing the state from unreasonably restricting an individual's access to information and the Internet:
In December 2003, the World Summit on the Information Society (WSIS) was convened under the auspice of the United Nations . After lengthy negotiations between governments, businesses and civil society representatives the WSIS Declaration of Principles was adopted reaffirming the importance of the Information Society to maintaining and strengthening human rights : [101] [127]
The WSIS Declaration of Principles makes specific reference to the importance of the right to freedom of expression in the " Information Society " in stating:
A poll of 27,973 adults in 26 countries, including 14,306 Internet users, [128] conducted for the BBC World Service between 30 November 2009 and 7 February 2010 found that almost four in five Internet users and non-users around the world felt that access to the Internet was a fundamental right. [129] 50% strongly agreed, 29% somewhat agreed, 9% somewhat disagreed, 6% strongly disagreed, and 6% gave no opinion. [130]
The 88 recommendations made by the Special Rapporteur on the promotion and protection of the right to freedom of opinion and expression in a May 2011 report to the Human Rights Council of the United Nations General Assembly include several that bear on the question of the right to Internet access: [131]

Network neutrality
Network neutrality (also net neutrality, Internet neutrality, or net equality) is the principle that Internet service providers and governments should treat all data on the Internet equally, not discriminating or charging differentially by user, content, site, platform, application, type of attached equipment, or mode of communication. [132] [133] [134] [135] Advocates of net neutrality have raised concerns about the ability of broadband providers to use their last mile infrastructure to block Internet applications and content (e.g. websites, services, and protocols), and even to block out competitors. [136] Opponents claim net neutrality regulations would deter investment into improving broadband infrastructure and try to fix something that isn't broken. [137] [138] In April 2017, a recent attempt to compromise net neutrality in the United States is being considered by the newly appointed FCC chairman, Ajit Varadaraj Pai . [139]

Natural disasters and access
Natural disasters disrupt internet access in profound ways. This is important—not only for telecommunication companies who own the networks and the businesses who use them, but for emergency crew and displaced citizens as well. The situation is worsened when hospitals or other buildings necessary to disaster response lose their connection. Knowledge gained from studying past internet disruptions by natural disasters could be put to use in planning or recovery. Additionally, because of both natural and man-made disasters, studies in network resiliency are now being conducted to prevent large-scale outages. [140]
One way natural disasters impact internet connection is by damaging end sub-networks (subnets), making them unreachable. A study on local networks after Hurricane Katrina found that 26% of subnets within the storm coverage were unreachable. [141] At Hurricane Katrina’s peak intensity, almost 35% of networks in Mississippi were without power, while around 14% of Louisiana’s networks were disrupted. [142] Of those unreachable subnets, 73% were disrupted for four weeks or longer and 57% were at “network edges where important emergency organizations such as hospitals and government agencies are mostly located”. [141] Extensive infrastructure damage and inaccessible areas were two explanations for the long delay in returning service. [141] The company Cisco has revealed a Network Emergency Response Vehicle (NERV), a truck that makes portable communications possible for emergency responders despite traditional networks being disrupted. [143]
A second way natural disasters destroy internet connectivity is by severing submarine cables—fiber-optic cables placed on the ocean floor that provide international internet connection. A sequence of undersea earthquakes cut six out of seven international cables connected to that country and caused a tsunami that wiped out one of its cable and landing stations. [144] [145] The impact slowed or disabled internet connection for five days within the Asia-Pacific region as well as between the region and the United States and Europe. [146]
With the rise in popularity of cloud computing , concern has grown over access to cloud-hosted data in the event of a natural disaster. Amazon Web Services (AWS) has been in the news for major network outages in April 2011 and June 2012. [147] [148] AWS, like other major cloud hosting companies, prepares for typical outages and large-scale natural disasters with backup power as well as backup data centers in other locations. AWS divides the globe into five regions and then splits each region into availability zones. A data center in one availability zone should be backed up by a data center in a different availability zone. Theoretically, a natural disaster would not affect more than one availability zone. [149] This theory plays out as long as human error is not added to the mix. The June 2012 major storm only disabled the primary data center, but human error disabled the secondary and tertiary backups, affecting companies such as Netflix, Pinterest, Reddit, and Instagram. [150] [151]

See also
WebPage index: 00085
Geographic data and information
Geographic data and information are defined in the ISO/TC 211 series of standards as data and information having an implicit or explicit association with a location relative to the Earth. [1]
It is also called geospatial data and information , [ citation needed ] georeferenced data and information , [ citation needed ] as well as geodata and geoinformation . [ citation needed ]

See also
WebPage index: 00086
Smartphone
A smartphone is a mobile personal computer with an advanced mobile operating system with features useful for mobile or handheld use. [1] [2] [3] Smartphones, which are typically pocket-sized (as opposed to tablets , which are much larger in measurement), have the ability to place and receive voice/video calls and create and receive text messages , have personal digital assistants (such as Siri , Google Assistant , Alexa , Cortana , or Bixby ), an event calendar, a media player , video games , GPS navigation , digital camera and digital video camera . Smartphones can access the Internet through cellular or Wi-Fi and can run a variety of third-party software components (" apps " from places like Google Play Store or Apple App Store ). They typically have a color display with a graphical user interface that covers more than 76% of the front surface. The display is almost always a touchscreen and sometimes additionally a touch-enabled keyboard like the Priv/Passport BlackBerrys, which enables the user to use a virtual keyboard to type words and numbers and press onscreen icons to activate "app" features.
In 1999, the Japanese firm NTT DoCoMo released the first smartphones to achieve mass adoption within a country. [4] Smartphones became widespread in the late 2000s. Most of those produced from 2012 onward have high-speed mobile broadband 4G LTE , motion sensors , and mobile payment features. In the third quarter of 2012, one billion smartphones were in use worldwide. [5] Global smartphone sales surpassed the sales figures for regular cell phones in early 2013. [6]

History

Early years
Devices that combined telephony and computing were first conceptualized by Nikola Tesla in 1909 and Theodore Paraskevakos in 1971 and patented in 1974, and were offered for sale beginning in 1993. Paraskevakos was the first to introduce the concepts of intelligence, data processing and visual display screens into telephones. In 1971, while he was working with Boeing in Huntsville, Alabama , Paraskevakos demonstrated a transmitter and receiver that provided additional ways to communicate with remote equipment, however it did not yet have general purpose PDA applications in a wireless device typical of smartphones. They were installed at Peoples' Telephone Company in Leesburg, Alabama and were demonstrated to several telephone companies. The original and historic working models are still in the possession of Paraskevakos. [7]

Forerunner
The first mobile phone to incorporate PDA features was a prototype developed by Frank Canova [9] in 1992 while at IBM and demonstrated that year at the COMDEX computer industry trade show. It included PDA features and other visionary mobile applications such as maps, stock reports and news. A refined version was marketed to consumers in 1994 by BellSouth under the name Simon Personal Communicator . The Simon was the first commercially available device that could be properly referred to as a "smartphone", although it was not called that in 1994. [9] [10] [11] In addition to placing and receiving cellular calls, Simon could send and receive faxes and emails and included an address book, calendar, appointment scheduler, calculator, world time clock and notepad, utilizing its touch screen display. [12] The term "smart phone" appeared in print as early as 1995, describing AT&T's PhoneWriter Communicator. [13] [ non-primary source needed ]

PDAs
In the mid-late 1990s, many mobile phone users carried a separate dedicated PDA device, running early versions of operating systems such as Palm OS , BlackBerry OS or Windows CE / Pocket PC . [1] These operating systems would later evolve into mobile operating systems . In March 1996, Hewlett-Packard released the OmniGo 700LX , a modified HP 200LX palmtop PC that supported a Nokia 2110 phone with ROM -based software to support it. It had a 640×200 resolution CGA compatible four-shade gray-scale LCD screen and could be used to place and receive calls, and to create and receive text messages, emails and faxes. It was also 100% DOS 5.0 compatible, allowing it to run thousands of existing software titles, including early versions of Windows .
In August 1996, Nokia released the Nokia 9000 Communicator , a digital cellular phone based on the Nokia 2110 with an integrated PDA based on the PEN/GEOS 3.0 operating system from Geoworks . The two components were attached by a hinge in what became known as a clamshell design , with the display above and a physical QWERTY keyboard below. The PDA provided e-mail; calendar, address book, calculator and notebook applications; text-based Web browsing; and could send and receive faxes. When closed, the device could be used as a digital cellular phone. In June 1999 Qualcomm released the "pdQ Smartphone", a CDMA digital PCS Smartphone with an integrated Palm PDA and Internet connectivity. [14]
Subsequent landmark devices included:
Smartphones before present-day Android-, iOS- and BlackBerry-based phones typically used the Symbian operating system. Originally developed by Psion , it was the world's most widely used smartphone operating system until the last quarter of 2010. [ citation needed ]

Mass adoption
In 1999, the Japanese firm NTT DoCoMo released the first smartphones to achieve mass adoption within a country. These phones ran on i-mode , which provided data transmission speeds up to 9.6 kbit/s. [21] Unlike future generations of wireless services, NTT DoCoMo's i-mode used cHTML , a language which restricted some aspects of traditional HTML in favor of increasing data speed for the devices. Limited functionality, small screens and limited bandwidth allowed for phones to use the slower data speeds available. [22] The rise of i-mode helped NTT DoCoMo accumulate an estimated 40 million subscribers by the end of 2001. It was also ranked first in market capitalization in Japan and second globally. This power would wane in the face of the rise of 3G and new phones with advanced wireless network capabilities. [23] Outside Japan smartphones were still rare until the introduction of the Danger Hiptop in 2002, which saw moderate success in the US as the T-Mobile Sidekick. Later, in the mid-2000s, devices based on Microsoft's Windows Mobile started to gain popularity among business users in the U.S. The BlackBerry later gained mass adoption in the U.S., and American users popularized the term "CrackBerry" in 2006 due to its addictive nature. [24] The company first released its GSM BlackBerry 6210, BlackBerry 6220, and BlackBerry 6230 devices in 2003. [25]

Operating systems
Symbian was the most popular smartphone OS in Europe during the middle to late 2000s. Initially, Nokia's Symbian devices were focused on business, similar to Windows Mobile and BlackBerry devices at the time. From 2006 onwards, Nokia started producing entertainment-focused smartphones, popularized by the Nseries . In Asia, with the exception of Japan, the trend was similar to that of Europe. [ citation needed ] In 2003, Motorola launched the first smartphone to use Linux , the A760 handset. [26] While the initial release was limited to a single high-end handset only available in the Asia-Pacific region, the maker's intention was to eventually use Linux on most of its handsets, including the lower-end models. Further models to use Linux such as the Motorola Ming A1200i in 2005 and several successors to the Ming line would be unveiled through 2010. In late 2009, Motorola released the Motorola Cliq , [27] the first of Motorola's smartphones to run the Linux-based Android operating system.
In early 2007, Apple Inc. introduced the iPhone , one of the first smartphones to use a multi-touch interface. The iPhone was notable for its use of a large touchscreen for direct finger input as its main means of interaction, instead of a stylus, keyboard, or keypad typical for smartphones at the time. [28] In October 2008, the first phone to use Android called the HTC Dream (also known as the T-Mobile G1) was released. [29] [30] Android is an open-source platform founded by Andy Rubin and now owned by Google . [31] [32] Although Android's adoption was relatively slow at first, it started to gain widespread popularity in 2010, and in early 2012 dominated the smartphone market share worldwide, which continues to this day. [33]
These new platforms led to the decline of earlier ones. Microsoft , for instance, started a new OS from scratch, called Windows Phone . Nokia abandoned Symbian and partnered with Microsoft to use Windows Phone on its smartphones. Windows Phone then became the third-most-popular OS. Palm's webOS was bought by Hewlett-Packard and later sold to LG Electronics for use on LG smart TVs . BlackBerry Limited , formerly known as Research In Motion, also made a new platform based on QNX , BlackBerry 10 , which was later discontinued. The capacitive touchscreen also changed smartphone form factors . Before 2007, it was common for devices to have a physical numeric keypad or physical QWERTY keyboard in either a candybar or sliding form factor. However, by mid 2010s, almost all smartphones were touchscreen phones.

Technological developments in the 2010s
In 2013, Fairphone launched its first "socially ethical" smartphone at the London Design Festival to address concerns regarding the sourcing of materials in the manufacturing. [34] In late 2013, QSAlpha commenced production of a smartphone designed entirely around security, encryption and identity protection. [35] Some companies began to release smartphones incorporating flexible displays to create curved form factors, such as the Samsung Galaxy Round and LG G Flex . [36] [37] [38]
In October 2013, Motorola Mobility announced Project Ara , a concept for a modular smartphone platform that would allow users to customize and upgrade their phones with add-on modules that attached magnetically to a frame. [39] [40] Ara was retained by Google following its sale of Motorola Mobility to Lenovo , [41] but was shelved in 2016. [42] That year, LG and Motorola both unveiled smartphones featuring a limited form of modularity for accessories; the LG G5 allowed accessories to be installed via the removal of its battery compartment, [43] while the Moto Z utilizes accessories attached magnetically to the rear of the device. [44]
By 2014, 1440p displays began to appear on high-end smartphones. [45] In 2015, Sony released the Xperia Z5 Premium , featuring a 4K resolution display, although only images and videos could actually be rendered at that resolution (all other software is upscaled from 1080p). [46] Microsoft, expanding upon the concept of Motorola's short-lived "Webtop", unveiled functionality for its Windows 10 operating system for phones that allows supported devices to be docked for use with a PC-styled desktop environment . [47] [48] Other major technologies began to trend in 2016, including a focus on virtual reality and augmented reality experiences catered towards smartphones, the newly introduced USB-C connector, and improving LTE technologies. [49] As of 2015, the global median for smartphone ownership was 43%. [50] Statista has forecast that 2.87 billion people will own smartphones in 2020. [51]

Future possible developments
Foldable OLED smartphones have been anticipated for years but have failed to materialize because of the relatively high failure rate when producing these screens. [ citation needed ] As well, creating a battery that can be folded is another hurdle. [52]

Hardware

Display
One of the main characteristics of smartphones is their screen . It usually fills most of the phone's front surface (about 70%); screen size usually defines the size of a smartphone. Many have an aspect ratio of 16:9 ; some are 4:3 or other ratios. They are measured in diagonal inches , starting from 2.45 inches. [53] Phones with screens larger than 5.2 inches are often called " phablets ". Smartphones with screens over 4.5 inches commonly are shifted while using a single hand, since most thumbs cannot reach the entire screen surface, or used in place with both hands. Liquid-crystal displays are the most common; others are IPS , LED , OLED , AMOLED and E Ink displays. In the 2010s, Braille screens, which can be used by visually impaired people are being developed. It is expected that Braille screens will use some type of microfluidics technology. [54] In addition, some displays are integrated with pressure sensitive digitizers such as those developed by Wacom and Samsung . These digitizers allow users to have greater precision when utilizing touch-screens for drawing or for jotting down notes. [55]

Accessories
As with cellphones , a range of accessories are sold for smartphones, including cases, screen protectors, power charging cables, add-on batteries, headphones, combined headphone-microphones which allow a person to use the phone without holding it to the ear, and Bluetooth -enabled powered speakers that enable users to listen to media files from their smartphones wirelessly. Cases range from relatively inexpensive rubber or soft plastic cases which provide moderate protection from bumps and good protection from scratches to more expensive, heavy-duty cases that combine a rubber padding with a hard outer shell. Some cases have a "book"-like form, with a cover that the user opens to use the device; when the cover is closed, it protects the screen. Some "book"-like cases have additional pockets for credit cards, thus enabling people to use them as wallets . Accessories include products sold by the manufacturer of the smartphone and compatible products made by other manufacturers.

Software

Mobile operating systems

Android
Android is a mobile operating system developed by Google , and backed by an industry consortium known as the Open Handset Alliance . It is an open source platform with optional proprietary components, including a suite of flagship software for Google services , and the application and content storefront Google Play . [56] Android was officially introduced via the release of its inaugural device, the HTC Dream (T-Mobile G1) on 20 October 2008. [57] As an open source product, Android has also been the subject of third-party development. Development groups have used the Android source code to develop and distribute their own modified versions of the operating system, such as CyanogenMod , to add features to the OS and provide newer versions of Android to devices that no longer receive official updates from their vendor. [58] [59] [60] Forked versions of Android have also been adopted by other vendors, such as Amazon.com , who used its " Fire OS " on a range of tablets and the Fire Phone . [61] [62] As it is a non-proprietary platform that has shipped on devices covering a wide range of market segments, Android has seen significant adoption. Gartner Research estimated that 325 million Android smartphones were sold during the fourth quarter of 2015, leading all other platforms. Samsung Electronics , who produces Android devices, was also the top smartphone vendor across all platforms in the same period of time. [63] Android is the top-selling smartphone OS in 2016. [64] [65]

iOS
iOS (formerly iPhone OS ) is a proprietary mobile operating system developed by Apple Inc. primarily for its iPhone product line. The iPhone was first unveiled in January 2007. The device introduced numerous design concepts that have been adopted by modern smartphone platforms, such as the use of multi-touch gestures for navigation, eschewing physical controls such as physical keyboard in favor of those rendered by the operating system itself on its touchscreen (including the keyboard), and the use of skeumorphism —making features and controls within the user interface resemble real-world objects and concepts in order to improve their usability. [66] [67] In 2008, Apple introduced the App Store , a centralized storefront for purchasing new software for iPhone devices. [68] [69] iOS can also integrate with Apple's desktop music program iTunes to sync media to a personal computer. [70] [71] The dependency on a PC was removed with the introduction of iCloud on later versions of iOS, which provides synchronization of user data via internet servers between multiple devices. [72] The iPhone line's early dominance was credited with reshaping the smartphone industry, and helping make Apple one of the world's most valuable publicly traded companies by 2011. However, the iPhone and iOS have generally been in second place in worldwide market share. [63] [73] [74]

Windows 10 Mobile
Windows 10 Mobile (formerly known as Windows Phone ) is from Microsoft . It is closed source and proprietary. It has the third largest installed base on smartphones behind Android and iOS.
Unveiled on February 15, 2010, Windows Phone includes a user interface inspired by Microsoft's Metro Design Language . It is integrated with Microsoft services such as OneDrive and Office , Xbox Music , Xbox Video , Xbox Live games and Bing , but also integrates with many other non-Microsoft services such as Facebook and Google accounts . Windows Phone devices are made primarily by Microsoft Mobile / Nokia , and also by HTC and Samsung .
In January 2015, Microsoft announced that its Windows Phone brand will be phased out and replaced with Windows 10 Mobile, bringing tighter integration and unification with its PC counterpart Windows 10 , and provide a platform for smartphones and tablets with screen sizes under 8 inches.
Windows Mobile smartphone series has had poor adoption, that also led to a decrease in third-party applications, and some vendors ended their support for Windows Mobile altogether. [75] [76] As of 2016, Windows 10 Mobile global market share dropped below 0.6%. [77]

Tizen
Tizen is a Linux-based operating system for devices, including smartphones, tablets , in-vehicle infotainment (IVI) devices, smart TVs, laptops and smart cameras. Tizen is a project within the Linux Foundation and is governed by a Technical Steering Group (TSG) composed of Samsung and Intel among others. In April 2014, Samsung released the Samsung Gear 2 and the Gear 2 Neo, running Tizen. [78] The Samsung Z1 is the first smartphone produced by Samsung that runs Tizen; it was released in the Indian market on January 14, 2015. [79]

Sailfish OS
The Sailfish OS is based on the Linux kernel and Mer . [80] Additionally Sailfish OS includes a partially or completely proprietary multi-tasking user interface programmed by Jolla . This user interface differentiate Jolla smartphones from others. [81] Sailfish OS is intended to be a system made by many of the MeeGo team, which left Nokia to form Jolla, utilizing funding from Nokia's "Bridge" program which helps establish and support start-up companies formed by ex-Nokia employees. [82] [83] [84]

Discontinued operating systems

BlackBerry 10
In early 2010s, BlackBerry Limited started making new devices on a new platform named " BlackBerry 10 ", which is based on their BlackBerry Tablet OS , to replace the BlackBerry OS . [85] While the company has started to release smartphone based on the Android operating system in 2015, with the BlackBerry Priv , [86] they claim there would be no new devices with BB10 and they would still support the OS. [87]

BlackBerry OS
In 1999, RIM released its first BlackBerry devices, providing secure real-time push-email communications on wireless devices. Services such as BlackBerry Messenger provide the integration of all communications into a single inbox. In September 2012, RIM announced that the 200 millionth BlackBerry smartphone was shipped. As of September 2014, there were around 46 million active BlackBerry service subscribers. [88] In early 2010s, RIM has undergone a platform transition, changing its company name to BlackBerry Limited and making new devices on a new platform named " BlackBerry 10 ". [85]

Windows Mobile
Windows Mobile was based on the Windows CE kernel and first appeared as the Pocket PC 2000 operating system. Throughout its lifespan, the operating system was available in both touchscreen and non-touchscreen formats. It was supplied with a suite of applications developed with the Microsoft Windows API and was designed to have features and appearance somewhat similar to desktop versions of Windows. Third parties could develop software for Windows Mobile with no restrictions imposed by Microsoft. Software applications were eventually purchasable from Windows Marketplace for Mobile during the service's brief lifespan. Windows Mobile was eventually phased out in favor of Windows Phone OS.

Symbian
Symbian was originally developed by Psion as EPOC32 . It was the world's most widely used smartphone operating system until Q4 2010, though the platform never gained popularity in the U.S., as it did in Europe and Asia. The first Symbian phone, the touchscreen Ericsson R380 Smartphone, was released in 2000, [89] [90] and was the first device marketed as a "smartphone". [91] It combined a PDA with a mobile phone. [92] Variants of Symbian OS began to emerge, most notably Symbian UIQ, MOAP and S60, each supported by different manufacturers. With the creation of Symbian Foundation in 2008, Symbian OS was unified under one variant under the stewardship of Nokia. In February 2011, Nokia announced that it would replace Symbian with Windows Phone as the operating system on all of its future smartphones, with the platform being abandoned over the following few years. [93]

Firefox OS
Firefox OS was demonstrated by Mozilla in February 2012. It was designed to have a complete community-based alternative system for mobile devices, using open standards and HTML5 applications. The first commercially available Firefox OS phones were ZTE Open and Alcatel One Touch Fire. As of 2014, more companies had partnered with Mozilla including Panasonic (which was making a smart TV with Firefox OS) and Sony. [94] In December 2015, Mozilla announced that it would phase out development of Firefox OS for smartphones, and would reposition the project to focus on other forms of Internet-connected devices. [95]

Bada
The Bada operating system for smartphones was announced by Samsung in November 2009. [96] [97] The first Bada-based phone was the Samsung Wave S8500 , released in June 2010. [98] [99] Samsung shipped 4.5 million phones running Bada in Q2 of 2011. [100] In 2013, Bada merged with a similar platform called Tizen.

webOS
webOS is a proprietary mobile operating system running on the Linux kernel, initially developed by Palm, which launched with the Palm Pre . After being acquired by HP, two phones (the Veer and the Pre 3 ) and a tablet (the TouchPad ) running webOS were introduced in 2011. On August 18, 2011, HP announced that webOS hardware was to be discontinued [101] but would continue to support and update webOS software and develop the webOS ecosystem. [102] HP released webOS as open source under the name Open webOS, and plans to update it with additional features. [103] On February 25, 2013 HP announced the sale of WebOS to LG Electronics, who used the operating system for its current "smart" or Internet-connected TVs, but not smartphones. In January 2014, Qualcomm has announced that it has acquired technology patents from HP, which includes all the WebOS patents. [104]

Palm OS
In late 2001, Handspring launched the Springboard GSM phone module with limited success. In May 2002, Handspring released the Palm OS Treo 270 smartphone, which did not support Springboard, with both a touchscreen and a full keyboard. The Treo had wireless web browsing, email, calendar, a contact organizer and mobile third-party applications that could be downloaded or synced with a computer. [105] Handspring was purchased by Palm, Inc which released the Treo 600 and continued releasing Treo devices with a few Treo devices using Windows Mobile.

MeeGo/Maemo/Moblin
MeeGo is an operating system created from the source code of Moblin (produced by Intel) and Maemo (produced by Nokia). Before that, Nokia used Maemo on some of its smartphones and internet tablets (such as Nokia N810 and N900). MeeGo was originally envisioned to power a variety of devices from netbooks, tablets to smartphones and smart TVs. However, the only smartphones which used MeeGo was the Nokia N9 and Nokia N950 (MeeGo v1.2 Harmattan). Following Nokia's decision to move to Windows Phone OS in 2011 and to cease MeeGo development, the Linux Foundation canceled MeeGo in September 2011 in favor of the development of Tizen.

Ubuntu Touch
Ubuntu Touch (also known as Ubuntu Phone ) is a mobile version of the Ubuntu operating system developed by Canonical UK Ltd and Ubuntu Community. [106] It is designed primarily for touchscreen mobile devices such as smartphones and tablet computers.

Mobile app

Application stores
The introduction of Apple's App Store for the iPhone and iPod Touch in July 2008 popularized manufacturer-hosted online distribution for third-party applications ( software and computer programs ) focused on a single platform. There are a huge variety of apps, including video games , music products and business tools. Up until that point, smartphone application distribution depended on third-party sources providing applications for multiple platforms, such as GetJar , Handango , Handmark , and PocketGear . Following the success of the App Store, other smartphone manufacturers launched application stores, such as Google's Android Market (now Google Play Store ) and RIM's BlackBerry App World in April 2009. In February 2014, 93% of mobile developers were targeting smartphones first for mobile app development. [107]

Sales
Since 1996, smartphone shipments have had positive growth. In November 2011, 27% of all photographs created were taken with camera-equipped smartphones. [108] In September 2012, a study concluded that 4 out of 5 smartphone owners use the device to shop online. [109] Global smartphone sales surpassed the sales figures for feature phones in early 2013. [6] Worldwide shipments of smartphones topped 1 billion units in 2013, up 38% from 2012's 725 million, while comprising a 55% share of the mobile phone market in 2013, up from 42% in 2012. [110] In Q1 2016 for the first time the shipments dropped by 3 percent year on year . The situation was caused by the maturing China market. [111]

By manufacturer
In 2011, Samsung had the highest shipment market share worldwide, followed by Apple. In 2013, Samsung had 31.3% market share, a slight increase from 30.3% in 2012, while Apple was at 15.3%, a decrease from 18.7% in 2012. Huawei, LG and Lenovo were at about 5% each, significantly better than 2012 figures, while others had about 40%, the same as the previous years figure. Only Apple lost market share, although their shipment volume still increased by 12.9 percent; the rest had significant increases in shipment volumes of 36 to 92 percent. [114] In Q1 2014, Samsung had a 31% share and Apple had 16%. [115] In Q4 2014, Apple had a 20.4% share and Samsung had 19.9%. [116] In Q2 2016, Samsung had a 22.3% share and Apple had 12.9%. [112]

By operating system
The market has been dominated by the Android operating system since 2010. Android's market share (measured by units shipment) rose from 33.2% in Q4 2011 to 81.7% of the market in Q4 2016. Apple's market share oscillated between 18% and 12.5% during the same period. Windows Phone market share also oscillated between 1.5% and 0.3% during the same time frame. As of the end of Q4 2016, Android was the most popular operating system sold with new smartphones with an 81.7% market share, followed by iOS with 17.9%, Windows 10 Mobile with 0.3% and other OSes at 0.1%. [117]

Historical sales figures, in millions

Use

Social
A 2012 University of Southern California study found that unprotected adolescent sexual activity was more common among owners of smartphones. [124] A study conducted by the Rensselaer Polytechnic Institute 's (RPI) Lighting Research Center (LRC) concluded that smartphones, or any backlit devices, can seriously affect sleep cycles . [125] Some persons might become psychologically attached to cellphones resulting in anxiety when separated from the devices. [126] A " smombie " (a combination of "smartphone" and " zombie ") is a walking person using a smartphone and not paying attention as they walk, possibly risking an accident in the process, an increasing social phenomenon. [127] The issue of slow-moving smartphone users led to the temporary creation of a "mobile lane" for walking in Chongqing , China . [128] The issue of distracted smartphone users led the city of Augsburg, Germany to embed pedestrian traffic lights in the pavement. [129]

While driving
Mobile phone use while driving, including talking on the phone, texting, using mapping apps or operating other phone features, is common but controversial. It is widely considered dangerous due to distracted driving . Being distracted while operating a motor vehicle has been shown to increase the risk of accidents. In September 2010, the US National Highway Traffic Safety Administration (NHTSA) reported that 995 people were killed by drivers distracted by cell phones . In March 2011 a US insurance company, State Farm Insurance , announced the results of a study which showed 19% of drivers surveyed accessed the Internet on a smartphone while driving. [130] Many jurisdictions prohibit the use of mobile phones while driving. In Egypt, Israel, Japan, Portugal and Singapore, both handheld and hands-free use of a mobile phone (which uses a speakerphone ) is banned. In other countries including the UK and France and in many U.S. states , only handheld phone use is banned, while hands-free use is permitted.
A 2011 study reported that over 90% of college students surveyed text (initiate, reply or read) while driving. [131] The scientific literature on the danger of driving while sending a text message from a mobile phone, or texting while driving , is limited. A simulation study at the University of Utah found a sixfold increase in distraction-related accidents when texting. [132] Due to the increasing complexity of smartphones, this has introduced additional difficulties for law enforcement officials when attempting to distinguish one usage from another in drivers using their devices. This is more apparent in countries which ban both handheld and hands-free usage, rather than those which ban handheld use only, as officials cannot easily tell which function of the mobile phone is being used simply by looking at the driver. This can lead to drivers being stopped for using their device illegally for a phone call when, in fact, they were using the device legally, for example, when using the phone's incorporated controls for car stereo, GPS or satnav .
A 2010 study reviewed the incidence of mobile phone use while cycling and its effects on behavior and safety. [133] In 2013 a national survey in the US reported the number of drivers who reported using their cellphones to access the Internet while driving had risen to nearly one of four. [134] A study conducted by the University of Illinois examined approaches for reducing inappropriate and problematic use of mobile phones, such as using mobile phones while driving. [135]
Accidents involving a driver being distracted by talking on a mobile phone have begun to be prosecuted as negligence similar to speeding. In the United Kingdom , from 27 February 2007, motorists who are caught using a hand-held mobile phone while driving will have three penalty points added to their license in addition to the fine of £ 60. [136] This increase was introduced to try to stem the increase in drivers ignoring the law. [137] Japan prohibits all mobile phone use while driving, including use of hands-free devices. New Zealand has banned hand held cellphone use since 1 November 2009. Many states in the United States have banned texting on cell phones while driving. Illinois became the 17th American state to enforce this law. [138] As of July 2010, 30 states had banned texting while driving, with Kentucky becoming the most recent addition on July 15. [139]
Public Health Law Research maintains a list of distracted driving laws in the United States. This database of laws provides a comprehensive view of the provisions of laws that restrict the use of mobile communication devices while driving for all 50 states and the District of Columbia between 1992, when first law was passed through December 1, 2010. The dataset contains information on 22 dichotomous, continuous or categorical variables including, for example, activities regulated (e.g., texting versus talking, hands-free versus handheld), targeted populations, and exemptions. [140]

Legal
A "patent war" between Samsung and Apple started when the latter claimed that the original Galaxy S Android phone copied the interface‍—‌and possibly the hardware‍—‌of Apple's iOS for the iPhone 3GS . There was also smartphone patents licensing and litigation involving Sony Mobile , Google , Apple Inc. , Samsung , Microsoft , Nokia , Motorola , HTC , Huawei and ZTE , among others. The conflict is part of the wider "patent wars" between multinational technology and software corporations. To secure and increase market share , companies granted a patent can sue to prevent competitors from using the methods the patent covers. Since 2010 the number of lawsuits, counter-suits, and trade complaints based on patents and designs in the market for smartphones, and devices based on smartphone OSes such as Android and iOS , has increased significantly. Initial suits, countersuits, rulings, license agreements, and other major events began in 2009 as the smartphone market grew more rapidly.

Medical
With the rise in number of mobile medical apps in the market place, government regulatory agencies raised concerns on the safety of the use of such applications. These concerns were transformed into regulation initiatives worldwide with the aim of safeguarding users from untrusted medical advice. [141]

Security
Smartphone malware is easily distributed through an insecure app store . [142] [143] Often malware is hidden in pirated versions of legitimate apps, which are then distributed through third-party app stores. [144] [145] Malware risk also comes from what's known as an "update attack", where a legitimate application is later changed to include a malware component, which users then install when they are notified that the app has been updated. [146] As well, one out of three robberies in 2012 in the United States involved the theft of a mobile phone. An online petition has urged smartphone makers to install kill switches in their devices. [147] In 2014, Apple's "Find my iPhone" and Google's "Android Device Manager" can disable phones that have been lost/stolen. With BlackBerry Protect in OS version 10.3.2, devices can be rendered unrecoverable to even BlackBerry's own Operating System recovery tools if incorrectly authenticated or dissociated from their account. [148]

Sleep
Using smartphones late at night can disturb sleep, due to the brightly lit screen affecting melatonin levels and sleep cycles . In an effort to alleviate these issues, several apps that change the color temperature of a screen to a warmer hue based on the time of day to reduce the amount of blue light generated have been developed for Android, while iOS 9.3 integrated similar, system-level functionality known as "Night Shift". Amazon released a feature known as "blue shade" in their Fire OS "Bellini" 5.0 and later. It has also been theorized that for some users, addicted use of their phones, especially before they go to bed, can result in " ego depletion ". Many people also use their phones as alarm clocks, which can also lead to loss of sleep. [149] [150] [151] [152] [153]

Comparison with feature phones
Smartphones have presented issues similar to those affecting other mobile phones. As well, there are some issues which are unique to smartphones.

Battery
Compared to earlier non-smartphone mobile phones, smartphone battery life has generally been poor, due to the significant power requirements of their computer systems and color screens. Poor smartphone battery life has negatively affected customer satisfaction. [154] [155] [156] There is also a trend towards using batteries that the user cannot replace. [157] Smartphone users have addressed the challenge of limited battery life by purchasing additional chargers for use outside the home, at work, and in cars and by buying portable external "battery packs". External battery packs include generic models which are connected to the smartphone with a cable and custom-made models that "piggyback" onto a smartphone's case. Most recently, Samsung had to recall millions of the Galaxy Note 7 smartphones due to a battery issue. [158]

Terminology
" Phablet ", a portmanteau of the words phone and tablet , describes smartphones with larger screens. [159] [160]
"Superphone" is also used by some companies to market phones with unusually large screens and other expensive features. [161] [162]
"Ultra Premium" is a term used to identify a smartphone which has top of the line materials. [163]

See also
WebPage index: 00087
Słubice
Słubice [swuˈbʲit͡sɛ] ( German Dammvorstadt ) is a border town in the Lubusz Voivodeship of western Poland . Located on the Oder river, directly opposite the city of Frankfurt (Oder) in Germany , of which it was a part until 1945 (as Dammvorstadt ). At the 2011 census, the town had a total population of 18,000 (urban agglomeration Słubice-Frankfurt 85,000). Previously located in the Gorzów Wielkopolski Voivodeship (1975–1998), the town is currently the capital of Słubice County and the administrative seat of the Gmina Słubice .

Town
The name is a modern Polish restored version of Zliwitz , a West Slavic settlement east of the Brandendamm causeway across the Oder, mentioned in Frankfurt's city charter of 1253. [1] The Ascanian margraves of Brandenburg had purchased the surrounding Lubusz Land from the Silesian Duke Bolesław II the Bald in 1248.
Słubice is closely linked to its German sister city Frankfurt (Oder) , of which it was a part until 1945. The two cities share many urban amenities and collaborate on various projects, such as a wastewater treatment plant in Słubice that serves both towns, as well as the Collegium Polonicum extension of some of the Viadrina European University's departments on the Polish side of the border. Furthermore, Słubice is part of a special Słubice-Kostrzyn Economic Zone .
Słubice was the setting for the 2003 film Distant Lights ( Lichter ) as well as for scenes in the 2002 film Grill Point .
On October 22, 2014, a monument to Wikipedia was unveiled in the town. [2]

Districts

Gallery

International relations

Twin towns — Sister cities
Słubice is twinned with:
WebPage index: 00088
World Intellectual Property Organization
The World Intellectual Property Organization ( WIPO ) is one of the 17 specialized agencies of the United Nations .
WIPO was created in 1967 "to encourage creative activity, to promote the protection of intellectual property throughout the world". [1]
WIPO currently has 189 member states, [2] administers 26 international treaties , [3] and is headquartered in Geneva , Switzerland . The current Director-General of WIPO is Francis Gurry , who took office on October 1, 2008. [4] 186 of the UN Members as well as the Cook Islands , Holy See and Niue are Members of WIPO. Non-members are the states of Marshall Islands , Federated States of Micronesia , Nauru , Palau , Solomon Islands , South Sudan and East Timor . The Palestinians have observer status. [5]

History
The predecessor to WIPO was the United International Bureaux for the Protection of Intellectual Property ( Bureaux Internationaux Réunis pour la Protection de la Propriété Intellectuelle , with the French acronym for "BIRPI"), which had been established in 1893 to administer the Berne Convention for the Protection of Literary and Artistic Works and the Paris Convention for the Protection of Industrial Property .
WIPO was formally created by the Convention Establishing the World Intellectual Property Organization , which entered into force on April 26, 1970. Under Article 3 of this Convention, WIPO seeks to "promote the protection of intellectual property throughout the world". WIPO became a specialized agency of the UN in 1974. The Agreement between the United Nations and the World Intellectual Property Organization [6] notes in Article 1 that WIPO is responsible
The Agreement marked a transition for WIPO from the mandate it inherited in 1967 from BIRPI, to promote the protection of intellectual property, to one that involved the more complex task of promoting technology transfer and economic development. [7] [ need quotation to verify ]
Unlike other branches of the United Nations, WIPO has significant financial resources independent of the contributions from its Member States. In 2006, over 90 percent of its income of just over CHF 250 million [8] was expected to be generated from the collection of fees by the International Bureau (IB) under the intellectual property application and registration systems which it administers (the Patent Cooperation Treaty , the Madrid system for trademarks and the Hague system for industrial designs ).
In October 2004, WIPO agreed to adopt a proposal offered by Argentina and Brazil, the "Proposal for the Establishment of a Development Agenda for WIPO"—from the Geneva Declaration on the Future of the World Intellectual Property Organization . [9] This proposal was well supported by developing countries. The agreed "WIPO Development Agenda" [10] (composed of over 45 recommendations) was the culmination of a long process of transformation for the organization from one that had historically been primarily aimed at protecting the interests of rightholders, to one that has increasingly incorporated the interests of other stakeholders in the international intellectual property system as well as integrating into the broader corpus of international law on human rights, environment and economic cooperation.
A number of civil society bodies have been working on a draft Access to Knowledge (A2K) [11] treaty which they would like to see introduced.
In December 2011, WIPO published its first World Intellectual Property Report on the Changing Face of Innovation, the first such report of the new Office of the Chief Economist. [12] WIPO is also a co-publisher of the Global Innovation Index. [13]

Information network
WIPO has established WIPOnet, a global information network. The project seeks to link over 300 intellectual property offices (IP offices) in all WIPO Member States. In addition to providing a means of secure communication among all connected parties, WIPOnet is the foundation for WIPO's intellectual property services. [14]

Economics and Statistics Division
The Economics and Statistics Division is responsible for collecting statistics on IP activity worldwide and making these statistics available to the public. In addition, the Division carries out economic analysis on how IP and innovation policy choices affect economic performance. [15]

Directors-General

See also
WebPage index: 00089
Time (magazine)
Time is an American weekly news magazine published in New York City . It was founded in 1923 and for decades was dominated by Henry Luce , who built a highly profitable stable of magazines.
A European edition ( Time Europe , formerly known as Time Atlantic ) is published in London and also covers the Middle East, Africa and, since 2003, Latin America. An Asian edition ( Time Asia ) is based in Hong Kong . The South Pacific edition, which covers Australia, New Zealand and the Pacific Islands , is based in Sydney , Australia. In December 2008, Time discontinued publishing a Canadian advertiser edition. [2]
Time has the world's largest circulation for a weekly news magazine, and has a readership of 26 million, 20 million of which are based in the United States.
As of 2012, it had a circulation of 3.3 million making it the eleventh most circulated magazine in the United States reception room circuit, and the second most circulated weekly behind People . [3] As of 2015, its circulation was 3,036,602. [1]
Richard Stengel was the managing editor from May 2006 to October 2013, when he joined the U.S. State Department . [4] [5] Nancy Gibbs has been the managing editor since October 2013. [5]

History
Time magazine was created in 1923 by Briton Hadden and Henry Luce , making it the first weekly news magazine in the United States. [6] The two had previously worked together as chairman and managing editor respectively of the Yale Daily News . They first called the proposed magazine Facts . They wanted to emphasize brevity, so that a busy man could read it in an hour. They changed the name to Time and used the slogan "Take Time–It's Brief". [7] Hadden was considered carefree and liked to tease Luce and saw Time as important but also fun, which accounted for its heavy coverage of celebrities (including politicians), the entertainment industry, and pop culture—criticized as too light for serious news.
It set out to tell the news through people, and for many decades the magazine's cover depicted a single person. More recently, Time has incorporated "People of the Year" issues which grew in popularity over the years. Notable mentions of them were Barack Obama, Steve Jobs, Matej Turk, etc. The first issue of Time was published on March 3, 1923, featuring Joseph G. Cannon , the retired Speaker of the House of Representatives , on its cover; a facsimile reprint of Issue No. 1, including all of the articles and advertisements contained in the original, was included with copies of the February 28, 1938 issue as a commemoration of the magazine's 15th anniversary. [8] The cover price was 15¢ (equivalent to $2.11 today) On Hadden's death in 1929, Luce became the dominant man at Time and a major figure in the history of 20th-century media. According to Time Inc.: The Intimate History of a Publishing Enterprise 1972–2004 by Robert Elson, " Roy Edward Larsen [...] was to play a role second only to Luce's in the development of Time Inc". In his book, The March of Time , 1935–1951 , Raymond Fielding also noted that Larsen was "originally circulation manager and then general manager of Time , later publisher of Life , for many years president of Time Inc., and in the long history of the corporation the most influential and important figure after Luce". [ citation needed ]
Around the time they were raising $100,000 from wealthy Yale alumni like Henry P. Davison, partner of J.P. Morgan & Co. , publicity man Martin Egan and J.P. Morgan & Co. banker Dwight Morrow, Henry Luce, and Briton Hadden hired Larsen in 1922 – although Larsen was a Harvard graduate and Luce and Hadden were Yale graduates. After Hadden died in 1929, Larsen purchased 550 shares of Time Inc., using money he obtained from selling RKO stock which he had inherited from his father, who was the head of the Benjamin Franklin Keith theatre chain in New England . However, after Briton Hadden's death, the largest Time stockholder was Henry Luce , who ruled the media conglomerate in an autocratic fashion, "at his right hand was Larsen", Time's second-largest stockholder, according to Time Inc.: The Intimate History of a Publishing Enterprise 1923–1941 . In 1929, Roy Larsen was also named a Time Inc. director and vice-president. J. P. Morgan retained a certain control through two directorates and a share of stocks, both over Time and Fortune . Other shareholders were Brown Brothers W. A. Harriman & Co., and The New York Trust Company ( Standard Oil ). [ citation needed ]
The Time Inc. stock owned by Luce at the time of his death was worth about $109 million, and it had been yielding him a yearly dividend of more than $2.4 million, according to Curtis Prendergast's The World of Time Inc.: The Intimate History of a Changing Enterprise 1957–1983 . The Larsen family's Time stock was worth around $80 million during the 1960s, and Roy Larsen was both a Time Inc. director and the chairman of its Executive Committee, later serving as Time's vice-chairman of the board until the middle of 1979. According to the September 10, 1979 issue of The New York Times , "Mr. Larsen was the only employee in the company's history given an exemption from its policy of mandatory retirement at age 65." [ citation needed ]
After Time magazine began publishing its weekly issues in March 1923, Roy Larsen was able to increase its circulation by utilizing U.S. radio and movie theaters around the world. It often promoted both Time magazine and U.S. political and corporate interests. According to The March of Time , as early as 1924, Larsen had brought Time into the infant radio business with the broadcast of a 15-minute sustaining quiz show entitled Pop Question which survived until 1925". Then, in 1928, Larsen "undertook the weekly broadcast of a 10-minute programme series of brief news summaries, drawn from current issues of Time magazine [...] which was originally broadcast over 33 stations throughout the United States". [ citation needed ]
Larsen next arranged for a 30-minute radio program, The March of Time , to be broadcast over CBS , beginning on March 6, 1931. Each week, the program presented a dramatisation of the week's news for its listeners, thus Time magazine itself was brought "to the attention of millions previously unaware of its existence", according to Time Inc.: The Intimate History of a Publishing Enterprise 1923–1941 , leading to an increased circulation of the magazine during the 1930s. Between 1931 and 1937, Larsen's The March of Time radio program was broadcast over CBS radio and between 1937 and 1945 it was broadcast over NBC radio – except for the 1939 to 1941 period when it was not aired. People Magazine was based on Time' s People page.
In 1989, when Time, Inc. and Warner Communications merged, Time became part of Time Warner , along with Warner Bros. .
In 1988, Jason McManus succeeded Henry Grunwald as Editor-in-Chief and oversaw the transition before Norman Pearlstine succeeded him in 1995.
In 2000, Time magazine became part of AOL Time Warner, which reverted to the name Time Warner in 2003.
In 2007, Time moved from a Monday subscription/newsstand delivery to a schedule where the magazine goes on sale Fridays, and is delivered to subscribers on Saturday. The magazine actually began in 1923 with Friday publication.
During early 2007, the year's first issue was delayed for roughly a week due to "editorial changes", including the layoff of 49 employees. [9]
In 2009 Time announced that they were introducing a personalized print magazine, Mine , mixing content from a range of Time Warner publications based on the reader's preferences. The new magazine met with a poor reception, with criticism that its focus was too broad to be truly personal. [10]
The magazine has an online archive with the unformatted text for every article published. The articles are indexed and were converted from scanned images using optical character recognition technology. There are still minor errors in the text that are remnants of the conversion into digital format.
Time Inc. and Apple have come to an agreement wherein U.S. subscribers to Time will be able to read the iPad versions for free, at least until the two companies sort out a viable digital subscription model. [11]
In January 2013, Time Inc. announced that it would cut nearly 500 jobs – roughly 6% of its 8,000 staff worldwide. [12] Although Time magazine has maintained high sales, its ad pages have declined significantly over time. [13]
Also in January 2013, Time Inc. named Martha Nelson as the first female editor-in-chief of its magazine division. [14] In September 2013, Nancy Gibbs was named as the first female managing editor of Time magazine. [14]

Circulation
During the second half of 2009, the magazine saw a 34.9% decline in newsstand sales. [15] During the first half of 2010, there was another decline of at least one-third in Time magazine sales. In the second half of 2010, Time magazine newsstand sales declined by about 12% to just over 79,000 copies per week. [ citation needed ] As of 2012, it has a circulation of 3.3 million, making it the eleventh most circulated magazine in the United States, and the second most circulated weekly behind People . [3] As of 2014, its circulation was 3,286,467 [1]

Style
Time initially possessed a distinctive writing style, making regular use of inverted sentences . This was parodied in 1936 by Wolcott Gibbs in The New Yorker : "Backward ran sentences until reeled the mind [...] Where it all will end, knows God!" [16]
Until the mid-1970s, Time had a weekly section called "Listings", which contained capsule summaries and/or reviews of then-current significant films, plays, musicals, television programs, and literary bestsellers similar to The New Yorker ' s "Current Events" section. [17]
Time is also known for its signature red border, first introduced in 1927. The iconic red border was homaged or satirized by Seattle's The Stranger newspaper in 2010. [18]
The border has only been changed four times since 1927: The issue released shortly after the September 11 attacks on the United States featured a black border to symbolize mourning . However, this edition was a special "extra" edition published quickly for the breaking news of the event; the next regularly scheduled issue contained the red border. Additionally, the April 28, 2008 Earth Day issue, dedicated to environmental issues , contained a green border. [19] The next change in border was in the September 19, 2011 issue, commemorating the 10th anniversary of September 11 attacks with a metallic silver border. The most recent change (again with a silver border) was in the December 31, 2012 issue, noting Barack Obama 's selection as Person of the Year.
In 2007, Time engineered a style overhaul of the magazine. Among other changes, the magazine reduced the red cover border in order to promote featured stories, enlarged column titles, reduced the number of featured stories, increased white space around articles, and accompanied opinion pieces with photographs of the writers. The changes have met both criticism and praise. [20] [21] [22]

Special editions

Person of the Year
Time ' s most famous feature throughout its history has been the annual "Person of the Year" (formerly "Man of the Year") cover story, in which Time recognizes the individual or group of individuals who have had the biggest impact on news headlines over the past 12 months. The distinction is supposed to go to the person who, for good or ill , has most affected the course of the year; it is therefore not necessarily an honor or a reward. In the past, such figures as Adolf Hitler and Joseph Stalin have been Man of the Year.
In 2006, Person of the Year was designated as "You" , a move that was met with split reviews. Some thought the concept was creative; others wanted an actual person of the year. Editors Pepper and Timmer reflected that, if it had been a mistake, "we're only going to make it once". [23]

Time
In recent years, Time has assembled an annual list of the 100 most influential people of the year. Originally, they had made a list of the 100 most influential people of the 20th century. These issues usually have the front cover filled with pictures of people from the list and devote a substantial amount of space within the magazine to the 100 articles about each person on the list. There have, in some cases, been over 100 people, when two people have made the list together, sharing one spot.
The magazine also compiled "All- TIME 100 best novels" and " All- TIME 100 best movies " lists in 2005, [24] [25] [26] "The 100 Best TV Shows of All- TIME " in 2007, [27] and "All- TIME 100 Fashion Icons" in 2012. [28]
In February 2016, Time included the British and male author Evelyn Waugh on its "100 Most Read Female Writers in College Classes" list (he was 97th on the list) which created much media attention and concerns about the level of basic education among the magazine's staff. [29] Time later issued a retraction. [30] In a BBC interview with Justin Webb , Professor Valentine Cunningham of Corpus Christi College, Oxford , described the mistake as "a piece of profound ignorance on the part of Time magazine". [31]

Red X covers
During its history, for five non-consecutive occasions, Time has released a special issue with a cover showing an X scrawled over the face of a man or a national symbol. The first Time magazine with a red X cover was released on May 7, 1945, showing a red X over Adolf Hitler 's face. The second X cover was released more than three months later on August 20, 1945, with a black X (to date, the magazine's only such use of a black X) covering the flag of Japan , representing the recent surrender of Japan and which signaled the end of World War II .
Fifty-eight years later, on April 21, 2003, Time released another issue with a red X over Saddam Hussein 's face, two weeks after the invasion. On June 13, 2006, Time magazine printed a red X cover issue following the death of Abu Musab al-Zarqawi in a U.S. airstrike in Iraq . The most recent red X cover issue of Time was published on May 2, 2011, after the death of Osama bin Laden . [32]

Time for Kids
Time for Kids is a division magazine of Time that is especially published for children and is mainly distributed in classrooms. TFK contains some national news, a " Cartoon of the Week", and a variety of articles concerning popular culture . An annual issue concerning the environment is distributed near the end of the U.S. school term. The publication rarely exceeds ten pages front and back.

Time LightBox
Time LightBox is a photography blog created and curated by Time's photo department, that was launched in 2011. [33] In 2011 Life picked LightBox for its Photo Blog Awards. [34]

Staff

Editors

Managing editors

Notable contributors

See also
WebPage index: 00090
BBC Radio 4
BBC Radio 4 is a radio station owned and operated by the British Broadcasting Corporation (BBC) that broadcasts a wide variety of spoken-word programmes including news, drama, comedy, science and history. It replaced the BBC Home Service in 1967. [1] The station controller is Gwyneth Williams ; and the station is part of BBC Radio and the BBC Radio department. The station is broadcast from the BBC's headquarters at Broadcasting House , London .
It is the second most popular domestic radio station in the UK , broadcast throughout the UK, the Isle of Man and the Channel Islands on FM , LW and DAB ; and can be received in eastern and south eastern counties of Ireland, the north of France and Northern Europe . It is also available through Freeview , Sky , Virgin Media and on the Internet . Its sister station, BBC Radio 4 Extra (formerly BBC Radio 7 ), complements the main channel by broadcasting repeats from the Radio 4 archive, extended versions of Radio 4 programmes and supplements to series such as The Archers and Desert Island Discs .
It is notable for its news bulletins and programmes such as Today and The World at One , heralded on air by the Greenwich Time Signal "pips" or the chimes of Big Ben .

Outline
BBC Radio 4 is the second most popular British domestic radio station by total hours, [2] after Radio 2 – and the most popular in London and the South of England . [ citation needed ] It recorded its highest audience, of 11 million listeners, in May 2011 [3] and was "UK Radio Station of the Year" at the 2003, 2004 and 2008 Sony Radio Academy Awards . [4] [5] It also won a Peabody Award in 2002 for File On 4: Export Controls . [6] Costing £71.4 million (2005/6), [7] it is the BBC's most expensive national radio network and is considered by many to be its flagship. There is no comparable British commercial network: Channel 4 abandoned plans to launch its own speech-based digital radio station in October 2008 as part of a £100m cost cutting review. [8]
In 2010 Gwyneth Williams [9] replaced Mark Damazer as Radio 4 controller. Damazer became Master of St Peter's College, Oxford . [10]
Music and sport are the only fields that largely fall outside the station's remit. It broadcasts occasional concerts, and documentaries related to various forms of both popular and classical music, and the long-running music-based Desert Island Discs . Prior to the creation of BBC Radio 5 it broadcast sports-based features, notably Sport on Four , and since the creation of BBC Radio 5 Live has become the home of ball-by-ball commentaries of most Test cricket matches played by England, broadcast on long wave . As a result, for around 70 days a year listeners have to rely on FM broadcasts or increasingly DAB for mainstream Radio 4 broadcasts – the number relying solely on long wave is now a small minority.
The cricket broadcasts take precedence over on-the-hour news bulletins, but not the Shipping Forecast, carried since its move to long wave in 1978 because that can be received clearly at sea. [11] The station is the UK's national broadcaster in times of national emergency such as war, due to the wide coverage of the Droitwich signal: if all other radio stations were forced to close, it would carry on broadcasting. [8] It has been claimed that the commanders of nuclear-armed submarines believing that Britain had suffered nuclear attack were required to check if they could still receive Radio 4 on 198 long wave, and if they could not they would open sealed orders that might authorise a retaliatory strike . [12] [13]
As well as news and drama, the station has a strong reputation for comedy, including experimental and alternative comedy , many successful comedians and comedy shows first appearing on the station. Following the six o'clock news from Monday to Friday, the station normally broadcasts a thirty minute comedy programme.
The station is available on FM in most of Great Britain, parts of Ireland and the north of France; LW throughout the UK and in parts of Northern Europe, and the Atlantic north of the Azores to about 20 degrees west; MW in some areas; DAB ; Digital TV including Freeview , Freesat , Sky and Virgin Media ; and on the Internet.

History
The BBC Home Service was the predecessor of Radio 4 and broadcast between 1939 and 1967. It had regional variations and was broadcast on medium wave with a network of VHF FM transmitters being added from 1955. Radio 4 replaced it on 30 September 1967, when the BBC renamed many of its domestic radio stations, [1] in response to the challenge of offshore radio . It moved to long wave in November 1978, taking over the 200 kHz frequency previously held by Radio 2 , and later moved to 198 kHz as a result of international agreements aimed at avoiding interference.
For a time during the 1970s Radio 4 carried regional news bulletins Monday to Saturday. These were broadcast twice at breakfast, at lunchtime and an evening bulletin was aired at 5.55pm. There were also programme variations for the parts of England not served by BBC Local Radio stations. These included Roundabout East Anglia , a VHF opt-out of the Today programme broadcast from BBC East 's studios in Norwich each weekday from 6.45 am to 8.45 am. [14] Roundabout East Anglia came to an end in 1980, when local radio services were introduced to East Anglia with the launch of BBC Radio Norfolk . [14]
All regional news bulletins broadcast from BBC regional news bases around England ended in August 1980 apart from in the south west. Until January 1983 there was no BBC Local Radio in the south west so these news bulletins and its weekday morning regional programme, Mornin' Sou West , continued to be broadcast from the BBC studios in Plymouth on VHF and on the Radio 4 medium wave Plymouth relay until 31 December 1982.
The launch of Radio 5 on 27 August 1990 saw the removal of Open University , schools programming and the "Study on 4" adult education slot to the new station resulting in the full Radio 4 schedule being available on FM for the first time. Between 17 January 1991 and 2 March 1991 FM broadcasts were replaced by a continuous news service devoted to the Gulf War , Radio 4 News FM , with the main Radio 4 service being exclusively on long wave. In September 1991 it was decided that the main Radio 4 service would be on FM as coverage had extended to cover almost all of the UK. Opt-outs were transferred to long wave: currently Test Match Special , extra shipping forecasts, The Daily Service and Yesterday in Parliament . Long wave very occasionally opts out at other times, such as to broadcast special services, the most recent being when Pope Benedict XVI visited Britain in 2010 .
The longwave signal is part of the Royal Navy 's system of Last Resort Letters . In the event of a suspected catastrophic attack on Britain, submarine commanders, in addition to other checks, check for a broadcast signal from Radio 4 on 198 longwave to verify the annihilation of organised society in Great Britain. [15]

Programmes and schedules

Daily schedule
The simulcast from the BBC World Service begins at 01:00 and ends at 05:20 with a brief introduction from the early shift continuity announcer . The five-minute Radio 4 UK Theme composed by Fritz Spiegl followed this for 28 years until April 2006. It was replaced by an extension to the early news bulletin , [16] [17] despite public opposition [18] and a campaign to save it. [19] After a continuity link and programme trail there are a shipping forecast , weather reports from coastal stations for 04:00 GMT and the inshore waters forecasts, followed at 05:30 by a news bulletin, a review of British and international newspapers, and a business report. On weekdays at 05:45, Farming Today , which deals with news of relevance to the agricultural sector, is followed by Tweet of the Day , a 2-minute feature looking at different species of birds through their songs and calls. The morning news and current affairs sequence Today then runs for three hours from 06:00 to 09:00 on weekdays (for two hours from 07:00 on Saturdays).
The remainder of the day's schedule is determined by the day of the week, with the following 'fixtures' on weekdays: Book of the Week at 09:45 (the Daily Service on LW), Woman's Hour at 10:02 (including a 15 Minute Drama at 10:45), You and Yours at 12:15, The World at One and a repeat of the previous day's The Archers at 14:02, the Afternoon Drama at 14:15. At 17:00 another current affairs programme, PM , is broadcast. At 18:30 there is a regular comedy 'slot', The Archers at 19:02, Front Row at 19:15 and a repeat of the 15 Minute Drama at 19:45. The World Tonight airs at 22:00, followed by Book at Bedtime at 22:45. At weekends the schedule is different, with other fixed features at various times.
News is broadcast at the top of each hour: a two-minute summary, a longer bulletin as part of a current affairs programme, or a 30-minute programme on weekdays at 18:00 and midnight. At 12:00, FM carries a four-minute bulletin while long wave has the headlines followed by a shipping forecast; on weekdays, long wave also leaves PM for a three-minute shipping forecast at 17:54.
There is a news programme or bulletin (depending on the day) at 22:00. A report on the day's proceedings in the Westminster Parliament is broadcast (as Today in Parliament ) at 23:30 and repeated (as Yesterday in Parliament ), on LW only, at 08:31 the following morning. The midnight news is followed on weekdays by a repeat of Book of the Week . The tune Sailing By is played until 00:48, when the late shipping forecast is broadcast. As the timing of the forecast is critical, the Sailing By theme must be started at a set time and faded in as the last programme ends. Radio 4 finishes with God Save the Queen , and the World Service takes over from 01:00 until 05:20.
Timing is sacrosanct on the channel. Running over the hour except in special circumstances or the occasional scheduled instance is unheard of, and interrupting the Greenwich Time Signal [20] on the hour (known as 'crashing the pips') is frowned upon.
An online schedule page lists the running order of programmes. [21]

Production
Many programmes are pre-recorded. Programmes transmitted live include Today , magazine programme Woman's Hour , consumer affairs programme You and Yours , and (often) the music, film, books, arts and culture programme Front Row . Continuity is managed from Broadcasting House with news bulletins, including the hourly summaries and longer programmes such as the Six O'Clock News and Midnight News , and news programmes such as Today , The World at One and PM , which by early 2013 had returned to Broadcasting House after 15 years at BBC Television Centre in White City . [22] The news returning to Broadcasting House has also meant that newsreaders can provide cover for continuity, which regularly occurs at 23:00 each night and 16:00 on a Sunday. This has reduced the total number of continuity announcers required each day down from four to three.
The Time Signal , known as 'the pips', is broadcast every hour to herald the news bulletin, except at midnight and 18:00, where the chimes of Big Ben are played.

Programmes
Radio 4 programmes cover a wide variety of genre including news and current affairs, history, culture, science, religion, arts, drama and light entertainment. A number of the programmes on Radio 4 take the form of a "magazine" show, featuring numerous small contributions over the course of the programme— Woman's Hour , From Our Own Correspondent , You and Yours . The rise of these magazine shows is primarily due to the work of Tony Whitby , controller of Radio 4 from 1970 to 1975. [23]
The station hosts a number of long-running programmes, many of which have been broadcast for over 40 years.
Most programmes are available for four weeks after broadcast as streaming audio from Radio 4's listen again page [24] and via BBC iPlayer . A selection of programmes is also available as podcasts or downloadable audio files. [25] Many comedy and drama programmes from the Radio 4 archives are rebroadcast on BBC Radio 4 Extra (formerly BBC Radio 7).
Due to the capacity limitations of DAB and increasing sport broadcasts on BBC Radio 5 Live Sports Extra , BBC Radio 4 DAB has to reduce its bit rate most evenings, such that after 7pm its DAB output is usually in mono, even though many of its programmes are made in stereo (including its flagship drama "The Archers"), these can only be heard in stereo on FM, Digital TV on Freeview & Freesat (Ch. 704), Sky, Virgin and on line via BBC i-player radio. BBC World Service which uses BBC Radio 4 FM & DAB frequencies between 01:00am and 05:20am is in stereo, but only on Radio 4 FM & DAB and not on its own dedicated DAB channel. BBC Radio 4 Extra broadcasts in mono on DAB, but has always been in stereo on Digital TV (Freeview / Freesat Ch 708), Sky, Virgin and online.

Notable continuity announcers and newsreaders
Announcers carry out the following duties from Broadcasting House:
Newsreaders read hourly summaries and longer bulletins from New Broadcasting House. [26] [27] In 2012 the BBC announced that it would be reducing its main presentation team from 12 to ten. [28]

BBC

Freelance

Former staff

Frequencies and other means of reception
Radio 4 is broadcast on: [29]

Criticisms
There have been criticisms voiced by newspapers in recent years over a perceived left-wing bias across a range of issues such as the EU and the Iraq War, [33] [34] [35] as well as sycophancy in interviews, particularly on the popular morning news magazine Today [36] as part of a reported perception of a general "malaise" at the BBC. Conversely, the journalist Mehdi Hasan has criticised the station for an overtly " socially and culturally conservative" approach. [37]
There has been frequent criticism of Radio 4—and Today in particular—for a lack of female broadcasters. [38] In September 1972, Radio 4 employed the first female continuity announcers—Hylda Bamber and Barbara Edwards (an event which caused the Daily Mail to proclaim that Radio 4 had "fallen" to women's liberation). For quite some time, the introduction of female newsreaders led to complaints from listeners; women discussing topics of feminist interest led to similar complaints. [39]
This led the satirical magazine Private Eye to lampoon Woman's Hour as "Women's Whinge", and the network as FemFM.
Radio 4 has also been frequently criticised for being too middle class and being of little interest to non-white listeners. [40] [41] [42]

See also
WebPage index: 00091
Quadriga (award)
Quadriga was an annual German award sponsored by Netzwerk Quadriga gGmbH , a non-profit organization based in Berlin . The award recognized four people or groups for their commitment to innovation, renewal, and a pioneering spirit through political, economic, and cultural activities.
The award consisted of a small statue resembling the quadriga atop the Brandenburg Gate in Berlin. Werkstatt Deutschland presented the award annually on German Unity Day , which commemorates German reunification in 1990. The award was presented by prominent individuals, including Viktor Yushchenko , Bernard Kouchner , and Mikhail Gorbachev .

History
The award was first given in 2003. For the first two years, the award ceremony took place at Konzerthaus Berlin . From 2005 until 2008, the ceremony was held at Komische Oper Berlin opera house. In 2009, the award ceremony was hosted at the seat of the Foreign Office of Germany .
The announcement that Vladimir Putin would receive the award in 2011 was widely condemned. As a result of protests by Quadriga board members and former recipients, the 2011 awards and ceremonies were cancelled. Likewise, the Quadriga was not awarded in 2012.

Recipients

2003
[1] [2]

2004
[3]

2005
[4] [5]

2006
[6] [7]

2007
[8] [9]

2008

2009

2010

2011
The announcement that Prime Minister of Russia Vladimir Putin would be awarded the prize led to a public outcry. [10] Quadriga board members Cem Özdemir of the German Green Party, Jimmy Wales of Wikipedia, and Heidelberg University history professor Edgar Wolfrum stepped down in protest. [11] Former recipients Olafur Eliasson and Václav Havel decided to return their awards. [12] [13] The New York Times commented that from the volume of outcry the ranks of people feeling Putin, a former East Germany -assigned KGB agent and later chief, [14] [15] had rolled back democracy and human rights in Russia are apparently quite large. [10] The organisers decided not to make any awards in 2011 as a result of the controversy. [14] They released a statement on 16 July 2011 saying they acted "in light of the growing and unbearable pressure and the danger of further escalation" and that they deeply regretted hearing news of Havel's decision. [10] The awards ceremony scheduled for that October was therefore cancelled. [10] [15] [16] [17]
WebPage index: 00092
Stanford University
Stanford University ( Stanford ; officially Leland Stanford Junior University [11] ) is a private research university in Stanford , California , adjacent to Palo Alto and between San Jose and San Francisco . Its 8,180-acre (12.8 sq mi; 33.1 km 2 ) [12] campus is one of the largest in the United States . [note 1] Stanford also has land and facilities elsewhere. [7] [12]
The university was founded in 1885 by Leland and Jane Stanford in memory of their only child, Leland Stanford Jr. , who had died of typhoid fever at age 15 the previous year. Stanford was a former Governor of California and U.S. Senator ; he made his fortune as a railroad tycoon . The school admitted its first students 125 years ago on October 1, 1891, [2] [3] as a coeducational and non-denominational institution.
Stanford University struggled financially after Leland Stanford's death in 1893 and again after much of the campus was damaged by the 1906 San Francisco earthquake . [15] Following World War II , Provost Frederick Terman supported faculty and graduates' entrepreneurialism to build self-sufficient local industry in what would later be known as Silicon Valley . [16] The university is also one of the top fundraising institutions in the country, becoming the first school to raise more than a billion dollars in a year. [17]
There are three academic schools that have both undergraduate and graduate students and another four professional schools. Students compete in 36 varsity sports, and the university is one of two private institutions in the Division I FBS Pac-12 Conference . It has gained 113 NCAA team championships, [18] the most for a university (tied with UCLA), 483 individual championships, the most in Division I, [19] and has won the NACDA Directors' Cup , recognizing the university with the best overall athletic team achievement, for 22 consecutive years, beginning in 1994–1995. [20]
Stanford faculty and alumni have founded a large number of companies that produce more than $2.7 trillion in annual revenue, equivalent to the 10th-largest economy in the world. [21] It is the alma mater of 30 living billionaires, 17 astronauts, and 20 Turing Award laureates . [note 2] It is also one of the leading producers of members of the United States Congress . [42] [43] Sixty Nobel laureates and seven Fields Medalists have been affiliated with Stanford as students, alumni, faculty or staff. [44]

History
Stanford University was founded in 1885 by Leland and Jane Stanford, dedicated to Leland Stanford Jr, their only child. The institution opened in 1891 on Stanford's previous Palo Alto farm. Despite being impacted by earthquakes in both 1906 and 1989, the campus was rebuilt each time. In 1919, The Hoover Institution on War, Revolution and Peace was started by Herbert Hoover to preserve artifacts related to World War I . The Stanford Medical Center, completed in 1959, is a teaching hospital with over 800 beds. The SLAC National Accelerator Laboratory (originally named the Stanford Linear Accelerator Center), which was established in 1962, performs research in particle physics. [46]
Jane and Leland Stanford modeled their university after the great eastern universities and most specifically Cornell University and Harvard University . Stanford opened being called the "Cornell of the West" in 1891 due to faculty being former Cornell professors and alumni including its first president, David Starr Jordan . Both Cornell and Stanford were among the first to have higher education be accessible, nonsectarian, and open to women as well to men. Cornell is credited as one of the first American universities to adopt this radical departure from traditional education, and Stanford became an early adopter as well. [47]

Land
Most of Stanford University is on an 8,180-acre (12.8 sq mi; 33.1 km 2 ) [12] campus on the San Francisco Peninsula , in the northwest part of the Santa Clara Valley ( Silicon Valley ) approximately 37 miles (60 km) southeast of San Francisco and approximately 20 miles (30 km) northwest of San Jose ; this is the founding grant. In 2008, 60% of this land remained undeveloped. [48] Besides the central campus described below, the university also operates at several more remote locations, some elsewhere on the main campus, some further afield ( see below ).
Stanford's main campus includes a census-designated place within unincorporated Santa Clara County , although some of the university land (such as the Stanford Shopping Center and the Stanford Research Park ) is within the city limits of Palo Alto. The campus also includes much land in unincorporated San Mateo County (including the SLAC National Accelerator Laboratory and the Jasper Ridge Biological Preserve ), as well as in the city limits of Menlo Park (Stanford Hills neighborhood), Woodside , and Portola Valley . [49]

Central campus
The academic central campus is adjacent to Palo Alto, bounded by El Camino Real , Stanford Avenue, Junipero Serra Boulevard, and Sand Hill Road . The United States Postal Service has assigned it two ZIP codes : 94305 for campus mail and 94309 for P.O. box mail. It lies within area code 650 .

Non-central campus
Stanford currently operates or intends to operate in various locations outside of its central campus.
On the founding grant:
Off the founding grant:
Locations in development:

Faculty residences
Many Stanford faculty members live in the "Faculty Ghetto", within walking or biking distance of campus. [58] The Faculty Ghetto is composed of land owned entirely by Stanford. Similar to a condominium , the houses can be bought and sold but the land under the houses is rented on a 99-year lease. Houses in the "Ghetto" appreciate and depreciate, but not as rapidly as overall Silicon Valley values. However, it remains an expensive area in which to own property, and the average price of single-family homes on campus is actually higher than in Palo Alto. [ citation needed ]

Other uses
Some of the land is managed to provide revenue for the university such as the Stanford Shopping Center and the Stanford Research Park . Stanford land is also leased for a token rent by the Palo Alto Unified School District for several schools including Palo Alto High School and Gunn High School . [59] El Camino Park, the oldest Palo Alto city park (established 1914), is also on Stanford land. [60]

Landmarks
Contemporary campus landmarks include the Main Quad and Memorial Church , the Cantor Center for Visual Arts and the Bing Concert Hall , the Stanford Mausoleum with the nearby Angel of Grief , Hoover Tower , the Rodin sculpture garden, the Papua New Guinea Sculpture Garden , the Arizona Cactus Garden , the Stanford University Arboretum , Green Library and the Dish . Frank Lloyd Wright 's 1937 Hanna–Honeycomb House and the 1919 Lou Henry Hoover House are both listed on the National Historic Register . The Claw (officially White Memorial Fountain) between the Stanford Bookstore and the Old Union is a popular place to meet and to engage in the Stanford custom of “fountain hopping”; it was installed in 1964 and designed by Aristides Demetrios after a national competition as a memorial for two brothers in the class of 1949, William N. White and John B. White II, one of whom died before graduating and one shortly after in 1952. [61] [62] [63] [64]

Administration and organization
Stanford University is a tax-exempt corporate trust governed by a privately appointed Board of Trustees with a maximum membership of 38. [6] [note 3] Trustees serve five-year terms (not more than two consecutive terms) and meet five times annually. [66] A new trustee is chosen by the current trustees by ballot. [65] The Stanford trustees also oversee the Stanford Research Park , the Stanford Shopping Center , the Cantor Center for Visual Arts , Stanford University Medical Center , and many associated medical facilities (including the Lucile Packard Children's Hospital ). [67]
The Board appoints a President to serve as the chief executive officer of the university and prescribe the duties of professors and course of study, manage financial and business affairs, and appoint nine vice presidents. [68] The Provost is the chief academic and budget officer, to whom the deans of each of the seven schools report. [69] [70] Persis Drell became the 13th Provost in February 2017.
As of 2013 the university was organized into seven academic schools. [71] The schools of Humanities and Sciences (27 departments), Engineering (9 departments), and Earth, Energy & Environmental Sciences (4 departments) have both graduate and undergraduate programs while the Schools of Law , Medicine , Education and Business have graduate programs only. The powers and authority of the faculty are vested in the Academic Council, which is made up of tenure and non-tenure line faculty, research faculty, senior fellows in some policy centers and institutes, the president of the university, and some other academic administrators, but most matters are handled by the Faculty Senate, made up of 55 elected representatives of the faculty. [72]
The Associated Students of Stanford University (ASSU) is the student government for Stanford University and all registered students are members. Its elected leadership consists of the Undergraduate Senate elected by the undergraduate students, the Graduate Student Council elected by the graduate students, and the President and Vice President elected as a ticket by the entire student body. [73]
Stanford is the beneficiary of a special clause in the California Constitution , which explicitly exempts Stanford property from taxation so long as the property is used for educational purposes. [74]

Endowment and fundraising
The university's endowment , managed by the Stanford Management Company, was valued at $22.2 billion in August 2015, 3.6% over the previous year. [75] [76] The endowment fell 25% in 2009 as a result of the late-2000s recession, but posted gains of 14.4% in 2010 and 22.4% in 2011, when it was valued at $16.5 billion. [77]
Stanford has been the top fundraising university in the United States for several years. It raised $911 million in 2006, [78] $832 million in 2007, [79] $785 million in 2008, [80] $640 million in 2009, [81] $599 million in 2010, [82] $709 million in 2011, [83] and $1.035 billion in 2012, becoming the first school to raise more than a billion dollars in a year. [17] In 2013 and 2014 it raised $932 million and $928 million. [83] Payouts from the Stanford endowment covered approximately 23% of University expenses in the 2014 fiscal year, compared to Princeton at 55% and Harvard at 35%. [84]
In 2006, President John L. Hennessy launched a five-year campaign called the Stanford Challenge, which reached its $4.3 billion fundraising goal in 2009, two years ahead of time, but continued fundraising for the duration of the campaign. It concluded on December 31, 2011, having raised a total of $6.23 billion and breaking the previous campaign fundraising record of $3.88 billion held by Yale. [85] [86] Specifically, the campaign raised $253.7 million for undergraduate financial aid, as well as $2.33 billion for its initiative in "Seeking Solutions" to global problems, $1.61 billion for "Educating Leaders" by improving K-12 education, and $2.11 billion for "Foundation of Excellence" aimed at providing academic support for Stanford students and faculty. Funds supported 366 new fellowships for graduate students, 139 new endowed chairs for faculty, and 38 new or renovated buildings. The new funding also enabled the construction of a facility for stem cell research; a new campus for the business school; an expansion of the law school; a new Engineering Quad; a new art and art history building; an on-campus concert hall; a new art museum; and a planned expansion of the medical school, among other things. [87] [88]

Academics

Teaching and learning
Stanford follows a quarter system with Autumn quarter usually starting in late September and Spring Quarter ending in early June. [89] The full-time, four-year undergraduate program has an arts and sciences focus with high graduate student coexistence. [89] Stanford is accredited by the Western Association of Schools and Colleges . [90]
Full-time undergraduate tuition was $42,690 for 2013–2014. [91] Stanford's admission process is need-blind for US citizens and permanent residents; while it is not need-blind for international students, 64% are on need-based aid, with an average aid package of $31,411. [91] In 2012–13, the university awarded $126 million in need-based financial aid to 3,485 students, with an average aid package of $40,460. [91] Eighty percent of students receive some form of financial aid. [91] Stanford has a no-loan policy. [91] For undergraduates admitted in 2015, Stanford waives tuition, room, and board for most families with incomes below $65,000, and most families with incomes below $125,000 are not required to pay tuition; those with incomes up to $150,000 may have tuition significantly reduced. [92] 17% of students receive Pell Grants, [91] a common measure of low-income students at a college.

Research centers and institutes
As of 2016 the Office of the Vice Provost and Dean of Research oversaw eighteen independent laboratories, centers, and institutes . [93]
Other Stanford-affiliated institutions include the SLAC National Accelerator Laboratory (originally the Stanford Linear Accelerator Center), the Stanford Research Institute (an independent institution which originated at the university), the Hoover Institution on War, Revolution and Peace (a major public policy think tank that attracts visiting scholars from around the world), and the Hasso Plattner Institute of Design (a multidisciplinary design school in cooperation with the Hasso Plattner Institute of University of Potsdam that integrates product design, engineering, and business management education). [ citation needed ]
Stanford is home to the Martin Luther King Jr. Research and Education Institute which grew out of and still contains the Martin Luther King Jr. Papers Project, a collaboration with the King Center to publish the King papers held by the King Center. [94] It also runs the John S. Knight Fellowship for Professional Journalists and the Center for Ocean Solutions, which brings together marine science and policy to address challenges facing the ocean. [95]

Libraries and digital resources
As of 2014 Stanford University Libraries (SUL) held a collection of more than 9.3 million volumes, nearly 300,000 rare or special books, 1.5 million e-books, 2.5 million audiovisual materials, 77,000 serials, nearly 6 million microform holdings, and thousands of other digital resources. [96]
The main library in the SU library system is Green Library , which also contains various meeting and conference rooms, study spaces, and reading rooms. Lathrop Library (previously Meyer Library , demolished in 2015), holds various student-accessible media resources and houses one of the largest East Asia collections with 540,000 volumes.

Arts
Stanford University is home to the Cantor Center for Visual Arts museum with 24 galleries, sculpture gardens, terraces, and a courtyard first established in 1891 by Jane and Leland Stanford as a memorial to their only child. The Center's collection of works by Rodin is among the largest in the world [97] The Thomas Welton Stanford Gallery, built in 1917, serves as a teaching resource for the Department of Art & Art History as well as an exhibition venue. There are outdoor art installations throughout the campus, primarily sculptures, but some murals as well. The Papua New Guinea Sculpture Garden near Roble Hall features includes wood carvings and "totem poles."
The Stanford music department sponsors many ensembles including five choirs, the Stanford Symphony Orchestra, Stanford Taiko , and the Stanford Wind Ensemble. Extracurricular activities include theater groups such as Ram's Head Theatrical Society, the Stanford Improvisors, [98] the Stanford Shakespeare Society, and the Stanford Savoyards, a group dedicated to performing the works of Gilbert and Sullivan . There are award-winning a cappella music groups including the Mendicants , [99] Counterpoint, [100] the Stanford Fleet Street Singers, [101] Harmonics , Mixed Company, [102] Testimony, Talisman , Everyday People , and Raagapella . [103]
The creative writing program brings young writers to campus via the Stegner Fellowships and other graduate scholarship programs. Knight Journalism Fellows are invited to spend a year at the campus taking seminars and courses of their choice. The Stanford Spoken Word Collective, an extracurricular writing and performance group, also serves as the school's poetry slam team. [104]
Stanford also hosts various publishing courses for professionals. The Stanford Professional Publishing Course, which was offered on campus since the late 1970s, brought together international publishing professionals to discuss changing business models in magazine and book publishing. It ended in 2009, although the tradition has continued at Yale with the Yale Publishing Course that began in 2010. Videos from the Stanford Professional Publishing Courses were available on their website as of 2014. [105]

Reputation and rankings
Notably, Stanford ranks high and often first in many domestic college ranking measures , leading Slate to dub Stanford in 2014 as "the Harvard of the 21st century," [114] and The New York Times in the same year to conclude that "Stanford University has become America’s 'it' school, by measures that Harvard once dominated." [115] From polls done by The Princeton Review in 2013, 2014, 2015, and 2016, the most commonly named "dream college" for students was Stanford; separately, parents, too, most frequently named Stanford as their "dream college." [116] The inaugural 2017 Wall Street Journal/Times Higher Education College Rankings picked Stanford as the No. 1 school in the United States. [117]
Globally, the Academic Ranking of World Universities (ARWU) ranked Stanford second in the world most years from 2003 to 2016. [118]

Discoveries and innovation
Stanford is one of the most successful universities in creating companies and licensing its inventions to existing companies; it is often held up as a model for technology transfer . [119] [120] Stanford's Office of Technology Licensing is responsible for commercializing developments.
Stanford faculty and alumni have founded many companies including Google , Hewlett-Packard , Nike , Instagram , Snapchat , LinkedIn , and Yahoo! , and companies founded by Stanford alumni generate more than $2.7 trillion in annual revenue, equivalent to the 10th-largest economy in the world. [21]
Developments include:
[133]

Student life

Student body
Stanford enrolled 7,061 undergraduate [91] and 11,075 graduate students [91] as of October 2013, and women comprised 47% of undergraduates and 41% of professional and graduate students. [91] In the same academic year, the freshman retention rate was 99%.
Stanford awarded 1,715 undergraduate degrees, 2,278 Master's degrees, 764 doctoral degrees, and 366 professional degrees in the 2011–2012 school year. [91] The four-year graduation rate in the class of 2011 was 76%, and the six-year rate was 96%. [91] The relatively low four-year graduation rate is a function of the university's coterminal degree (or "coterm") program, which allows students to earn a master's degree as an extension of their undergraduate program. [136]
As of 2010, fifteen percent of undergraduates were first-generation students. [137]

Dormitories and student housing
As of 2013, 89% of undergraduate students lived in on-campus university housing. First-year undergraduates are required to live on campus, and all undergraduates are guaranteed housing for all four undergraduate years. [91] [138] Undergraduates live in 80 different houses, including dormitories, co-ops, row houses , and fraternities and sororities . [139] At Manzanita Park, 118 mobile homes were installed as "temporary" housing from 1969 to 1991, but as of 2015 was the site of newer dorms Castano, Kimball, Lantana, and the Humanities House, completed in 2015. [140] [141] Most student residences are just outside the campus core, within ten minutes (on foot or bike) of most classrooms and libraries. Some are reserved for freshman, sophomores, or upperclass students and some are open to all four classes. Most residences are co-ed; seven are all-male fraternities , three are all-female sororities , and there is also one all-female non-sorority house, Roth House. In most residences, men and women live on the same floor, but a few dorms are configured for men and women to live on separate floors (single-gender floors), including all Wilbur dorms except for Arroyo and Okada. [142]
Several residences are considered theme houses. The Academic, Language and Culture Houses include EAST (Education And Society Themed House), Hammarskjöld (International Themed House), Haus Mitteleuropa (Central European Themed House), La Casa Italiana (Italian Language and Culture), La Maison Française (French Language and Culture House), Slavianskii Dom (Slavic/East European Themed House), Storey (Human Biology Themed House), and Yost (Spanish Language and Culture). Cross-Cultural Themed Houses include Casa Zapata (Chicano/Latino Theme in Stern Hall), Muwekma-tah-ruk (American Indian/Alaska Native, and Native Hawaiian Themed House), Okada (Asian-American Themed House in Wilbur Hall), and Ujamaa (Black/African-American Themed House in Lagunita Court). Focus Houses include Freshman-Sophomore College (Academic Focus), Branner Hall (Community Service), Kimball (Arts & Performing Arts), Crothers (Global Citizenship), and Toyon (Sophomore Priority). [139] Theme houses predating the current "theme" classification system are Columbae (Social Change Through Nonviolence, since 1970), [143] and Synergy (Exploring Alternatives, since 1972). [144]
Co-ops or "Self-Ops" are another housing option. These houses feature cooperative living, where residents and eating associates each contribute work to keep the house running, such as cooking meals or cleaning shared spaces. These houses have unique themes around which their community is centered. Many co-ops are hubs of music, art and philosophy. The co-ops on campus are 576 Alvarado Row (formerly Chi Theta Chi), Columbae, Enchanted Broccoli Forest (EBF), Hammarskjöld, Kairos, Terra (the unofficial LGBT house), [145] and Synergy. [146] Phi Sigma, at 1018 Campus Drive was formerly Phi Sigma Kappa fraternity, but in 1973 became a Self-Op. [147]
As of 2015 around 55 percent of the graduate student population lived on campus. [148] First-year graduate students are guaranteed on-campus housing. Stanford also subsidizes off-campus apartments in nearby Palo Alto , Menlo Park , and Mountain View for graduate students who are guaranteed on-campus housing but are unable to live on campus due to a lack of space. [149]

Athletics
As of 2016 Stanford had 16 male varsity sports and 20 female varsity sports, [150] 19 club sports [151] and about 27 intramural sports [152] In 1930, following a unanimous vote by the Executive Committee for the Associated Students, the athletic department adopted the mascot "Indian." The Indian symbol and name were later dropped by President Richard Lyman in 1972, after objections from Native American students and a vote by the student senate. [10] The sports teams are now officially referred to as the "Stanford Cardinal", referring to the deep red color , not the cardinal bird . Stanford is a member of the Pac-12 Conference in most sports, the Mountain Pacific Sports Federation in several other sports, and the America East Conference in field hockey [153] with the participation in the inter-collegiate NCAA's Division I FBS .
Its traditional sports rival is Berkeley , the neighbor to the north in the East Bay. The winner of the annual " Big Game " between the Cal and Cardinal football teams gains custody of the Stanford Axe . [154]
Stanford has had at least one NCAA team champion every year since the 1976–77 school year [155] and has earned 113 NCAA national team titles since its establishment, the most among universities (tied with the four times larger enrollment UCLA Bruins ), and Stanford has won 483 individual national championships, the most by any university. [18] Stanford has won the award for the top-ranked collegiate athletic program — the NACDA Directors' Cup , formerly known as the Sears Cup – annually for the past twenty-two straight years. [156] [157] [158] Stanford athletes have won medals in every Olympic Games since 1912, winning 270 Olympic medals total, 139 of them gold. [159] In the 2008 Summer Olympics , and 2016 Summer Olympics, Stanford won more Olympic medals than any other university in the United States. [160] [161] Stanford athletes won 16 medals at the 2012 Summer Games (12 gold, 2 silver and 2 bronze), and 27 medals at the 2016 Summer Games. [162]

Traditions

Religious life
Students and staff at Stanford are of many different religions. The Stanford Office for Religious Life's mission is "to guide, nurture and enhance spiritual, religious and ethical life within the Stanford University community" by promoting enriching dialogue, meaningful ritual, and enduring friendships among people of all religious backgrounds. It is headed by a dean with the assistance of a senior associate dean and an associate dean. Stanford Memorial Church , in the center of campus, has a Sunday University Public Worship service (UPW) usually in the "Protestant Ecumenical Christian" tradition where the Memorial Church Choir sings and a sermon is preached usually by one of the Stanford deans for Religious Life. UPW sometimes has multifaith services. [175] In addition the church is used by the Catholic community and by some of the other Christian denominations at Stanford. Weddings happen most Saturdays and the university has for over 20 years allowed blessings of same-gender relationships and now legal weddings.
In addition to the church, the Office for Religious Life has a Center for Inter-Religious Community, Learning and Experiences (CIRCLE) on the third floor of Old Union. It offers a common room, an interfaith sanctuary, a seminar room, a student lounge area and a reading room, as well as offices housing a number of Stanford Associated Religions (SAR) member groups and the Senior Associate Dean and Associate Dean for Religious Life. Most though not all religious student groups belong to SAR. The SAR directory includes organizations that serve atheist, Baha'i, Buddhist, Christian, Hindu, Islam, Jewish, and Sikh groups, though these groups vary year by year. [176]
The Windhover Contemplation Center was dedicated in October 2014, and was intended to provide spiritual sanctuary for students and staff in the midst of their course and work schedules; the center displays the "Windhover" paintings by Nathan Olivera , the late Stanford professor and artist. [177]
Some religions have a larger and more formal presence on campus in addition to the student groups; these include the Catholic Community at Stanford [178] and Hillel at Stanford. [179]

Greek life
Fraternities and sororities have been active on the Stanford campus since 1891, when the university first opened. In 1944, University President Donald Tresidder banned all Stanford sororities due to extreme competition. [180] However, following Title IX , the Board of Trustees lifted the 33-year ban on sororities in 1977. [181] Students are not permitted to join a fraternity or sorority until Spring quarter of their freshman year. [182]
As of 2016 Stanford had 31 Greek organizations, including 14 sororities and 16 fraternities. Nine of the Greek organizations are housed (eight in University owned houses and one, Sigma Chi , in their own house [though the land is the University] [183] ). Six chapters were members of the African American Fraternal and Sororal Association, 11 chapters were members of the Interfraternity Council, 7 chapters belonged to the Intersorority Council, and 6 chapters belonged to the Multicultural Greek Council. [184]

Student groups
As of 2014 Stanford had 650 student organizations. [187] Groups are often, though not always, partially funded by the University via allocations directed by the student government organization, the ASSU. These funds include "special fees", which are decided by a Spring Quarter vote by the student body. Groups span from Athletic/Recreational (see section on Athletics ), Careers/Pre-professional, Community Service, Ethnic/Cultural, Fraternities/Sororities, Health/Counseling, Media/Publications, Music/Dance/Creative Arts (see section on Arts ), Political/Social Awareness to Religious/Philosophical.
The Stanford Daily is the daily newspaper and has been published since the University was founded in 1892. [188] The Stanford Review is a conservative student newspaper founded in 1987. [189] The student-run radio station, KZSU Stanford 90.1 FM, features freeform music programming, sports commentary, and news segments; it started in 1947 as an AM radio station. [190]
Students run SUpost.com , an online marketplace for Stanford students and alumni, in partnership with Stanford Student Enterprises (SSE) and the Stanford Pre-Business Association. [191] The latter is intended to build connections among industry, alumni, and student communities. Stanford Marketing is a student group that provides students hands on training through research and strategy consulting projects with Fortune 500 clients, as well as workshops led by people from industry and professors in the Stanford Graduate School of Business . [192] [193] Stanford Finance provides mentoring and internships for students who want to enter a career in finance. The Business Association of Stanford Entrepreneurial Students (BASES), is one of the largest professional organizations in Silicon Valley, with over 5,000 members. Its goal is to support the next generation of entrepreneurs. Stanford Women In Business (SWIB) is an on-campus business organization consisting of over a board of 40 and 100 active members. Each year, SWIB organizes over 25 events and workshops, hosts a winter and spring conference, and provides mentorship and spring quarter internships. StartX is a non-profit startup accelerator for student and faculty-led startups [194] that over 12% of the study body has applied to. It is staffed primarily by students.
Other groups include:

Safety
Stanford's Department of Public Safety is responsible for law enforcement and safety on the main campus. Its deputy sheriffs are peace officers by arrangement with the Santa Clara County Sheriff's Office . [203] The department is also responsible for publishing an annual crime report covering the previous three years as required by the Clery Act . [204] Fire protection has been provided by contract with the Palo Alto Fire Department since 1976. [205]
Murder is rare on the campus though a few of the cases have been notorious including Theodore Streleski 's murder of his professor in 1978 and the unsolved 1974 murder of Arlis Perry in Stanford Memorial Church. [206]
In 2014, Stanford University was the tenth highest in the nation in "total of reports of rape" on their main campus, with 26 reports of rape. [207]
In Stanford University's 2015 Campus Climate Survey, 4.7 percent of female undergraduates reported experiencing sexual assault as defined by the university and 32.9 percent reported experiencing sexual misconduct. [208] According to the survey, 85% of perpetrators of misconduct were Stanford students and 80% were men. [208] Perpetrators of sexual misconduct were frequently aided by alcohol or drugs, according to the survey: "Nearly three-fourths of the students whose responses were categorized as sexual assault indicated that the act was accomplished by a person or person taking advantage of them when they were drunk or high, according to the survey. Close to 70 percent of students who reported an experience of sexual misconduct involving nonconsensual penetration and/or oral sex indicated the same." [208] Associated Students of Stanford University and student and alumni activists with the anti-rape group Stand with Leah criticized the survey methodology for downgrading incidents involving alcohol if students did not check two separate boxes indicating they were both intoxicated and incapacity while sexually assaulted. [208] Reporting on the Brock Turner rape case, a reporter from The Washington Post analyzed campus rape reports submitted by universities to the U.S. Department of Education, and found that Stanford was one of the top ten universities in campus rapes in 2014, with 26 reported that year, but when analyzed by rapes per 1000 students, Stanford was not among the top ten. [209]
Early in the morning of January 18, 2015, a woman visiting campus to attend a party at the Kappa Alpha fraternity was raped by Brock Turner, a freshman who had a swimming scholarship. The rape was interrupted by two Swedish graduate students. [210] Stanford immediately referred the case to prosecutors and offered the woman counseling, and within two weeks had barred Turner from campus after conducting an investigation. [211] Turner was convicted on three felony charges in March 2016 and in June 2016 he received a jail sentence of six months and was declared a sex offender, requiring him to register as such for the rest of his life; prosecutors had sought a six-year prison sentence out of the maximum 14 years that was possible. [212] The case and the relatively lenient sentence drew nationwide attention. [213] The judge in the case, a Stanford graduate, faced a recall effort in the aftermath. [210]
In February 2015, Elise Clougherty filed a sexual assault and harassment lawsuit against venture capitalist Joe Lonsdale . [214] [215] Lonsdale and Clougherty entered into a relationship in the spring of 2012 when she was a junior and he was her mentor in a Stanford entrepreneurship course. [215] By the spring of 2013 Clougherty had broken off the relationship and filed charges at Stanford that Lonsdale had broken the Stanford policy against consensual relationships between students and faculty and that he had sexually assaulted and harassed her, which resulted in Lonsdale being banned from Stanford for 10 years. [215] Lonsdale challenged Stanford's finding that he had had sexually assaulted and harassed her and Stanford rescinded that finding and the campus ban in the fall of 2015. [216] Clougherty withdrew her suit that fall as well. [217]

People
As of late 2014, Stanford had 2,118 tenure-line faculty, senior fellows, center fellows, and medical center faculty. [5]

Award laureates and scholars
Stanford's current community of scholars includes:
Stanford's faculty and former faculty includes 31 Nobel laureates , [5] as well as 19 recipients (22 if visiting professors and consulting professors included) of the Turing Award , the so-called "Nobel Prize in computer science", comprising one third of the awards given in its 44-year history. The university has 27 ACM fellows. It is also affiliated with 4 Gödel Prize winners, 4 Knuth Prize recipients, 10 IJCAI Computers and Thought Award winners, and about 15 Grace Murray Hopper Award winners for their work in the foundations of computer science. Stanford alumni have started many companies and, according to Forbes , has produced the second highest number of billionaires of all universities. [222] [223] [224]
13 Stanford alumni have won the Nobel Prize . [225] [226] [227] As of 2016, 116 Stanford students have been named Rhodes Scholars . [228]

See also

Notes
WebPage index: 00093
Boris Tadić
Boris Tadić ( Serbo-Croatian pronunciation: [bǒris tǎdiːt͡ɕ] , Serbian Cyrillic : Борис Тадић ; born 15 January 1958) is a Serbian politician who served as President of Serbia from 2004 to 2012. He was elected to his first term on 27 June 2004, and was sworn into office on 11 July. He was re-elected for a de facto [a] second term on 3 February 2008 and was sworn in on 15 February. He resigned on 5 April 2012 in order to trigger an early election. Prior to his presidency, Tadić served as the last Minister of Telecommunications of the Federal Republic of Yugoslavia and as the first Minister of Defence of Serbia and Montenegro . He is a psychologist by profession.
Tadić was member of the Democratic Party since its establishment in 1990, and its president since 2004. Following his defeat in the 2012 presidential election and poor party ratings, he stepped down in November 2012, to take the position of the party's Honorary President. After a split with the new leadership in January 2014, Tadić left the Democratic Party and formed his own New Democratic Party (later renamed Social Democratic Party ) for upcoming 2014 parliamentary election .
Tadić strongly advocates close ties with the European Union and Serbia's European integration . [1] He is widely regarded as a pro-Western [2] [3] [4] leader but who also favors balanced relations with Russia , the United States and the EU . [5]

Early life
Boris Tadić was born in Sarajevo , the capital of the People's Republic of Bosnia and Herzegovina , a republic within the Federal People's Republic of Yugoslavia . His father, Ljubomir , was a philosopher and a member of the Serbian Academy of Sciences and Arts . His mother, Nevenka , is a psychologist. His maternal grandfather and six other relatives were killed by the Croatian Ustaše during World War II at the Jasenovac concentration camp . [6]
The Tadićs are descendants of the Serb clan of Piva , in the region of Old Herzegovina, Montenegro . The family's Slava (Patron Saint) is Saint John the Baptist . [7] His parents frequently relocated between various cities and had moved to Sarajevo from Paris, where they pursued their doctoral studies, only a few days prior to his birth. Tadić and his family moved to Belgrade when he was three years old, and his father got a job at the newspaper Liberation ( Oslobođenje ) . [8] [9]
Tadić finished Pera Popović Aga (today Mika Petrović Alas ) [10] elementary school and matriculated at the First Belgrade Gymnasium in Dorćol . During his teenage years he played water polo for VK Partizan , but had to quit due to injuries. He graduated from the University of Belgrade Faculty of Philosophy with a degree in psychology, specifically social psychology in the department of clinical psychology .
He was arrested during his studies for "participating in the demonstrations demanding that arrested students be released from detention" and spent one month in penal labour prison in Padinska Skela . [11] He worked as a journalist, military clinical psychologist and as a teacher of psychology at the First Belgrade Gymnasium. [10] Until 2003, Tadić also worked at the Faculty of Drama at the University of Belgrade as a lecturer of political advertising.

Political career
Tadić joined the Democratic Party, founded in 1990. The Democrats received seven seats in the National Assembly that year.
Boris Tadić founded the Centre for modern skills (Centar modernih veština, CMV) in 1998, a NGO dealing with political and civil education, and the development of the political culture and dialogue. [12]
The Democratic Party was part of the Democratic Opposition of Serbia (DOS), a grand coalition of anti- Milošević parties which played a key role in his downfall in 2000. Tadić served two terms as the deputy leader of the Democratic Party before he was elected as the new leader in 2004 following the assassination of Zoran Đinđić . As of November 2012, Tadic has publicly announced that he will abandon his position as leader of the Democratic Party due to his declining support across Serbia. [13]
Tadić served as Minister of Telecommunications in the Federal Republic of Yugoslavia in 2000 and as Minister of Defence from 17 March 2003 until he started his presidential campaign. He served as an MP of the Democratic Party in the parliament and later on as vice-speaker. He served as the leader of the Democratic Opposition of Serbia coalition in the Parliament of Serbia and Montenegro in 2003 and as leader of the Democratic Party in the Parliament of Serbia in 2004. As an MP he was a member of the science and technology parliamentary committee.
The assassination of Zoran Đinđić in March 2003 led to a leadership convention of the Democratic Party in 2004, which was won by Tadić against Zoran Živković . [14] He was reelected in regular leadership convention in 2006.

Presidency

President of Serbia within state union (2004–2008)
Tadić, as the newly elected Democratic Party leader, was chosen as the candidate for the presidential election. He defeated Tomislav Nikolić of the nationalist Radical Party in the run-off of the 2004 presidential election with 53% [15] of the vote. He was inaugurated on 11 July of that year. [16]
During the 2004 election campaign, Tadić promised to form a new special institution called the People's Office. The People's Office of the President of the Republic was opened on 1 October 2004. The role of the People's Office is to make communication between the citizens and the President easier, and to cooperate between other state bodies and institutions, in order to enable the citizens of Serbia to exercise their rights. The People's Office of the President is divided into four divisions: Legal Affairs Division, Social Affairs Division, Projects Division and General Affairs Division. The first Director of the People's Office was Dragan Đilas . When he joined the Government of Serbia as the Minister in charge of the National Investment Plan in 2007, Tatjana Pašić became the new Director. [17]
Tadić advocated cooperation and reconciliation of the former Yugoslav countries, strained by the burden of the Yugoslav Wars of the 1990s. On 6 December 2004, Boris Tadić made an apology in Bosnia and Herzegovina to all those who suffered crimes committed in the name of the Serbian people. [18] In July 2005, Tadić visited the Bosnian town of Srebrenica on the 10th anniversary of massacre of 8,000 Muslim men and boys by Bosnian Serb forces. [19] In 2007, Tadić issued an apology to Croatia for any crimes committed in Serbia's name during the war in Croatia . [20]
Tadić presided during the independence referendum in Montenegro (2006) . He was the first foreign head of state to visit Montenegro after it became independent on 8 June, and promised to continue friendly relations. Serbia declared independence as well, and Tadić attended the first raising of the flag of Serbia at the United Nations Headquarters in New York. [21]
On 6 September 2007, Tadić was a signatory of the agreement that led to the formation of the Council for Cooperation between Serbia and Republika Srpska , together with Milorad Dodik and Vojislav Koštunica . [22] In late 2007, he stated that Serbia does not support a break-up of Bosnia and Herzegovina and that, as a guarantor of the Dayton Accords that brought peace to Bosnia, he supports its territorial integrity. Tadić also said that Serbia supports the accession of Bosnia and Herzegovina to the EU , [23] and NATO . [24]
As President, Tadić has pursued a pro-Western foreign policy . On 28 September 2005, he met with Pope Benedict XVI in Vatican City, making him the first Serbian head of state to be granted an audience with a pope. This helped improve traditionally strained Catholic- Orthodox relations. [25]
On 22 June 2007, Tadić presided over the 1000th meeting of the Council of Europe Committee of Ministers in Belgrade. [26]
Contrary to his earlier decision in the 2004 Kosovan parliamentary election , Tadić stated that he had no right to call on Kosovo Serbs to vote in the 2007 Kosovo parliamentary election , as the standards he asked for in 2004 were not reached. [27]

Reelection campaign
Boris Tadić has advocated an early presidential election that is required under constitutional law, since the adoption of the new Constitution of Serbia , after the successful constitutional referendum in October 2006. On 13 December 2007, the speaker of the Parliament, Oliver Dulić , set the election date for 20 January 2008. The Democratic Party submitted the candidacy of its leader to the Republic Electoral Commission on 21 December. The re-election campaign was led under the slogan ”For a strong and stable Serbia“ in the first round and "Let's win Europe together!" in the second. Tadić advocated integration of Serbia into the European Union but also territorial integrity of Serbia with sovereignty over Kosovo and Metohija .
Tadić received support from G17 Plus and Sanjak Democratic Party , partners from the Government. He also received support of various national minority parties including Hungarian and Romani parties. He received 1,457,030 votes (35.39 percent) in the first round. In the second round on 3 February 2008, he faced Tomislav Nikolić and won the election with 2,304,467 votes (50.31 percent). [28]

President of Serbia (2008–2012)
Tadić was sworn in at the inauguration ceremony on 15 February 2008 in the National Assembly of Serbia . [29]
The Assembly of Kosovo proclaimed a declaration of independence on 17 February 2008. [30] Boris Tadić urged a United Nations Security Council meeting to react urgently and annul the act. He also said that Belgrade would never recognise the independence of Kosovo and would never give up the struggle for its legitimate interests. [31] Russia backed Serbia's position and President Vladimir Putin said that any support for Kosovo's unilateral declaration is immoral and illegal. [32]
On 21 February Tadić met President of Romania Traian Băsescu in Bucharest where he thanked him for Romanian support and stated that "Serbia will not give up its future in Europe".
Tadić said that Serbia would never recognise an independent Kosovo. [33] He stated that the problem of Kosovo was not solved by the unilaterally declared independence and that the decade-long problems between Serbs and Albanians still exist. He called the international institutions to find a solution within the UN Security Council , for the continuation of negotiations. [34] He also called a decision made by the US President George W. Bush to send arms to Kosovo “bad news.” [35]
Tadić also said that Serbia would not accept the legality of the EU's planned policing and judiciary mission for Kosovo. [36] On 25 February 2008, Boris Tadić met with Dmitry Medvedev and Sergei Lavrov in Belgrade where Medvedev stated that “We proceed from the understanding that Serbia is a single state with its jurisdiction spanning its entire territory, and we will adhere to this principled stance in the future, We have made a deal to coordinate together our efforts in order to get out of this complicated situation”. Agreement on the South Stream pipeline was also signed during this visit. [37] [38]
On 5 April 2008, Tadić called the acquittal of Ramush Haradinaj "disgraceful because of the innocent victims" and demanded the ICTY to appeal. He said that Serbia wishes to help the Tribunal to collect evidence "because Haradinaj’s place is in prison". He said that former Hague Chief Prosecutor Carla Del Ponte had said that witnesses in the case against Haradinaj had been intimidated and even murdered to prevent them testifying to his crimes. [39]
Following the Republic of Kosovo's formation of the Kosovo Security Forces in January 2009, he sent protest letters both to the [ clarification needed ] and NATO Secretaries-General. The letter states that Serbia views those forces as an illegal paramilitary organisation that constitutes a threat to the country’s security and a danger to peace and stability in the Western Balkans. Tadić drew attention to the fact that the KSF were formed on the basis of the Ahtisaari Plan that was never adopted by the Security Council and added that the creation of these forces constitutes a breach of the Serbian Constitution and international law, which is why they should be disbanded. He called for the demilitarisation of Kosovo. [40]
On 13 March 2008, President Tadić signed a decree dissolving the country's parliament and slating early parliamentary elections for 11 May. [41] Boris Tadić gathered a large pro-EU coalition around his Democratic Party and G17 Plus for the Serbian parliamentary election in 2008, named “ For a European Serbia – Boris Tadić”. The coalition list was led by Dragoljub Mićunović and it also included Sanjak Democratic Party , Serbian Renewal Movement and League of Social Democrats of Vojvodina . [42] The coalition won 38% of the vote, more than any other list. [43] He condemnеd remarks regarding the election made by Javier Solana and Pieter Feith and called on the European Union not to interfere with Serbian elections. [44] [45]
Tadić said that he was ready, authorised as per Vienna Convention , [46] to sign the Stabilisation and Association Agreement (SAA) with the European Union if it were offered on 28 April, but not at the price of recognising Kosovo's unilaterally declared independence. [47] Tadić attended the signing of the SAA ceremony in Luxembourg on 29 April, where the Deputy Prime Minister Božidar Đelić signed the document on behalf of Serbia, as per the authorisation of the Government from December 2007. He was opposed by the then Prime Minister Vojislav Koštunica who believed that Serbia ought not to sign any agreements with the European Union. [48] While, on 1 May, Koštunica said that Russian Foreign Minister Sergei Lavrov was right when he said that the SAA should have been signed, he nonetheless vowed to annul the agreement after the parliamentary elections, calling it "not in the service of Serbia's territorial integrity." [49] [50]
On 27 June 2008, Tadić named Mirko Cvetković for the new Prime Minister , following the victory of his party coalition in parliamentary election that took place in May. Cvetković was sworn in after giving the oath in the National Assembly on 7 July 2008. [51]
Following the 2008 South Ossetia War , and Russian recognition of Abkhazia and South Ossetia , Tadić refused to follow suit, saying that even though he respects the Russian support to Serbia regarding Kosovo, "Serbia is not going to recognise these so-called new countries". He stated that "Serbia is not going to do something that is against our interest, because we are defending out territorial integrity and sovereignty by using international law" and that by constitution he must defend the interests of Serbia, and not the interests of any other country in the world. [52] [53]
Tadić invoked his constitutional powers of Commander-in-Chief of the Military of Serbia and dismissed the Chief of the General Staff Zdravko Ponoš on 30 December 2008. Ponoš made public accusations against the Defence Minister Dragan Šutanovac in the media. It was also revealed that he ignored the minister and has not submitted a single report in a year. [54] [55]
In April 2009, Tadić announced a constitutional reform proposal. His initiative includes the proposal to reduce the number of the National Assembly members from 250 to 150 to better reflect the size of the country followed by changes in law on party registration and financing in order to consolidate similar parties and limit those with little support which should bring Serbia closer to a two-party system . The second proposed amendment would change the administrative division of Serbia by dividing it into more autonomous regions in order to achieve a more balanced development. This change would lead to Serbia's being divided into seven regions instead of the current asymmetrical division which includes two autonomous provinces but where the majority of the territory has no special autonomy. [56] [57] [58] However, the proposals haven't came to fruition.
During his visit to Serbia in May 2009, Lech Kaczyński , President of Poland , stated that he doesn't agree with the decision of the Polish Government to recognise the independence of Kosovo and that he as the President "favours the policy pursued by Serbian President Boris Tadić". They also discussed energy, particularly Europe's dependence on natural gas from just one source, and agreed that there is a need for a common EU energy policy that should also include the Balkan states. [59]
On 21 May 2009, Dragan Marić, a former businessman who was revolted over the court decision in his dispute with the national air carrier Jat Airways , entered the Presidency office carrying two hand grenades and seeking an out-of-court settlement signed by President or Government. Members of the Battalion of Military Police Cobras , providing security to the President of Serbia, managed to take one of the grenades immediately and isolate the attacker, however the perpetrator removed the pin from the second grenade and threatened to detonate it by releasing the lever. The negotiations were handled by the special team of the Serbian Ministry of Internal Affairs , supported by the officials of the Ministry of Justice, and lasted for several hours until the man was disarmed and arrested. After the incident, Tadić, who was present in the secured area of the building, congratulated the police and army special units, the security and negotiation team for doing a terrific job, peacefully and with no casualties and also said that problems, no matter what kind, cannot be resolved by force and by jeopardising citizens' lives. [60] [61]
In October 2009, after the Serbian national team qualified for the 2010 FIFA World Cup in South Africa, Boris Tadić and other Serbian ministers celebrated at the end of the match in Belgrade's Red Star Stadium by toasting the winning team with a glass of champagne. It is illegal to consume alcohol at Serbian sporting events to stop violence. Tadić pleaded guilty, saying "I did not know that consumption of alcohol, even if only for a toast, has been forbidden so I fully take responsibility for the violation" and was fined € 400. [62]

Advisors
Advisors to the President of the Republic carry out the analytical, advisory and other corresponding tasks for the needs of the President of the Republic as well as other expert tasks in relations of the President with the Government and the Parliament. [63]
Chief of Staff is Miodrag Rakić . Acting Secretary General of the Office of the President was Vladimir Cvijan from 2008 to 2010.
Previous advisors who served from 2005 to 2008 are Biserka Jevtimijević Drinjaković (economic issues), Vladimir Cvijan (legal issues) and Dušan T. Bataković and Leon Kojen (political issues). Most of the former advisors are now serving as directors of public enterprises and ambassadors.

Post-presidency

2012 elections and aftermath
On 5 April 2012, a day after announcing his decision, Tadić submitted his resignation to the speaker of parliament, Slavica Đukić-Dejanović , who then took over as acting president. This led to bringing forward the presidential election [64] to coincide with the parliamentary election on 6 May. [65]
Amid controversy regarding the legitimacy of the third mandate and the legality of certain decisions, [66] incumbent Tadić lost the presidential elections to his opponent, Tomislav Nikolić from the Serbian Progressive Party . Nikolić has won 49.7% of the votes in the runoff vote, versus 47% for Tadić, according to data of the Serbian Center for Free Elections and Democracy. [67] The result was considered somewhat of a surprise, as Tadić had exploited his resignation for the presidential vote to coincide with parliamentary elections.
Tadić was criticized both inside and outside the party for the manoeuvre of calling early presidential elections without a clear goal, and entering them with over-confidence. [68] Dragan Đilas , long-time mayor of Belgrade and one of rare Democrats who remained in his seat after 2012 elections, announced that he would challenge Tadić in December party elections. After a period of gauging the odds, it became obvious that Đilas would receive majority support. Before the electoral conference, Đilas and Tadić reached a face-saving agreement whereby Tadić would step down from the race and remain the party's honorary president, and Đilas thus became the only major candidate. [69] Đilas was elected president of the Democratic Party on 25 November 2012. [70]

New Democratic Party
In early 2014, after losing the internal reelections in the Democratic Party to Dragan Đilas [71] Tadić resigned from his position of honorary president and left the party. [72] Subsequently, a number of prominent party members all across defected from the party and stated that they intend to form a list in the forthcoming parliamentary election with Tadić as its leader. So far, coalition has been agreed with the League of Social Democrats of Vojvodina . A political party, most likely named New Democratic Party , is in the process of forming and registration. [73]

Personal life
Tadić's sister, Vjera, is a psychologist and currently teaches psychology in the First Belgrade Gymnasium . Besides his native language , Boris Tadić is reportedly fluent in English, French, Italian and German. [74]
He was previously married to journalist Veselinka Zastavniković from 1980 to 1996, but they divorced, having had no children. [75] They met in the 1970s. [76] Throughout their marriage they were actively involved in various socio-political activities including protests and petitions against human-rights abuses and so-called 'verbal delict' in SFR Yugoslavia in the 1980s as well as anti- Milošević protests in the 1990s.
Tadić is married to Tatjana Rodić, with whom he has two daughters. [77]
He is 6 feet 2 inches (188 cm) tall. [78]

Honours and awards
On 4 August 2007, Tadić was awarded the "European Prize for Political Culture" that is given by the Swiss Foundation Hans Ringier of the Ringier Publishing House in Locarno . Previously it was awarded to Jean-Claude Juncker . Tadić decided to donate the financial part of the award for humanitarian purposes for the maternity hospital in a town near Gračanica . [79] [80]
Tadić received the Quadriga award in September 2008, an annual German award sponsored by Werkstatt Deutschland, a non-profit organisation based in Berlin. The award recognises four people or groups for their commitment to innovation, renewal, and a pioneering spirit through political, economic, and cultural activities. The other three winners were Wikipedia, represented by Jimmy Wales ; Eckart Höfling , Franciscan and director; and Peter Gabriel , musician and human rights activist. The award given to Tadić was named The Courage of Perseverance and was presented by Heinz Fischer , the Federal President of Austria . [81] In March 2010, Tadić received the Steiger Award Europe of the Rhine-Ruhr for "respectfulness, openness, humanity, and tolerance". [82]
In 2011, he won the North-South Prize awarded by the Council of Europe and distinguishing his deep commitment and actions for the promotion and protection of human rights, defense of pluralist democracy and the strengthening partnership and the North-South solidarity.
In 2012, in Brussels, Boris Tadic, together with the ex-President of Croatia Ivo Josipovic , has been awarded with the European Medal of Tolerance by the European Council on Tolerance and Reconciliation , in recognition of the Balkan statesmen’s “significant contribution to promoting, seeking, safeguarding or maintaining Tolerance and Reconciliation on the European continent”. [83]
WebPage index: 00094
Asturian language
WebPage index: 00095
Michael Scott ( The Office )
Michael Gary Scott is a fictional character in NBC 's The Office , portrayed by Steve Carell and based on David Brent from the original British version of the program. Michael is the central character of the series, serving as Regional Manager of the Scranton branch of paper distribution company Dunder Mifflin Inc. from season 1 through 7. However, he leaves Dunder Mifflin temporarily to form the Michael Scott Paper Company during the late end of the 5th season and shares a co-managerial position with Jim Halpert during a 6th season arc from " The Meeting " to " The Manager and the Salesman ". In the end of the 7th season, he proposes to HR representative Holly Flax and moves to Colorado to take care of her aging parents, leaving the manager position to Deangelo Vickers in " Goodbye, Michael ", to Andy Bernard in season 8 after Vickers becomes brain dead, and ultimately to Dwight Schrute in season 9.

Casting
All original series characters were adapted for the U.S. version. NBC programmer Tracy McLaughlin suggested Paul Giamatti to producer Ben Silverman for the role of Michael Scott, but the actor declined. Martin Short , Hank Azaria , and Bob Odenkirk were also reported to be interested. [2] In January 2004, Variety reported Steve Carell of the popular Comedy Central program The Daily Show with Jon Stewart , was in talks to play the role. At the time, he was already committed to another NBC midseason replacement comedy, Come to Papa . [3] Due to Carell being unavailable, Bob Odenkirk was selected as Michael Scott and was part of the cast presented to NBC executives. [4] However, Come to Papa was quickly canceled, allowing Carell to commit to The Office . Carell later stated he had only seen about half of the original pilot episode of the British series before he auditioned. He did not continue watching for fear that he would start copying Gervais' characterizations. On the audio commentary of The Pilot episode, director Ken Kwapis says that Carell's unfamiliarity with the British version of The Office and their experience working together on Watching Ellie influenced his being cast as Scott. [5]
Two supporting roles in films helped get the attention of audiences: Bruce Almighty , in which Carell plays Evan Baxter (an arrogant rival to Jim Carrey 's character), who gets a humorous comeuppance while co-anchoring the news. In Anchorman: The Legend of Ron Burgundy , Carell plays another news personality, as slow-witted weatherman Brick Tamland. Although the series premiered to mediocre ratings, NBC renewed it for another season because of the anticipated success of Carell's movie The 40-Year-Old Virgin , [6] and the show subsequently became a ratings success. Carell won a Golden Globe and Television Critics Association award in 2006 for his role. He also received Emmy nominations in 2006, 2007 and 2011 for his work in the series. Although The 40-Year-Old Virgin was a surprise success, Carell revealed in an interview with Entertainment Weekly that he had no plans to leave The Office . However, on the BBC Radio 5 Live Film Review show, he stated in an interview that his time on the show would probably end after his contract ran out after Season 7. [7] This was later confirmed on June 28, 2010, when Carell confirmed that the seventh season of the show was to be his last after his contract with NBC expired.

Character Information, Arc, and Backstory

Biography
Michael's hometown is also Scranton, Pennsylvania. His birthdate is March 15, 1964, as described in " Michael's Birthday " and " Dream Team ". He came from a relatively difficult childhood of loneliness, describing to Jan's child Astrid that she will be able to survive not having a father figure around because he was in that position as a child. In " Diversity Day ", Michael claims to be of English, Irish, German and Scottish ancestry. He also claims to be two-fifteenths Native American. He has mentioned a stepfather, Jeff, whom he despises. In " Nepotism ", it is revealed that Michael had a half-sister, from whom he was estranged from 1995 through 2010. As a consequence of their reunion, Michael hires his nephew Luke as an intern for the office, but eventually confronts the incompetent and rude Luke and ends up spanking him in front of the office, leading Luke to burst into tears and quit.
In the episode " Take Your Daughter to Work Day ", Michael makes the claim that he was a child star on a kids' show called Fundle Bundle, however, it becomes clear that he simply appeared on the show as one of many guest children who usually watched from home. In the old recording being played, he speaks touchingly about what he wanted when he grew up: get married, have "100 kids" so he could then have "100 friends" and none of them could say no to being his friend. Michael did not attend college, having lost all his tuition money in a pyramid scheme .
He was hired as a salesman at Dunder Mifflin in the 1990s, where he proved to be extremely effective. Dwight praised him in a deleted scene from " The Coup " for winning consecutive awards for best salesman. In " Two Weeks ", he claims to have acquired half of the Scranton branch clientbase. In " The Client ", he impresses his then-manager, Jan Levinson-Gould , by singlehandedly acquiring an important client through somewhat unorthodox methods. Both Pam Halpert and Ryan Howard are impressed watching him make sales and negotiate their contracts when working in The Michael Scott Paper Company. Even Jim Halpert concedes that he might never become as good a salesman as Michael in " Koi Pond ".
The skills that made him successful as a salesman, however, are not effective when applied to managerial duties and Michael is shown to be ill-suited to that position, injecting a lot of his personal feelings into the work environment. During a candid conversation in " The Fire ", Michael tells Ryan that he became a salesman because he loved to make friends and, after being promoted to regional manager at a young age, continued to treat work-related relationships as personal friendships which he acknowledges is more difficult because his colleagues are all lower than him in the workplace's hierarchy. He seems to have few relationships outside the office. In his interactions with other characters, he is shallow, callous, ignorant and unaware of basic social norms. He tends to overestimate his own importance in the eyes of his co-workers and cannot understand why they do not seem to have much fun at work, as he believes an office to be the "place where dreams come true." However, Michael is somewhat loyal to the company and honestly tries to help his employees when he thinks they are having a problem. Michael has been at Dunder Mifflin (as of "Michael's Last Dundies") 9,986,000 minutes, meaning he would have been working at Dunder Mifflin since May 6, 1992.
Michael's constant desire to be the center of attention often manifests itself in selfish behavior. For example, when he burns his foot in " The Injury ", he expects Pam and Ryan to tend to his needs, despite Dwight's much more serious concussion. When invited to be an usher in " Phyllis's Wedding ", he assumes that his participation will be the high point of the ceremony and pouts when he is upstaged by Phyllis' elderly father, eventually giving an insulting and overly familiar toast that gets him banned from the reception altogether. His desire to be liked often leads him to make unwise decisions or unfeasible promises without considering the consequences, only to back out when they result in an undesirable comeuppance. Michael appears to emphasize moments of sympathy or civility directed at him by his co-workers (mostly Jim) and inflates their importance in order to compensate for his loneliness.
Michael is irresponsible with his finances, and at one point is so heavily in debt he has to take up a second job as a telemarketer . Oscar makes a chart of Michael's spending habits and chides him for spending too much money on things "nobody ever needs" like multiple magic sets and professional bass fishing equipment. Eventually, Michael is forced to declare bankruptcy (which he thinks requires only standing up and shouting "I declare bankruptcy!")
Due to his overall lack of common sense, Michael can withstand significant abuse from his peers and is often the butt of jokes. He is quick to take offense when he realizes he is being wronged and his response is often disproportionate to the harm suffered; similarly, he tends to unintentionally offend people, but will usually sincerely apologize on the rare occasion that he realizes he has inadvertently insulted someone, the most notable example being in " Gay Witch Hunt " when he cries upon realizing his use of the term "faggy" hurt Oscar's feelings. Even though he is generally oblivious to criticism, derision and sarcasm, Michael has some limits to his patience, and leaves to question the extent of offense that he can actually acknowledge (demanding professional respect from Stanley Hudson in " Did I Stutter? " or standing up to the employees in favor of Holly in " Business Ethics ").
In " The Meeting ", it is shown that Michael does not aim for his employees' betterment or his own, thinking that this would put his job at jeopardy; he unwittingly turns down a promotion that would put Jim in his position, choosing the status quo over his employees' ambitions, and sabotaging Jim with a bad recommendation because he mistakenly believes that Jim's promotion to his job would lead to his firing. He does, however, concede to a co-managerial position with Jim to avoid losing him.

Interests
Michael's catchphrase is " That's what she said! ", a sexually suggestive double entendre he uses even in the most inappropriate circumstances, including business meetings and legal depositions. Michael finds uttering the phrase so irresistible that in " Sexual Harassment " he is goaded into saying it just seconds after Jan Levinson and a lawyer from Corporate specifically ask him not to do so.
He has diverse interests in media. Song parody writing is often referred to: in " Goodbye, Toby ", he relates the titles of two of his songs, "Beers in Heaven" and "Total Eclipse of the Fart" , before singing a rendition of " Goodbye Stranger " as a departing gesture to Toby. He performs his parody of " The Chanukah Song " to reflect the Diwali celebration Kelly invites Michael to. In Dream Team , he comes up with "Achey Breaky Fart" and "My Stumps" during a brainstorming exercise. He hopes to finish the video production of his script, "Threat Level: Midnight", whose script was found and read by the office and whose finished movie (after ten years of production) was viewed in the seventh season episode of the same name.
He adores the theatrical stylings of Meryl Streep , describing her in " The Job " as the "best actor around," and mimics her character from The Devil Wears Prada after seeing the film. He adores Wikipedia and YouTube , although he doesn't seem to really understand how they work and believes them to be news media organizations. Michael also likes the music of Billy Joel , the movies Mean Girls , Million Dollar Baby , Die Hard , What a girl wants , and television series such as ALF , Entourage , The L Word and Queer as Folk . Michael tends to be a bit "behind" when it comes to popular culture references, such as when he refers to his then-girlfriend Jan's youthful male assistant as " James Van Der Beek " or in his numerous ringtones, including "My Humps," "Mambo Number Five" and "Salt N Pepa."
He appears to have a history of playing ice hockey and demonstrates his talent in " Michael's Birthday ", and mentions in " Dream Team " that in high school, after his math teacher told him he was going to flunk out, he went out the next day and "scored more goals than anyone in the history of the hockey team." He also has invited potential clients to " Wilkes-Barre/Scranton Penguins " games. On multiple occasions, Michael has also expressed interest in basketball even though he is terrible at it (in " The Fire ", " Basketball " and " Goodbye, Michael "). Michael is a Pittsburgh Pirates fan, and does not like the New York Mets. This appears in episode 6 season 1, when he is on a phone call with Jan Levinson-Gould. In addition, He has also been shown wearing a Pittsburgh Pirates cap.
Other interests include a pair of Levi's he refers to as his "fun jeans", which he has professionally dry cleaned and likely instituted Casual Friday for, according to Pam, in " The Convention ", his self-bought "World's Best Boss" mug he bought at Spencer Gifts , that he has duplicates of, and Chrysler automobiles. He drives a silver 2004 Sebring convertible for the first three seasons until he trades it in with Jan's Volvo for a shared Porsche Boxster in the episode " Money ". After their relationship, he drives a red PT Cruiser convertible and later a newer-model Sebring as a benefit of the buyout of the Michael Scott Paper Company to Dunder Mifflin in " Broke ". Michael enjoys planning fantasy entrepreneurial schemes that he would like to start, such as a men's shoe store called "Shoe La La", or another paper company simply called "Michael".

Personality and management style
Apart from his masterful salesmanship, Michael is lacking in almost any other skills, management or otherwise. Co-manager Jim Halpert once made a color graph of how Michael spends his time: 80% "distracting others," 19% "procrastination," and 1% "critical thinking", and added that he inflated the "critical thinking" percentage so people could actually see it on the graph. His laid-back approach more often results in lower than expected workplace productivity, particularly when Michael places his personal interests as a priority over work (such as his birthday, someone else's birthday, or his various seminars). To avoid being disciplined for his foolish actions, Michael often resorts to scapegoating employees to cover himself. Although his actions often lead to more problems for his employees, Michael believes that Scranton is "the cool, fun branch... like Animal House ," and is genuinely upset when the top salesman from the Utica office trashes Scranton in a phone call by saying it's "worse than Camden ".
Although his position as Regional Manager gives him broad decision-making authority on branch operations, he often places those responsibilities secondary to his desire to be friends with his employees. On the other hand, he also oversteps his authority by hosting events that Corporate disapproves of, such as The Dundies and a booze cruise .
It is revealed in the episode " The Duel " that, despite Michael's incompetence, the Scranton branch is the best-performing company branch, well ahead of Utica and Nashua. Michael is called to Corporate to answer the question, "What are you doing right?" After several minutes of Michael's inarticulate babble, his superiors concede that while Michael is definitely doing something right, they will probably never know exactly what. They send him on a lecture tour for Michael to spread his wisdom; instead, he wastes time and annoys the workers who have to listen to his drivel.
Despite his apparent ineptitude, Michael is prone to brief bouts of surprising insight and is shown to have a kind heart as he shows deep, family-like affection towards most of the people working for him in the Scranton branch. The staff initially finds Michael annoying but he grows on them and is given emotional goodbyes during his final days in Scranton. In the episode " Broke ", Michael displays self-awareness of his inability to keep secrets when he, Pam and Ryan all agree not to let Dunder Mifflin know that the Michael Scott Paper Company is broke, yet moments later he is seen bent over and in a near panic when he admits that he's afraid he won't be able to keep himself from letting the truth slip. Later in the same episode, he displays a remarkable ability to negotiate with Dunder Mifflin and convince the company to hire himself as well as Pam and Ryan back with full benefits.
In the episode " Business School ", Michael is one of the few Dunder Mifflin employees to show up to Pam's gallery showing. Unlike Oscar and his then-boyfriend Gil, who had shown up and were critical of Pam's drawings (which Pam overheard), Michael immediately marvels at her work and asks to buy Pam's drawing of their office building. In a moment of sincere kindness, Michael tells Pam that he is very proud of her. Pam begins to tear up and hugs Michael, who also seems touched by Pam's reaction. During " The Seminar ", Michael advises a fledgling Andy Bernard to step up and begin selling at a seminar Andy's hosting, in order to boost his sagging sales.
While Michael's habits of joking around and treating professional colleagues as personal friends are often inappropriate for management, they are, along with his near encyclopedic knowledge of the paper industry, remarkably effective when utilized to sign clients, as seen in " The Client " and " Heavy Competition ." In " Initiation ", Pam balks at Michael's sugar-fueled phone calls to a local business, but later realizes that his silly conversation (including a Bill Cosby imitation) helped to secure a major sale for Dunder-Mifflin. He remembers people through word association starting with nicknames such as "baldy" and "fatso" which, while offensive to the individuals in question, works to his advantage. Although he is unsuccessful using his sales methods as a telemarketer in " Money ", his social interactions with coworkers suggest that he would be a more popular presence in an office of peers as opposed to subordinates.
It seems clear that Michael loves Dunder Mifflin very much, but he has also shown signs that he sometimes feels underappreciated, given his long history with the company. In the episode " The Negotiation ", Michael discovers that he is making only slightly more money than Darryl, the warehouse manager, even though at that point he had worked for the company for 14 years and was in a management position. Later in the episode he drives to New York and demands a raise from Jan at corporate headquarters.
In the episode " New Boss ", after Dunder Mifflin's CFO David Wallace ducks Michael's calls throughout the day and Michael's 15-year anniversary party is cancelled by Michael's new superior, Charles Miner, Michael drives to New York to confront Wallace. Citing his long history of service with the company and his many sacrifices for Dunder Mifflin, Michael asks that he be treated more respectfully. Wallace, seeing Michael's heartfelt openness, promises Michael his party and pledges to attend, as well. But Michael surprisingly recognizes that the CFO is just humoring him, and stuns Wallace by quitting his job.

Relationships
Michael tends to overestimate his importance to his employees, but despite constantly offending some of them, he has a close bond with them. Most of the employees have been the focus of Michael's jokes at one point or another, usually in reference to their race, sex, size, attractiveness, or sexual orientation. Examples of Michael's difficult relationship with his staff include getting slapped by Kelly for being racist, hitting Meredith with his car, getting kicked out of Phyllis and Bob's wedding, and outing Oscar to the entire office without his permission. They are, however, generally sympathetic to his shortcomings and, while regularly losing patience when he interrupts their workflow, often try to assist him with his personal problems.
Michael's relationship with the company warehouse employees is tense. He has a tendency to disrupt their daily work flow, and in a talking head interview, warehouse supervisor Darryl Philbin ( Craig Robinson ) explains that they have never been able to make a full year accident-free because of Michael's antics. CFO David Wallace tolerates Michael's antics because he values his loyalty to the company, but Michael offends CEO Allan and the rest of the executives during his only meeting with them.
Although many Dunder Mifflin employees are initially barely able to tolerate Michael, they gradually grow to appreciate his sincere intentions, even at times coming to find amusement in his sophomoric humor and behavior; this transition is most apparent in Pam Halpert , with whom he eventually develops a genuine friendship. His co-workers are overjoyed when Michael finds his soulmate in Holly Flax , participate in his romantic proposal to her and are shown to be emotional at his leaving Scranton to be with her. Jim Halpert even teared up while calling Michael "the best boss [he] ever had."

Dwight Schrute
Dwight has the most respect for Michael, viewing him as a model for success, and is thrilled when asked to handle any task given to him, however ill-conceived it may be. Although on the surface, Michael usually appears dismissive of Dwight and generally views him as a suck-up, he is genuinely hurt and angry at the few times when Dwight has deceived him, such as when Dwight went over Michael's head to vie for the manager's job or when Dwight refused to reveal office secrets to Michael's new company, the Michael Scott Paper Company. In the episode " Heavy Competition " of Season 5, Dwight steals Michael's Rolodex and finds his own business card, on the back of which, Michael had written (before leaving Dunder Mifflin): "Dwight Schrute, tall, beets". Michael also cares how Dwight feels about him. After Michael beats Dwight at his own dojo, Michael finds out that Dwight no longer wanted Michael as his primary contact in case of an emergency which causes Michael to promote him from "Assistant to the Regional Manager" to "Assistant Regional Manager", with a three-month probational period. Dwight told Michael in Season 6 that Michael's pathetic career path hurt Dwight and he regretted working for him instead of taking a fast-track job at Home Depot , but they buried their differences later on. When Deangelo Vickers arrives to be the new Branch Manager, Dwight is depressed that he didn't get the job after Michael recommended him, only to learn from Gabe that Michael didn't recommend him after all. At first Dwight is angry with Michael, but they make amends when Michael gives him a letter of recommendation on his final day at Dunder Mifflin. They end the day with a paintball fight behind the building. In the series finale , Michael is the best man at Dwight's wedding after Jim arranges it.

Ryan Howard
Michael has a one-sided mancrush on Ryan, which makes Ryan uncomfortable. Examples of this are when Michael gave Ryan a $400 iPod for the staff's Christmas Secret Santa exchange, despite an agreed upon office limit of $20 per person, and when in " The Dundies ", Michael gives Ryan the "Hottest in the Office" award. Michael appears to view Ryan both as an idolized friend, such as when he grew a goatee just because Ryan also grew one, and as a son, which he says he views Ryan as in " Secret Santa ". In " The Deposition ", a page from Michael's diary reveals he describes Ryan as being "just as hot as Jan, but in a different way." He is horrified when he finds out about Ryan's arrest for fraud, and much to the dismay of David Wallace, he re-hires Ryan despite the fact that he was fired by corporate office for his crime. He later earns Ryan's respect when Ryan sees Michael's talents as a salesman over the phone. In " Prince Family Paper ", Michael acknowledges that his heart has led him astray before, naming Jan and Ryan as examples of this. In Season 7, Michael shows the full gamut of his ties to Ryan: he heavily invests in WUPHF.com and won't agree to sell his majority shares when it's clear Ryan is incapable of saving the venture from bankruptcy, although Ryan exploits Michael's goodwill in their friendship to keep his venture going. But Ryan is later stunned when Michael later calls out his negative qualities and makes it clear Ryan only has nine days with no wiggle room before he fails everyone. Michael is later relieved when Ryan sells the project and everyone gets their money back. Ryan later appears as part of the group to help Michael brainstorm a perfect proposal to Holly.

Jim and Pam Halpert
Michael doesn't hesitate to compliment or criticize Pam for her looks and he frequently mentions her breasts. In the episode " Diwali " Michael mistakenly thinks that he and Pam have a connection, and is rejected when he tries to kiss her. Throughout their relationship, Pam has served as something of a shoulder angel for Michael by encouraging him to be more productive and discouraging his bad ideas, with varying degrees of success. She grows closer to Michael as he supports her goals in pursuing sales and art. Pam is visibly touched when, after many art show attendees dismiss her artwork, Michael is so impressed that he asks to buy her painting of their office building. Their relationship comes to a rocky point when he begins dating her mother Helene. This is only repaired after he breaks up with Helene and allows Pam to slap him in the face in the parking lot. He trusts and respects Jim, although when they were co-managers they clashed due to their polar-opposite management styles. In " Secret Santa ", Michael mentions that in a future vision he sees himself and his future wife living next door to Jim and Pam and that their children will play together. He often also refers to Jim as his best friend in the office, although, based on his impersonation of Jim using surfer slang in " Michael's Last Dundies ", does not have a very good understanding of his personality. While Jim and Pam are both shown to care about Michael, his clingy nature makes them reluctant to socialize with him outside of the office; such as when, after numerous unsuccessful invitations, Michael is forced to trick them in order to have them over for a disastrous dinner in the episode " Dinner Party ." In a Season 5 episode, Michael also shows his admiration for Jim, when Jim wears a tuxedo to work and goes on and on about having a 'classy party' for the party planning committee, and frequently suggests all of the ideas Dwight had offered that Michael had then rejected, only to bother Dwight by having Michael accept the same ideas from him. During Cecilia Halpert's baptism, Michael approaches Pam referring to himself as "the godfather" while imitating Don Corleone , after which she sympathetically but emphatically asks him to acknowledge that he won't be Cece's godfather, he is disappointed but does so and is hurt to learn that the godparents are a couple they'd only recently met. Pam is shown to have a soft spot for Michael, consoling him after he finds Holly to be in a relationship with AJ, and her advising him on ideas on how to propose to Holly. In " Goodbye, Michael " it is revealed that Michael is secretly planning to leave for Colorado at the end of his penultimate work day, thereby avoiding having to say goodbye to everyone. Jim figures this out and goes along with it, telling Michael that he will tell him what a great boss he was the following day at lunch, which they both know Michael will not be around for; Michael and Jim both get sentimental during this final conversation between them. The strength of his relationship with Pam is revealed as he continuously asks about her whereabouts, not wanting to leave without saying goodbye. Pam, who spent the better part of the day away from the office, finds Michael at the airport and says goodbye in a touching scene just as he's about to board his plane for Colorado. She watches from the window as his plane flies off. In a deleted scene of " The Inner Circle ", Pam is flattered that Michael named his new dog "Pamela Beagsley." Pam later teases Jim that their second child will be named "little Michael Scott" displaying the affection she had developed for her former boss.

Toby Flenderson
Despite liking the majority of the staff, Michael fiercely hates Human Resources Manager Toby Flenderson, likely due to Toby's requirement to enforce the rules of proper office behavior that Michael loves to flout. Michael once reasoned that "Toby is in HR, which technically means he works for Corporate. So he's really not a part of our family. He's also divorced so he's not a part of his family either". His longtime goal is to get rid of Toby and any attempts at reconciliation between the two usually backfire, with Michael resorting to name calling or jokes at Toby's expense. In the episode " Goodbye, Toby ", Michael is thrilled when Toby decides to move to Costa Rica and gives as his going away present a rock with a note that reads "Suck on this". The next season, after Toby's replacement Holly is transferred, Michael is horrified when Toby returns to Dunder Mifflin. In " Frame Toby ", he goes to great lengths to get him fired, trying to frame him for possession of marijuana (which turns out to be a caprese salad). In " The Chump ", Michael says if he had a gun with two bullets and was in a room with Adolf Hitler , Osama bin Laden , and Toby, he would shoot Toby twice (which disgusts the rest of the office). In " Nepotism ", after Michael spanks Luke, the office intern who is also his nephew, he is ordered to attend counseling sessions moderated by Toby, much to Michael's horror. At first Michael is uncooperative but is gradually tricked by Toby into discussing therapeutic details of his life and childhood. In " Classy Christmas ", Michael is happy to hear the news that Toby is going to be on a leave of absence for jury duty and that Holly will be taking his place. In " Michael's Last Dundies ", Michael eggs Toby's house in the cold open while yelling, "you suck", while he and Deangelo are handing out Dundie nominations. Ironically, Michael is shown to have befriended Toby's daughter Sasha in " Take Your Daughter to Work ". In " Goodbye, Michael ", Michael is seen saying goodbye to Toby without insulting him, possibly indicating that he will miss Toby on some level. Toby suggests Michael visit his brother Rory, who also lives in Colorado.

Erin Hannon
Once Pam is promoted to salesperson following Dunder Mifflin's buyout of The Michael Scott Paper Company, Michael keeps Erin Hannon as her replacement. He is initially unkind to her as he misses having Pam as his receptionist, but she is able to earn his respect by cheering him up after his disastrous school visit in " Scott's Tots ." Unlike her predecessor, Erin loves working as a receptionist, admires Michael and cheerfully accommodates many of his unusual requests (such as serving him a plate of ants on a log every day at 2:30 and spinning him in his chair until he's dizzy) that Pam likely would have been apprehensive about. Although he generally enjoys Erin's thoughtful treatment, his dismissive feelings towards Erin continue until " Secretary's Day " when he reluctantly agrees to take her out to lunch. Erin relishes the opportunity to spend time with her boss while Michael finds their conversation awkward and mentions that her then-boyfriend Andy Bernard was previously engaged to Angela Martin of which Erin was previously unaware, she is upset to learn this and ends her relationship with Andy. Later that day, Michael apologizes to Erin; the two are finally able to relate to each other over their mutual fondness for silly humor, stemming from their similar immature tendencies (with Michael's ignorance and Erin's naïveté). Their working relationship then develops smoothly while they bond by making each other laugh with childish jokes, such as Erin pointing out that the phrase "it's not" sounds like "snot." In " Viewing Party ", Erin throws a Glee party with her new boyfriend, Gabe Lewis . Throughout the night, she unsuccessfully attempts to get Michael and Gabe to bond. Michael is jealous that the office looks to Gabe as the boss and attempts to sabotage the party. After being confronted by Erin in private, Michael questions why his opinion matters so much to her as he is not her father. In a moment of insight, Michael realizes that Erin, who was raised in foster care, does indeed look to him as a father figure and he instigates a playful fight as father and daughter by saying "go to your room, young lady!" Erin becomes protective of Michael to the point where she is hostile towards Holly Flax, saying in a talking head interview that she doesn't understand what Michael sees in her, until The Search when she, Dwight and Holly go searching for a missing Michael. Erin sees that Holly is able to sense where Michael is, and when she sees them reconcile, she finally understands their love for each other and smiles. Later in " Goodbye, Michael ", Erin talks to Michael about her love life and wishes that she knew her birth mother so she could tell Erin what to do. Michael advises Erin that she shouldn't rush things and that she'll know what to do when the right guy comes along. Michael then tells her that she won't need her mother for advice, because she will always have his personal phone number when she needs advice and kisses her on the head.

Holly Flax
Shortly after the dissolution of his troubled relationship with Jan, Michael found love with Holly Flax ( Amy Ryan ), Toby's replacement as HR Representative, who appears for a while to be Michael's best chance at love, with the two sharing a similar sense of humor and social awkwardness. However, after David Wallace witnesses them kissing, Holly is transferred to the Nashua branch and she and Michael break up after choosing not to pursue a long-distance relationship. Despite the breakup and Holly's new relationship with another man, their affection for each other doesn't go away, as it's shown that Holly had been writing a note for Michael on her work computer, as well as their subtle romantic glances at one another during the summer company picnic. Throughout her absence in Season 5 (excluding Company Picnic) and carrying on into Season 7, Michael hooks up with a few other women, but ultimately he realizes that they're nothing compared to her. Around Christmas in Season 7, Toby is forced to leave the office due to being selected as part of the jury duty for a local murder case, resulting in Holly returning as the temporary HR replacement. There's initial tension between the two of them and hesitation on her side (mostly after her sudden break-up with A.J.), but Holly finally reunites with Michael after realizing they're both soulmates. The two continue dating for a few weeks, and on Valentine's Day, they tell each other they love each other, decide to move in together, and resolve that they will not allow Dunder Mifflin to interfere with their future together. With her time at the Scranton branch almost up and the recent knowledge that her aging parents need to be taken care of, they ultimately become fiancees. Holly later moves back to Colorado and Michael follows her soon after. In the finale it is revealed that they have children together. It was revealed in a photo album on NBC that they have 3 children and are expecting their 4th child.

Other romantic relationships
Michael's longest relationship to date has been with Jan Levinson ( Melora Hardin ), his original-then-former boss from Corporate. Starting with a one-night stand after they closed their business deal at Chilli's in " The Client " (which featured guest star Tim Meadows as the eponymous client), Michael and Jan begin awkward dating, become an official couple, and eventually move in together after Jan is fired from her job — although it should be noted that Jan usually treated Michael with contempt. After Michael fails to defend Jan in her Wrongful Dismissal suit against Dunder Mifflin, they remain together for a short while, but end up blowing up at each other during an ill-fated dinner party and eventually break up. He also dated Carol (played by Carell's wife Nancy Walls ), a real estate agent from whom Michael bought his condominium. Michael was much more interested in Carol than vice versa, and after he made an unwanted and rejected impromptu public marriage proposal, Michael's decision to Photoshop pictures of himself over Carol's ex-husband in her family pictures resulted in their breakup. On a business trip to Winnipeg, Michael & "Concierge Marie" become close, and Michael does not wish to leave her after they are caught necking in her suite. After Jim and Pam's wedding, Michael begins dating Pam's mother Helene (much to Pam's horror), but he breaks up with her on her birthday after discovering she is turning 58. Near the end of season six, Michael begins dating Donna ( Amy Pietz ), the manager of a local bar, but later finds out that she's married and he is, as he puts it, "the mistress". He continues seeing her until the disgust of his employees drives him to listen to his conscience and break things off with her. In Season 7's " Sex Ed ", Michael reunites (in person or by telephone) with all of his aforementioned past girlfriends when he believes that he has contracted herpes . In doing so, he realizes that Holly was the only one he truly loved.

Alter egos of Michael Scott
Given his proclivity of constantly trying to keep his employees entertained (and coupled with his juvenile personality), Michael has created a variety of different alter egos which he uses for both entertainment, and, at times, educational purposes. Often at times he uses these characters names to hide transacting information, and at one point his credit card uses "Michael Scarn", instead of Michael Scott.

Legacy of "That's What She Said"
The show often uses the joke " that's what she said " which was popularized by the Wayne's World sketch on Saturday Night Live . [9] In the original BBC version of The Office, Ricky Gervais's character David Brent frequently used the similar phrase "as the actress said to the bishop" as an inappropriate joke. Michael inserts the phrase as a sexually suggestive double entendre even in the most inappropriate circumstances, including business meetings and legal depositions. Michael finds uttering the phrase so irresistible that in " Sexual Harassment " he is goaded into saying it just seconds after Jan Levinson and a lawyer from Corporate specifically ask him not to do so. The phrase has become so associated with the character that the television show 30 Rock in the episode " TGS Hates Women " there was a scene in which Liz Lemon became infuriated at another character's use of 'TWSS' because " Steve Carell owns 'That's What She Said,' okay? He owns it!" In the episode, " Goodbye, Michael ", "that's what she said" was Steve Carell's final (inaudible) line as a series regular, and was his first line upon returning as a guest star in " Finale ".

Comparison with David Brent
Although originally based on David Brent , Scott has developed into a significantly different character than his British counterpart. Whereas Brent is shown to be irredeemably incompetent, Scott is portrayed as an outstanding salesman who is unwisely promoted to a management role to which he appears completely ill-suited. (In a scathing performance review during episode eight of season two, Jan Levinson suggests that Scott should be removed from his management role and return to sales). Scott is thus an apt example of the Peter Principle which states that competent persons in a hierarchical organization will "rise to the level of their incompetence" after which they will not advance.
Despite his failings, Scott has been oddly successful as regional manager. This is attributed, in part, to his weakness of procrastination wherein he typically forfeits a bad choice by seeking the advice of his more competent subordinates (such as Jim, Oscar, or Darryl) and uses their recommendations. Scott's success is also partly attributed to his main strength: genuinely caring about the well-being of the office and treating his employees like family. When he took over the Scranton Branch he decreased costs by 17%, without firing any personnel. After the merger of the two branches Scott does not lose a single client despite a great deal of employee turnover (much of which he was directly responsible for). He received a $3,000 bonus for firing Devon, most likely because his doing so saved the company around $50,000. Although it is suggested that Brent has had similar success, such claims only ever come from Brent himself, thus making them unreliable.
Scott's social immaturity and inability to cope with responsibility is balanced with a personality that is much more caring than Brent's, even if both make unwise comments in the heat of the moment. Unlike Brent, who pretends to be friendly with many of his employees purely for the benefit of the cameras, Scott seems to genuinely like his colleagues, with the exception of Human Resources Director Toby Flenderson . Scott's need to be liked by his staff and his belief that people see him as a genuine friend leads him to become very hurt when he realizes this is not the case. Most, if not all, of Scott's managerial blunders can be directly correlated with the degree to which he desires to be liked by his employees or jealously seeks their approval.
The DVD commentary to the pilot episode suggests that Scott's character continues a process begun in the second UK series, in which Gervais and Merchant intentionally made Brent less nasty, and more of a buffoon . It is said in the commentary that Gervais and Merchant suggested that this be applied to Scott. This also reflects a general change in the US version's attitude, which is more sympathetic to the characters, and tones down the cruel humor of the original. The commentary also says that Steve Carell had not seen more than a few minutes of the original UK series when he was offered the role of Scott, and has since made a conscious decision not to watch it in case it influences his own performance.
The show's writers have said that the 2005 hit movie The 40-Year-Old Virgin provided very useful guidance as they refined the character along with Steve Carell between the 1st and 2nd seasons. Michael Scott wore a large amount of hair gel and dressed sloppily in Season 1, but by Season 2 he had a more conventional haircut and dressed much more neatly. Also, while Michael is often rude and nasty in Season 1, he is generally nicer and less hard-edged in subsequent seasons.
In the seventh season episode " The Seminar ", Michael in fact briefly meets David Brent in the lobby and they establish an immediate rapport, joking together and generally signalling that they would have been good friends.

Behind the scenes
WebPage index: 00096
Raw foodism
Raw foodism (or following a raw food diet ) is the dietary practice of eating only, or mostly, uncooked , unprocessed foods. Depending on the philosophy, or type of lifestyle and results desired, raw food diets may include a selection of fruits, vegetables, nuts, seeds, eggs, fish, meat, and dairy products. [1]
It may also include simply processed foods such as various types of sprouted seeds , cheese, and fermented foods such as yogurts , kefir , kombucha or sauerkraut , but generally not foods that have been pasteurized , homogenized , or produced with the use of synthetic pesticides , chemical fertilizers , industrial solvents or chemical food additives .

Varieties
Raw food diets are diets composed entirely or mostly of food that is uncooked or which is cooked at low temperatures. [2]

Raw veganism
A raw vegan diet consists of unprocessed, raw plant foods, that have not been heated above 40–49 °C (104–120 °F ). Raw vegans such as Brian Clement, Gabriel Cousens , Thierry Browers a.k.a. "Superlight", and Douglas Graham [3] believe that foods cooked above this temperature have lost much of their nutritional value and are less healthy or even harmful to the body. [ unbalanced opinion ] Advocates argue that raw or living foods have natural enzymes, which are critical in building proteins and rebuilding the body, and that heating these foods destroys the natural enzymes and can leave toxic materials behind. However, enzymes, as with other proteins consumed in the diet, are denatured and eventually lysed by the digestive process, rendering them non-functional. [4] Typical foods included in raw food diets are fruits, vegetables, nuts, seeds, and sprouted grains and legumes.
Among raw vegans there are some subgroups such as fruitarians , juicearians, or sproutarians. Fruitarians eat primarily or exclusively fruits, berries, seeds, and nuts. Juicearians process their raw plant foods into juice. Sproutarians adhere to a diet consisting mainly of sprouted seeds .

Raw vegetarianism
Vegetarianism is a diet that excludes meat (including byproducts like gelatin), fish (including shellfish and other sea animals), and poultry, but allows dairy and/or eggs. Common foods include fruit, vegetables, sprouts, nuts, seeds, grains, legumes, dairy, eggs, and honey. There are several variants of this diet, including raw versions. [5]

Raw animal food diets
Included in raw animal food diets are any food that can be eaten raw, such as uncooked, unprocessed raw muscle-meats/organ-meats/eggs, raw dairy, and aged, raw animal foods such as century eggs , fermented meat/fish/shellfish/ kefir , as well as vegetables/fruits/nuts/sprouts/honey, but in general not raw grains, raw beans, and raw soy. Raw foods included on such diets have not been heated above 40 °C (104 °F). [6] Raw animal foodists believe that foods cooked above this temperature have lost a lot of their nutritional value and are less bioavailable. [ unbalanced opinion ]
Examples of raw animal food diets include the Primal Diet, [7] [8] anopsology (otherwise known as "Instinctive Eating" or "Instincto"), and the Raw Paleolithic diet [9] [10] (otherwise known as the "Raw Meat Diet"). [11]
The Primal Diet consists of fatty meats, organ meats, dairy, honey, minimal fruit and vegetable juices, and coconut products, all raw.
The "Raw Meat Diet", otherwise known as the "Raw, Paleolithic Diet", [10] [12] is a raw version of the (cooked) Paleolithic Diet, incorporating large amounts of raw animal foods such as meats/organ-meats, seafood, eggs, and some raw plant-foods, but usually avoiding non-Paleo foods such as raw dairy, grains, and legumes. [10] [11]
A number of traditional aboriginal diets consisted of large quantities of raw meats, organ meats, and berries, including the traditional diet of the Nenets tribe of Siberia and the Inuit people. [13] [14] [15]

History
Contemporary raw food diets were first developed in Switzerland by Maximilian Bircher-Benner (1867 – 1939), who was influenced as a young man by the German Lebensreform movement, which saw civilization as corrupt and sought to go "back to nature"; it embraced holistic medicine, nudism, free love, exercise and other outdoors activity, and foods that it judged were more "natural". [16] :31–33 Bircher-Benner eventually adopted a vegetarian diet, but took that further and decided that raw food was what humans were really meant to eat; he was influenced by Charles Darwin 's ideas that humans were just another kind of animal and Bircher-Benner noted that other animals do not cook their food. [16] :31–33 In 1904 he opened a sanatorium in the mountains outside of Zurich called "Lebendinge Kraft" or "Vital Force," a technical term in the Lebensreform movement that referred especially to sunlight; he and others believed that this energy was more "concentrated" in plants than in meat, and was diminished by cooking. [16] :31–33 Patients in the clinic were fed raw foods, including muesli , which was created there. [16] :31–33 These ideas were dismissed by scientists and the medical profession of his day as quackery. [16] :31–33
Other proponents from the early part of the twentieth century include Ann Wigmore , Norman W. Walker (inventor of the Norwalk Juicing Press), and Herbert Shelton . Shelton was arrested, jailed, and fined numerous times for practicing medicine without a license during his career as an advocate of rawism and other alternative health and diet philosophies. [17] Shelton's legacy, as popularized by books like Fit for Life by Harvey and Marilyn Diamond, has been deemed "pseudonutrition" by the National Council Against Health Fraud. [18]
Leslie Kenton 's book Raw Energy - Eat Your Way to Radiant Health , published in 1984, added popularity to foods such as sprouts, seeds, and fresh vegetable juices. [19] The book advocates a diet of 75% raw food which it claims will prevent degenerative diseases , slow the effects of aging, provide enhanced energy, and boost emotional balance; it cites examples such as the sprouted-seed-enriched diets of the long-lived Hunza people and Gerson therapy , an unhealthy, dangerous and potentially very harmful [20] [21] raw juice-based diet and detoxification regime claimed to treat cancer. [20]

Claims
Claims held by raw food proponents include:

Health effects
A meta-analysis clinical trials and epidemiological studies published in 2004, and covering a broad range of cancers, found that it appears that there is an inverse relationship between the risk of developing certain types of cancer and eating both raw and cooked vegetables. Consumption of raw vegetables tended to be associated with decreased cancer risks somewhat more often than consumption of cooked vegetables. [32] On the other hand, a raw food diet is likely to impair the development of children and infants. [33]
Care is required in planning a raw vegan diet, especially for children. [34] Dr. Joel Fuhrman , author of Disease-Proof Your Child , says there may not be enough vitamin B 12 , enough vitamin D, and enough calories for a growing child on a totally raw vegan diet. Fuhrman fed his own four children raw and cooked vegetables, fruits, nuts, grains, beans, and occasionally eggs. [35]
Food poisoning is a health risk for all people eating raw foods, and increased demand for raw foods is associated with greater incidence of foodborne illness , [36] especially for raw meat, fish, and shellfish. [37] [38] Outbreaks of gastroenteritis among consumers of raw and undercooked animal products (including smoked, pickled or dried animal products [37] ) are well-documented, and include raw meat, [37] [39] [40] raw organ meat, [39] raw fish (whether ocean-going or freshwater), [37] [38] [40] shellfish, [41] raw milk and products made from raw milk, [42] [43] [44] and raw eggs. [45]
In his book Health or Hoax , nutritionist Arnold E. Bender has written that "Many raw foods are toxic and only become safe after they have been cooked. Some raw foods contain substances that destroy vitamins, interfere with digestive enzymes or damage the walls of the intestine. Raw meat can be contaminated with bacteria which would be destroyed by cooking; raw fish can contain substances that interfere with vitamin B1 (anti-thiaminases)" [46]

Cooking and global warming
It has also been pointed out that cooking food, directly or indirectly, requires energy and may thus release gases associated with global warming. [47] Raw diets mitigate the use of non-renewable resources, which results in raw diets being less environmentally deleterious than cooked food diets in this respect.

Role of cooking in human evolution
Richard Wrangham , professor of biological anthropology at Harvard University, [48] proposes that cooked food played a pivotal role in human evolution. Evidence of a cooked diet, according to Wrangham, can be seen as far back as 1.8 million years ago in the anatomical adaptations of Homo erectus . Reduction in the size of teeth and jaw in H. erectus indicate a softer diet, requiring less chewing time. This combined with a smaller gut and larger brain indicate to Wrangham that H. erectus was eating a higher quality diet than its predecessors. [49] To explain a decreased gut providing the amount of energy required for an increased brain size, Wrangham links his research on the digestive effects of cooked versus raw foods with the lower reproductive abilities of female raw foodists, and BMI in both sexes, to support his hypothesis that cooked starches provided the energy necessary to fuel evolution from H. erectus to H. sapiens . [50]
Theories opposed to Wrangham's include that of Leslie Aiello, professor of biological anthropology at University College London, and physiologist Peter Wheeler. Aiello and Wheeler believe it was soft animal foods, including bone marrow and brains, which contributed to humans developing the characteristics Wrangham attributes to cooked foods. [51] Further, archaeological evidence suggests that cooking fires began in earnest only around 250 kya, when ancient hearths, earth ovens, burnt animal bones, and flint appear regularly across Europe and the Middle East. Two million years ago, the only sign of fire is burnt earth with human remains, which many anthropologists consider coincidence rather than evidence of intentional fire. [52] Many anthropologists believe the increases in human brain-size occurred well before the advent of cooking, due to a shift away from the consumption of nuts and berries to the consumption of raw meat. [53] [54] [55]

See also
WebPage index: 00097
Bigipedia
Bigipedia is a comedy sketch show broadcast on BBC Radio 4 that first aired between 23 July and 13 August 2009. A second series of four episodes began on 12 July 2011. [1] The show's storyline revolves around "Bigipedia", a fictional website broadcast on radio and parody of Wikipedia , the online encyclopedia . The series mocks Wikipedia and other aspects of the Internet. [2] The BBC Press Office described the show as "a unique experiment in 'broadwebcasting'". [3] [4] The series was created by co-star Nick Doody , who also co-writes the show with Matt Kirshen and a wider team of writers. It is produced by Pozzitive Productions .
Critics have given Bigipedia positive reviews. The series was marketed by the BBC as " The Sunday Format for the online age", [4] and critics have given Bigipedia favourable comparisons with its predecessor. [2] [5] The quality of the writing has also been praised. [5] However, a few critics have expressed reservations about the way the show is presented. [6] The first series of Bigipedia was made available to purchase as a download from Audible.co.uk from 1 December 2009. The second series was made available to purchase as a download from AudioGo from 5 December 2011. [7]

Plot
Bigipedia is a website broadcast on the radio. Like Wikipedia, it contains articles and discussion pages about a range of different subjects, which can be edited by anyone. Among the similarities are articles , discussion pages , disambiguation pages , featured articles , a news section and a " Did you know? " section for new articles. [8] [9] The articles cover a range of fictional celebrities, bands, films, television series, products and a running gag series of articles on anthropomorphic animal characters from Uruguayan safety campaigns.
Bigipedia differs from Wikipedia in some ways. For example, Bigipedia includes puzzles and competitions , sells its own software , [8] [9] has a range of screensavers , [10] and a section for children called Bigikids , which has had different names in the past which have all had to be changed for different reasons. For example, the name changed from Kidipedia "due to a misunderstanding", [2] [8] Hanging at the School Gates "for reasons you may have seen in the news" [10] and Underage Fun "due to a copyright infringement". [9]
Also, while Wikipedia does not have advertising , Bigipedia does and is also sponsored by a fictional wine -like drink called "Chianto" which is referred to as "this horrific drink". [3] The Bigipedia article on Chianto says: "Over the years it has been sold as a hair remover, self-defence spray, hair restorer, and to farmers as a humane way of killing chickens – by putting it into the pig's feed and leaving the gate open. By morning not only were the chickens killed, but often plucked, too." [8]
The first series ended with Bigipedia attempting to take over the world, having crushed a rebellion in the Philippines and feeding nanobots into the heads of anyone listening to the programme. [11] At the start of the second series, Bigipedia acknowledges that the original Bigipedia , dubbed Bigipedia 1.0 suffered from "security and sentient omniscience issues" and apologises for, "the temporary cyber enslavement of 88% of mankind and the forming of a BigiHuman hybrid hivemind centred in the Philippines", in an incident they refer to as "The Glitch". The site has been updated and is now known as Bigipedia 2.0 . [12]
The second series begins with reports of a gigantic Chianto slick in the Gulf of Mexico , a parody of the Deepwater Horizon oil spill . At the end of the series, a mix of white and red Chianto in the slick result in the creation of a Chianto " ovum ", which hatches at the bottom of the sea as a monstrous party-animal being called the Chianto Leviathan, which makes its way to the Bigipedia servers in Mexico. The Leviathan attempts to gain all the world's knowledge by accessing the system. The programme ends with Bigipedia playing "prerecorded programmes" while they attempt to stop the Leviathan. [13]

Production
The series was originally conceived by Doody, who was working with producer David Tyler on another BBC Radio 4 comedy series, Armando Iannucci's Charm Offensive . Doody attended a meeting where people were discussing new ideas for radio shows, and Kirshen suggested the idea, and both he and Kirshen wrote the full proposal. Radio 4 liked the idea and a pilot was made. [3] Tyler went on to produce and direct Bigipedia .
Doody and Kirshen describe the show as "writing-heavy". Doody said in an interview with the British Comedy Guide : "Compared to most radio shows, it's incredibly dense, material-wise, and very fast-moving. I think Matt and I would like some of it to be even faster, but sometimes people who've heard the pilot say things like, "It's almost too much." I really like that. I like that it's something you kind of need to hear twice to catch everything. When we got the series, I honestly didn't know where we'd come up with the material of the quality we were determined to keep up." [3]
Some of the sketches in Bigipedia are inspired directly by articles on Wikipedia. Kirshen said in the same interview: "There's a 'Bee Whisperer' in Episode 3 that came from clicking the "Random article" link on Wikipedia. I don't remember what the page we got was, but about three logical leaps later we landed on that idea." [3]
It was revealed by Doody on his Doubling Up podcast with Rob Heeney that there was an extended edition of "The Line" sketch, which he broadcast on the show. [14]

Reception
The reviews of Bigipedia have been mainly positive. Before the series began, Scott Matthewman in The Stage compared Bigipedia to The Sunday Format , saying: "Indeed, the comparison even makes it into the BBC's own press notes. Will this version, which takes the mickey out of online communication, deserve the comparison? That's something we'll have to wait and see." [15] Chris Maume in The Independent on Sunday also commented that there are references to Spinal Tap , On the Hour and Brass Eye . [2]
Elisabeth Mahoney in The Guardian said that she liked the Chianto running gag, [5] while Gillian Reynolds from the Daily Telegraph commented positively on Bigipedia saying it was, "the first late-night comedy in ages that has made me laugh, about computers and why I'm scared of them, about vile TV shows and meaningless commercials. Written by Nick Doody and Matt Kirshen, performed with zest by a sparkling cast. Bound to become a cult." [16] Reviewing the second series Elizabeth Day in The Observer described Bigipedia as, "a hilariously mad portrayal of information overload in the computer age." [17]
Clare Heal in the Sunday Express gave a mixed review, saying that while she found it amusing, it was too similar to the Internet saying, "The programme's only failing was that on occasion it was a little to [sic] reminiscent of the real Internet, ie a virtual ocean full of morons willing to shout loudly about things even (or perhaps especially) if they know nothing about them. You wouldn't want more than half an hour of Bigipedia , no matter how amusing it is." [6]

Episodes

Series 1

Series 2

See also
WebPage index: 00098
John Julius Norwich
John Julius Cooper, 2nd Viscount Norwich , CVO (born 15 September 1929), known as John Julius Norwich , is an English popular historian , [1] travel writer and television personality.

Biography

Early life
Norwich is the son of the Conservative politician and diplomat Duff Cooper and of Lady Diana Manners , a celebrated beauty and society figure. [2] Through his father, he is descended from King William IV and his mistress Dorothea Jordan .
He was educated at Upper Canada College , Toronto, Canada (as a wartime evacuee ), Eton , and the University of Strasbourg . He served in the Royal Navy before taking a degree in French and Russian at New College, Oxford .

Career
Joining the British Foreign Service after Oxford, John Julius Cooper served in Yugoslavia and Lebanon and as a member of British delegation to the Disarmament Conference in Geneva . On his father's death in 1954, he inherited the title of Viscount Norwich , created for Duff Cooper in 1952. This gave him a right to sit in the House of Lords , though he lost this right with the House of Lords Act 1999 .
In 1964, Viscount Norwich left the diplomatic service to become a writer. Apart from his many books (see list), he has also served as editor of series such as Great Architecture of the World , The Italian World , The New Shell Guides to Great Britain , The Oxford Illustrated Encyclopaedia of Art and the Duff Cooper Diaries . Viscount Norwich has often contributed to Cornucopia , a magazine devoted to the history and culture of Turkey.
Viscount Norwich has worked extensively in radio and television. He was host of the BBC radio panel game My Word! for four years (1978–82) and also a regional contestant on Round Britain Quiz . He has written and presented some 30 television documentaries, including The Fall of Constantinople , Napoleon's Hundred Days , Cortés and Montezuma , The Antiquities of Turkey , The Gates of Asia , Maximilian of Mexico , Toussaint l'Ouverture of Haiti , The Knights of Malta , The Treasure Houses of Britain , and The Death of the Prince Imperial in the Zulu War .
Norwich has also worked for various charitable projects. He is the former chairman of the Venice in Peril Fund , [3] honorary chairman of the World Monuments Fund , and a Vice-President of the National Association of Decorative and Fine Arts Societies. [4] For many years he was a member of the Executive Committee of the National Trust , and also served on the Board of English National Opera . Viscount Norwich is also a patron of SHARE Community, which provides vocational training to disabled people.

Christmas Crackers
Viscount Norwich began to compile 24-page anthologies for friends in 1970. Later producing around 2,000 copies a year and expanding to the United States in the mid-1980s. Several anthologies have been published and certain single issues fetch high prices in secondhand bookstores.
Christmas Crackers are compiled from whatever attracts Norwich: letters and diaries and gravestones and poems, boastful Who's Who entries, indexes from biographies, word games such as palindromes, holorhymes and mnemonics, occasionally in untranslated Greek, French, Latin, German or whatever language it was sourced from as well as such oddities as a review from the American outdoors magazine Field and Stream concerning the re-publication of "Lady Chatterley's Lover". [5] [6]

Family
Viscount Norwich's first wife was Anne Frances May Clifford, daughter of the Hon. Sir Bede Edmund Hugh Clifford ; they had one daughter, the Hon. Artemis Cooper , a historian, and a son, the Hon. Jason Charles Duff Bede Cooper, an architect. After their divorce, Lord Norwich married his second wife, the Hon. Mary (Makins) Philipps, daughter of the 1st Baron Sherfield GCB GCMG .
Viscount Norwich is also the father of Allegra Huston , born of his affair with the American ballet dancer Enrica Soma while she was married to the American film director John Huston . [7]

Honours and styles of address

Honours
Viscount Norwich was appointed to the Royal Victorian Order as a Commander [8] in 1992 by the Queen after curating a Victoria and Albert Museum exhibition entitled Sovereign , which marked the 40th anniversary of the Queen's accession.

Styles of address

Ancestry

Works
WebPage index: 00099
Wikiversity
Wikiversity is a Wikimedia Foundation project [2] [3] that supports learning communities, their learning materials, and resulting activities. It differs from more structured projects such as Wikipedia in that it instead offers a series of tutorials, or courses, for the fostering of learning, rather than formal content.

History
Wikiversity's beta phase officially began on August 15, 2006, with the English language Wikiversity .
The idea of Wikiversity began with the initial development of the Wikiversity community within the Wikibooks project, however when it was nominated for deletion from Wikibooks, soon there was a proposal to make Wikiversity an independent Wikimedia project, [4] with the fundamental goal to broaden the scope of activities within the Wikimedia community to include additional types of learning resources in addition to textbooks.
Two proposals were made. The first project proposal was not approved (2005) and the second, modified proposal, was approved (2006). [5]
The launch of Wikiversity was announced at Wikimania 2006 as:

Project details
Wikiversity is a center for the creation of and use of free learning materials, and the provision of learning activities . Wikiversity is one of many wikis used in educational contexts, [7] as well as many initiatives that are creating free and open educational resources .
The primary priorities and goals for Wikiversity are to:
The Wikiversity e-Learning model places emphasis on "learning groups" and "learning by doing" . Wikiversity's motto and slogan is "set learning free", [9] [10] indicating that groups/communities of Wikiversity participants will engage in learning projects. Learning is facilitated through collaboration on projects that are detailed, outlined, summarized or results reported by editing Wikiversity pages. Wikiversity learning projects include collections of wiki webpages concerned with the exploration of a particular topic. [11] Wikiversity participants are encouraged to express their learning goals, and the Wikiversity community collaborates to develop learning activities and projects to accommodate those goals. The Wikiversity e-Learning activities give learners the opportunity to build knowledge. Students have to be language aware in order to be able to correct their classmates. By doing this, students develop their reflection skills. Secondly, they enable students to be autonomous deciding what to write or edit, also when and how to do it. Students are able to free resort to any mean of support. At the same time, it fosters the Cognitive development engaging students to collaborate between them. However, as the project is still in its early stages, [12] [13] its learning model is still in development.
Learning resources are developed by an individual or groups, either on their own initiative, or as part of a learning project. [14] Wikiversity resources include teaching aids, lesson plans, curricula, links to off-site resources, course notes, example and problem sets, computer simulations, reading lists, and other as devised by participants – but do not include final polished textbooks. Texts useful to others are hosted at Wikibooks for update and maintenance. [15] Learning groups with interests in each subject area create a web of resources that form the basis of discussions and activities at Wikiversity. Learning resources can be used by educators outside of Wikiversity for their own purposes, under the terms of the GFDL and a Creative Commons license (like Wikipedia ).
Wikiversity also allows original research (in contrast to Wikipedia which does not). [16] [17] Such research content may lack any peer review . [16] WikiJournal is a project that provides quality control by having expert peer review of all included content. This activity started with WikiJournal of Medicine in 2014. [18] WikiJournal of Medicine can also peer review and publish Wikipedia content, making it easier for scholars to cite it in external works. [19]

Languages
There are currently fifteen different Wikiversities - Arabic, Czech, English, Finnish, French, German, Greek, Italian, Japanese, Korean, Portuguese, Russian, Slovene, Spanish, and Swedish; Wikiversity projects in other languages are being developed at the "beta" multilingual hub.
For newly established specific language Wikiversities to move out of the initial exploratory "beta" phase, the new Wikiversity community must establish policies governing research activities. Wikiversity may act as a repository of research carried out by the Wikimedia Research Network , or others who are involved in wiki-based, or other research. Wikiversity hosts original research in addition to secondary research, unless a specific language group decides upon no research. It is expected that researchers will respect and update guidelines for appropriate research through a community consensus process. [20] [21] Currently the English Wikiversity hosts more than 376 research pages. [22]

See also
WebPage index: 00100
User-generated content
User-generated content ( UGC ), alternatively known as user-created content ( UCC ), is any form of content created by users of a system or service and made available publicly on that system. UGC most often appears as supplements to online platforms, such as social media websites , and may include such content types as blog posts, wikis, videos, or comments. [1]
The term "user-generated content" and concept it refers to entered mainstream usage in the mid-2000s, having arisen in web publishing and new media content production circles. The BBC adopted a user-generated content platform for its websites in 2005, and TIME Magazine named "You" as the Person of the Year in 2006, referring to the rise in the production of UGC on Web 2.0 platforms. [2] [3]
User-generated content is used for a wide range of applications, including problem processing, news, entertainment, advertising, gossip and research. It is an example of the democratization of content production; whereas during the 1970s and 1980s, traditional "gatekeepers" such as newspaper editors, publishers and news shows approved all content and information before it was aired or published, in the 1990s and 2000s, as media production through new technologies has become more accessible, user friendly and affordable to the general public, large numbers of individuals are able to post text, digital photos and digital videos online, with little or no "gatekeepers" or filters. [4]

Definition
The advent of user-generated content marked a shift among media organizations from creating online content to providing facilities for amateurs to publish their own content. [ citation needed ] User-generated content has also been characterized as Citizen Media as opposed to the 'Packaged Goods Media' of the past century . [5] Citizen Media is audience-generated feedback and news coverage. [6] People give their reviews and share stories in the form of user-generated and user-uploaded audio and user-generated video. [7] The former is a two-way process in contrast to the one-way distribution of the latter. Conversational or two-way media is a key characteristic of so-called Web 2.0 which encourages the publishing of one's own content and commenting on other people's.
The role of the passive audience therefore has shifted since the birth of New Media, and an ever-growing number of participatory users are taking advantage of the interactive opportunities, especially on the Internet to create independent content. Grassroots experimentation then generated an innovation in sounds, artists, techniques and associations with audiences which then are being used in mainstream media. [8] The active, participatory and creative audience is prevailing today with relatively accessible media, tools and applications, and its culture is in turn affecting mass media corporations and global audiences.
The OECD has defined three central schools for UGC: [9]
It is important to have an objective before attempting to become part of the UGC/social networking environment. For example, companies may ask users to post their reviews directly to their Facebook page. This could end up disastrous if a user makes a comment that steers people away from the product. [10]
Mere copy & paste or hyperlinking could also be seen as user-generated self-expression. The action of linking to a work or copying a work could in itself motivate the creator, express the taste of the person linking or copying. Digg.com , StumbleUpon.com , and leaptag.com are good examples of where such linkage to work happens. The culmination of such linkages could very well identify the tastes of a person in the community and make that person unique.

History
User-generated content in publications may have started with the letters to the editor columns of eighteenth century newspapers. In the 1990s several electronic bulletin board systems were based on user-generated content. Some of these systems have been converted into websites, including the film information site IMDb which started as rec.arts.movies in 1990. With the growth of the World Wide Web the focus moved to websites, several of which were based on user-generated content, including Wikipedia (2001) and Flickr (2004).
The BBC set up a user generated content team as a pilot in April 2005 with 3 staff. In the wake of the 7 July 2005 London bombings and the Buncefield oil depot fire , the team was made permanent and was expanded, reflecting the arrival in the mainstream of the citizen journalist . After the Buncefield disaster the BBC received over 5,000 photos from viewers. The BBC does not normally pay for content generated by its viewers.
In 2006 CNN launched CNN iReport , a project designed to bring user generated news content to CNN. Its rival Fox News Channel launched its project to bring in user-generated news, similarly titled "uReport". This was typical of major television news organisations in 2005–2006, who realised, particularly in the wake of the London 7 July bombings, that citizen journalism could now become a significant part of broadcast news. [11] Sky News , for example, regularly solicits for photographs and video from its viewers.
User-generated content was featured in Time magazine's 2006 Person of the Year , in which the person of the year was "you", meaning all of the people who contribute to user generated media such as YouTube and Wikipedia . [12] A precursor to user-generated content uploaded on YouTube was America's Funniest Home Videos . [13]

Motivation for creating UGC
While the benefit derived from user generated content for the content host is clear, the benefit to the contributor is less direct. There are various theories behind the motivation for contributing user generated content, ranging from altruistic, to social, to materialistic. Due to the high value of user generated content, many sites use incentives to encourage their generation. These incentives can be generally categorized into implicit incentives and explicit incentives. [14]

Ranking and Assessment
The distribution of UGC across the Web provides a high volume data source that is accessible for analysis , and offers utility in enhancing the experiences of end users . Social science research can benefit from having access to the opinions of a population of users, and use this data to make inferences about their traits. Applications in information technology seek to mine end user data to support and improve machine-based processes, such as information retrieval and recommendation . However, processing the high volumes of data offered by UGC necessitate the ability to automatically sort and filter these data points according to their value. [16]
Determining the value of user contributions for assessment and ranking can be difficult due to the variation in the quality and structure of this data. The quality and structure of the data provided by UGC is application-dependent, and can include items such as tags, reviews, or comments that may or may not be accompanied by useful metadata . Additionally, the value of this data depends on the specific task for which it will be utilized and the available features of the application domain. Value can ultimately be defined and assessed according to whether the application will provide service to a crowd of humans, a single end user, or a platform designer. [16]
The variation of data and specificity of value has resulted in various approaches and methods for assessing and ranking UGC. The performance of each method essentially depends on the features and metrics that are available for analysis. Consequently, it is critical to have an understanding of the task objective and its relation to how the data is collected, structured, and represented in order to choose the most appropriate approach to utilizing it. The methods of assessment and ranking can be categorized into two classes: human-centered and machine-centered. Methods emphasizing human-centered utility consider the ranking and assessment problem in terms of the users and their interactions with the system, whereas the machine-centered method considers the problem in terms of machine learning and computation . The various methods of assessment and ranking can be classified into one of four approaches: community-based, user-based, designer-based, and hybrid. [16]

Types
There are many types of user-generated content: Internet forums , where people talk about different topics; blogs are services where users can post about many topics, product reviews on a supplier website or in social media; wikis such as Wikipedia and Wikia allow users, sometimes including anonymous users, to edit the content. Another type of user-generated content are social networking sites like Facebook , Twitter , Instagram or VK , where users interact with other people chatting, writing messages, or posting images or links. Media hosting sites such as YouTube allow users to post content.

Websites
Entertainment media publications include Reddit , 9Gag , 4chan , Upworthy , Inbound.org, and Distractify. [17] [18] Sites like 9Gag allow users to create memes and quick video clips. Sites like Tech in Asia and Buzzfeed engage readers with professional communities by posting articles with user-generated comment sections. [19] Other types of this content are fanfiction like FanFiction.Net , imageboards ; various works of art , as with deviantArt and Newgrounds ; mobile photos and video sharing sites such as Picasa and Flickr ; customer review sites ; audio social networks such as SoundCloud ; crowd funding , like Kickstarter ; or crowdsourcing . Some forms of user-generated content can be considered as a form of citizen journalism .

Video games
Video games can have fan-made content in the form of mods , fan patches and fan translations . Some games come with level editor programs to aid in their creation. A few massively multiplayer online role-playing games including Star Trek Online and EverQuest 2 have UGC systems integrated into the game itself. [20] A metaverse can be a user-generated world, such as Second Life .

Advertising
A popular use of UGC involves collaboration between a brand and a user. For example, the "Elf Yourself" videos by Jib Jab that come back every year around Christmas. The Jib Jab website lets people use their photos of friends and family that they have uploaded to make a holiday video to share across the internet. You cut and paste the faces of the people in the pictures to animated dancing elves. [21]

Retailers
Some bargain hunting websites feature user-generated content, such as Dealsplus , Slickdeals , and FatWallet which allow users to post, discuss, and control which bargains get promoted within the community. Because of the dependency of social interaction, these sites fall into the category of social commerce .

Educational
Wikipedia , a free encyclopedia, is one of the largest user-generated content databases in the world.

Photo sharing
Photo sharing websites: Flickr is a site in which users are able to upload personal photos they have taken and label them in regards to their "motivation". [22] Flickr not only hosts images but makes them publicly available for reuse and reuse with modification. [23] It is entirely user-generated content.

Effect on journalism
The incorporation of user-generated content into mainstream journalism outlets is considered to have begun in 2005 with the BBC's creation of a user-generated content team, which was expanded and made permanent in the wake of the July 7, 2005 London bombings . [2] The incorporation of Web 2.0 technologies into news websites allowed user-generated content online to move from more social platforms such as MySpace , LiveJournal , and personal blogs , into the mainstream of online journalism, in the form of comments on news articles written by professional journalists, but also through surveys, content sharing, and other forms of citizen journalism. [24]
Since the mid-2000s, journalists and publishers have had to consider the effects that user-generated content has had on how news gets published, read, and shared. A 2016 study on publisher business models suggests that readers of online news sources value articles written both by professional journalists, as well as users-- provided that those users are experts in a field relevant to the content that they create. In response to this, it is suggested that online news sites must consider themselves not only a source for articles and other types of journalism, but also a platform for engagement and feedback from their communities. The ongoing engagement with a news site that is possible due to the interactive nature of user-generated content is considered a source of sustainable revenue for publishers of online journalism going forward. [25]

Use in marketing
The use of user-generated content has been prominent in the efforts of marketing online, especially among millennials. [26] A good reason for this may be that while in the US, 14 percent of consumers trust a brand-made ad, 48 percent of consumers trust UGC. An increasing number of companies have been employing UGC techniques into their marketing efforts, such as Starbucks with their "White Cup Contest" campaign where customers competed to create the best doodle on their cups. [27]
The effectiveness of UGC in marketing has been shown to be significant as well. For instance, the " Share a Coke " by Coca-Cola campaign in which customers uploaded images of themselves with bottles to social media attributed to a two percent increase in revenue. Of millennials, UGC can influence purchase decisions up to fifty-nine percent of the time, and eighty-four percent say that UGC on company websites has at least some influence on what they buy, typically in a positive way. As a whole, consumers place peer recommendations and reviews above those of professionals. [28]
User-generated content used in a marketing context has been known to help brands in numerous ways. [29]

Criticism
The term "user-generated content" has received some criticism. The criticism to date has addressed issues of fairness, quality, [30] privacy, [31] the sustainable availability of creative work and effort among legal issues namely related to intellectual property rights such as copyrights etc.
Some commentators assert that the term "user" implies an illusory or unproductive distinction between different kinds of "publishers", with the term "users" exclusively used to characterize publishers who operate on a much smaller scale than traditional mass-media outlets or who operate for free. [32] Such classification is said to perpetuate an unfair distinction that some argue is diminishing because of the prevalence and affordability of the means of production and publication. A better response [ according to whom? ] might be to offer optional expressions that better capture the spirit and nature of such work, such as EGC, Entrepreneurial Generated Content (see external reference below). [ citation needed ]
Sometimes creative works made by individuals are lost because there are limited or no ways to precisely preserve creations when a UGC Web site service closes down. One example of such loss is the closing of the Disney massively multiplayer online game " VMK ". VMK, like most games, has items that are traded from user to user. Many of these items are rare within the game. Users are able to use these items to create their own rooms, avatars and pin lanyard. This site shut down at 10 pm CDT on 21 May 2008. There are ways to preserve the essence, if not the entirety of such work through the users copying text and media to applications on their personal computers or recording live action or animated scenes using screen capture software, and then uploading elsewhere. Long before the Web, creative works were simply lost or went out of publication and disappeared from history unless individuals found ways to keep them in personal collections. [ citation needed ]
Another criticized aspect is the vast array of user-generated product and service reviews that can at times be misleading for consumer on the web. A study conducted at Cornell University found that an estimated 1 to 6 percent of positive user-generated online hotel reviews are fake. [33]

Legal problems
The ability for services to accept user-generated content opens up a number of legal concerns: depending on local laws, the operator of a service may be liable for the actions of its users. In the United States, the " Section 230 " exemptions of the Communications Decency Act state that "no provider or user of an interactive computer service shall be treated as the publisher or speaker of any information provided by another information content provider." This clause effectively provides a general immunity for websites that host user-generated content that is defamatory, deceptive or otherwise harmful, even if the operator knows that the third-party content is harmful and refuses to take it down. An exception to this general rule may exist if a website promises to take down the content and then fails to do so. [34]
Copyright laws also play a factor in relation to user-generated content, as users may use such services to upload works—particularly videos—that they do not have the sufficient rights to distribute. In many cases, the use of these materials may be covered by local " fair use " laws, especially if the use of the material submitted is transformative . [35] Local laws also vary on who is liable for any resulting copyright infringements caused by user-generated content; in the United States, the Online Copyright Infringement Liability Limitation Act (OCILLA)—a portion of the Digital Millennium Copyright Act (DMCA), dictates safe harbor provisions for " online service providers " as defined under the act, which grants immunity from secondary liability for the copyright-infringing actions of its users. However, to qualify for the safe harbors, the service must promptly remove access to alleged infringing materials upon the receipt of a notice from a copyright holder or registered agent, and the service provider must not have actual knowledge that their service is being used for infringing activities. [36] [37] The European Union's approach is horizontal by nature, which means that civil and criminal liability issues are addressed under the Electronic Commerce Directive . Section 4 deals with liability of the ISP while conducting "mere conduit" services, caching and web hosting services. [38]

Research
A study from York University in Ontario in 2012 conducted a research that resulted in a proposed framework for comparing brand-related UGC and to understand how the strategy used by a company could influence the brand sentiment across different social media channels. [39] A study by Dhar and Chang, published in 2007, found that the volume of blogs posted on a music album was positively correlated with future sales of that album. [40]

See also
WebPage index: 00101
Peer review
Peer review is the evaluation of work by one or more people of similar competence to the producers of the work ( peers ). It constitutes a form of self-regulation by qualified members of a profession within the relevant field . Peer review methods are employed to maintain standards of quality, improve performance, and provide credibility. In academia , scholarly peer review is often used to determine an academic paper 's suitability for publication . Peer review can be categorized by the type of activity and by the field or profession in which the activity occurs, e.g., medical peer review .

Professional
Professional peer review focuses on the performance of professionals, with a view to improving quality, upholding standards, or providing certification. In academia, peer review is common in decisions related to faculty advancement and tenure. [ citation needed ]
A prototype professional peer-review process was recommended in the Ethics of the Physician written by Ishāq ibn ʻAlī al-Ruhāwī (854–931). He stated that a visiting physician had to make duplicate notes of a patient's condition on every visit. When the patient was cured or had died, the notes of the physician were examined by a local medical council of other physicians, who would decide whether the treatment had met the required standards of medical care. [1]
Professional peer review is common in the field of health care, where it is usually called clinical peer review . [2] Further, since peer review activity is commonly segmented by clinical discipline, there is also physician peer review, nursing peer review, dentistry peer review, etc. [3] Many other professional fields have some level of peer review process: accounting, [4] [5] law, [6] [7] engineering (e.g., software peer review , technical peer review ), aviation, and even forest fire management. [8]
Peer review is used in education to achieve certain learning objectives, particularly as a tool to reach higher order processes in the affective and cognitive domains as defined by Bloom's taxonomy . This may take a variety of forms, including closely mimicking the scholarly peer review processes used in science and medicine. [9] [10]

Scholarly
Scholarly peer review (also known as refereeing ) is the process of subjecting an author's scholarly work, research, or ideas to the scrutiny of others who are experts in the same field, before a paper describing this work is published in a journal or as a book. The peer review helps the publisher (that is, the editor-in-chief or the editorial board ) decide whether the work should be accepted, considered acceptable with revisions, or rejected. Peer review requires a community of experts in a given (and often narrowly defined) field, who are qualified and able to perform reasonably impartial review. Impartial review, especially of work in less narrowly defined or inter-disciplinary fields, may be difficult to accomplish, and the significance (good or bad) of an idea may never be widely appreciated among its contemporaries. Peer review is generally considered necessary to academic quality and is used in most major scientific journals, but it does by no means prevent publication of all invalid research. Traditionally, peer reviewers have been anonymous, but there is currently a significant amount of open peer review , where the comments are visible to readers, generally with the identities of the peer reviewers disclosed as well.

Government policy
The European Union has been using peer review in the 'Open Method of Co-ordination' of policies in the fields of active labour market policy since 1999. [11] In 2004, a program of peer reviews started in social inclusion . [12] Each program sponsors about eight peer review meetings in each year, in which a 'host country' lays a given policy or initiative open to examination by half a dozen other countries and the relevant European-level NGOs. These usually meet over two days and include visits to local sites where the policy can be seen in operation. The meeting is preceded by the compilation of an expert report on which participating 'peer countries' submit comments. The results are published on the web.
The United Nations Economic Commission for Europe , through UNECE Environmental Performance Reviews , uses peer review, referred to as peer learning, to evaluate progress made by its member countries in improving their environmental policies.
The State of California is the only U.S. state to mandate scientific peer review. In 1997, the California Governor signed into law Senate Bill 1320 (Sher), Chapter 295, statutes of 1997, which mandates that, before any CalEPA Board, Department, or Office adopts a final version of a rule-making, the scientific findings, conclusions, and assumptions on which the proposed rule are based must be submitted for independent external scientific peer review. This requirement is incorporated into the California Health and Safety Code Section 57004. [13]

Medical
Medical peer review may refer to clinical peer review , or the peer evaluation of clinical teaching skills for both physicians and nurses, [14] [15] or scientific peer review of journal articles, or to a secondary round of peer review for the clinical value of articles concurrently published in medical journals . [16] " Medical peer review " has been used by the American Medical Association to refer not only to the process of improving quality and safety in health care organizations, but also to the process of rating clinical behavior or compliance with professional society membership standards. [17] [18] Thus, the terminology has poor standardization and specificity, particularly as a database search term. [ citation needed ]

See also
WebPage index: 00102
Natural language processing
Natural language processing ( NLP ) is a field of computer science , artificial intelligence and computational linguistics concerned with the interactions between computers and human (natural) languages , and, in particular, concerned with programming computers to fruitfully process large natural language corpora . Challenges in natural language processing frequently involve natural language understanding , natural language generation (frequently from formal, machine-readable logical forms ), connecting language and machine perception , managing human-computer dialog systems , or some combination thereof.

History
The history of NLP generally started in the 1950s, although work can be found from earlier periods. In 1950, Alan Turing published an article titled " Computing Machinery and Intelligence " which proposed what is now called the Turing test as a criterion of intelligence.
The Georgetown experiment in 1954 involved fully automatic translation of more than sixty Russian sentences into English. The authors claimed that within three or five years, machine translation would be a solved problem. [2] However, real progress was much slower, and after the ALPAC report in 1966, which found that ten-year-long research had failed to fulfill the expectations, funding for machine translation was dramatically reduced. Little further research in machine translation was conducted until the late 1980s, when the first statistical machine translation systems were developed.
Some notably successful NLP systems developed in the 1960s were SHRDLU , a natural language system working in restricted " blocks worlds " with restricted vocabularies, and ELIZA , a simulation of a Rogerian psychotherapist , written by Joseph Weizenbaum between 1964 and 1966. Using almost no information about human thought or emotion, ELIZA sometimes provided a startlingly human-like interaction. When the "patient" exceeded the very small knowledge base, ELIZA might provide a generic response, for example, responding to "My head hurts" with "Why do you say your head hurts?".
During the 1970s, many programmers began to write "conceptual ontologies", which structured real-world information into computer-understandable data. Examples are MARGIE (Schank, 1975), SAM (Cullingford, 1978), PAM (Wilensky, 1978), TaleSpin (Meehan, 1976), QUALM (Lehnert, 1977), Politics (Carbonell, 1979), and Plot Units (Lehnert 1981). During this time, many chatterbots were written including PARRY , Racter , and Jabberwacky .
Up to the 1980s, most NLP systems were based on complex sets of hand-written rules. Starting in the late 1980s, however, there was a revolution in NLP with the introduction of machine learning algorithms for language processing. This was due to both the steady increase in computational power (see Moore's law ) and the gradual lessening of the dominance of Chomskyan theories of linguistics (e.g. transformational grammar ), whose theoretical underpinnings discouraged the sort of corpus linguistics that underlies the machine-learning approach to language processing. [3] Some of the earliest-used machine learning algorithms, such as decision trees , produced systems of hard if-then rules similar to existing hand-written rules. However, part-of-speech tagging introduced the use of hidden Markov models to NLP, and increasingly, research has focused on statistical models , which make soft, probabilistic decisions based on attaching real-valued weights to the features making up the input data. The cache language models upon which many speech recognition systems now rely are examples of such statistical models. Such models are generally more robust when given unfamiliar input, especially input that contains errors (as is very common for real-world data), and produce more reliable results when integrated into a larger system comprising multiple subtasks.
Many of the notable early successes occurred in the field of machine translation , due especially to work at IBM Research, where successively more complicated statistical models were developed. These systems were able to take advantage of existing multilingual textual corpora that had been produced by the Parliament of Canada and the European Union as a result of laws calling for the translation of all governmental proceedings into all official languages of the corresponding systems of government. However, most other systems depended on corpora specifically developed for the tasks implemented by these systems, which was (and often continues to be) a major limitation in the success of these systems. As a result, a great deal of research has gone into methods of more effectively learning from limited amounts of data.
Recent research has increasingly focused on unsupervised and semi-supervised learning algorithms. Such algorithms are able to learn from data that has not been hand-annotated with the desired answers, or using a combination of annotated and non-annotated data. Generally, this task is much more difficult than supervised learning , and typically produces less accurate results for a given amount of input data. However, there is an enormous amount of non-annotated data available (including, among other things, the entire content of the World Wide Web ), which can often make up for the inferior results.
In recent years, there has been a flurry of results showing deep learning techniques [4] [5] achieving state-of-the-art results in many natural language tasks, for example in language modeling, [6] parsing, [7] [8] and many others.

Statistical natural language processing
Since the so-called "statistical revolution" [9] [10] in the late 1980s and mid 1990s, much Natural Language Processing research has relied heavily on machine learning .
Formerly, many language-processing tasks typically involved the direct hand coding of rules, [11] [12] which is not in general robust to natural language variation. The machine-learning paradigm calls instead for using statistical inference to automatically learn such rules through the analysis of large corpora of typical real-world examples (a corpus (plural, "corpora") is a set of documents, possibly with human or computer annotations).
Many different classes of machine learning algorithms have been applied to NLP tasks. These algorithms take as input a large set of "features" that are generated from the input data. Some of the earliest-used algorithms, such as decision trees , produced systems of hard if-then rules similar to the systems of hand-written rules that were then common. Increasingly, however, research has focused on statistical models , which make soft, probabilistic decisions based on attaching real-valued weights to each input feature. Such models have the advantage that they can express the relative certainty of many different possible answers rather than only one, producing more reliable results when such a model is included as a component of a larger system.
Systems based on machine-learning algorithms have many advantages over hand-produced rules:

Major evaluations and tasks
The following is a list of some of the most commonly researched tasks in NLP. Note that some of these tasks have direct real-world applications, while others more commonly serve as subtasks that are used to aid in solving larger tasks.
Though NLP tasks are obviously very closely intertwined, they are frequently, for convenience, subdivided into categories. A coarse division is given below.

Syntax

Semantics

Discourse

Speech

See also
WebPage index: 00103
Paul Sabatier University
Paul Sabatier University ( Université Paul Sabatier , UPS, also known as Toulouse III) is a French university, in the Academy of Toulouse . It is one of the several successor universities of the University of Toulouse . [1]
Toulouse III was named after Paul Sabatier , winner of the 1912 Nobel prize in chemistry, [2] when it was established on the foundations of the old university in 1969. The Université Paul Sabatier (UPS), an educational leader in France’s Midi-Pyrénées region, offers a broad array of programs in the sciences, technology, health, and athletics.

University research activities

Major fields of study
Major fields of study include sciences, engineering, and athletics.

Bachelor
The university offers the Licence programs in eight areas: Mathematics, Computer Science and their applications; Engineering; Physics, Chemistry, and their applications; Space Sciences, Organisms, and Biospheres; Life and Health Sciences; Sciences and Techniques of Physical Activity and Sports; Communication and Organizational Management.

Master
The university offers master 's programs in six areas: Informatics and Systems Modeling (in partnership with the École Nationale de l'Aviation Civile ); [3] Sciences and techniques of matter and energy; Space sciences; Life and health sciences; Social Sciences and Humanities ; Management .
A number of bilingual programs have been designed to appeal to international students — among them a Joint European Master in Space Science and Technology , a European Master’s in materials for energy storage and conversion, an international Master’s in micro and nanotechnologies for wireless communications, a new Master's in Management International of Air Transport and Tourism (MITAT) and a French Master’s in agri-food innovations for sustainable agriculture and better products.

Doctorate
The university accepts doctoral candidates in all of the areas described above.

Health

Points of interest

Notable alumni

See also
WebPage index: 00104
Everything2
Everything2 (styled Everything 2 ), or E2 for short, is a collaborative Web -based community consisting of a database of interlinked user-submitted written material. E2 is moderated for quality, but has no formal policy on subject matter. Writing on E2 covers a wide range of topics and genres, including encyclopedic articles, diary entries (known as "daylogs"), poetry, humor, and fiction.

History
The predecessor of E2 was a similar database called Everything (later labeled "Everything2" or "E2") which was started around March 1998 by Nathan Oostendorp and was initially closely aligned with and promoted by the technology-related news website Slashdot (by virtue of various key principals having attended the Holland Christian High School ), even sharing (at the time) some administrators. The E2 software offered vastly more features, and the Everything1 data was twice incorporated into E2: once on November 13, 1999, and again in January 2000.
The Everything2 server used to be colocated with the Slashdot servers. However, some time after OSDN acquired Slashdot, and moved the Slashdot servers, this hosting was terminated on short notice. This resulted in Everything2 being offline from roughly November 6 to December 9, 2003. Everything2 was then hosted by the University of Michigan for a time. As the Everything2 site put it on October 2, 2006:
The Everything2 servers were moved to the nearby Michigan State University in February 2007.
E2 was privately owned by the Blockstackers Intergalactic company, [4] but does not make a profit and is viewed by its long-term users as a collaborative work-in-progress. Until mid-2007 it accepted donations of money and, on occasion, of computer hardware but no longer does so. Some of its administrators are affiliated with Blockstackers, some are not. The site is not a democracy, and the degree to which users influence decisions depends on the nature of the decisions and the administrators making them. As of January 23, 2012, it was announced that the site had been sold to long-time user and coder Jay Bonci under the name Everything2 Media LLC.
Writeups in E1 were limited to 512 bytes in size. This, plus the predominantly "geek" membership back then and the lack of chat facilities, meant the early work was often of poor quality and was filled with self-referential humor . As E2 has expanded, stricter quality standards have developed, much of the old material has been removed, and the membership has become broader in interest, although smaller in number. Many noders prefer to write encyclopedic articles similar to those on Wikipedia (and indeed some actively contribute to both E2 and Wikipedia). Some write fiction or poetry, some discuss issues, and some write daily journals, called "daylogs." Unlike Wikipedia, E2 does not have an enforced neutral point of view . An informal survey of noder political beliefs [5] indicates that the user base tends to lean left politically. There are conservative voices as well, however, and while debate nodes (of any kind, political or not) are rarely tolerated, well-formed points of view from any part of the political or cultural spectrum are.
According to E2's "Site Trajectory,", [6] traffic has dropped from 9976 new write-ups created in the month of August 2000, down to 93 new write-ups in February 2017.

Community

Policies
Some of the management regard Everything2 as a publication, to which authors submit content. Although Everything2 does not seek to become an encyclopedia , a substantial amount of factual content has been submitted to Everything2.
Policy states that "Everything2 is not a bulletin board." Writeups which exist as replies to other writeups, or which add a minor point to them or which otherwise do not stand well alone are discouraged, not least because the deletion of the original writeup orphans any replies. This policy helps to moderate flame wars on controversial topics.
Everything2 is not a wiki , and there is no direct way for non-content editors to make corrections or amendments to another author's article. Avenues for correction involve discussing the writeup with its author; petitioning a content editor; adding a note in a special "broken nodes" section; or superseding the original writeup with an original, stand-alone follow-up.

Code of behavior
Like other online communities, E2 has a social hierarchy and code of behavior, to which it is sometimes difficult for a newcomer to adjust. Moreover, some people complain that new users are held to a different standard from established contributors, and that their writeups are singled out for deletion regardless of content. Another complaint is that all too often, site administrators remove articles that they do not agree with or which they do not see explicit value in, thus biasing the content of the database. Others dismiss such complaints as unjustified; they observe that few communities treat newcomers exactly like long-time members, and they claim that those who learn and obey the rules are usually—though not always—treated fairly.
There is no consistent, written site policy on acceptable behavior, although the usual intolerance for trolling or hatemongering remains, as is the case with most web-based communities. Bans have occurred for antisocial and/or insulting behaviour, [ citation needed ] albeit very rarely and only after a more personal approach to change the offender's behavior. Though these decisions are broadly accepted, some current and ex-members of the site believe that this amounts to mismanagement, and point to accumulation of disgruntled ex-users as evidence of a problem. [ citation needed ]
Rarely, a noder will request their E2 account be locked, preventing them from logging in. The causes for this are equally varied as the causes for disruptive noders being forcibly locked out, and happens about as often.

Nodes and writeups
E2 users called noders create entries called nodes and add information in multiple writeups. Only logged-in users can create writeups, and only the author of a writeup or an editor appointed by the site administrators can edit a writeup. E2 categorizes writeups into thirteen types: person , place , idea , thing , dream , personal , fiction , poetry , review , log , recipe , essay , and event . Two additional writeup types, lede and definition , are usable only by editors and are applied retroactively. Writeups are written in a simplified HTML dialect and do not contain images.
There are other types of nodes that do not contain writeups; for instance, the administrators can create "superdoc" nodes (similar to Wikipedia 's special pages ) such as Everything New Nodes and Page of Cool that allow interaction, and each user has a "homenode" where he or she can add a short autobiography or other text (or a picture, if the user has posted ten writeups—see Rewards , below).

Copyright practice
The copyright in a writeup rests with the author, and no agreement to any kind of license is entered into by writing on E2 (except for giving the site permission to publish). Authors retain the right to place their work in the public domain, to release it under a copyleft license such as one of those offered by the GNU project or Creative Commons , or to request the removal of their work from the site at some later date.
For a long time, the posting of copyrighted song lyrics and poetry to the site without approval from the copyright holders, while certainly frowned upon, was not actually prohibited. E2 chose to only passively enforce copyright law, in a manner similar to an ISP (for which see OCILLA section 512(c) ). This policy changed in August 2003 to a more active one where writeups containing copyrighted material had to either conform to fair use guidelines (length limits, proportion of quoted material to new text) or be posted with permission.

Rewards
The administrators loosely based E2's incentive system on a dual currency system borrowed from many role-playing games . Users may earn experience points ("XP"), which count strictly toward level progress, or convertible currency ("GP"), which may be used to purchase lesser, temporary privileges. Every time a user creates a writeup, he or she earns five XP. Users with at least ten contributed writeups and 500 experience points can vote (up or down) on a writeup. A positive vote grants the writeup's author one experience point while also having a roughly ⅓ chance of giving one GP to the voter. After voting on a writeup, a noder can see the writeup's "reputation," or number of positive and negative votes (staff do not need to vote in order to see a writeup's reputation). The site's editors may remove writeups that do not meet editorial standards from public view. Authors have the ability to withdraw their own writeups. In both cases the removed writeup is sent to its author's personal "drafts" space, where it may be prepared for re-submission or deleted. The only effect writeup deletion has on the author's account is that the five XP granted for creating the writeup is removed. Writeups deleted before March 2011 are visible to the author on a legacy page called "Node Heaven"; newer or more recently removed items become drafts.
New levels are attained by reaching a predefined, but arbitrary total of XP and writeups, which are given in the FAQ. [7] The system grants special powers at certain experience levels, such as "cool", which rewards the author with 20 XP and sends the writeup to the "cool user picks" column on the front page; the ability to create basic chat rooms on the site; space for uploading a picture to a user's "homenode"; and the ability to hide one's self in the list of logged-in users.
Website views used to be tracked, but due to a glitch this ability was removed. The glitch looped the view counter and crashed the site on more than one occasion.

Messaging
Everything2 provides two communication tools: the Chatterbox [8] and the message system.
The Chatterbox is similar to an IRC channel. It is also nicknamed the catbox. It appears as a panel on the right side of the page that logged-in users can use to read conversations and participate in them. The site's administrators used to have the ability to "borg"—prevent from using the Chatterbox or message system—those users whose behavior violated the unwritten standards of politeness and decorum. This was done through a bot called EDB (short for "Everything Death Borg"), which announced when it had "swallowed" a user. This silencing lasted for five minutes, though persistent trolls were silenced for a longer period—sometimes permanently. As of 2003 [update] , the EDB was no longer much used, only making mostly token appearances for humorous effect. Noders who consistently cause trouble (usually by trolling ) can be silenced permanently and can be forbidden from noding altogether, though this is rarely done. This would be initiated by a chanops, (A staff member with a + by his or her username that monitors potential abuse ). There is also a utility called 'chatterlight', which provides the chatlog / message buffer with a larger portion of the screen.
The message system lets users send private messages to other users. The messages are stored in the user's mailbox to be read when he or she next logs in. The main use for the message system is giving constructive criticism to the author of a writeup; however, it can be and is used like any medium of private communication. Messages received can be archived or deleted at the receiver's discretion.

Links

Hard links
Hard links in E2 are simply words or phrases surrounded by [square brackets]. Any words inside square brackets in a writeup will become a link to the E2 node of that title. If a node with that title does not yet exist, following the link will bring up the option to create it.
For the longest part of its existence, E2 did not permit links to third-party web sites in submitted content. In February 2009, a degree of support for linking external URLs was implemented. A hard linked URL will be clearly marked as an external link with the same link icon that Wikipedia uses. Heavy use of external URLs is discouraged as E2 content is expected to stand on its own within a largely self-supportive infrastructure.

Pipe links
Pipe links are a variant form of hard links. While a hard link to the node Wikipedia would look like [Wikipedia] , the pipe link allows the author a greater degree of freedom without restricting what nodes can be linked to. For example, one could write " [Wikipedia|Online encyclopedias] have started to become common sources in my students' research papers. " The sentence looks like this to the reader: " Online encyclopedias have started to become common sources in my students' research papers." Rolling over the phrase with the mouse (e.g. "online encyclopedias") shows the hidden content (in this case, "Wikipedia") as the link's title.
Noders can link to a specific writeup within a node by appending (person) , (place) , (idea) or (thing) to a pipe link. For example, the pipe link [Wiki (thing)|Wiki] links directly to the writeup of the type thing within the Wiki node. If the node contains more than one writeup of the specified type, the pipe link returns a "Duplicates Found" page linking to every writeup of the specified type within the node.
Pipe links on E2 often add " easter egg " content, such as commentary, humor and hidden information. [9]

Soft links
At the bottom of every node, the system displays up to 64 soft links , though each node can store an unlimited number thereof. "Guest Users"—any viewers not logged in—can see 24, a logged-in user can see up to 48, and the senior administrators ("gods," though this term has fallen out of favour in recent years) can see up to 64. These are two-way links intended to approximate "thought processes," similar in concept to Jason Rohrer 's tangle proxy. Whenever a logged-in user moves from one node to another, be it through a hard link, another soft link, or through the title search box, the system creates (or strengthens) the bidirectional soft link between the two; however, some nodes—namely the special pages and the user profiles—will not display the soft links so created. By repeatedly moving from one node to another, users can and do deliberately create and increase the degree of integration of such soft links; some users will use these soft links to make anonymous comments on others' writing. The site's administrators have the ability to remove soft links at their discretion.

Firm links
Firm links are special, editor-created links that serve to redirect between nodes. Firm links are typically used to link multiple forms of a single name or title to aid searching and ensure that readers find the content that they are seeking. A typical use of firm links would be to permanently link the empty node titled 'USA' to a node titled 'United States of America' that contained writeups about the topic. Alternatively, automatic forwarding can be set up for the same thing, in much the same way as forwards exist on Wikipedia.

Software
E2 is run by the free Everything Engine ( ecore ), a Perl -based system; its data is stored in a MySQL database. [10]

Media coverage
In 2001, The New York Times cited E2 as an example of an emerging class of autonomous, self-organizing sites. [11] A 2001 column in The Japan Times called E2 "awe-inspiring in its expansiveness and depth" and "a Sim City of knowledge management". [12] In 2003, Guardian Unlimited listed E2 as one of the best collaborative encyclopedias on the Web. [13] E2 was nominated for a 2004 Webby Award for Technical Achievement. [14]

See also
WebPage index: 00105
Knowledge base
A knowledge base ( KB ) is a technology used to store complex structured and unstructured information used by a computer system. The initial use of the term was in connection with expert systems which were the first knowledge-based systems .
The original use of the term knowledge-base was to describe one of the two sub-systems of a knowledge-based system. A knowledge-based system consists of a knowledge-base that represents facts about the world and an inference engine that can reason about those facts and use rules and other forms of logic to deduce new facts or highlight inconsistencies. [1]
The term "knowledge-base" was coined to distinguish this form of knowledge store from the more common and widely used term database . At the time (the 1970s) virtually all large Management Information Systems stored their data in some type of hierarchical or relational database . At this point in the history of Information Technology the distinction between a database and a knowledge base was clear and unambiguous. A database had these properties:
The first knowledge-based systems had data needs that were the opposite of these database requirements. An expert system requires structured data. Not just tables with numbers and strings, but pointers to other objects that in turn have additional pointers. The ideal representation for a knowledge base is an object model (often called an ontology in artificial intelligence literature) with classes, subclasses, and instances.
Early expert systems also had little need for multiple users or the complexity that comes with requiring transactional properties on data. The data for the early expert systems was used to arrive at a specific answer, such as a medical diagnosis, the design of a molecule, or a response to an emergency. [1] Once the solution to the problem was known there was not a critical demand to store large amounts of data back to a permanent memory store. A more precise statement would be that given the technologies available researchers compromised and did without these capabilities because they realized they were beyond what could be expected and they could develop useful solutions to non-trivial problems without them. Even from the beginning the more astute researchers realized the potential benefits of being able to store, analyze, and reuse knowledge. For example, see the discussion of Corporate Memory in the earliest work of the Knowledge-Based Software Assistant program by Cordell Green et al. [2]
The volume requirements were also different for a knowledge-base compared to a conventional database. The knowledge-base needed to know facts about the world. For example, to represent the statement that "All humans are mortal". A database typically could not represent this general knowledge but instead would need to store information about thousands of tables that represented information about specific humans. Representing that all humans are mortal and being able to reason about any given human that they are mortal is the work of a knowledge-base. Representing that George, Mary, Sam, Jenna, Mike,... and hundreds of thousands of other customers are all humans with specific ages, sex, address, etc. is the work for a database. [3] [4]
As expert systems moved from being prototypes to systems deployed in corporate environments the requirements for their data storage rapidly started to overlap with the standard database requirements for multiple, distributed users with support for transactions. Initially, the demand could be seen in two different but competitive markets. From the AI and Object-Oriented communities object-oriented databases such as Versant emerged. These were systems designed from the ground up to have support for object-oriented capabilities but also to support standard database services as well. On the other hand, the large database vendors such as Oracle added capabilities to their products that provided support for knowledge-base requirements such as class-subclass relations and rules.
The next evolution for the term knowledge-base was the Internet. With the rise of the Internet documents, hypertext, and multimedia support were now critical for any corporate database. It was no longer enough to support large tables of data or relatively small objects that lived primarily in computer memory. Support for corporate web sites required persistence and transactions for documents. This created a whole new discipline known as Web Content Management . The other driver for document support was the rise of knowledge management vendors such as Lotus Notes . Knowledge Management actually predated the Internet but with the Internet there was great synergy between the two areas. Knowledge management products adopted the term "knowledge-base" to describe their repositories but the meaning had a subtle difference. In the case of previous knowledge-based systems the knowledge was primarily for the use of an automated system, to reason about and draw conclusions about the world. With knowledge management products the knowledge was primarily meant for humans, for example to serve as a repository of manuals, procedures, policies, best practices, reusable designs and code, etc. Of course in both cases the distinctions between the uses and kinds of systems were ill defined. As the technology scaled up it was rare to find a system that could really be cleanly classified as knowledge-based in the sense of an expert system that performed automated reasoning and knowledge-based in the sense of knowledge management that provided knowledge in the form of documents and media that could be leveraged by humans. [5]

See also

Notes
WebPage index: 00106
Encyclopedia of Life
The Encyclopedia of Life ( EOL ) is a free, online collaborative encyclopedia intended to document all of the 1.9 million living species known to science. It is compiled from existing databases and from contributions by experts and non-experts throughout the world. [2] It aims to build one "infinitely expandable" page for each species, including video, sound, images, graphics, as well as text. [3] In addition, the Encyclopedia incorporates content from the Biodiversity Heritage Library , which digitizes millions of pages of printed literature from the world's major natural history libraries. The project was initially backed by a US$50 million funding commitment, led by the MacArthur Foundation and the Sloan Foundation , who provided US$20 million and US$5 million, respectively. The additional US$25 million came from five cornerstone institutions—the Field Museum , Harvard University , the Marine Biological Laboratory , the Missouri Botanical Garden , and the Smithsonian Institution . The project was initially led by Jim Edwards [4] and the development team by David Patterson . Today, participating institutions and individual donors continue to support EOL through financial contributions.

Overview
EOL went live on 26 February 2008 with 30,000 entries. [5] The site immediately proved to be extremely popular, and temporarily had to revert to demonstration pages for two days when it was overrun by traffic from over 11 million views it received. [6]
The site relaunched on 5 September 2011 with a redesigned interface and tools. [7] The new version – referred to as EOLv2 – was developed in response to requests from the general public, citizen scientists, educators and professional biologists for a site that was more engaging, accessible and personal. EOLv2 is redesigned to enhance usability and encourage contributions and interactions among users. The product is also internationalized with interfaces provided for English , German , Spanish , French , Galician , Serbian , Macedonian , Arabic , Chinese , Korean and Ukrainian language speakers. On 16 January 2014, EOL launched TraitBank, a searchable, open digital repository for organism traits, measurements, interactions and other facts for all taxa across the tree of life. [8]
The initiative's Executive Committee includes senior officers from the Atlas of Living Australia, the Biodiversity Heritage Library consortium, the Chinese Academy of Sciences , CONABIO , Field Museum , Harvard University , the Bibliotheca Alexandrina (Library of Alexandria), MacArthur Foundation , Marine Biological Laboratory , Missouri Botanical Garden , Sloan Foundation , and the Smithsonian Institution . [9] [10]

Intention
Information about many species is already available from a variety of sources, in particular about the megafauna . Gathering currently available data on all 1.9 million species will take about 10 years. [11] As of September 2011 [update] , EOL had information on more than 700,000 species available, along with more than 600,000 photos and millions of pages of scanned literature. [12] The initiative relies on indexing information compiled by other efforts, including the Sp2000 and ITIS Catalogue of Life , Fishbase and the Assembling Tree of Life project of NSF , AmphibiaWeb, Mushroom explorer, microscope, etc. The initial focus has been on living species but will later include extinct species. As the discovery of new species is expected to continue (the current rate is about 20,000 per year), the encyclopedia will grow continuously. As taxonomy finds new ways to include species discovered by molecular techniques, the rate of new species additions will increase – in particular in respect of the microbial work of (eu)bacteria, archaebacteria and viruses.
The goal of EOL is to serve as a resource for the general public, enthusiastic amateurs, educators, students and professional scientists from around the world. [2]

Resources and collaborations
The Encyclopedia of Life has content partners around the world who share information through the EOL platform, [13] including Wikipedia and Flickr .
Its interface is translated at translatewiki.net .

See also
WebPage index: 00107
Democratization of knowledge
The democratization of knowledge is the acquisition and spread of knowledge amongst the common people, not just privileged elites such as clergy and academics. Libraries—public libraries in particular—and modern digital technology such as the internet—play a key role in the democratization of knowledge, as they provide open access of information to the masses.

History
The printing press was one of the early steps towards the democratization of knowledge.
Another small example of this during the Industrial Revolution was the creation of libraries for miners in some Scottish villages in the 18th century. [1]
Wikipedia is rapidly turning into a real-time reference tool in which public entries can be updated by anyone at any time. This phenomenon—a product of the digital age —has greatly contributed to the democratization of knowledge in the post-modern era. At the same time, it has raised a number of valid criticisms in this regard (see Reliability of Wikipedia page). For instance, one could draw a distinction between the mere spread of information and the spread of accurate or credible information. Wikipedia may thus be a more reliable source of information in certain spheres, but not necessarily in others.

In the Digital Age
The democratization of technology has played a major facilitating role. Wikipedia co-founder, Larry Sanger , states in his article, [2] that “Professionals are no longer needed for the bare purpose of the mass distribution of information and the shaping of opinion.” Sanger’s article confronts the existence of “common knowledge” and pits it against knowledge that everyone agrees on.
In terms of democratization of knowledge, Wikipedia has played a major role. For instance, Wikipedia has attracted 400 million viewers across the globe and has communicated with them in over 270 languages.
Google Book Search has been pointed to as an example of democratization of knowledge, but Malte Herwig in Der Spiegel raised concerns that the virtual monopoly Google has in the search market , combined with Google's hiding of the details of its search algorithms , could undermine this move towards democratization. [3]

Role of libraries
An article written in 2005 by the editors of Reference & User Services Quarterly calls the library the greatest force for the democratization of knowledge or information. [4] It continues to say that public libraries in particular are inextricably linked with the history and evolution of the United States, but school library media centers, college and university libraries, and special libraries have all also been inﬂuential in their support for democracy. [4] Libraries play an essential role in the democratization of knowledge and information by providing communities with the resources and tools to find information free of charge. Democratic access to knowledge has also been co-opted to mean providing information in a variety of formats, which essentially means electronic and digital formats for use by library patrons. [5] Public libraries help further the democratization of information by guaranteeing freedom of access to information, by providing an unbiased variety of information sources and access to government services, as well as the promotion of democracy and an active citizenship. [6] Dan Cohen, the founding executive director of the Digital Public Library of America, writes that the democratic access to knowledge is a profound idea that requires constant tending and revitalization. [5] In 2004, a World Social Forum and International workshop was held entitled "Democratization of Information: Focus on Libraries". The focus of the forum was to bring awareness to the social, technological, and financial challenges facing libraries dealing with the democratization of information. Social challenges included globalization and the digital divide , technological challenges included information sources, and financial challenges constituted shrinking budgets and manpower. [7] Longtime Free Library of Philadelphia director Elliot Shelkrot said that “Democracy depends on an informed population. And where can people get all the information they need? —At the Library.” [8]

See also
WebPage index: 00108
Print Wikipedia
Print Wikipedia is an art project by Michael Mandiberg that printed 106 of the 7,473 volumes of English Wikipedia as it existed on April 7, 2015 and also included wallpaper displaying 1,980 additional volumes. [1] [2] A 36-volume index of all of the 7.5 million contributors to English Wikipedia is also part of the project. The table of contents takes up 91 700-page volumes. [3] The printed volume only includes text of the articles. Images and references are not included. [4] The project was shown at Denny Gallery in New York City in the summer of 2015. [5]
Mandiberg originally thought of the project in 2009 but ran into technical difficulties. He then engaged an assistant, Jonathan Kirinathan, to aid with the programming of the code to compile, format and upload an entire English Wikipedia download. [1] The print files were uploaded to self book publisher Lulu.com and are available for printout as paper volumes.
Mandiberg's motivation was to answer the question, "How big is it?" For a big data entity, its size is on the threshold of what can be perceived as a collection of volumes, but not so large as to overwhelm one's senses, such as the data files of Facebook or the NSA . [6] Katherine Maher , chief communications officer of the Wikimedia Foundation , has described it as "a gesture at knowledge". It has also been described as a "futile grand gesture". Wikimedia has cooperated with the project and Lulu.com has helped fund it. [3]
The task took three years, and the upload process took 24 days, 3 hours and 18 minutes. It was completed on 12 July 2015. [7] PediaPress had attempted to raise money for a full English Wikipedia print out on Indiegogo in 2014, but the project was pulled. [8] Mandiberg estimates that the printing costs of a full printout are around $500,000. The Denny art exhibit featured only a selection of actually printed volumes with about 2000 of the other volumes represented as spines on the wall. The show revolved around the actual upload of the print files to Lulu.com. [5]

See also
WebPage index: 00109
Wayback Machine
The Wayback Machine is a digital archive of the World Wide Web and other information on the Internet created by the Internet Archive , a nonprofit organization , based in San Francisco , California , United States . The Internet Archive launched the Wayback Machine in October 2001. [4] [5] It was set up by Brewster Kahle and Bruce Gilliat , and is maintained with content from Alexa Internet . The service enables users to see archived versions of web pages across time, which the archive calls a "three dimensional index".
Since 1996, the Wayback Machine has been archiving cached pages of websites onto its large cluster of Linux nodes. It revisits sites every few weeks or months and archives a new version. Sites can also be captured on the fly by visitors who enter the site's URL into a search box. The intent is to capture and archive content that otherwise would be lost whenever a site is changed or closed down. The overall vision of the machine's creators is to archive the entire Internet. [6]
The name Wayback Machine was chosen as a reference to the " WABAC machine " (pronounced way-back ), a time-traveling device used by the characters Mr. Peabody and Sherman in The Rocky and Bullwinkle Show , an animated cartoon. [7] [8] In one of the animated cartoon's component segments, Peabody's Improbable History , the characters routinely used the machine to witness, participate in, and, more often than not, alter famous events in history. [ citation needed ]

History

Origins
In 1996, Deepak, with Bruce Gilliat, developed software to crawl and download all publicly accessible World Wide Web pages, the Gopher hierarchy, the Netnews (Usenet) bulletin board system, and downloadable software. [9] The information collected by these "crawlers" does not include all the information available on the Internet, since much of the data is restricted by the publisher or stored in databases that are not accessible. To overcome inconsistencies in partially cached websites, Archive-It.org was developed in 2005 by the Internet Archive as a means of allowing institutions and content creators to voluntarily harvest and preserve collections of digital content, and create digital archives.
Information had been kept on digital tape for five years, with Kahle occasionally allowing researchers and scientists to tap into the clunky database. [10] When the archive reached its fifth anniversary, it was unveiled and opened to the public in a ceremony at the University of California, Berkeley .
Snapshots usually become available more than six months after they are archived or, in some cases, even later; it can take twenty-four months or longer. [11] The frequency of snapshots is variable, so not all tracked website updates are recorded. Sometimes there are intervals of several weeks or years between snapshots.
After August 2008 sites had to be listed on the Open Directory in order to be included. [12] According to Jeff Kaplan of the Internet Archive in November 2010, other sites were still being archived, [13] but more recent captures would become visible only after the next major indexing, an infrequent operation.

Storage capabilities
As of 2009 [update] , the Wayback Machine contained approximately three petabytes of data and was growing at a rate of 100 terabytes each month; [14] the growth rate reported in 2003 was 12 terabytes/month. The data is stored on PetaBox rack systems manufactured by Capricorn Technologies . [15]
In 2009, the Internet Archive migrated its customized storage architecture to Sun Open Storage , and hosts a new data center in a Sun Modular Datacenter on Sun Microsystems ' California campus. [16]
In 2011 a new, improved version of the Wayback Machine, with an updated interface and fresher index of archived content, was made available for public testing. [17]
In March 2011, it was said on the Wayback Machine forum that "The Beta of the new Wayback Machine has a more complete and up-to-date index of all crawled materials into 2010, and will continue to be updated regularly. The index driving the classic Wayback Machine only has a little bit of material past 2008, and no further index updates are planned, as it will be phased out this year". [18]
In January 2013, the company announced a ground-breaking milestone of 240 billion URLs. [19]
In October 2013, the company announced the "Save a Page" feature [20] which allows any Internet user to archive the contents of a URL. This became a threat of abuse by the service for hosting malicious binaries . [21] [22]
As of December 2014 [update] , the Wayback Machine contained almost nine petabytes of data and was growing at a rate of about 20 terabytes each week. [23]
As of July 2016 [update] , the Wayback Machine reportedly contained around 15 petabytes of data. [24]

Growth
Between October 2013 and March 2015 the website's global Alexa rank changed from 162 [25] to 208. [26]

Website exclusion policy
Historically, Wayback Machine respected the robots exclusion standard (robots.txt) in determining if a website would be crawled or not; or if already crawled, if its archives would be publicly viewable. Website owners had the option to opt-out of Wayback Machine through the use of robots.txt. It applied robots.txt rules retroactively; if a site blocked the Internet Archive, any previously archived pages from the domain were immediately rendered unavailable as well. In addition the Internet Archive stated, "Sometimes a website owner will contact us directly and ask us to stop crawling or archiving a site. We comply with these requests." [38] In addition, the website says: "The Internet Archive is not interested in preserving or offering access to Web sites or other Internet documents of persons who do not want their materials in the collection." [39]
This policy began to relax in 2017, when it stopped honoring robots.txt on U.S. government and military web sites for both crawling and displaying web pages. As of April 2017, Wayback is exploring ignoring robots.txt more broadly, not just for U.S. government websites. [40] [41] [42] [43]

Uses
The site is frequently used by journalists and citizens to review dead websites, dated news reports or changes to website contents. Its content has been used to hold politicians accountable and expose battlefield lies. [44]
In 2014 an archived social media page of separatist rebel leader in Ukraine Igor Girkin showed him boasting about his troops having shot down a suspected Ukrainian military airplane before it became known that the plane actually was a civilian Malaysian Airlines jet after which he deleted the post and blamed Ukraine's military. [44] [45]
In 2017 the March for Science originated from a discussion on reddit that indicated someone had visited Archive.org and discovered that all references to climate change had been deleted from the White House website. In response, a user commented, "There needs to be a Scientists' March on Washington". [46] [47] [48]
Furthermore the site is used heavily for verification, providing access to references and content creation by Wikipedia editors . [ citation needed ]

In legal evidence

Civil litigation

Netbula LLC v. Chordiant Software Inc.
In a 2009 case, Netbula, LLC v. Chordiant Software Inc. , defendant Chordiant filed a motion to compel Netbula to disable the robots.txt file on its website that was causing the Wayback Machine to retroactively remove access to previous versions of pages it had archived from Netbula's site, pages that Chordiant believed would support its case. [49]
Netbula objected to the motion on the ground that defendants were asking to alter Netbula's website and that they should have subpoenaed Internet Archive for the pages directly. [50] An employee of Internet Archive filed a sworn statement supporting Chordiant's motion, however, stating that it could not produce the web pages by any other means "without considerable burden, expense and disruption to its operations." [49]
Magistrate Judge Howard Lloyd in the Northern District of California, San Jose Division, rejected Netbula's arguments and ordered them to disable the robots.txt blockage temporarily in order to allow Chordiant to retrieve the archived pages that they sought. [49]

Telewizja Polska
In an October 2004 case, Telewizja Polska USA, Inc. v. Echostar Satellite , No. 02 C 3293, 65 Fed. R. Evid. Serv. 673 (N.D. Ill. Oct. 15, 2004), a litigant attempted to use the Wayback Machine archives as a source of admissible evidence, perhaps for the first time. Telewizja Polska is the provider of TVP Polonia and EchoStar operates the Dish Network . Prior to the trial proceedings, EchoStar indicated that it intended to offer Wayback Machine snapshots as proof of the past content of Telewizja Polska's website. Telewizja Polska brought a motion in limine to suppress the snapshots on the grounds of hearsay and unauthenticated source, but Magistrate Judge Arlander Keys rejected Telewizja Polska's assertion of hearsay and denied TVP's motion in limine to exclude the evidence at trial. [51] [52] At the trial, however, district Court Judge Ronald Guzman, the trial judge, overruled Magistrate Keys' findings, [ citation needed ] and held that neither the affidavit of the Internet Archive employee nor the underlying pages ( i.e. , the Telewizja Polska website) were admissible as evidence. Judge Guzman reasoned that the employee's affidavit contained both hearsay and inconclusive supporting statements, and the purported web page printouts were not self-authenticating. [ citation needed ]

Patent law
Provided some additional requirements are met (e.g., providing an authoritative statement of the archivist), the United States patent office and the European Patent Office will accept date stamps from the Internet Archive as evidence of when a given Web page was accessible to the public. These dates are used to determine if a Web page is available as prior art for instance in examining a patent application. [53]

Limitations of utility
There are technical limitations to archiving a website, and as a consequence, it is possible for opposing parties in litigation to misuse the results provided by website archives. This problem can be exacerbated by the practice of submitting screen shots of web pages in complaints, answers, or expert witness reports, when the underlying links are not exposed and therefore, can contain errors. For example, archives such as the Wayback Machine do not fill out forms and therefore, do not include the contents of non- RESTful e-commerce databases in their archives. [54]

Legal status
In Europe the Wayback Machine could be interpreted as violating copyright laws. Only the content creator can decide where their content is published or duplicated, so the Archive would have to delete pages from its system upon request of the creator. [55] The exclusion policies for the Wayback Machine may be found in the FAQ section of the site. [ citation needed ]

Archived content legal issues
A number of cases have been brought against the Internet Archive specifically for its Wayback Machine archiving efforts.

Scientology
In late 2002, the Internet Archive removed various sites that were critical of Scientology from the Wayback Machine. [56] An error message stated that this was in response to a "request by the site owner". [57] Later, it was clarified that lawyers from the Church of Scientology had demanded the removal and that the site owners did not want their material removed. [58]

Healthcare Advocates, Inc.
In 2003, Harding Earley Follmer & Frailey defended a client from a trademark dispute using the Archive's Wayback Machine. The attorneys were able to demonstrate that the claims made by the plaintiff were invalid, based on the content of their website from several years prior. The plaintiff, Healthcare Advocates, then amended their complaint to include the Internet Archive, accusing the organization of copyright infringement as well as violations of the DMCA and the Computer Fraud and Abuse Act . Healthcare Advocates claimed that, since they had installed a robots.txt file on their website, even if after the initial lawsuit was filed, the Archive should have removed all previous copies of the plaintiff website from the Wayback Machine. [59] The lawsuit was settled out of court. [60]

Suzanne Shell
In December 2005, activist Suzanne Shell filed suit demanding Internet Archive pay her US $100,000 for archiving her website profane-justice.org between 1999 and 2004. [61] [62] Internet Archive filed a declaratory judgment action in the United States District Court for the Northern District of California on January 20, 2006, seeking a judicial determination that Internet Archive did not violate Shell's copyright . Shell responded and brought a countersuit against Internet Archive for archiving her site, which she alleges is in violation of her terms of service . [63] On February 13, 2007, a judge for the United States District Court for the District of Colorado dismissed all counterclaims except breach of contract . [62] The Internet Archive did not move to dismiss copyright infringement claims Shell asserted arising out of its copying activities, which would also go forward. [64]
On April 25, 2007, Internet Archive and Suzanne Shell jointly announced the settlement of their lawsuit. [61] The Internet Archive said it "...has no interest in including materials in the Wayback Machine of persons who do not wish to have their Web content archived. We recognize that Ms. Shell has a valid and enforceable copyright in her Web site and we regret that the inclusion of her Web site in the Wayback Machine resulted in this litigation." Shell said, "I respect the historical value of Internet Archive's goal. I never intended to interfere with that goal nor cause it any harm." [65]

Daniel Davydiuk
In 2013–14, a pornographic actor was trying to remove archived images of himself, first by sending multiple DMCA requests to the Archive and then in the Federal Court of Canada . [66] [67]

Search engine links
In 2005, Yahoo! Search began to provide links to other versions of pages archived on the Wayback Machine. [68]

Censorship and other threats
Archive.org is currently blocked in China . [69] [70] After the site enabled the encrypted HTTPS protocol, the Internet Archive was blocked in its entirety Russia in 2015. [71] [72] [44] [ needs update? ]
Alison Macrina, director of the Library Freedom Project, notes that "while librarians deeply value individual privacy, we also strongly oppose censorship". [44]
There are known rare cases where online access to content which "for nothing" has put people in danger was disabled. [44]
In April 2017, emails of French presidential candidate Emmanuel Macron were leaked to the site and elsewhere . [73] [74] As archive.org is not a website for publishing original leaks, uploading this data to the site first may have been intended to or may effectively cause harm to the site. [ citation needed ]
Other threats include natural disasters, [75] destruction (remote or physical), [ citation needed ] manipulation of the archive's contents (see also: cyberattack , backup ), problematic copyright laws [76] and surveillance of the site's users. [77]
Kevin Vaughan suspects that in the long-term of multiple generations "next to nothing" will survive in a useful way besides "if we have continuity in our technological civilization" by which "a lot of the bare data will remain findable and searchable". [78]
Some find the Internet Archive, which describes itself to be built for the long-term, [79] to be working furiously to capture data before it disappears without any long-term infrastructure to speak of. [80]

See also
WebPage index: 00110
First Monday (journal)
First Monday is a monthly peer-reviewed open access academic journal covering research on the Internet .

Publication
The journal is sponsored and hosted by the University of Illinois at Chicago . It is published on the first Monday of every month. [1] In 2011, the journal had an acceptance rate of about 15%. [1]
The journal has no article processing charges and no advertisements. [1]

History
According to the chief editor, Edward Valauskas, the journal emerged before the open access model emerged:
First Monday originated in the summer of 1995 with a proposal to start a new Internet-only, peer-reviewed journal about the Internet by eventual editor-in-chief Edward J. Valauskas to Munksgaard , a Danish publisher. Munksgaard agreed to publish the journal in September 1995. The first issue appeared on 6 May 1996, the first Monday of May, also the opening of the Fifth International World Wide Web Conference in Paris. The first issue was distributed at that conference on diskette as well as released on the Internet from a server in Copenhagen at the address www.firstmonday.dk.
In December 1998, Munksgaard sold the journal to three of the editors: Edward J. Valauskas, Esther Dyson, and Rishab Aiyer Ghosh. The server was moved from Copenhagen to the University of Illinois at Chicago’s Library. The first issue based on a server in Chicago appeared 4 January 1999.

Conferences
The first First Monday conference took place 4–6 November 2001 in Maastricht at the International Institute of Infonomics . To celebrate First Monday’s 10th birthday in 2006, a conference took place at the University of Illinois at Chicago, 15–17 May 2006. The theme of the conference was Openness: Code, science and content. Over 200 participants from over 30 countries took part in the meeting. Papers from the Conference were published in the June and July issues. The conference was sponsored by The Open Society Institute , The John D. and Catherine T. MacArthur Foundation , The University of Illinois at Chicago University Library and The Maastricht Economic Research Institute on Innovation and Technology (MERIT), University of Maastricht .
WebPage index: 00111
Clay Shirky
Clay Shirky (born 1964 [2] ) is an American writer, consultant and teacher on the social and economic effects of Internet technologies and journalism.
He has a joint appointment at New York University (NYU) as a Distinguished Writer in Residence at the Arthur L. Carter Journalism Institute and Assistant Arts Professor in the New Media focused graduate Interactive Telecommunications Program (ITP). [3] His courses address, among other things, the interrelated effects of the topology of social networks and technological networks, how our networks shape culture and vice versa. [4]
He has written and been interviewed about the Internet since 1996. His columns and writings have appeared in Business 2.0 , The New York Times , the Wall Street Journal , the Harvard Business Review and Wired . Shirky divides his time between consulting, teaching, and writing on the social and economic effects of Internet technologies. His consulting practice is focused on the rise of decentralized technologies such as peer-to-peer , web services , and wireless networks that provide alternatives to the wired client–server infrastructure that characterizes the World Wide Web . He is a member of the Wikimedia Foundation's Advisory Board . In The Long Tail , Chris Anderson calls Shirky "a prominent thinker on the social and economic effects of Internet technologies." [5]

Education and career
After graduating from Yale University with a Bachelor of Arts degree in fine art in 1986, he moved to New York. [6] In the 1990s he founded the Hard Place Theater, a theatre company that produced non-fiction theater using only found materials such as government documents, transcripts and cultural records. [6] and also worked as a lighting designer for other theater and dance companies, including the Wooster Group , Elevator Repair Service and Dana Reitz. [7] During this time, Shirky was vice-president of the New York chapter of the Electronic Frontier Foundation , and wrote technology guides for Ziff Davis . He appeared as an expert witness on cyberculture in Shea v. Reno , a case cited in the U. S. Supreme Court 's decision to strike down the Communications Decency Act in 1996.
Shirky was the first Professor of New Media in the Media Studies department at Hunter College , where he developed the MFA in Integrated Media Arts program.
In the Fall of 2010, Shirky was a visiting Morrow Lecturer at Harvard University 's John F. Kennedy School of Government [8] instructing a course titled: "New Media and Public Action". [9]

Views
In his book Here Comes Everybody , Shirky explains how he has long spoken in favor of crowdsourcing and collaborative efforts online. He uses the phrase "the Internet runs on love" to describe the nature of such collaborations. [10] In the book, he discusses the ways in which the action of a group adds up to something more than just aggregated individual action borrowing the phrase "more is different" from physicist Philip Warren Anderson .
Shirky asserts that collaborative crowdsourced work results from "a successful fusion of a plausible promise, an effective tool, and an acceptable bargain with the users." He states that the promise of what the user will get out of participating in a project leads to a person's desire to get involved. Collaborators will then choose the best social networking tool to do the job. One that "must be designed to fit the job being done, and it must help people do something they actually want to do." The bargain, Shirky states, defines what collaborators expect from each other's participation in the project. [11] Shirky's 'Promise, Tool, Bargain' premise restates aspects of the Uses and Gratifications Theory of mass media research.
He points to four key steps. The first is sharing, a sort of “me-first collaboration” in which the social effects are aggregated after the fact; people share links, URLs , tags, and eventually come together around a type. This type of sharing is a reverse of the so-called old order of sharing, where participants congregate first and then share (examples include Flickr , and Delicious ). The second is conversation, that is, the synchronization of people with each other and the coming together to learn more about something and to get better at it. The third is collaboration, in which a group forms under the purpose of some common effort. It requires a division of labor, and teamwork. It can often be characterized by people wanting to fix a market failure, and is motivated by increasing accessibility.
The fourth and final step is collective action , which Shirky says is “mainly still in the future.” The key point about collective action is that the fate of the group as a whole becomes important.
Shirky also introduces his theory of mass amateurization :
Combined with the lowering of transaction costs associated with creating content, mass amateurization of publishing changes the question from "Why publish this?" to "Why not?" [11] Tied to mass amateurization is the idea of publish-then-filter which is now required due to the mere size and amount of material being created on a daily basis. Shirky calls this mass amateurization of filtering a forced move. He uses the Portland Pattern Repository , which introduced the wiki concept that inspired Wikipedia, as an example of this new marriage of mass content creation and mass filtering.
In 2010 Shirky published Cognitive Surplus: Creativity and Generosity in a Connected Age which expands on themes introduced in Here Comes Everybody . The book follows concepts he introduced in a Web 2. 0 conference presentation April 23, 2008 called "Gin, Television, and Social Surplus", [12] Herein he popularizes the concept of cognitive surplus , the time freed from watching television which can be enormously productive when applied to other social endeavors. Technology has turned many past consumers into producers. This new production capacity, combined with humanity's willingness to share, can change society if applied to civic endeavors.
Shirky introduces Cognitive Surplus as a continuation of his work in Here Comes Everybody . "This book picks up where that one left off, starting with the observation that the wiring of humanity lets us treat free time as a shared global resource, and lets us design new kinds of participation and sharing that take advantage of that resource." [13]
Shirky has also written about "algorithmic authority," which describes the process through which unverified information is vetted for its trustworthiness through multiple sources. [14] [15]

Institutions vs collaboration
In July 2005, Shirky gave a talk titled "Institutions vs collaboration" as a part of TEDGlobal 2005. [16] This presentation reveals many of the ideas and concepts that would ultimately be presented in Here Comes Everybody and in future TED talks. Shirky compares the coordination costs between groups formed under traditional institutions and those formed by groups which "build cooperation into the infrastructure." [16] Classic institutions have to create economic, management, legal and physical structures and inherently, by creating these rigid structures, must exclude large numbers of people. Companies like Flickr , however, having built "cooperation into the infrastructure" of their company, do not have to build massive infrastructure nor exclude large groups of potential contributors.
Shirky states that since many social systems follow the Pareto principle wherein 20% of contributors account for 80% of contributions, traditional institutions lose out of the long tail of contributors by turning only the few that dominate the distribution into employees. The cooperative infrastructure model escapes having to lose this resource. Shirky presents an institution as enabler and institution as obstacle concept. The relatively small number of high-volume contributors can be assimilated, as employees, into the old-style corporate model and thus can live in an "institution-as-enabler world". The long tail of contributors, however, who make few and infrequent contributions, see institutions as an obstacle as they would never have been hired, therefore, disenfranchised. Shirky argues that an idea or contribution may be infrequent and significant. Furthermore, all of the long tail contributors, taken in aggregate, can be substantial.
One pitfall of the "mass amateurs" creating their own groups is that not all niches that are filled will be positive ones; Shirky presents pro-ana groups as an example. Shirky closes by stating that the migration from institutions to self-organizing, collaborative groups will be incomplete and will not end in a utopian society. Rather, chaos will follow as was created by the advent of the printing press before it, and that this period of transition will last roughly fifty years.
Shirky claims that our actions and behavior are generated by convenience. Writer and analyst Megan Garber writes: “The more people we have participating in media, and the more people we have consuming it -- and the more people we have, in particular, creating it -- the better. Not because bigger is implicitly better than the alternative compact, but because abundance changes the value proposition of media as a resource." [17]
According to Jay Baer by making collaboration more convenient for the user, it will eventually become a more commonplace. Further, enhancing the outcome of collaboration will instill motivation within the users. [18]
According to Audrey Tang , Shirky has pioneered the notion of a "cognitive surplus", to describe the way that time spent on the internet can have an increasing social value. [19]

Evolution of asymmetric media
In June 2009, Shirky participated in a TED@State talk titled "How cellphones, Twitter and Facebook can make history" aka "How social media can make history." [20] In the talk, he explains that this is the first time in history that communication is possible from many to many. In the past, communication to a large group excluded the possibility of having a conversation, and having a conversation meant not interacting with a group and instead was necessarily a one-to-one structure. Shirky labels this incongruous exchange as asymmetric. In Shirky's view, this feature is one of the main reasons that the internet revolution is different from communication revolutions that preceded it. [20]
The second difference between the twentieth and twenty-first century communication revolution, Shirky states, is now all media is digitized. This means that the Internet now encapsulates all forms of media from the past and the medium itself has become the site of exchange, not just a means of exchange.
Finally, the Internet allows people to create content, thus the line between producers and consumers has become blurred. As Shirky puts it, "Every time a new consumer joins this media landscape, a new producer joins as well." [20] Even countries like China, as Shirky gives as an example, go to great lengths to control information exchange on the Internet but are having trouble as the "amateurization" of media creation has effectively turned every owner of a cellphone and Twitter account into a journalist. The populace as a whole, Shirky claims, is a force much harder to control than a handful of professional news sources. He compares the "Great Firewall of China" to the Maginot Line as both were built to protect from external threats but that is not where the majority of content is being created in this new media landscape.
As an example of the potential of this two-way, collaborative environment Shirky believes we are now living in, he presents as a case study MyBarackObama.com. Over the issue of the Foreign Intelligence Surveillance Act , members of the website were upset over Obama's announcement that he was changing his stance and that now he was going to sign the bill "that granted immunity for possibly warrantless spying on American persons." [20] Despite the disagreement between the President and the posters opposed to his altered view, Shirky cites the mere fact that the President posted a reply to their concerns, instead of persecuting/ignoring the group, as hope for the future of this new form of mass media.

Shirky principle
In April 2010, Kevin Kelly cited the phrase "Institutions will try to preserve the problem to which they are the solution," and called it the "Shirky Principle", as the phrasing reminded him of the clarity of the Peter Principle . [21] [22] [23]

Communal value vs civic value
In June 2010, Shirky participated in TED@Cannes wherein he spoke about cognitive surplus and its role furthering communal and civic value . [24] The talk was titled, "How cognitive surplus will change the world," and the possibility for change, which Shirky presents, runs the spectrum at one end with communal value being increased and at the other end with civic value being furthered. Digital technology has allowed human generosity and "the world's free time and talents," which Shirky calls cognitive surplus , to combine and create a new form of creative expression. This creative expression can take the form of lolcats or endeavors such as Ushahidi ; the former Shirky says increases communal value , "it is created by the participants for each other" for simple amusement, whereas the latter he cites furthers civic value meaning the group action is taken to benefit society as a whole.
Shirky then presents the view that society lives under social constraint and that these social constraints can create a culture that is "more generous than" the environment created by contractual constraints alone. [24] Understanding where the economic or contractual motivation of a situation ends and where the social part begins, Shirky claims is key when designing to maximize generosity. This being the case, to have society use its "trillion hours a year of participatory value" to advance civic value , society itself simply needs to prize, and collectively praise, endeavors like Ushahidi .
Clay Shirky wrote an essay about the aspects of online community building through broadcast media. As members of a broad social community and users of media outlets, Shirky suggests ways in which we can build up this type of society.
Shirky suggests five different things to think about when dealing with broadcast media outlets: Audiences are built. Communities grow. Communities face a tradeoff between size and focus. Participation matters more than quality. You may own the software, but the community owns itself. The community will want to build. Help it, or at least let it. [25]

Response to Evgeny Morozov on consulting for the Libyan government
In March 2011, Shirky responded to questions raised by Evgeny Morozov about consulting he had done for the Libyan government. Morozov tweeted "With Clay Shirky consulting the Libyan govt, it's now clear why dictators are so smart about the Web". [26] Shirky explained he had been invited in 2007 to speak in Boston to Libya's IT Minister. [27] Shirky stated the talk was "about using social software to improve citizen engagement in coastal towns. The idea was that those cities would be more economically successful if local policies related to the tourist trade were designed by the locals themselves." Shirky added that nothing came of the project beyond his initial talk. He defended his underlying desire to expand representative government in Libya and concluded that "the best reason to believe that social media can aid citizens in their struggle to make government more responsive is that both citizens and governments believe that."

Reaction to SOPA
In January 2012, at TED Salon NY, Shirky gave a talk titled "Why SOPA is a bad idea." [28] He cites SOPA as a way for traditional, mass media producers to "raise the cost of copyright compliance to the point where people simply get out of the business of offering it as a capability to amateurs." [28] After an offending internet site is identified, with the identification process itself not specified in the bill, the targeted site will be removed from the Domain Name System (DNS). Shirky claims since you can still use the static IP address of the site in question, removal from DNS is futile. He identifies the Audio Home Recording Act of 1992 as a law that was able to delineate between sharing with your friends as being legal and selling for commercial gain as illegal. Unsatisfied, media companies, Shirky claims, continued to push government to create more sweeping legislation which would hinder any form of sharing. This pressure, in 1998, created the Digital Millennium Copyright Act . It was now legal for media companies to sell uncopyable material although uncopyable digital material does not exist. To remedy this fact, Shirky states that media companies now tried to break consumer's computer hardware to create the illusion that the media they purchased was indeed uncopyable.
Whereas DMCA was "surgical," SOPA is "nuclear" since the law stipulates any sites pointing to "illegal" content may be censored. Ultimately, Shirky points out the public-at-large is by far the largest producers of content and they are the ones that which will be censured. They will be presumed guilty until they can prove the content they published is not illegal. This turns the American legal system on its head. He closes by encouraging Americans to contact their senators and congressmen and reminding them they prefer "not to be treated like a thief." [28]

Distributed version control and democracy
On June 29, 2012, Shirky participated in Session 12: Public Sphere of TEDGlobal 2012. [29] Shirky made the observation that many of the technological advancements in communication throughout history, from the printing press to the television , were heralded as harbingers of world peace yet ended up creating greater dissent. "The more ideas there are in circulation, the more ideas there are for any individual to disagree with." [29] However, Shirky claims, with this increased "arguing," comes an increased "speed" of information exchange. [29] Shirky cites " The Invisible College " as an example of a group that was able to utilize this effect created by the printing press , via the scientific journal , to help launch the scientific revolution .
He then states we are in a similar period today with open-source programmers and their use of distributed version control or DVCS. DVCS, he argues, allows for "more arguments" to be made into "better arguments". DVCS also allows for "cooperation without coordination" which Shirky states is "the big change". [29] He then suggests that DVCS fits naturally with law as it, and software development, are "dependency-related." Shirky presents another application for DVCS - drafting legislation. He cites Open Legislation , a listing of legislative information from the New York State Senate and Assembly, as an early step in that direction.
The talk culminates with Shirky posing the open question of whether or not government will transition from striving towards one-way transparency to mutual collaboration and suggests if it does, there is already a "new form of arguing" centered around DVCS to aid the transition. [29]

Bibliography

See also

Footnotes
WebPage index: 00112
Conference on Human Factors in Computing Systems
The ACM Conference on Human Factors in Computing Systems ( CHI ) series of academic conferences is generally considered the most prestigious in the field of human–computer interaction and is one of the top ranked conferences in computer science. [1] It is hosted by ACM SIGCHI , the Special Interest Group on computer–human interaction. CHI has been held annually since 1982 and attracts thousands of international attendees. CHI 2015 was held in Seoul , South Korea, [2] and CHI 2016 was held in San Jose , United States from May 7 to May 12. [3] CHI 2017 was held in Denver, Colorado from May 6–11, 2017.

History
The CHI conference series started with the Human Factors in Computer Systems conference in Gaithersburg , Maryland, US in 1982, organized by Bill Curtis and Ben Shneiderman . [4] During this meeting the formation of the ACM Special Interest Group on Computer–Human Interaction (SIGCHI) was first publicly announced. ACM SIGCHI became the sponsor of the Conference on Human Factors in Computing Systems. The first CHI conference was held in Boston, Massachusetts, US, in 1983. The second conference took place in San Francisco, in 1985. [5] Since then, CHI conferences have been held annually in spring each year. Until 1992 the conference was held in Canada or the US. In 1993 CHI moved to Europe for the first time and was held in Amsterdam , the Netherlands. [6]
Over the years, CHI has grown in popularity. The 1982 meeting drew 907 attendees. CHI 90 attracted 2,314. Attendance has been fairly stable since then. [7] After the early years CHI became highly selective. Since 1993 the acceptance rate for full papers was consistently below 30 percent. After 1992 the average acceptance rate was around 20 percent. The number of accepted full papers is slowly increasing and reached 157 accepted papers with an acceptance rate of 22 percent in 2008. [8] CHI continues to grow, reaching over 3,300 attendees in 2013 [9] and 3,800 in 2016.

Tracks
The CHI conference consists of multiple tracks, including:

Past and upcoming CHI conferences
Past [10] and future [11] CHI conferences include:
WebPage index: 00113
Farrar, Straus and Giroux
Farrar, Straus and Giroux ( FSG ) is an American book publishing company, founded in 1946 by Roger W. Straus, Jr. and John C. Farrar . [1] FSG is known for publishing literary books, and its authors have won numerous awards, including Pulitzer Prizes , National Book Awards , and Nobel Peace Prizes . The publisher is currently a division of MacMillan , whose parent company is the German publishing conglomerate Georg von Holtzbrinck Publishing Group . [2]

Early years
Farrar, Straus and Giroux was founded in 1946 by Roger W. Straus, Jr. and John C. Farrar. [1] The first years of existence were rough until they published the diet book, Look Younger, Live Longer by Gayelord Hauser in 1950. The book went on to sell 500,000 copies and Straus said that the book carried them along for awhile. [1] In the early years, Straus and his wife Dorthea, went prospecting for books in Italy. It was there that they found the memoir Christ Stopped at Eboli by Carlo Levi and other rising Italian authors Alberto Moravia , Giovanni Guareschi and Cesare Pavese . [1] Farrar, Straus also poached or lured away authors from other publishers—one was Edmund Wilson who was unhappy with Random House at the time but remained with Farrar, Straus for the remainder of his career. [1]
Robert Giroux joined the company in 1955 and after he later became a partner, the name was changed to Farrar, Straus and Giroux. [1] Giroux had been working for Harcourt and had been angered when Harcourt refused to allow him to publish Salinger 's Catcher in the Rye . [1] Giroux brought many literary authors with him including Thomas Merton , John Berryman , Robert Lowell , Flannery O'Connor , Jack Kerouac , Peter Taylor , Randall Jarrell , T.S. Eliot , and Bernard Malamud . [1] Alan Williams described Giroux's 'Pied Piper sweep' as "almost certainly the greatest number of authors to follow, on their own iniative, a single editor from house to house in the history of modern publishing." [1] In 1964, Straus named Giroux chairman of the board and officially added Giroux's name to the publishing company. [1]
Straus continued to run the company for twenty years after his partner Farrar died, until 1993 when he sold a majority interest of the company to the privately owned German publishing conglomerate Georg von Holtzbrinck Publishing Group . [1] Straus offered FSG to the Holtzbrinck family because of their reputation for publishing serious works of literature. [1]

21st century
Jonathan Galassi is president and publisher. Andrew Mandel joined in 2004 as deputy publisher. Eric Chinski is editor-in-chief. In 2008, Mitzi Angel came from Fourth Estate in the UK to be publisher of the Faber and Faber Inc. imprint. Other notable editors include Sean McDonald , Ileene Smith, Alex Star, Amanda Moon, and Sarah Crichton (eponymous publisher of her own imprint).
In February 2015 FSG and Faber and Faber announced the end of their partnership. All books scheduled for release and previously released under the imprint will be moved to the FSG colophon by August 2016. [3]

Notable authors

Notable editors and publishers

Current imprints

Bibliography

Books for Young Readers
FSG Books for Young Readers publishes National Book Award winners Madeleine L'Engle (1980), William Steig (1983), Louis Sachar (1998), and Polly Horvath (2003). Books for Young Readers also publishes Natalie Babbitt , Roald Dahl , Jack Gantos , George Selden , Uri Shulevitz , and Peter Sis .

Winners of the Nobel Prize in Literature

Winners of the Nobel Peace Prize

Winners of the Pulitzer Prize

Winners of the National Book Award

Other authors published by FSG
WebPage index: 00114
Emory University School of Law
Emory University School of Law (also known as Emory Law or ELS ) is a US law school that is part of Emory University in Atlanta, Georgia . It is currently ranked #22 among ABA -approved law schools by the 2018 U.S. News & World Report . [8]

Campus
Emory Law is located in Gambrell Hall, part of Emory ’s 630-acre (2.5 km 2 ) campus in the Druid Hills neighborhood, six miles (10 km) northeast of downtown Atlanta.
Gambrell Hall contains classrooms, faculty offices, administrative offices, student-organization offices, and a 325-seat auditorium. The school provides wireless Internet access throughout its facilities. Gambrell Hall also houses a courtroom. [9] [ not in citation given ]
Emory's five-story Hugh F. MacMillan Law Library opened in August 1995. The library is situated adjacent to Gambrell Hall and includes access to over 400,000 volumes and more than 4,000 serials subscriptions. [10]

Admissions and academics
Admission to the law school is selective. For the class entering in the fall of 2014, 223 JD candidates enrolled. The 25th and 75th LSAT percentiles for the 2014 entering class were 158 and 166, respectively, with a median of 165. The 25th and 75th undergraduate GPA percentiles were 3.30 and 3.85, respectively, with a median of 3.75. [11]
Nearly half of Emory Law students are women, and about 32% are from underrepresented ethnic groups. Approximately 60% of students come from outside the Southeastern U.S. [12]
It is ranked #22, tied with the University of Minnesota Law School, among ABA -approved law schools by the 2017 U.S. News & World Report. [13]
The School of Law offers a three-year, full-time program leading to a Juris Doctor degree. Emory Law is particularly known for its expertise in Bankruptcy Law , Environmental Law , Feminist Legal Theory , Intellectual Property Law, International law , Law and Religion , and Transactional Law .
Emory Law also offers joint-degree programs through cooperation with the Goizueta Business School (JD/MBA and JM/MBA), the Candler School of Theology (JD/MTS and JD/MDiv), the Graduate School of Arts and Sciences (JD/PhD), the Rollins School of Public Health (JD/MPH), the Emory Center for Ethics (JD/MA in Bioethics), and joint JD and Master of Laws degree (JD/LLM) through Emory School of Law.
In partnership with Central European University , Emory also provides an LLM program for students with a U.S. law degree seeking advanced training in international commercial law and international politics. Emory also has a separate LLM program for qualified foreign professionals seeking training in international and comparative law.
Emory Law's Juris Master is a 30-credit hour program that is intended to supplement a student's interest or professional experience in allied fields to law. The program offers a range of customized concentrations to allow students to enhance their skills in their home profession or interest area through a greater understanding of the law, legal concepts and frameworks. The coursework can be completed either full-time in as little as nine months or part-time in up to four years.

Clinics and programs
Students' expertise is developed through several clinics and programs. Emory Law also offers several summer study abroad programs in Budapest at the Central European University (CEU) and throughout the world. [14]
A team from Emory Law's TI:GER IP/patent/technology program, a collaborative program between Emory and Georgia Tech , was featured on CNN Money. [15] Other academic programs at Emory Law include:

Publications

Employment
According to Emory's official 2013 ABA-required disclosures, 62.4% of the Class of 2013 obtained full-time, long-term, JD-required, non-school funded employment nine months after graduation. [20] Emory's Law School Transparency under-employment score is 5.5%, indicating the percentage of the Class of 2013 unemployed, pursuing an additional degree, or working in a non-professional, short-term, or part-time job nine months after graduation, and an additional 21.2% were in school funded positions. [21]

Costs
The total cost of attendance (indicating the cost of tuition, fees, and living expenses) at Emory for the 2013-2014 academic year is $75,716. [22] The Law School Transparency estimated debt-financed cost of attendance for three years is $290,430. [23]

Notable Alumni

Notable Faculty
WebPage index: 00115
IBM Research
IBM Research is IBM 's research and development division. It is the largest industrial research organization in the world, with twelve labs on six continents. [1]
The roots of today's IBM Research began with the 1945 opening of the Watson Scientific Computing Laboratory at Columbia University . [2] This was the first IBM laboratory devoted to pure science and later expanded into additional IBM Research locations in Westchester County, New York starting in the 1950s, [3] [4] including the Thomas J. Watson Research Center in 1961. [3] [4]
IBM employees have garnered six Nobel Prizes , six Turing Awards , 20 inductees into the U.S. National Inventors Hall of Fame, 19 National Medals of Technology , five National Medals of Science and three Kavli Prizes. [5]
As of 2016, the company held the record for most patents generated by a business for 24 consecutive years. [6]

Advances
Notable company inventions include the floppy disk , the hard disk drive , the magnetic stripe card , the relational database , the Universal Product Code (UPC) , the financial swap , the Fortran programming language, SABRE airline reservation system , DRAM , copper wiring in semiconductors , the silicon-on-insulator (SOI) semiconductor manufacturing process, Watson artificial intelligence [7] and the Quantum Experience .
Advances in nanotechnology include IBM in atoms , where a scanning tunneling microscope was used to arrange 35 individual xenon atoms on a substrate of chilled crystal of nickel to spell out the three letter company acronym . It was the first time atoms had been precisely positioned on a flat surface. [8]

Applications
Major undertakings at IBM Research have included the invention of innovative materials and structures, high-performance microprocessors and computers , analytical methods and tools, algorithms , software architectures , methods for managing, searching and deriving meaning from data and in turning IBM's advanced services methodologies into reusable assets.
IBM Research's numerous contributions to physical and computer sciences include the Scanning Tunneling Microscope and high temperature superconductivity , both of which were awarded the Nobel Prize . IBM Research was behind the inventions of the SABRE travel reservation system, the technology of laser eye surgery , magnetic storage, the relational database , UPC barcodes and Watson , the question-answering computing system that won a match against human champions on the Jeopardy! television quiz show. The Watson technology is now being commercialized as part of a project with healthcare company Anthem Inc. .

Notable IBM Research computer scientists
There are a number of computer scientists "who made IBM Research famous." [9] These include Frances E. Allen , [10] Marc Auslander, John Backus , [11] [12] [13] [14] [15] [16] Charles H. Bennett (computer scientist) , Erich Bloch , [17] Grady Booch , [18] [19] [20] [21] [22] Fred Brooks (known for his book The Mythical Man-Month ), [23] [24] [25] [26] Peter Brown, [27] Larry Carter, [28] [29] Gregory Chaitin , John Cocke , Alan Cobham, [30] Edgar F. Codd , Don Coppersmith , Ronald Fagin , Horst Feistel , Jeanne Ferrante , Zvi Galil , Ralph E. Gomory , Jim Gray , Joseph Halpern , Kenneth E. Iverson , Frederick Jelinek , Reynold B. Johnson , Benoit Mandelbrot , Robert Mercer (businessman) , C. Mohan , Michael O. Rabin , Arthur Samuel , Alfred Spector , Moshe Vardi , John Vlissides , Mark N. Wegman and Shmuel Winograd .

Other notable developments

Laboratories

Historic research centers

Publications
WebPage index: 00116
PLOS ONE
PLOS ONE (originally PLoS ONE ) is a peer-reviewed open access scientific journal published by the Public Library of Science (PLOS) since 2006. The journal covers primary research from any discipline within science and medicine . Operating under a pay-to-publish model, PLOS ONE publishes approximately 50% of submitted manuscripts. [1] All submissions go through a pre-publication review by a member of the board of academic editors, who can elect to seek an opinion from an external reviewer. According to the journal, papers are not to be excluded on the basis of lack of perceived importance or adherence to a scientific field. Although the number of submissions decreased from 2013 to 2014, PLOS ONE remained the world’s largest journal by number of papers published (about 30,000 a year, or 85 papers per day). Numbers decreased further to 22,000 published papers in 2016, [1] and since 2017 PLOS ONE is the second largest journal (after Scientific Reports ). [2]

History

Development
The Gordon and Betty Moore Foundation awarded PLOS a $9 million grant in December 2002 and $1 million grant in May 2006 for its financial sustainability and launch of new free-access biomedical journals. [3] [4] Later, PLOS ONE was launched in December 2006 as a beta version named PLoS ONE . It launched with Commenting and Note making functionality, and added the ability to rate articles in July 2007. In September 2007 the ability to leave " trackbacks " on articles was added. [5] In August 2008 it moved from a weekly publication schedule to a daily one, publishing articles as soon as they became ready. [6] In October 2008 PLoS ONE came out of "beta". Also in September 2009, as part of its Article-Level Metrics program, PLoS ONE made the full online usage data—e.g., HTML page views , PDF , XML downloads—for every published article publicly available. In mid-2012, as part of a rebranding of PLoS as PLOS, the journal changed its name to PLOS ONE . [7]

Output and turnaround
The number of papers published by PLOS ONE grew rapidly from inception to 2013 and has since declined somewhat. By 2010, it was estimated to have become the largest journal in the world, [9] and in 2011, 1 in 60 articles indexed by PubMed were published by PLOS ONE . [16]
At PLOS ONE , the median review time has grown from 37 days to 125 days over the first ten years of operation, according to Himmelstein's analysis, done for Nature . The median between acceptance and posting a paper on the site has decreased from 35 to 15 days over the same period. Both numbers for 2016 roughly correspond to the industry-wide averages for biology-related journals. [17] [18]

Management
The founding managing editor was Chris Surridge. [19] He was succeeded by Peter Binfield in March 2008, who was publisher until May 2012. [20] Damian Pattinson then held the chief editorial position until December 2015. [21] Joerg Heber was confirmed as editor-in-chief from November 2016. [22]

Publication concept
PLOS ONE is built on several conceptually different ideas compared to traditional peer-reviewed scientific publishing in that it does not use the perceived importance of a paper as a criterion for acceptance or rejection. The idea is that, instead, PLOS ONE only verifies whether experiments and data analysis were conducted rigorously, and leaves it to the scientific community to ascertain importance, post publication, through debate and comment. [23]
According to Nature , the journal's aim is to "challenge academia 's obsession with journal status and impact factors ". [25] Being an online-only publication allows PLOS ONE to publish more papers than a print journal. In an effort to facilitate publication of research on topics outside, or between, traditional science categories, it does not restrict itself to a specific scientific area. [23]
Papers published in PLOS ONE can be of any length, contain full color throughout, and contain supplementary materials such as multimedia files. Reuse of articles is subject to a Creative Commons Attribution License , version 2.5. In the first four years following launch, it made use of over 40,000 external peer reviewers. [26] The journal uses an international board of academic editors with over 6,000 academics handling submissions and publishes approximately 50 % of all submissions, after review by, on average, 2.9 experts. [27] Registered readers can leave comments on articles on the website. [25]

Business model
As with all journals of the Public Library of Science, PLOS ONE is financed by charging authors a publication fee . The "author-pays" model allows PLOS journals to provide all articles to everybody for free (i.e., open access) immediately after publication. As of October 2015, PLOS ONE charged authors US$1,495 [30] to publish an article. Depending on circumstances, it may waive or reduce the fee for authors who do not have sufficient funds. [31] This model has drawn criticism, however. In 2011 Richard Poynder posited that journals such as PLoS ONE that charge authors for publication rather than charging users for access may produce a conflict of interest that reduces peer review standards (accept more articles, earn more revenue). [32] Stevan Harnad instead argues for a "no fault" peer-review model, in which authors are charged for each round of peer review, regardless of the outcome, rather than for publication. [33] PLoS had been operating at a loss until 2009 but covered its operational costs for the first time in 2010, [34] largely due to the growth of PLOS ONE .

Influence
The " PLOS ONE model" has inspired a series of other journals, [35] [36] [37] having broad scope and low selectivity, now called megajournals , and a pay-to-publish model, usually published under Creative Commons licenses .

Reception
In September 2009, PLOS ONE received the Publishing Innovation Award of the Association for Learned and Professional Society Publishers . [38] The award is given in recognition of a "truly innovative approach to any aspect of publication as adjudged from originality and innovative qualities, together with utility, benefit to the community and long-term prospects". In January 2010, it was announced that the journal would be included in the Journal Citation Reports , [39] and the journal received an impact factor of 4.411 in 2010. According to the Journal Citation Reports , the journal has a 2015 impact factor of 3.057. [40] In 2015/2016 it had a "scijournal.org" impact factor of 4.411. [41]

Abstracting and indexing
The articles are indexed in: [24]

Controversies

Alleged Sexism in one peer review instance
On April 29, 2015, Fiona Ingleby and Megan Head, postdoctoral fellows at the University of Sussex and Australian National University respectively, posted a rejection letter, which they said was sent to them by a peer reviewer for a journal they did not wish to name. The excerpt made negative comments about women's aptitude for science and advised Ingleby and Head to find male co-authors. Shortly afterward, the journal was reported to be PLOS ONE . By May 1, PLOS announced that it was severing ties with the reviewer responsible for the comments and asking the editor who relayed them to step down. PLOS ONE immediately issued a statement following the incident, written by PLOS ONE director Damian Pattinson, saying,
"I want to sincerely apologize for the distress the report caused the authors, and to make clear that we completely oppose the sentiments it expressed,"
He also stated that the journal was considering moving away from the tradition of anonymous peer review. [42]

CreatorGate
On March 3, 2016, the editors of PLOS ONE initiated a reevaluation of an article about the functioning of the human hand [43] due to outrage among the journal's readership over a reference to "Creator" inside the paper. [44] The authors, who received grants from the Chinese National Basic Research Program and National Natural Science Foundation of China for this work, responded by saying "Creator" is a poorly-translated idiom ( 造化 ( 者 ), literally "(that which) creates or transforms") [45] which means "nature" in the Chinese language. Despite the authors' protests, the article was retracted . [46] "Creator" is found in the paper in three sentences:
A less sympathetic explanation for the use of "Creator" was suggested to The Chronicle of Higher Education by Chinese-language experts who noted that the academic editor listed on the paper, Renzhi Han, previously worked at the Chinese Evangelical Church in Iowa City. [47]
Sarah Kaplan of The Washington Post presented detailed analysis of the problem, which she named #CreatorGate , and concluded that the journal’s hasty retraction may have been an even bigger offense than the publication of the paper in the first place. [48] To contrast PLOS ONE' s handling of the problem, she used a 12-year history of retraction of the fraudulent paper on vaccine and autism by The Lancet and no retraction of debunked study on " arsenic life " by Science . [49] [50] Others added the history of the article in Nature on " water memory " that was not retracted either. [51]
Jonathan Eisen , chair of advisory board of a sister journal PLOS Biology and an advocate for open-access , defended PLOS ONE for prompt response to social media , which in his words "most journals pretend doesn’t even exist". [52] David Knutson issued a statement about the paper processing at PLOS ONE , which praised the importance of post-publication peer review and described their intention to offer open signed reviews in order to ensure accountability of the process. [53] From March 2 to 9, the research article received total 67 post-publication reader comments and 129 responses on PLOS ONE site, the first one from cell biologist turned science journalist Leonid Schneider who cited a Wikipedia article rather than scientific literature as an authority. [54] [55] Signe Dean of SBS put #CreatorGate in perspective: it is not the most scandalous retraction in science, yet it shows how a social media outrage storm does expedite a retraction. [56]
The dissemination activity on social media within one week of publicity was:
The article was viewed 169,926 times on PLOS site in the first ten days of March, compared to 555 views in January and 116 views in February. [57]
On March 10, 2016, BioLogos , a website of a Christian advocacy group established by the 16th Director of the National Institutes of Health Francis Collins after publication of his book The Language of God: A Scientist Presents Evidence for Belief , started Blog series Faith and Science Seeking Understanding to review the controversy raised by #CreatorGate. [58] The series follows the accusations of anti-Christian/anti-”design” bias in the scientific world by Ken Ham of Answers in Genesis and David Klinghoffer of Evolution News and Views . [59] [60] BioLogos authors argue that avoiding mentions of God in scientific literature is not a censorship but a rule of a successful game akin to the rules of soccer or football . [61] [62]
WebPage index: 00117
University of California, Berkeley
The University of California, Berkeley , (also referred to as UC Berkeley , Berkeley , Cal , Cal Berkeley , and California ) [7] is a public research university located in Berkeley , California . Founded in 1868, Berkeley is the oldest of the ten research universities in the University of California system, and is often cited as the top public university in the United States and around the world. [8] [9] [10] [11] [12] [13] [14] [15] [16]
Established in 1868 as the University of California , resulting from the merger of the private College of California and the public Agricultural, Mining, and Mechanical Arts College in Oakland , Berkeley offers approximately 350 undergraduate and graduate degree programs in a wide range of disciplines. [17] The Dwinelle Bill of March 5, 1868 (California Assembly Bill No. 583) stated that the "University shall have for its design, to provide instruction and thorough and complete education in all departments of science, literature and art, industrial and profession[al] pursuits, and general education, and also special courses of instruction in preparation for the professions... ." [18] [19] In 1960s, UC Berkeley was particularly noted for the Free Speech Movement as well as the Anti-Vietnam War Movement led by its students. [20] [21] [22] [23]
Berkeley is a founding member of the Association of American Universities and continues to have very high research activity with $789 million in research and development expenditures in the fiscal year ending June 30, 2015. [24] [25] It also co-manages three United States Department of Energy National Laboratories , including Lawrence Berkeley National Laboratory , Lawrence Livermore National Laboratory and Los Alamos National Laboratory for the U.S. Department of Energy , and is home to many world-renowned research institutes and organizations including Mathematical Sciences Research Institute and Space Sciences Laboratory .
Berkeley faculty, alumni, and researchers include 91 Nobel laureates (including 33 alumni) . They have also won 9 Wolf Prizes , 13 Fields Medals (including 3 alumni medalists) , 23 Turing Awards (including 11 alumni awardees) , 45 MacArthur Fellowships , [26] 20 Academy Awards , 14 Pulitzer Prizes [27] and 117 Olympic gold medals (51 silver and 39 bronze) . [28] Faculty member J. R. Oppenheimer , the "father of the atomic bomb", led the Manhattan project to create the first atomic bomb . Nobel laureate Ernest Lawrence invented the cyclotron , based on which UC Berkeley scientists and researchers, along with Berkeley Lab , have discovered 16 chemical elements of the periodic table – more than any other university in the world. [29] [30] Lawrence Livermore Lab also discovered or co-discovered six chemical elements (113 to 118). [31] [32]
Berkeley is considered by the Times Higher Education World University Rankings as one of six university brands that lead in world reputation rankings in 2016 [33] and is ranked third on the U.S. News ' 2015 Best Global Universities rankings conducted in the U.S. and nearly 50 other countries. [34] The Academic Ranking of World Universities (ARWU) also ranks the University of California, Berkeley, third in the world overall, and first among public universities.

History
In 1866, the private College of California purchased the land comprising the current Berkeley campus. Because it lacked sufficient funds to operate, it eventually merged with the state-run Agricultural, Mining, and Mechanical Arts College to form the University of California, the first full-curriculum public university in the state.
Ten faculty members and almost 40 students made up the new University of California when it opened in Oakland in 1869. [35] Frederick H. Billings was a trustee of the College of California and suggested that the college be named in honor of the Anglo-Irish philosopher George Berkeley . [36] In 1870, Henry Durant , the founder of the College of California, became the first president. With the completion of North and South Halls in 1873, the university relocated to its Berkeley location with 167 male and 22 female students [37] and held its first classes. [38]
Beginning in 1891, Phoebe Apperson Hearst made several large gifts to Berkeley, funding a number of programs and new buildings, and sponsoring, in 1898, an international competition in Antwerp, Belgium, where French architect Émile Bénard submitted the winning design for a campus master plan. In 1905, the University Farm was established near Sacramento , ultimately becoming the University of California, Davis . [39] By the 1920s, the number of campus buildings had grown substantially, and included twenty structures designed by architect John Galen Howard . [40]
Robert Gordon Sproul served as president from 1930 to 1958. [41] By 1942, the American Council on Education ranked UC Berkeley second only to Harvard University in the number of distinguished departments. [41]
During World War II, following Glenn Seaborg 's then-secret discovery of plutonium, Ernest Orlando Lawrence 's Radiation Laboratory began to contract with the U.S. Army to develop the atomic bomb. UC Berkeley physics professor J. Robert Oppenheimer was named scientific head of the Manhattan Project in 1942. [42] [43] Along with the Lawrence Berkeley National Laboratory (formerly the Radiation Lab), Berkeley is now a partner in managing two other labs, Los Alamos National Laboratory (1943) and Lawrence Livermore National Laboratory (1952).
Originally, military training was compulsory for male undergraduates, and Berkeley housed an armory for that purpose. In 1917, Berkeley's ROTC program was established, [44] and its School of Military Aeronautics trained future pilots, including Jimmy Doolittle , who graduated with a B.A. in 1922. Both Robert McNamara and Frederick C. Weyand graduated from UC Berkeley's ROTC program, earning B.A. degrees in 1937 and 1938, respectively. In 1926, future fleet admiral Chester W. Nimitz established the first Naval Reserve Officers Training Corps unit at Berkeley. During World War II, the military increased its presence on campus to recruit more officers, and by 1944, more than 1,000 Berkeley students were enrolled in the V-12 Navy College Training Program and naval training school for diesel engineering. [45] The Board of Regents ended compulsory military training at Berkeley in 1962.
During the McCarthy era in 1949, the Board of Regents adopted an anti- communist loyalty oath . A number of faculty members objected and were dismissed; [46] ten years passed before they were reinstated with back pay. [47]
In 1952, the University of California became an entity separate from the Berkeley campus. Each campus was given relative autonomy and its own Chancellor. Then-president Sproul assumed presidency of the entire University of California system, and Clark Kerr became the first Chancellor of UC Berkeley. [41]
Berkeley gained a reputation for student activism in the 1960s with the Free Speech Movement of 1964 [48] and opposition to the Vietnam War . In the highly publicized People's Park protest in 1969, students and the school conflicted over use of a plot of land; the National Guard was called in and violence erupted. Then governor of California Ronald Reagan called the Berkeley campus "a haven for communist sympathizers, protesters, and sex deviants." [48] [49] [50] Modern students at Berkeley are less politically active, with a greater percentage of moderates and conservatives. [51] [52] Democrats outnumber Republicans on the faculty by a ratio of 9:1. [53]
Various human and animal rights groups have conflicted with Berkeley. Native Americans conflicted with the school over repatriation of remains from the Phoebe A. Hearst Museum of Anthropology . [54] Animal-rights activists have threatened faculty members using animals for research. [55] The school's response to tree sitters protesting construction caused controversy in the local community. [56]
On May 1, 2014, UC Berkeley was named one of fifty-five higher education institutions under investigation by the Office of Civil Rights "for possible violations of federal law over the handling of sexual violence and harassment complaints" by the White House Task Force to Protect Students from Sexual Assault . [57] The investigation comes after 31 female students made three federal complaints: first, a Clery Act complaint was filed in May 2013, and then, after a lack of response from the University, a second Clery Act Complaint and Title IX complaint were filed on February 26, 2014. [58] Investigations have continued into 2016, with hundreds of pages of records released in April 2016, showing a pattern of documented sexual harassment and firings of non-tenured staff. [59]

Funding
As state funding declined, [60] Berkeley turned to private sources: BP donated $400 million over 10 years to develop biofuels , [61] the Hewlett Foundation gave $113 million to endow 100 faculty chairs , and Dow Chemical gave $10 million to research sustainability . [62] [63] The BP grant has been criticized for diverting food production to fuel production. [64] [65] The 2008–13 Campaign for Berkeley raised $3.13 billion from 281,855 donors. [66]

Name
The original name University of California was frequently shortened to California or Cal . UC Berkeley's athletic teams date to this time and so are referred to as the California Golden Bears , Cal Bears , or just Cal . Today, University of California refers to a statewide school system. Referring to the University of California, Berkeley as UCB or University of California at Berkeley is discouraged [67] and the domain name is berkeley.edu . Moreover, the term "Cal Berkeley" is not a correct reference to the school, but is occasionally used. Berkeley is unaffiliated with the Berklee College of Music or Berkeley College .

Academics
Berkeley is a large, primarily residential research university with a majority of enrollments in undergraduate programs but also offers a comprehensive doctoral graduate program. [68] The university has been accredited by the Western Association of Schools and Colleges Senior College and University Commission since 1949. [69] The university is one of only two UC campuses operating on a semester calendar , (the other is UC Merced ). Berkeley offers 106 Bachelor's degrees, 88 Master's degrees, 97 research-focused doctoral programs, and 31 professionally focused graduate degrees. [70] The university awarded 7,565 Bachelor's, 2,610 Master's or Professional, and 930 Doctoral degrees in 2013-14. [71]
Berkeley's 130-plus academic departments and programs are organized into 14 colleges and schools in addition to UC Berkeley Extension. [4] "Colleges" are both undergraduate and graduate, while "Schools" are generally graduate only, though some offer undergraduate majors, minors, or courses.
UC Berkeley does not have a medical school ; however, the university offers the UC Berkeley – UCSF Joint Medical Program with the University of California, San Francisco , a standalone medical school that is located nearby.

Undergraduate programs
The four-year, full-time undergraduate program has a focus on the arts and sciences with a high level of co-existence in undergraduate and graduate programs. Freshman admission is selective but there are high levels of transfer-in. [68] 107 Bachelor's degrees are offered across the Haas School of Business (1), College of Chemistry (5), College of Engineering (20), College of Environmental Design (4), College of Letters and Science (67), College of Natural Resources (10), and other individual majors (2). [70] The most popular majors are Electrical Engineering and Computer Science, Political Science, Molecular and Cell Biology, Environmental Science, and Economics. [72]
Requirements for undergraduate degrees come from four sources: the University of California system, the Berkeley campus, the college or school, and the department. These requirements include an entry-level writing requirement before enrollment (typically fulfilled by minimum scores on standardized admissions exams such as the SAT or ACT), completing coursework on "American History and Institutions" before or after enrollment by taking an introductory class, passing an "American Cultures Breadth" class at Berkeley, as well as requirements for reading and composition and specific requirements declared by the department and school. [73] Three-hour final examinations are required in most undergraduate classes and take place over a week following the last day of instruction in mid-December for the Fall semester and in mid-May for the Spring semester. [74] Academic grades are reported on a five-letter scale (A,B,C,D,F) with grade points being modified by three-tenths of point for pluses and minuses. [75] Requirements for academic honors are specified by individual schools and colleges, scholarly prizes are typically awarded by departments, and students are elected to honor societies based on these organizations' criteria. [76]

Graduate and professional programs
Berkeley has a "comprehensive" graduate program with high coexistence with the programs offered to undergraduates, but no medical school. [68] The university offers graduate degrees in Master's of Art, Master's of Science, Master's of Fine Art, and Ph.D.s in addition to professional degrees such as the Juris Doctor and Master of Business Administration . [77] The university awarded 887 doctoral degrees and 2,506 Master's degrees in 2012. [78] Admission to graduate programs is decentralized; applicants apply directly to the department or degree program. Most graduate students are supported by fellowships, teach assistantships, or research assistantships. [78] The 2010 United States National Research Council Rankings identified UC Berkeley as having the highest number of top-ranked doctoral programs in the nation. [79] UC Berkeley doctoral programs that received a #1 ranking include Agricultural and Resource Economics, Astrophysics, Chemistry, Civil and Environmental Engineering, Computer Science, English, Epidemiology, Geography, German, Mathematics, Mechanical Engineering, Biochemistry and Molecular Biology, Genetics, Genomics, and Development, Physics, Plant Biology, and Political Science. UC Berkeley was also the #1 recipient of National Science Foundation Graduate Research Fellowships between 2001 and 2010, with 1,333 awards. [78]

Faculty and research
Berkeley is a research university with a "very high" level of research activity. [68] In fiscal year 2015 Berkeley spent $789 million on research and development (R&D). [25] There are 1,620 full-time and 500 part-time faculty members dispersed among more than 130 academic departments and more than 80 interdisciplinary research units. [80] Berkeley's current faculty includes 235 American Academy of Arts and Sciences Fellows, 3 Fields Medal winners, 77 Fulbright Scholars , 139 Guggenheim Fellows , 73 members of the National Academy of Engineering , 149 members of the National Academy of Sciences , [81] 8 Nobel Prize winners, 4 Pulitzer Prize winners, 125 Sloan Fellows , 7 Wolf Prize winners and 1 Pritzker Prize winner. [80] [82] [83] 91 Nobel laureates have been affiliated with the university as faculty, alumni or researchers, the most of any public university in the United States and fourth most of any university in the world.
Faculty at UC Berkeley are more likely to be registered Democrats than Republicans; this is similar to findings at Stanford University. [84]

Library system
Berkeley's 32 libraries tie together to make the fourth largest academic library in the United States surpassed only by Harvard University Library , Yale University Library and University of Illinois at Urbana-Champaign Library. [85] However, considering the relative sizes and ages of these University libraries, Berkeley's collections have been growing about as fast as those at Harvard and Yale combined: specifically, 1.8 times faster than Harvard, and 1.9 times faster than Yale. In 2003, the Association of Research Libraries ranked it as the top public and third overall university library in North America based on various statistical measures of quality. [86] As of 2006, Berkeley's library system contains over 11 million volumes and maintains over 70,000 serial titles. [87] The libraries together cover over 12 acres (4.9 ha) of land and form one of the largest library complexes in the world. [88] Doe Library serves as the library system's reference, periodical, and administrative center, while most of the main collections are housed in the subterranean Gardner Main Stacks and Moffitt Undergraduate Library. The Bancroft Library , with holdings of over 400,000 printed volumes and 70 million manuscripts, pictorial items, maps, and more, maintains special collections that document the history of the western part of North America, with an emphasis on California, Mexico and Central America. The Bancroft Library also houses The Mark Twain Papers , The Oral History Center , the Center for the Tebtunis Papyri and the University Archives .

Rankings and reputation

Global
The Times Higher Education World University Rankings for 2015–2016 ranks Berkeley 13th in the world for academics and 6th in the world for reputation. [33] In its 2017 edition, U.S. News & World Report ranked Berkeley 4th in their "Best Global University Rankings". [34] In 2016, Berkeley was ranked 3rd in the world by the Academic Ranking of World Universities (ARWU) and 28th in the 2016/17 QS World University Rankings . The Center for World University Rankings (CWUR) ranked the university 7th in the world based on quality of education, alumni employment, quality of faculty, publications, influence, citations, broad impact, and patents in 2015. [98] In 2016, the Nature Index ranked Berkeley 7th in the world based on research publication output in top tier academic journals in the life sciences, chemistry, earth and environmental sciences and physical sciences based on publication data from 2015. [99]

National
The 2016 U.S. News & World Report "Best Colleges" report ranked Berkeley first among public universities and 20th among national universities. [34] Washington Monthly ranked Berkeley 7th among national universities in 2016, with criteria based on research, community service, and social mobility. The Money Magazine Best Colleges ranking for 2015 ranked Berkeley 9th in the United States based on educational quality, affordability and alumni earnings. [100] For 2015 Kiplinger ranked Berkeley the 4th best-value public university in the nation for in-state students, and 6th for out-of-state students. [101] The 2016 Forbes America's Top Colleges report ranked Berkeley 40th among all universities and liberal arts colleges in the United States. [102]
In 2014, The Daily Beast' s Best Colleges report ranked Berkeley 11th in the country. [103] The 2013 Top American Research Universities report by the Center for Measuring University Performance ranked Berkeley 8th over-all, 5th in resources, faculty, and education, 9th in resources and education, and 1st in education. [104] Berkeley was listed as a " Public Ivy " in Richard Moll's 1985 Public Ivies . [105]

Discoveries and innovation
[111]

Campus
The Berkeley campus encompasses approximately 1,232 acres (499 ha), though the "central campus" occupies only the low-lying western 178 acres (72 ha) of this area. Of the remaining acres, approximately 200 acres (81 ha) are occupied by the Lawrence Berkeley National Laboratory; other facilities above the main campus include the Lawrence Hall of Science and several research units, notably the Space Sciences Laboratory , the Mathematical Sciences Research Institute , an undeveloped 800-acre (320 ha) ecological preserve, the University of California Botanical Garden and a recreation center in Strawberry Canyon. Portions of the mostly undeveloped, eastern area of the campus are actually within the City of Oakland ; these portions extend from the Claremont Resort north through the Panoramic Hill neighborhood to Tilden Park . [112]
To the west of the central campus is the downtown business district of Berkeley ; to the northwest is the neighborhood of North Berkeley, including the so-called Gourmet Ghetto , a commercial district known for high quality dining due to the presence of such world-renowned restaurants as Chez Panisse . Immediately to the north is a quiet residential neighborhood known as Northside with a large graduate student population; [113] situated north of that are the upscale residential neighborhoods of the Berkeley Hills . Immediately southeast of campus lies fraternity row, and beyond that the Clark Kerr Campus and an upscale residential area named Claremont . The area south of the university includes student housing and Telegraph Avenue , one of Berkeley's main shopping districts with stores, street vendors and restaurants catering to college students and tourists. In addition, the University also owns land to the northwest of the main campus, a 90-acre (36 ha) married student housing complex in the nearby town of Albany ("Albany Village" and the "Gill Tract"), and a field research station several miles to the north in Richmond, California .
The campus is home to several museums including the University of California Museum of Paleontology , the UC Berkeley Art Museum and Pacific Film Archive , and the Lawrence Hall of Science . The Museum of Paleontology, found in the lobby of the Valley Life Sciences Building, showcases a variety of dinosaur fossils including a complete cast of a Tyrannosaurus Rex.
Outside of the Bay Area, the University owns various research laboratories and research forests in both northern and southern Sierra Nevada.

Architecture
What is considered the historic campus today was the result of the 1898 "International Competition for the Phoebe Hearst Architectural Plan for the University of California," funded by William Randolph Hearst 's mother and initially held in the Belgian city of Antwerp ; eleven finalists were judged again in San Francisco in 1899. [114] The winner was Frenchman Émile Bénard , however he refused to personally supervise the implementation of his plan and the task was subsequently given to architecture professor John Galen Howard . Howard designed over twenty buildings, which set the tone for the campus up until its expansion in the 1950s and 1960s. The structures forming the "classical core" of the campus were built in the Beaux-Arts Classical style, and include Hearst Greek Theatre , Hearst Memorial Mining Building , Doe Memorial Library , California Hall, Wheeler Hall , (Old) Le Conte Hall, Gilman Hall, Haviland Hall, Wellman Hall, Sather Gate , and the 307-foot (94 m) Sather Tower (nicknamed "the Campanile" after its architectural inspiration, St Mark's Campanile in Venice). Buildings he regarded as temporary, nonacademic, or not particularly "serious" were designed in shingle or Collegiate Gothic styles; examples of these are North Gate Hall, Dwinelle Annex, and Stephens Hall. Many of Howard's designs are recognized California Historical Landmarks [115] and are listed on the National Register of Historic Places .
Built in 1873 in a Victorian Second-Empire-style , South Hall is the oldest university building in California. It, and the Frederick Law Olmsted -designed Piedmont Avenue east of the main campus, are the only remnants from the original University of California before John Galen Howard's buildings were constructed. Other architects whose work can be found in the campus and surrounding area are Bernard Maybeck [116] (best known for the Palace of Fine Arts in San Francisco), Maybeck's student Julia Morgan (Hearst Women's Gymnasium), Charles Willard Moore (Haas School of Business) and Joseph Esherick (Wurster Hall).

Natural features
Flowing into the main campus are two branches of Strawberry Creek . The south fork enters a culvert upstream of the recreational complex at the mouth of Strawberry Canyon and passes beneath California Memorial Stadium before appearing again in Faculty Glade. It then runs through the center of the campus before disappearing underground at the west end of campus. The north fork appears just east of University House and runs through the glade north of the Valley Life Sciences Building, the original site of the Campus Arboretum.
Trees in the area date from the founding of the University in the 1870s. The campus, itself, contains numerous wooded areas; including: Founders' Rock , Faculty Glade, Grinnell Natural Area, and the Eucalyptus Grove, which is both the tallest stand of such trees in the world and the tallest stand of hardwood trees in North America. [117]
The campus sits on the Hayward Fault , which runs directly through California Memorial Stadium. [118] There is ongoing construction to retrofit the stadium. The "treesit" protest revolved around the controversy of clearing away trees by the stadium to build the new Student Athlete High Performance Center. As the stadium sits directly on the fault, this raised campus concerns of the safety of student athletes in the event of an earthquake as they train in facilities under the stadium stands. [119]

Environmental record
Through its Office of Sustainability and Energy, UC Berkeley works to implement sustainability initiatives on campus. The university encourages green purchasing when possible and installing energy-efficient technologies. [120] UC Berkeley has a green building policy. Two buildings on campus are LEED certified, and six others meet LEED standards. Multiple building spaces have been repurposed for alternative use, and waste from construction projects is reduced. Water conservation technologies have been installed across campus, and the university employs a variety of techniques to manage storm water. [120] UC Berkeley heats, cools, and powers its lab equipment with power from an on-campus natural gas plant. [121] UC Berkeley's efforts toward sustainability earned the school an overall grade of B+ on one sustainability report card. [120]

Organization and administration
The University of California is governed by a 26-member Board of Regents , 18 of which are appointed by the Governor of California to 12-year terms, 7 serving as ex officio members, a single student regent and a non-voting student regent-designate. [122] The position of Chancellor was created in 1952 to lead individual campuses. The Board appointed Nicholas Dirks the 10th Chancellor of the university in 2013 after Robert J. Birgeneau , originally appointed in 2004, announced his resignation. [123] 12 vice chancellors report directly to the Chancellor. The Executive Vice Chancellor and Provost serves as the chief academic officer and is the office to which the deans of the 14 colleges and schools report. [124]
On August 16, 2016, Dirks announced he would step down as chancellor after months of heavy criticism from faculty over his management of university finances and his handling of a string of sexual misconduct cases involving high-profile faculty. [125] Dirks said he would step down upon the selection of a successor, who will be picked by a search committee of a dozen university leaders. [126] In March 2017, his successor, Carol T. Christ , was confirmed by the UC Regents and will assume the position July 1, 2017. [127]
The 2006–07 budget totaled $1.7 billion; 33% came from the State of California. In 2006–07, 7,850 donors contributed $267.9 million and the endowment was valued at $2.89 billion. [72]
UC Berkeley employs 24,700 people directly and employees are permitted to unionize and are represented by AFSCME , California Nurses Association (CNA), CUE-Teamsters Local 2010 (formerly the Coalition of University Employees (CUE)), UAW , UC-AFT, and UPTE. [72] [128]

University finances
UC Berkeley receives funding from a variety of sources, including federal and state authorities, and private donors. With the exception of government contracts, public money is proportioned to UC Berkeley and the other 9 universities of the University of California system through the UC Office of the President.
State funding has, historically, been very high at the University of California. In 1987, the state provided 54% of the UC Berkeley's budget. However, due in part to the 2008–11 California budget crisis , recent educational appropriations to the university have seen a significant decline. [129] State educational appropriations such as general support given in the state's annual budget, and appropriations given to the state through the federal American Reinvestment and Recovery Act (ARRA) dropped $37M in 2010–11 from the previous calendar year. In 2013, state general support dropped to 12% of the university's total revenues. [130] State budget shortfalls as well as rising costs in pensions have been cited by the university as two of the leading reasons for its current financial woes. In response to revenue shortfalls, the UC Regents have raised tuition, and the university is trying to increase the number of non-resident undergraduates, who will pay the more costly out-of-state tuition. Nearly one-third of revenues from tuition and other student fees are returned to students as scholarships and fellowships. [131]
Cal has controversially borrowed $445 million to fund the $321 million renovation of seismically unsafe Memorial Stadium and construction of a new $153 million student athletic center, [132] both of which opened in 2012. (See Athletics section for additional details).
In 2014, Cal presented a plan to the Board of Regents that would create a venture capital fund that would fund student and faculty startups. [133]

Financial aid and scholarship programs
Students and prospective students of UC Berkeley are eligible for a variety of public and private financial aid. Most [ weasel words ] financial aid inquiries are processed through the UC Berkeley Financial Aid and Scholarships Office . Some graduate schools, such as the Haas School of Business [134] and UC Berkeley School of Law [135] have their own financial aid offices.

Admissions and enrollment
The preliminary freshman Fall 2016 undergraduate acceptance rate at Berkeley was 17.5%. [136] For Fall 2015, Berkeley enrolled 27,496 undergraduate and 10,708 graduate students, with women making up 52.1% of undergraduate enrollments and 46.0% graduate and professional students. [3] Also in Fall 2015, California residents comprised 73% of undergraduates and 39% of graduate and professional students. [146] [147]
Of the Fall 2013 cohort, 96% of freshmen enrolled the next year. The four-year graduation rate for the Fall 2008 cohort was 72%, and the six-year rate was 91%. [148] [149] Enrolled freshman for the fall of 2015 had an average fully weighted high school GPA of 4.41 and an average unweighted GPA of 3.87. Fall 2015 admitted freshman applicants had an average ACT Composite score of 31–33, and average combined SAT scores of 2124 for in-state admits and 2171 for out-of-state admits. [141] [150] Berkeley's enrollment of National Merit Scholars was third in the nation until 2002, when participation in the National Merit program was discontinued. [151] 33% of admitted students receive federal Pell grants . [152]

Student life and traditions
The official university mascot is Oski the Bear , who debuted in 1941. Previously, live bear cubs were used as mascots at Memorial Stadium until it was decided in 1940 that a costumed mascot would be a better alternative. Named after the Oski-wow-wow yell, he is cared for by the Oski Committee, whose members have exclusive knowledge of the identity of the costume-wearer. [154]
The University of California Marching Band , which has served the university since 1891, performs at every home football game and at select road games as well. A smaller subset of the Cal Band, the Straw Hat Band, performs at basketball games, volleyball games, and other campus and community events. [155]
The UC Rally Committee, formed in 1901, is the official guardian of California's Spirit and Traditions. Wearing their traditional blue and gold rugbies, Rally Committee members can be seen at all major sporting and spirit events. Committee members are charged with the maintenance of the five Cal flags, the large California banner overhanging the Memorial Stadium Student Section and Haas Pavilion , the California Victory Cannon, Card Stunts and The Big "C" among other duties. The Rally Committee is also responsible for safekeeping of the Stanford Axe when it is in Cal's possession. [156] The Chairman of the Rally Committee holds the title "Custodian of the Axe" while it is in the Committee's care.
Overlooking the main Berkeley campus from the foothills in the east, The Big "C" is an important symbol of California school spirit. The Big "C" has its roots in an early 20th-century campus event called "Rush," which pitted the freshman and sophomore classes against each other in a race up Charter Hill that often developed into a wrestling match. It was eventually decided to discontinue Rush and, in 1905, the freshman and sophomore classes banded together in a show of unity to build the Big "C". [157] Owing to its prominent position, the Big "C" is often the target of pranks by rival Stanford University students who paint the Big "C" red and also fraternities and sororities who paint it their organization's colors. One of the Rally Committee's functions is to repaint the Big "C" to its traditional color of King Alfred Yellow.
Cal students invented the college football tradition of card stunts . Then known as Bleacher Stunts, they were first performed during the 1910 Big Game and consisted of two stunts: a picture of the Stanford Axe and a large blue "C" on a white background. The tradition continues today in the Cal student section and incorporates complicated motions, for example tracing the Cal script logo on a blue background with an imaginary yellow pen. [158]
The California Victory Cannon, placed on Tightwad Hill overlooking the stadium, is fired before every football home game, after every score, and after every Cal victory. First used in the 1963 Big Game, it was originally placed on the sidelines before moving to Tightwad Hill in 1971. The only time the cannon ran out of ammunition was during a game against Pacific in 1991, when Cal scored 12 touchdowns. [159]
Other traditions have included events that span only a few years. William (or Willie) the Polka Dot Man was a performance artist who frequented Sproul Plaza during the late 1970s and early 1980s. [160] The Naked Guy (now deceased) [161] and Larry the Drummer, who performed Batman tunes, appeared in the late 1980s and early 1990s. [160]
A few current traditions include streaking during finals week in the Main Stacks, the Happy Happy Man, and Stoney Burke .

Student housing
Students at UC Berkeley live in a variety of housing that cater to personal and academic preferences and styles. The immediately surrounding community offers apartments, Greek (fraternity and sorority) housing and cooperative housing, twenty of which are houses that are members of the Berkeley Student Cooperative .

University housing
The university runs twelve different residence halls, ranging from undergraduate residence halls (both themed and non-themed) and family student housing, to re-entry student housing and optional international student housing at the International House . Undergraduate residence halls are located off-campus in the city of Berkeley. Units 1, 2 and 3, located on the south side of campus, offer high-rise accommodations with common areas on every other floor. Units 1 and 2 share a common dining hall, called Crossroads. The oldest unit, Unit 3, is the oldest of the three and has its own dining hall on the bottom floor called Cafe 3. [162] Further away and also on the south side of campus is Clark Kerr, an undergraduate residence hall complex that houses many student athletes and was once a school for the deaf and blind.
In the foothills east of the central campus, there are three additional undergraduate residence hall complexes: Foothill, Stern, and Bowles. Foothill is a co-ed suite-style hall reminiscent of a Swiss chalet. According to the Chancellor, it is considered one of the best residence halls at UC Berkeley. Just south of Foothill, overlooking the Hearst Greek Theatre, is the all-women's traditional-style Stern Hall , which boasts an original mural by Diego Rivera . Because of their proximity to the College of Engineering and College of Chemistry , these residence halls often house science and engineering majors. They tend to be quieter than the southside complexes, but because of their location next to the theatre, often get free glimpses of concerts. Bowles Hall , the oldest state-owned residence hall in California, is located immediately north of California Memorial Stadium. Dedicated in 1929 and on the National Register of Historic Places, this residence hall has the appearance of a castle and large rooms that sleep four.
The Channing-Bowditch and Ida Jackson apartments are intended for older students. [163] [164] Family student housing consists of two main groups of housing: University Village and Smyth-Fernwald. University Village is located 3 miles (4.8 km) north-west of campus in Albany, California , and Smyth-Fernwald near the Clark Kerr campus.

Cooperative housing
Students in Berkeley have a number of cooperative housing options. The largest network of student housing cooperatives in the area is the Berkeley Student Cooperative (BSC).
Students of UC Berkeley, as well as students of other universities and colleges in the area, have the option of living in one of the twenty cooperative houses of the Berkeley Student Cooperative (BSC), formerly the University Students' Cooperative Association (USCA), and member of the national cooperative federation, NASCO . The BSC is a nonprofit housing cooperative network consisting of 20 cooperative homes and 1250 member-owners. [165] The USCA (as the BSC was known by at that time) was founded in 1933 by then-director of the YWCA , Harry Kingman . The birth of the USCA, as well as many other cooperative organizations around the country, coincided with the Great Depression precisely as a response to scant resources. By living together in large houses and pooling together resources, members found that their monetary resources could go further to pay for their cost of living than living separately. In the 1960s, the USCA pioneered the first co-ed university housing in Berkeley, called the Ridge Project (later renamed Casa Zimbabwe ). In 1975, the USCA founded its first and only vegetarian-themed house, Lothlorien. In 1997, the USCA opened its African-American theme house, Afro House, and in 1999 its LGBT -themed house, named after queer Irish author and poet Oscar Wilde . [166]
Notable alumni of the BSC include Marion Nestle , professor at New York University and author of Food Politics, and Beverly Cleary .

Fraternities and sororities
University-sanctioned fraternities and sororities comprise over 60 houses that are accredited to one of four Governing Councils, all under the umbrella organization of CalGreeks. [168] [169]

Student-run organizations

Student government
The Associated Students of the University of California (ASUC) is the student government organization that controls funding for student groups and organizes on-campus student events. It is considered one of the most autonomous student governments at any public university in the U.S. The two main political parties are "Student Action" [170] and "CalSERVE." [171] The organization was founded in 1887 and has an annual operating budget of $1.7 million, in addition to various investment assets.
The ASUC's Student Union Program, Entertainment, and Recreation Board (SUPERB) is a student-run, non-profit branch dedicated to providing entertainment for the campus and community. Founded in 1964, SUPERB's programming includes the Friday Film Series, free Noon Concerts on Lower Sproul Plaza, Comedy Competitions, Poker Tournaments, free Sneak Previews of upcoming movies, and more.
In April 2013, in an 11-9 vote, UC Berkeley's student senate passed a Boycott, Divestment and Sanctions resolution for the UC system to divest from companies that are assisting in Israel's "illegal occupation and ensuing human rights abuses". [172] [173]

Communications media
UC Berkeley's student-run online television station, CalTV , was formed in 2005 and broadcasts online. It is run by students with a variety of backgrounds and majors.
UC Berkeley's independent student-run newspaper is The Daily Californian . Founded in 1871, The Daily Cal became independent in 1971 after the campus administration fired three senior editors for encouraging readers to take back People's Park . The Daily Californian has both a print and online edition. Print circulation is about 10,000. The newspaper is an important source of information for students, faculty, staff, and the surrounding City of Berkeley.
Berkeley's FM Student radio station , KALX , broadcasts on 90.7 MHz. It is run largely by volunteers, including both students and community members.
Berkeley also features an assortment of student-run magazines, most notably Caliber Magazine. Founded in 2008, Caliber Magazine promotes itself as "the everything magazine" by featuring articles and blogs on a wide range of topics. It has been voted "Best Magazine on Campus" by the readers of the Daily Cal [174] as well as "Best Publication on Campus" by the ASUC.

Student groups
UC Berkeley has a reputation for student activism , stemming from the 1960s and the Free Speech Movement . Today, Berkeley is known as a lively campus with activism in many forms, from email petitions, presentations on Sproul Plaza and volunteering, to the occasional protest. During the 2006–07 school year, there were 94 political student groups on campus including MEChXA de UC Berkeley, Berkeley American Civil Liberties Union , Berkeley Students for Life, Campus Greens, The Sustainability Team (STEAM), the Berkeley Student Food Collective , Students for Sensible Drug Policy, Cal Berkeley Democrats, and the Berkeley College Republicans. Berkeley sends the most students to the Peace Corps of any university in the nation. [175]
The Residence Hall Assembly (RHA) is the student-run residence hall organization that oversees all aspects of residence wide event planning, legislation, sponsorships and activities for over 7,200 on-campus undergraduate residents. Founded in 1988 by the President's Council, it is now funded and supported by the Residential and Student Service Programs department on campus. [176]
The Berkeley Group [177] is a student consulting organization affiliated with UC Berkeley and the Haas School of Business. Students of all majors are recruited and trained to work on pro-bono consulting engagements with real-life nonprofit clients.
ImagiCal [178] has been the college chapter of the American Advertising Federation at Berkeley since the late 1980s. Every year, the team competes in the National Student Advertising Competition . Students from various backgrounds come together to work on a marketing case provided by the AAF and a corporate sponsor to college chapters across the nation. Most recently, the UC Berkeley team won in their region in 2005, 2009 and 2012, going on to win 4th and 3rd in the nation in 2005 and 2009, respectively.
The Berkeley Forum is a student organization that hosts panels, debates, and talks by leading experts from many different fields. [179] The organization is nonpartisan and has brought a wide variety of speakers to campus, including Senator Rand Paul , entrepreneur and venture capitalist Peter Thiel , Khan Academy founder Salman Khan , and many others.
Democratic Education at Cal, or DeCal, is a program that promotes the creation of professor-sponsored, student-facilitated classes through the Special Studies 98/198 program. [180] DeCal arose out of the 1960s Free Speech movement and was officially established in 1981. The program offers around 150 courses on a vast range of subjects that appeal to the Berkeley student community, including classes on the Rubik's Cube , James Bond , Batman , the Iranian Revolution , cooking , Israeli folk dancing , 3D animation , nuclear weapons , and meditation .
There are many a cappella groups on campus, including Artists in Resonance, Berkeley Dil Se, the UC Men's Octet , the California Golden Overtones , and Noteworthy. The UC Men's Octet is an eight-member a cappella group founded in 1948 featuring a repertoire of barbershop, doo-wop, contemporary pop, modern alternative, and fight songs. They are one of only two multiple time champions of the ICCA , having won the championship in both 1998 and 2000. The California Golden Overtones, founded in 1984, have a very similar repertoire to the Octet. Noteworthy competed in Season 5 of America's Got Talent. It is a tradition for every Berkeley a cappella group to perform under the campus' iconic Sather Gate each week at different times during the week. In addition to a Capella, Berkeley is host to a myriad of other performing arts groups in comedy, dance, acting and instrumental music. A few examples include jericho! Improv & Sketch Comedy, The Movement, Taiko drumming, BareStage student musical theater, the Remedy Music Project, Main Stacks, AFX Dance, and TruElement.
Since 1967, students and staff jazz musicians have had an opportunity to perform and study with the University of California Jazz Ensembles . Under the direction of Dr. David W. Tucker, who was hired by the Cal Band as a composer, arranger, and associate director, but was later asked to direct the jazz ensembles as it grew in popularity and membership, the group grew rapidly from one big band to multiple big bands, numerous combos, and numerous instrumental classes with multiple instructors. For several decades it hosted the Pacific Coast Collegiate Jazz Festival, part of the American Collegiate Jazz Festival, a competitive forum for student musicians. PCCJF brought jazz luminaries such as Hubert Laws , Sonny Rollins , Freddie Hubbard , and Ed Shaughnessy to the Berkeley campus as performers, clinicians, and adjudicators. The festival later included high school musicians. The jazz ensembles became an effective recruitment tool. Many high school musicians interested in strong academics as well as jazz found that the campus met both interests. Numerous alumni have had successful careers in jazz performance and education including Michael Wolff and Andy Narell .
UC Berkeley also hosts a large number of conferences, talks, and musical and theatrical performances. Many of these events, including the Annual UC Berkeley Sociological Research Symposium, are completely planned and organized by undergraduate students.

Athletics
The athletic teams at UC Berkeley are known as the California Golden Bears (often shortened to "Cal Bears" or just "Cal") and are primarily members of the NCAA Division I Pac-12 Conference (Pac-12). Cal is also a member of the Mountain Pacific Sports Federation in several sports not sponsored by the Pac-12 and the America East Conference in women's field hockey . The first school colors, established in 1873 by a committee of students, were Blue (specifically Yale Blue) and Gold. [181] [182] Yale Blue was originally chosen because many of the university's founders were Yale University graduates (for example Henry Durant, the first university president). Blue and Gold were specified and made the official colors of the university and the state colors of California in 1955. [181] [183] However, the athletic department has recently specified a darker blue, close to but not the same as the Berkeley Blue now used by the school. [184] [185] The California Golden Bears have a long history of excellence in athletics, having won national titles in football, men's basketball, baseball, softball, men's and women's crew, men's gymnastics, men's tennis, men's and women's swimming, men's water polo, men's Judo, men's track, and men's rugby. In addition, Cal athletes have won numerous individual NCAA titles in track, gymnastics, swimming and tennis. On January 31, 2009, the school's Hurling club made athletic history by defeating Stanford in the first collegiate hurling match ever played on American soil.
California finished in first place [186] in the 2007–08 Fall U.S. Sports Academy Directors' Cup standings (Now the NACDA Directors' Cup ), a competition measuring the best overall collegiate athletic programs in the country, with points awarded for national finishes in NCAA sports. Cal finished the 2007–08 competition in seventh place with 1119 points. [187] Most recently, California finished in third place in the 2010–11 NACDA Directors' Cup with 1219.50 points, finishing behind Stanford and Ohio State. This is California's highest ever finish in the Director's Cup. [188]
Cal's seismically unsafe Memorial Stadium reopened September 2012 after a $321 million renovation. The university incurred a controversial $445 million of debt for the stadium and a new $153 million student athletic center, which it planned to finance with the sale of special stadium endowment seats. However, in June 2013 news surfaced that the university has had trouble selling the seats. [189] The roughly $18 million interest-only annual payments on the debt consumes 20 percent of Cal's athletics' budget; principal repayment begins in 2032 and is scheduled to conclude in 2113. [132]
In 2014, Cal instituted a strict academic standard for an athlete's admission to the university. By the 2017 academic year 80 percent of incoming student athletes will need to comply with the University of California general student requirement of having a 3.0 or higher high school grade point average. [190]
The Golden Bears' traditional arch-rivalry is with the Stanford Cardinal . The most anticipated sporting event between the two universities is the annual football game dubbed the Big Game, and it is celebrated with spirit events on both campuses. Since 1933, the winner of the Big Game has been awarded custody of the Stanford Axe .

California – Stanford rivalry
One of the most famous moments in Big Game history occurred during the 85th Big Game on November 20, 1982. In what has become known as "the band play" or simply The Play , Cal scored the winning touchdown in the final seconds with a kickoff return that involved a series of laterals and the Stanford marching band rushing onto the field.

National championships
Berkeley teams have won national championships in baseball (2), men's basketball (2), men's crew (15), women's crew (3), football (5), men's golf (1), men's gymnastics (4), men's lacrosse (1), men's rugby (26), softball (1), men's swimming & diving (4), women's swimming & diving (3), men's tennis (1), men's track & field (1), and men's water polo (13).

Notable alumni, faculty, and staff
As of 2016, 33 alumni and 23 past and present full-time faculty are counted among the 91 Nobel laureates associated with the university . [193] The Turing Award , the "Nobel Prize of computer science", has been awarded to eleven alumni and ten past and present full-time faculty , with Dana Scott being an alumnus and a faculty member. [194]

Faculty
Shiing-Shen Chern , a leading geometer of the 20th century and a faculty member of the Berkeley mathematics department, co-founded the renowned Mathematical Sciences Research Institute at Berkeley in 1981 and served as the founding Director until 1984. [195] [196] Berkeley physicist J. Robert Oppenheimer was the scientific director of the Manhattan Project that developed the first atomic bomb in the world during World War II , and was the founder of the Berkeley Center for Theoretical Physics. [197] Faculty member Edward Teller was (together with Stanislaw Ulam ) the "father of the hydrogen bomb ", who laid important foundations for the establishment of Space Sciences Laboratory at Berkeley. [198] Ernest Lawrence , a Nobel laureate in physics who invented cyclotron at Berkeley, founded the Radiation Laboratory on campus which later became the renowned Lawrence Berkeley National Laboratory . [199] Nobel laureate Glenn T. Seaborg discovered or co-discovered 10 chemical elements at Berkeley and served as the Chancellor of UC Berkeley from 1958-1961. [200] [201] Former United States Secretary of Energy and Nobel laureate Steven Chu (PhD 1976), was Director of Berkeley Lab , 2004–2009. Janet Yellen , the 15th Chair of the Federal Reserve Board , is a professor emeritus at Berkeley Haas School of Business and the Department of Economics. [202] [203]

Alumni
Alumni have been involved in the field of politics and international relations , one of whom is Nicholas A. Veliotes (1928–). Veliotes went on to become the Ambassador to the countries of Jordan (1978–81) and Egypt (1984–86), among holding many other highly prestigious job titles and positions throughout his lengthy career.
Alumni have written novels and screenplays that have attracted Oscar-caliber talent. Irving Stone (BA 1923) wrote the novel Lust for Life , which was later made into an Academy Award–winning film of the same name starring Kirk Douglas as Vincent van Gogh . Stone also wrote The Agony and the Ecstasy , which was later made into a film of the same name starring Oscar winner Charlton Heston as Michelangelo . Mona Simpson (BA 1979) wrote the novel Anywhere But Here , which was later made into a film of the same name starring Oscar-winning actress Susan Sarandon . Terry McMillan (BA 1986) wrote How Stella Got Her Groove Back , which was later made into a film of the same name starring Oscar-nominated actress Angela Bassett . Randi Mayem Singer (BA 1979) wrote the screenplay for Mrs. Doubtfire , which starred Oscar-winning actor Robin Williams and Oscar-winning actress Sally Field . Audrey Wells (BA 1981) wrote the screenplay The Truth About Cats & Dogs , which starred Oscar-nominated actress Uma Thurman . James Schamus (BA 1982, MA 1987, PhD 2003) has collaborated on screenplays with Oscar-winning director Ang Lee on the Academy Award-winning movies Crouching Tiger, Hidden Dragon and Brokeback Mountain .
Alumni have made important contributions to science. Some have concentrated their studies on the very small universe of atoms and molecules. Nobel laureate William F. Giauque (BS 1920, PhD 1922) investigated chemical thermodynamics , Nobel laureate Willard Libby (BS 1931, PhD 1933) pioneered radiocarbon dating , Nobel laureate Willis Lamb (BS 1934, PhD 1938) examined the hydrogen spectrum , Nobel laureate Hamilton O. Smith (BA 1952) applied restriction enzymes to molecular genetics , Nobel laureate Robert Laughlin (BA math 1972) explored the fractional quantum Hall effect , and Nobel laureate Andrew Fire (BA math 1978) helped to discover RNA interference - gene silencing by double-stranded RNA . Nobel laureate Glenn T. Seaborg (PhD 1937) collaborated with Albert Ghiorso (BS 1913) to discover 12 chemical elements, such as americium , berkelium , and californium . David Bohm (PhD 1943) discovered Bohm Diffusion . Nobel laureate Yuan T. Lee (PhD 1965) developed the crossed molecular beam technique for studying chemical reactions. Carol Greider (PhD 1987), professor of molecular biology and genetics at Johns Hopkins University School of Medicine, was awarded the 2009 Nobel Prize in medicine for discovering a key mechanism in the genetic operations of cells, an insight that has inspired new lines of research into cancer. Harvey Itano (BS 1942), conducted breakthrough work on sickle cell anemia that marked the first time a disease was linked to a molecular origin. [204] While he was valedictorian of UC Berkeley's class of 1942, he was unable to attend commencement exercises due to internment . [205] Narendra Karmarkar (PhD 1983) is known for the interior point method, a polynomial algorithm for linear programming known as Karmarkar's algorithm . [206] National Medal of Science laureate Chien-Shiung Wu (PhD 1940), often known as the "Chinese Madame Curie," disproved the Law of Conservation of Parity for which she was awarded the inaugural Wolf Prize in Physics . [207] Kary Mullis (PhD 1973) was awarded the 1993 Nobel Prize in Chemistry for his role in developing the polymerase chain reaction , [208] a method for amplifying DNA sequences. Daniel Kahneman was awarded the 2002 Nobel Memorial Prize in Economics for his work in Prospect theory . Richard O. Buckius , engineer, Bachelor's in Mechanical Engineering '72, Masters '73, PhD '75, currently Chief Operating Officer of the National Science Foundation . Edward P. Tryon (PhD 1967) is the physicist who first said our universe originated from a quantum fluctuation of the vacuum. [209] [210] [211]
John N. Bahcall (BS 1956) worked on the Standard Solar Model and the Hubble Space Telescope , [212] resulting in a National Medal of Science . [212] Peter Smith (BS 1969) was the principal investigator and project leader for the NASA robotic explorer Phoenix , [213] which physically confirmed the presence of water on the planet Mars for the first time. [214] Astronauts James van Hoften (BS 1966), Margaret Rhea Seddon (BA 1970), Leroy Chiao (BS 1983), and Rex Walheim (BS 1984) have orbited the earth in NASA's fleet of space shuttles .
Undergraduate alumni have founded or cofounded such companies as Apple Computer , [215] Intel , [216] LSI Logic [217] The Gap , [218] MySpace , [219] PowerBar , [220] Berkeley Systems , [221] Bolt, Beranek and Newman [222] (which created a number of underlying technologies that govern the Internet ), Chez Panisse , [223] GrandCentral (known now as Google Voice ), [224] HTC Corporation , [225] VIA Technologies , [225] Marvell Technology Group , [226] MoveOn.org, [221] Opsware , [227] RedOctane , [228] Rimon Law P.C. , [229] SanDisk , [230] Scharffen Berger Chocolate Maker , [231] VMware , [232] and Zilog , [233] while graduate school alumni have cofounded companies such as DHL , [234] KeyHole Inc (known now as Google Earth), [235] Sun Microsystems , [236] and The Learning Company . [237] Berkeley alumni have also led various technology companies such as Electronic Arts , [238] Google , [239] Adobe Systems , [240] Softbank ( Masayoshi Son ) and Qualcomm . [241]
Berkeley alumni nurtured a number of key technologies associated with the personal computer and the development of the Internet. [242] Unix was created by alumnus Ken Thompson (BS 1965, MS 1966) along with colleague Dennis Ritchie . Alumni such as L. Peter Deutsch [243] [244] [245] (PhD 1973), Butler Lampson (PhD 1967), and Charles P. Thacker (BS 1967) [246] worked with Ken Thompson on Project Genie and then formed the ill-fated US Department of Defense -funded Berkeley Computer Corporation (BCC), which was scattered throughout the Berkeley campus in non-descript offices to avoid anti-war protestors. [247] After BCC failed, Deutsch, Lampson, and Thacker joined Xerox PARC , where they developed a number of pioneering computer technologies, culminating in the Xerox Alto that inspired the Apple Macintosh . In particular, the Alto used a computer mouse , which had been invented by Doug Engelbart (B.Eng 1952, Ph.D. 1955). Thompson, Lampson, Engelbart, and Thacker [248] all later received a Turing Award. Also at Xerox PARC was Ronald V. Schmidt (BS 1966, MS 1968, PhD 1971), who became known as "the man who brought Ethernet to the masses". [249] Another Xerox PARC researcher, Charles Simonyi (BS 1972), pioneered the first WYSIWIG word processor program and was recruited personally by Bill Gates to join the fledgling company known as Microsoft to create Microsoft Word . Simonyi later became the first repeat space tourist , blasting off on Russian Soyuz rockets to work at the International Space Station orbiting the earth.
In 1977, a graduate student in the computer science department named Bill Joy (MS 1982) assembled [250] the original Berkeley Software Distribution , commonly known as BSD Unix . Joy, who went on to co-found Sun Microsystems, also developed the original version of the terminal console editor vi , while Ken Arnold (BA 1985) created Curses , a terminal control library for Unix-like systems that enables the construction of text user interface (TUI) applications. Working alongside Joy at Berkeley were undergraduates William Jolitz (BS 1997) and his future wife Lynne Jolitz (BA 1989), who together created 386BSD , a version of BSD Unix that runs on Intel CPUs and evolved into the BSD family of free operating systems and the Darwin operating system underlying Apple Mac OS X . [251] Eric Allman (BS 1977, MS 1980) created SendMail , a Unix mail transfer agent that delivers about 12% of the email in the world. [252]
The XCF , an undergraduate research group located in Soda Hall , has been responsible for a number of notable software projects, including GTK+ (created by Peter Mattis , BS 1997), The GIMP ( Spencer Kimball , BS 1996), and the initial diagnosis of the Morris worm . [253] In 1992 Pei-Yuan Wei , [254] an undergraduate at the XCF, created ViolaWWW , one of the first graphical web browsers. ViolaWWW was the first browser to have embedded scriptable objects, stylesheets, and tables. In the spirit of Open Source, he donated the code to Sun Microsystems, inspiring Java applets( Kim Polese (BS 1984) was the original product manager for Java at Sun Microsystems.) ViolaWWW also inspired researchers at the National Center for Supercomputing Applications to create the Mosaic web browser , [255] a pioneering web browser that became Microsoft Internet Explorer .
Collectively, alumni have won at least twenty Academy Awards . Gregory Peck (BA 1939), nominated for four Oscars during his career, won an Oscar for acting in To Kill a Mockingbird . Chris Innis (BA 1991) won the 2010 Oscar for film editing for her work on best picture winner, The Hurt Locker . Walter Plunkett (BA 1923 ) won an Oscar for costume design (for An American in Paris ). Freida Lee Mock (BA 1961) and Charles H. Ferguson (BA 1978) have each [256] [257] won an Oscar for documentary filmmaking. Mark Berger (BA 1964) has won four Oscars for sound mixing and is an adjunct professor at UC Berkeley. [258] Edith Head (BA 1918), who was nominated for 34 Oscars during her career, won eight Oscars for costume design. Joe Letteri (BA 1981 [259] ) has won four Oscars for Best Visual Effects in the James Cameron film Avatar and the Peter Jackson films King Kong , The Two Towers , and The Return of the King . [260]
Alumni have collectively won at least twenty-five Emmy Awards : Jon Else (BA 1968) for cinematography; Andrew Schneider (BA 1973) for screenwriting; Linda Schacht (BA 1966, MA 1981), two for broadcast journalism; [261] [262] Christine Chen (dual BA's 1990), two for broadcast journalism; [263] Kristen Sze (BA), two for broadcast journalism; [264] Kathy Baker (BA 1977), three for acting; Ken Milnes (BS 1977), four for broadcasting technology; and Leroy Sievers (BA), [265] twelve for production. Elisabeth Leamy is the recipient of 13 Emmy awards . [266] [267] [268]
Alumni collectively have won at least eight Pulitzer Prizes. Pulitzer Prize–winning journalist Marguerite Higgins (BA 1941) was a pioneering female war correspondent [269] [270] who covered World War II, the Korean War , and the Vietnam War . [271] Novelist Robert Penn Warren (MA 1927) won three Pulitzer Prizes, [272] including one for his novel All the King's Men , which was later made into an Academy Award-winning [273] movie . Pulitzer Prize–winning cartoonist Rube Goldberg (BS 1904) invented the comically complex—yet ultimately trivial—contraptions known as Rube Goldberg machines . Journalist Alexandra Berzon (MA 2006) won a Pulitzer Prize in 2009, [274] and journalist Matt Richtel (BA 1989), who also coauthors the comic strip Rudy Park under the pen name of "Theron Heir", [275] won the 2010 Pulitzer Prize for National Reporting . [276] Pulitzer Prize-winning historian Leon Litwack (BA [277] 1951, PhD 1958) taught as a professor at UC Berkeley for 43 years; [278] three other UC Berkeley professors have also received the Pulitzer Prize. Alumna and professor Susan Rasky won the Polk Award for journalism in 1991. USC Professor and UC Berkeley alumna Viet Thanh Nguyen 's (PhD 1997) first novel The Sympathizer won the 2016 Pulitzer Prize for Fiction [279]
Alumni have acted in classic television series that are still broadcast on TV today. Karen Grassle (BA 1965) played the mother Caroline Ingalls in Little House on the Prairie , Jerry Mathers (BA 1974) starred in Leave it to Beaver , and Roxann Dawson (BA 1980) portrayed B'Elanna Torres on Star Trek: Voyager .
Former undergraduates have participated in the contemporary music industry, such as Grateful Dead bass guitarist Phil Lesh , The Police drummer Stewart Copeland , [280] Rolling Stone Magazine founder Jann Wenner , The Bangles lead singer Susanna Hoffs (BA 1980), Counting Crows lead singer Adam Duritz , electronic music producer Giraffage , MTV correspondent Suchin Pak (BA 1997), [281] AFI musicians Davey Havok and Jade Puget (BA 1996), and solo artist Marié Digby ( Say It Again ). People Magazine included Third Eye Blind lead singer and songwriter Stephan Jenkins (BA 1987) in the magazine's list of "50 Most Beautiful People". [282]
Alumni have also participated in the world of sports. Tennis athlete Helen Wills Moody (BA 1925) won 31 Grand Slam titles, including eight singles titles at Wimbledon . Tarik Glenn (BA 1999) is a Super Bowl XLI champion. Michele Tafoya (BA 1988) is a sports television reporter for ABC Sports and ESPN . [283] Sports agent Leigh Steinberg ( BA 1970, JD 1973) has represented professional athletes such as Steve Young , Troy Aikman , and Oscar de la Hoya ; Steinberg has been called the real-life inspiration [284] for the title character in the Oscar-winning [285] film Jerry Maguire (portrayed by Tom Cruise ). Matt Biondi (BA 1988) won eight Olympic gold medals during his swimming career, in which he participated in three different Olympics. At the Beijing Olympics in 2008, Natalie Coughlin (BA 2005) became the first American female athlete in modern Olympic history [286] to win six medals in one Olympics.
There are at least 15 living alumni billionaires: Masayoshi Son (SoftBank; second wealthiest Japanese), [287] Gordon Moore (Intel founder), Jon Stryker (Stryker Medical Equipment), [288] Bill Joy (computer programmer and Sun Microsystems founder), Eric Schmidt (Google Chairman), Bassam Alghanim (wealthiest Kuwaiti), Kutayba Alghanim, [287] Charles Simonyi (Microsoft), Cher Wang (HTC, wealthiest Taiwanese), Robert Haas (Levi's), Donald Fisher (Gap), Carlos Rodriguez-Pastor (Interbank, Peru), [289] Fayez Sarofim , James Harris Simons , and Michael Milken .

See also

Notes and references

Further reading and viewing

External links
Coordinates : 37°52′12″N 122°15′32″W ﻿ / ﻿ 37.870°N 122.259°W ﻿ / 37.870; -122.259
WebPage index: 00118
The Wall Street Journal
The Wall Street Journal is an American business-focused, English-language international daily newspaper based in New York City . The Journal , along with its Asian and European editions, is published six days a week by Dow Jones & Company , a division of News Corp . The newspaper is published in the broadsheet format and online.
The Wall Street Journal is the largest newspaper in the United States by circulation . According to the Alliance for Audited Media , the Journal had a circulation of about 2.4 million copies (including nearly 900,000 digital subscriptions) as of March 2013, [2] compared with USA Today ' s 1.7 million.
The newspaper has won 40 Pulitzer Prizes through 2017 [3] and derives its name from Wall Street in the heart of the Financial District of Lower Manhattan . The Journal has been printed continuously since its inception on July 8, 1889, by Charles Dow , Edward Jones , and Charles Bergstresser .
The Journal also publishes the luxury news and lifestyle magazine WSJ. .

History

Beginnings
The first products of Dow Jones & Company, the publisher of the Journal , were brief news bulletins, knick-named "flimsies," hand-delivered throughout the day to traders at the stock exchange in the early 1880s. They were later aggregated in a printed daily summary called the Customers' Afternoon Letter . Reporters Charles Dow, Edward Jones, and Charles Bergstresser converted this into The Wall Street Journal , which was published for the first time on July 8, 1889, and began delivery of the Dow Jones News Service via telegraph. [4] In 1896, The " Dow Jones Industrial Average " was officially launched. It was the first of several indices of stock and bond prices on the New York Stock Exchange . In 1899, the Journal' s Review & Outlook column, which still runs today, appeared for the first time, initially written by Charles Dow.
Journalist Clarence Barron purchased control of the company for US$130,000 in 1902; circulation was then around 7,000 but climbed to 50,000 by the end of the 1920s. Barron and his predecessors were credited with creating an atmosphere of fearless, independent financial reporting—a novelty in the early days of business journalism . In 1921, Barron's , America's premier financial weekly, was founded. [5] Barron died in 1928, a year before Black Tuesday , the stock market crash that greatly affected the Great Depression in the United States. Barron's descendants, the Bancroft family , would continue to control the company until 2007. [5]
The Journal took its modern shape and prominence in the 1940s, a time of industrial expansion for the United States and its financial institutions in New York. Bernard Kilgore was named managing editor of the paper in 1941, and company CEO in 1945, eventually compiling a 25-year career as the head of the Journal . Kilgore was the architect of the paper's iconic front-page design, with its "What's News" digest, and its national distribution strategy, which brought the paper's circulation from 33,000 in 1941 to 1.1 million at the time of Kilgore's death in 1967. Under Kilgore, in 1947 , that the paper won its first Pulitzer Prize , for William Henry Grimes's editorials . [5]
In 1967, Dow Jones Newswires began a major expansion outside of the United States that ultimately put journalists in every major financial center in Europe, Asia, Latin America, Australia, and Africa. In 1970, Dow Jones bought the Ottaway newspaper chain, which at the time comprised nine dailies and three Sunday newspapers. Later, the name was changed to "Dow Jones Local Media Group". [6]
1971 to 1997 brought about a series of launches, acquisitions, and joint ventures, including " Factiva ", The Wall Street Journal Asia , The Wall Street Journal Europe , the WSJ.com website, Dow Jones Indexes, MarketWatch , and "WSJ Weekend Edition". In 2007 News Corp. acquired Dow Jones. WSJ. , a luxury lifestyle magazine, was launched in 2008. [7]

Internet expansion
A complement to the print newspaper, The Wall Street Journal Online , was launched in 1996. In 2003, Dow Jones began to integrate reporting of the Journal' s print and online subscribers together in Audit Bureau of Circulations statements. [8] In 2007, it was commonly believed to be the largest paid-subscription news site on the Web, with 980,000 paid subscribers. [5] Since then, online subscribership has fallen, due in part to rising subscription costs, and was reported at 400,000 in March 2010. [2] In May 2008, an annual subscription to the online edition of The Wall Street Journal cost $119 for those who do not have subscriptions to the print edition. By June 2013, the monthly cost for a subscription to the online edition was $22.99, or $275.88 annually, excluding introductory offers. [9]
On November 30, 2004, Oasys Mobile and The Wall Street Journal released an app that would allow users to access content from the Wall Street Journal Online via their mobile phone. It "will provide up-to-the-minute business and financial news from the Online Journal, along with comprehensive market, stock and commodities data, plus personalized portfolio information—directly to a cell phone". [10]
Many of The Wall Street Journal news stories are available through free online newspapers that subscribe to the Dow Jones syndicate . Pulitzer Prize–winning stories from 1995 are available free on the Pulitzer [11] web site.
In September 2005, the Journal launched a weekend edition, delivered to all subscribers, which marked a return to Saturday publication after a lapse of some 50 years. The move was designed in part to attract more consumer advertising. [5]
In 2005, the Journal reported a readership profile of about 60 percent top management, an average income of $191,000, an average household net worth of $2.1 million, and an average age of 55. [12]
In 2007, the Journal launched a worldwide expansion of its website to include major foreign-language editions. The paper had also shown an interest in buying the rival Financial Times . [13]

Design changes
The nameplate is unique in having a period at the end. [14]
On September 5, 2006, the Journal included advertising on its front page for the first time. This followed the introduction of front-page advertising on the European and Asian editions in late 2005. [15]
After presenting nearly identical front-page layouts for half a century—always six columns, with the day's top stories in the first and sixth columns, "What's News" digest in the second and third, the "A-hed" feature story in the fourth (with 'hed' being jargon for headline ) and themed weekly reports in the fifth column [16] – the paper in 2007 decreased its broadsheet width from 15 to 12 inches while keeping the length at 22 3 ⁄ 4 inches, to save newsprint costs. News design consultant Mario Garcia collaborated on the changes. Dow Jones said it would save US$18 million a year in newsprint costs across all The Wall Street Journal papers. [17] This move eliminated one column of print, pushing the "A-hed" out of its traditional location (though the paper now usually includes a quirky feature story on the right side of the front page, sandwiched among the lead stories).
The paper still uses ink dot drawings called hedcuts , introduced in 1979 and originally created by Kevin Sprouls , [18] in addition to photographs, a method of illustration considered a consistent visual signature of the paper. The Journal still heavily employs the use of caricatures , notably those of Ken Fallin , such as when Peggy Noonan memorialized then-recently deceased newsman Tim Russert . [19] [20] The use of color photographs and graphics has become increasingly common in recent years with the addition of more "lifestyle" sections.
The daily was awarded by the Society for News Design World's Best Designed Newspaper award for 1994 and 1997. [21]

News Corporation and News Corp
On May 2, 2007, News Corporation made an unsolicited takeover bid for Dow Jones, offering US$60 a share for stock that had been selling for US$33 a share. The Bancroft family , which controlled more than 60% of the voting stock, at first rejected the offer, but later reconsidered its position. [22]
Three months later, on August 1, 2007, News Corporation and Dow Jones entered into a definitive merger agreement. [23] The US$5 billion sale added The Wall Street Journal to Rupert Murdoch 's news empire, which already included Fox News Channel , financial network unit and London's The Times , and locally within New York, the New York Post , along with Fox flagship station WNYW (Channel 5) and MyNetworkTV flagship WWOR (Channel 9). [24]
On December 13, 2007, shareholders representing more than 60 percent of Dow Jones's voting stock approved the company's acquisition by News Corporation. [25]
In an editorial page column, publisher L. Gordon Crovitz said the Bancrofts and News Corporation had agreed that the Journal ' s news and opinion sections would preserve their editorial independence from their new corporate parent: [26]
A special committee was established to oversee the paper's editorial integrity. When the managing editor Marcus Brauchli resigned on April 22, 2008, the committee said that News Corporation had violated its agreement by not notifying the committee earlier. However, Brauchli said he believed that new owners should appoint their own editor. [27]
A 2007 Journal article quoted charges that Murdoch had made and broken similar promises in the past. One large shareholder commented that Murdoch has long "expressed his personal, political and business biases through his newspapers and television stations". Former Times assistant editor Fred Emery remembers an incident when "Mr. Murdoch called him into his office in March 1982 and said he was considering firing Times editor Harold Evans . Mr. Emery says he reminded Mr. Murdoch of his promise that editors couldn't be fired without the independent directors' approval. 'God, you don't take all that seriously, do you?' Mr. Murdoch answered, according to Mr. Emery." Murdoch eventually forced out Evans. [28]
In 2011, The Guardian found evidence that the Journal had artificially inflated its European sales numbers, by paying Executive Learning Partnership for purchasing 16% of European sales. These inflated sales numbers then enabled the Journal to charge similarly inflated advertising rates, as the advertisers would think that they reached more readers than they actually did. In addition, the Journal agreed to run "articles" featuring Executive Learning Partnership, presented as news, but effectively advertising. [29] The case came to light after a Belgian Wall Street Journal employee, Gert Van Mol , informed Dow Jones CEO Les Hinton about the questionable practice. [30] As a result, the then Wall Street Journal Europe CEO and Publisher Andrew Langhoff was fired after it was found out he personally pressured journalists into covering one of the newspaper's business partners involved in the issue. [31] [32] Since September 2011 all the online articles that resulted from the ethical wrongdoing carry a Wall Street Journal disclaimer informing the readers about the circumstances in which they were created.
The Journal , along with its parent Dow Jones & Company, was among the businesses News Corporation spun off in 2013 as the new News Corp . In November 2016, in an effort to cut costs, the Journal 's editor-in-chief, Gerard Baker, announced that layoffs and consolidation to its sections would take place. In the memo, the new format for the newspaper will have a "Business & Finance" section that will combine its current "Business & Tech" and "Money & Investing" sections. It will also include a new "Life & Arts" section that will combine its current "Personal Journal" and "Arena" sections. In addition, the current "Greater New York" coverage will be reduced and will move into the main section of paper. [33]

Features
Since 1980, the Journal has been published in multiple sections. At one time, The Journal 's page count averaged as much as 96 pages an issue, [ citation needed ] but with the industry-wide decline in advertising, the Journal in 2009–10 more typically published about 50 to 60 pages per issue. Regularly scheduled sections are:
In addition, several columnists contribute regular features to the Journal opinion page and OpinionJournal.com :

WSJ.
WSJ. is The Wall Street Journal ' s luxury lifestyle magazine. Its coverage spans art, fashion, entertainment, design, food, architecture, travel and more. Kristina O'Neill is Editor in Chief and Anthony Cenname is Publisher.
Launched as a quarterly in 2008, the magazine grew to 12 issues a year for 2014. [35] The magazine is distributed within the U.S. Weekend Edition of The Wall Street Journal newspaper (average paid print circulation is +2.2 million*), the European and Asian editions, and is available on WSJ.com. Each issue is also available throughout the month in The Wall Street Journal' s iPad app.
Penélope Cruz , Carmelo Anthony , Woody Allen , Scarlett Johansson , Emilia Clarke , Daft Punk , and Gisele Bündchen have all been featured on the cover.
In 2012, the magazine launched its signature platform, The Innovator Awards. An extension of the November Innovators issue, the awards ceremony, held in New York City at Museum of Modern Art , honors visionaries across the fields of design, fashion, architecture, humanitarianism, art and technology. The 2013 winners were: Alice Waters (Humanitarianism); Daft Punk (Entertainment); David Adjaye (Architecture); Do Ho Su (Art); Nick D'Aloisio (Technology); Pat McGrath (Fashion); Thomas Woltz (Design).
In 2013, Adweek awarded WSJ. [36] "Hottest Lifestyle Magazine of the Year" for its annual Hot List.

Operations
The Wall Street Journal has a global news staff of more than 2,000 journalists in 85 news bureaus across 51 countries. [37] [38] It has 26 printing plants. [37]

Recent milestones

Editorial page and political stance
The Journal won its first two Pulitzer Prizes for editorial writing in 1947 and 1953. Subsequent Pulitzer Prizes have been awarded for editorial writing to Robert L. Bartley in 1980 and Joseph Rago in 2011; for criticism to Manuela Hoelterhoff in 1983 and Joe Morgenstern in 2005; and for commentary to Vermont Royster in 1984, Paul Gigot in 2000, Dorothy Rabinowitz in 2001, Bret Stephens in 2013, and Peggy Noonan in 2017.
Two summaries published in 1995 by the progressive blog Fairness and Accuracy in Reporting , and in 1996 by the Columbia Journalism Review [40] criticized the Journal 's editorial page for inaccuracy during the 1980s and 1990s.
The Journal describes the history of its editorials:
Its historical position was much the same. As former editor William H. Grimes wrote in 1951:
Every Thanksgiving the editorial page prints two famous articles that have appeared there since 1961. The first is titled The Desolate Wilderness , and describes what the Pilgrims saw when they arrived at the Plymouth Colony . The second is titled And the Fair Land , and describes the bounty of America. It was written by a former editor, Vermont C. Royster , whose Christmas article In Hoc Anno Domini , has appeared every December 25 since 1949.

Economic views
During the Reagan administration , the newspaper's editorial page was particularly influential as the leading voice for supply-side economics . Under the editorship of Robert Bartley , it expounded at length on economic concepts such as the Laffer curve , and how a decrease in certain marginal tax rates and the capital gains tax could allegedly increase overall tax revenue by generating more economic activity.
In the economic argument of exchange rate regimes (one of the most divisive issues among economists), the Journal has a tendency to support fixed exchange rates over floating exchange rates . For example, the Journal was a major supporter of the Chinese yuan 's peg to the dollar, and strongly disagreed with American politicians who criticized the Chinese government about the peg. It opposed China's move to let the yuan gradually float, arguing that the fixed rate benefited both the United States and China.
The Journal 's views compare with those of the British publication The Economist , with its emphasis on free markets [ citation needed ] . However, the Journal demonstrates important distinctions from European business newspapers, most particularly in regard to the relative significance of, and causes of, the American budget deficit . (The Journal generally points to the lack of foreign growth, while business journals in Europe and Asia blame the low savings rate and concordant high borrowing rate in the United States).

Political stance
The Journal 's editorial pages and columns , run separately from the news pages, are highly influential in American conservative circles. As editors of the editorial page, Vermont C. Royster (served 1958–1971) and Robert L. Bartley (served 1972–2000) were especially influential in providing a conservative interpretation of the news on a daily basis. [42] Some former The Wall Street Journal reporters have said that the paper has adopted a more conservative tone since Rupert Murdoch 's purchase. [43]
The editorial board has long argued for a pro-business immigration policy. In a July 3, 1984 editorial, the board wrote: "If Washington still wants to 'do something' about immigration, we propose a five-word constitutional amendment: There shall be open borders ." This stand on immigration reform places the Journal in contrast to most conservative activists, politicians, and media publications for example National Review and The Washington Times , who favor heightened restrictions on immigration. [44]
The Journal 's editorial page has been seen as critical of many aspects of Barack Obama 's presidency. In particular, it has been a prominent critic of the Affordable Care Act legislation passed in 2010 and has featured many opinion columns attacking various aspects of the bill. [45] The Journal 's editorial page has also criticized the Obama administration's energy policies and foreign policy. [46] [47] [48]
The editorial board of The Wall Street Journal tends to reject widely held views on climate change—namely that it poses a major threat to human existence, is largely caused by fossil fuel emissions, and can be prevented through public policy. The Journal has even been seen as a forum for climate change skeptics , [49] [50] publishing articles by scientists skeptical of the consensus position on climate change in its op-ed section, including several essays by Richard Lindzen of MIT . [51] [52] Similarly, the Journal has been accused of refusing to publish opinions of scientists which present the mainstream view on climate change. [53] According to a 2016 analysis, 14% of the guest editorials presented the results of "mainstream climate science," while the majority did not. Also, none of 201 editorials published in the WSJ since 1997 concede that the burning of fossil fuels was causing climate change. [54] A 2015 study found The Wall Street Journal was the newspaper that was least likely to present negative effects of global warming among several newspapers. It was also the most likely to present negative economic framing when discussing climate change mitigation policies, [55] tending to taking the stance that the cost of such policies generally outweighs their benefit.

Bias in news pages
The Journal ' s editors stress the independence and impartiality of their reporters. [26]
In a 2004 study, Tim Groseclose and Jeff Milyo argue the Journal 's news pages have a pro-liberal bias because they more often quote liberal think tanks. They calculated the ideological attitude of news reports in 20 media outlets by counting the frequency they cited particular think tanks and comparing that to the frequency that legislators cited the same think tanks. They found that the news reporting of The Journal was the most liberal (more liberal than NPR or The New York Times ). The study did not factor in editorials. [56] Mark Liberman criticized the model used to calculate bias in the study and argued that the model unequally affected liberals and conservatives and that "..the model starts with a very peculiar assumption about the relationship between political opinion and the choice of authorities to cite." [The authors assume that] "think tank ideology [...] only matters to liberals." [57]
The company's planned and eventual acquisition by News Corp in 2007 led to significant media criticism and discussion [58] about whether the news pages would exhibit a rightward slant under Rupert Murdoch . An August 1 editorial responded to the questions by asserting that Murdoch intended to "maintain the values and integrity of the Journal ." [59]

Notable stories and Pulitzer Prizes
The Journal has won more than 30 Pulitzer Prizes in its history. Staff journalists who led some of the newspaper's best-known coverage teams have later published books that summarized and extended their reporting.

1987: RJR Nabisco buyout
In 1987, a bidding war ensued between several financial firms for tobacco and food giant RJR Nabisco . Bryan Burrough and John Helyar documented the events in more than two dozen Journal articles. Burrough and Helyar later used these articles as the basis of a bestselling book, Barbarians at the Gate: The Fall of RJR Nabisco , which was turned into a film for HBO. [60]

1988: Insider trading
In the 1980s, then Journal reporter James B. Stewart brought national attention to the illegal practice of insider trading . He was awarded the Pulitzer Prize in explanatory journalism in 1988, which he shared with Daniel Hertzberg , [61] who went on to serve as the paper's senior deputy managing editor before resigning in 2009. Stewart expanded on this theme in his book, Den of Thieves .

1997: AIDS treatment
David Sanford, a Page One features editor who was infected with HIV in 1982 in a bathhouse, wrote a front-page personal account of how, with the assistance of improved treatments for HIV, he went from planning his death to planning his retirement. [62] He and six other reporters wrote about the new treatments, political and economic issues, and won the 1997 Pulitzer Prize for National Reporting about AIDS. [63]

2000: Enron
Jonathan Weil , a reporter at the Dallas bureau of The Wall Street Journal , is credited with first breaking the story of financial abuses at Enron in September 2000. [64] Rebecca Smith and John R. Emshwiller reported on the story regularly, [65] and wrote a book, 24 Days .

2001: 9/11
The Journal claims to have sent the first news report, on the Dow Jones wire, of a plane crashing into the World Trade Center on September 11, 2001. [66] Its headquarters, at One World Financial Center , was severely damaged by the collapse of the World Trade Center just across the street. [67] Top editors worried that they might miss publishing the first issue for the first time in the paper's 112-year history. They relocated to a makeshift office at an editor's home, while sending most of the staff to Dow Jones's South Brunswick, N.J. , corporate campus, where the paper had established emergency editorial facilities soon after the 1993 World Trade Center bombing . The paper was on the stands the next day, albeit in scaled-down form. Perhaps the most compelling story in that day's edition was a first-hand account of the Twin Towers' collapse written by then-Foreign Editor (and current Washington bureau chief) John Bussey, [67] who holed up in a ninth-floor Journal office, literally in the shadow of the towers, from where he phoned in live reports to CNBC as the towers burned. He narrowly escaped serious injury when the first tower collapsed, shattering all the windows in the Journal 's offices and filling them with dust and debris. The Journal won a 2002 Pulitzer Prize in Breaking News Reporting for that day's stories. [68]
The Journal subsequently conducted a worldwide investigation of the causes and significance of 9/11, using contacts it had developed while covering business in the Arab world. In Kabul, Afghanistan , a reporter from The Wall Street Journal bought a pair of looted computers that Al Qaeda leaders had used to plan assassinations, chemical and biological attacks, and mundane daily activities. The encrypted files were decrypted and translated. [69] It was during this coverage that terrorists kidnapped and killed Journal reporter Daniel Pearl .

2007: Stock option scandal
In 2007, the paper won the Pulitzer Prize for Public Service , with its iconic Gold Medal, [70] for exposing companies that illegally backdate stock options they awarded executives to increase their value.

2008: Bear Stearns fall
Kate Kelly wrote a three-part series that detailed events that led to the collapse of Bear Stearns .

2010: McDonald's health care
A report [71] published on September 30, 2010 detailing allegations McDonald's had plans to drop health coverage for hourly employees drew criticism from McDonald's as well as the Obama administration. The WSJ reported the plan to drop coverage stemmed from new health care requirements under the Patient Protection and Affordable Care Act . McDonald's called the report "speculative and misleading," stating they had no plans to drop coverage. [72] The WSJ report and subsequent rebuttal received coverage from several other media outlets. [73] [74] [75]

2015: Malaysia Prime Minister Najib Razak and 1MDB
In 2015, A report [76] published by the Journal alleged that up to US$700 million was wired from 1MDB , a Malaysian state investment company, to the personal accounts of Malaysia Prime Minister Najib Razak in AmBank , the fifth largest lender in Malaysia. Razak responded by threatening to sue the New York-based newspaper.
The report prompted a few governmental agencies in Malaysia to conduct an investigation into the allegation.

2015–present: Theranos investigation
In 2015, a report written by the Journal' s John Carreyrou alleged that blood testing company Theranos ' technology was faulty and founder Elizabeth Holmes was misleading investors. [77] [78] [79] According to Vanity Fair , "a damning report published in The Wall Street Journal had alleged that the company was, in effect, a sham—that its vaunted core technology was actually faulty and that Theranos administered almost all of its blood tests using competitors' equipment." [78] The Journal has subsequently published several reports questioning Theranos' and Holmes' credibility. [80] [81]

See also
WebPage index: 00119
The Wikipedia Revolution
The Wikipedia Revolution: How A Bunch of Nobodies Created The World's Greatest Encyclopedia is a 2009 popular history book by new media researcher and writer Andrew Lih . [1] [2] [3] [4]
At the time of its publication it was "the only narrative account" of the online encyclopedia Wikipedia (in English). [5] It covers the period from Wikipedia's founding in early 2000 up to early 2008. Written as a popular history, the text ranges from short biographies of Jimmy Wales , Larry Sanger and Ward Cunningham , to brief accounts of infamous events in Wikipedia's history such as the Essjay controversy and the Seigenthaler incident .
Lih describes the importance of early influences on Wikipedia including Usenet , Hypercard , Slashdot , and MeatballWiki . He also explores the cultural differences found within sister projects such as the German Wikipedia, the Chinese Wikipedia, and the Japanese Wikipedia.
There is a foreword by Wales, and an afterword partially created by volunteers through an online wiki detailing the problems and opportunities of Wikipedia's future. [6]

Publication

See also
WebPage index: 00120
Wikimedia Foundation
The Wikimedia Foundation, Inc. ( WMF ) is an American non-profit and charitable organization headquartered in San Francisco , California . It is mostly known for participating in the Wikimedia movement . It owns the internet domain names of most movement projects and hosts sites like Wikipedia . The foundation was founded in 2003 by Jimmy Wales as a way to fund Wikipedia and its sister projects through non-profit means. [5] [6]
As of 2015 [update] , the foundation employs over 280 people, with annual revenues in excess of US$ 75 million . [7] Christophe Henner is chair of the board . [8] Katherine Maher is the executive director since March 2016.

Goal
The Wikimedia Foundation has stated its goal is to develop and maintain open content , wiki -based projects and to provide the full contents of those projects to the public free of charge . [9] Another main objective of the Wikimedia Foundation is political advocacy . [10]
The Wikimedia Foundation was granted section 501(c)(3) status by the U.S. Internal Revenue Code as a public charity in 2005. [11] Its National Taxonomy of Exempt Entities (NTEE) code is B60 ( Adult , Continuing education ). [12] [13] The foundation's by-laws declare a statement of purpose of collecting and developing educational content and to disseminate it effectively and globally. [14]

History
In 2001, Jimmy Wales , an Internet entrepreneur , and Larry Sanger , an online community organizer and philosophy professor, founded Wikipedia as an Internet encyclopedia to supplement Nupedia . The project was originally funded by Bomis , Wales' for-profit business. As Wikipedia's popularity skyrocketed, revenues to fund the project stalled. [5] Since Wikipedia was depleting Bomis' resources, Wales and Sanger thought of a charity model to fund the project. [5] The Wikimedia Foundation was incorporated in Florida on June 20, 2003. [6] [15] It applied to the United States Patent and Trademark Office to trademark Wikipedia on September 17, 2004. The mark was granted registration status on January 10, 2006. Trademark protection was accorded by Japan on December 16, 2004, and, in the European Union , on January 20, 2005. There were plans to license the use of the Wikipedia trademark for some products, such as books or DVDs. [16]
In April 2005, the U.S. Internal Revenue Service approved the foundation as an educational foundation in the category " Adult , Continuing education ", meaning all contributions to the foundation are tax-deductible for U.S. federal income tax purposes.
On December 11, 2006, the Foundation's board noted that the corporation could not become the membership organization initially planned but never implemented due to an inability to meet the registration requirements of Florida statutory law. Accordingly, [ according to whom? ] the by-laws were amended to remove all reference to membership rights and activities. The decision to change the bylaws was passed by the board unanimously. [17]
On September 25, 2007, the foundation's board gave notice that the operations would be moving to the San Francisco Bay Area . Major considerations cited for choosing San Francisco were proximity to like-minded organizations and potential partners, a better talent pool, as well as cheaper and more convenient international travel than is available from St. Petersburg, Florida . [18] [19] [20]
Lila Tretikov was appointed executive director of the Wikimedia Foundation in May 2014. She resigned in March 2016. Former chief communications officer Katherine Maher was appointed the interim executive director, a position made permanent in June 2016.

Projects and initiatives

 Wikimedia projects
In addition to Wikipedia, the foundation operates other wikis that follow the free content model with their main goal being the dissemination of knowledge. These include:
Several additional projects exist to provide infrastructure or coordination of the free knowledge projects. For instance, a wiki helps coordinate work on MediaWiki software and Outreach gives guidelines for best practices on encouraging the use of Wikimedia sites.

Movement affiliates
Wikimedia movement affiliates are independent, but formally recognized, groups of people intended to work together to support and contribute to the Wikimedia movement. The Wikimedia Foundation's Board of Trustees has approved three active models for movement affiliates: chapters, thematic organizations, and user groups. Movement affiliates are intended to organize and engage in activities to support and contribute to the Wikimedia movement, such as regional conferences, outreach, edit-a-thons , hackathons , public relations , public policy advocacy, GLAM engagement, and Wikimania . [21] [22] [23]
Recognition of a chapter and thematic organization is approved by the foundation's board. Recommendations on recognition of chapters and thematic organizations are made to the foundation's board by an Affiliations Committee , composed of Wikimedia community volunteers. The Affiliations Committee approves the recognition of individual user groups. While movement affiliates are formally recognized by the Wikimedia Foundation, they are independent of the Wikimedia Foundation, with no legal control of nor responsibility for the Wikimedia projects. [22] [23] [24]
The foundation began recognizing chapters in 2004. [25] In 2010, development on additional models began. In 2012, the foundation approved, finalized, and adopted the thematic organization and user group recognition models. An additional model, movement partners, was also approved but as of 27 October 2015 [update] has not yet been finalized or adopted. [21] [23] [26]

Wikimania
Each year, an international conference called Wikimania brings the people together who are involved in the Wikimedia organizations and projects. The first Wikimania was held in Frankfurt , Germany, in 2005. Nowadays, Wikimania is organized by a committee supported usually by the national chapter, in collaboration with the Wikimedia Foundation. Wikimania has been held in cities such as Buenos Aires , [27] Cambridge , [28] Haifa , [29] Hong Kong , [30] and London . [31] In 2015, Wikimania took place in Mexico City . [32] In 2016, Wikimania was held in Esino Lario , Italy . [33]

Strategic plan
In response to the growing size and popularity of Wikipedia, the Wikimedia Foundation announced a Strategic Plan to improve and sustain the Wikimedia movement. The plan was announced in July 2009, followed by a process of interviews and surveys with people from across the Wikimedia movement, including board of trustees, members of staff and volunteer editors. [34] The ongoing plan was intended to be the basis of a five-year plan to further outreach, improve content quality and quality control, and optimising operational areas such as finance and infrastructure. [35]

Wikipedia Usability Initiative
In December 2008, the Wikimedia Foundation announced a restricted donation grant of US$890,000 from the Stanton Foundation , to improve Wikipedia's accessibility. [36] Later named the Wikipedia Usability Initiative, the grant was used by the Wikimedia Foundation to appoint project-specific staff to the technology department. [37]
A series of surveys were conducted throughout 2009. This began with a qualitative environment survey on MediaWiki extensions, followed by a Qualitative Statistical Survey focusing on volume of edits, number of new users, and related statistics. In March 2009, a usability and experience study was carried out on new and non-editors of the English Wikipedia. The aim was to discover what obstacles participants encountered while editing Wikipedia, ranging from small changes to more complicated syntax such as templates. The study recruited 2500 people for in-person laboratory testing via the Wikipedia website, which was filtered down to ten participants. The results were collated and used by the technology team to improve Wikipedia's usability. [38] The Usability and Experience Study was followed up by the Usability, Experience and Progress Study in September 2009. This study recruited different new and non-editors for in-person trials on a new Wikipedia skin. [39]
The initiative ultimately culminated in a new Wikipedia skin named Vector, constructed based on the results of the usability studies. This was introduced by default in stages, beginning in May 2010. [40]

Public Policy Initiative
In May 2010, the Wikimedia Foundation announced the Public Policy Initiative, following a US$1.2 million donation by the Stanton Foundation. The Initiative was set up to improve articles relating to public policy–related issues. [41] As part of the initiative, Wikipedia collaborated with ten universities to help students and professors create and maintain articles relating to public policy. [42] Volunteer editors of Wikipedia, known as "ambassadors", provided assistance to students and professors. This was either done on campus sites or online. [43]
In April 2017, the Foundation was one of the founding partners in the Initiative for Open Citations . [44]

Technology
The foundation employs technology including hardware and software to run its projects.

Hardware
Wikipedia employed a single server until 2004, when the server setup was expanded into a distributed multitier architecture . [45]
In January 2005, the project ran on 39 dedicated servers in Florida. [ citation needed ] This configuration included a single master database server running MySQL , multiple database servers, 21 web servers running the Apache HTTP Server , and seven Squid cache servers. [ citation needed ]
Wikimedia currently runs on dedicated clusters of Linux servers (mainly Ubuntu ). [46] [47] As of December 2009 [update] , there were 300 in Florida and 44 in Amsterdam . [48] The number of servers needed to run the infrastructure has been mostly stable since then: 520 servers are used in the main cluster (eqiad) as of November 2015. [49]
As of 2015, the system still runs on central master database and application servers, but there are several cache layers with various ever-changing technologies, as well as a multitude of subsystems for DNS resolution, load balancing, metrics, monitoring, other system administration etc. [50]

Softwаrе
The operation of Wikimedia depends on MediaWiki , a custom-made, free and open-source wiki software platform written in PHP and built upon the MySQL database. [51] The software incorporates programming features such as a macro language , variables , a transclusion system for templates , and URL redirection . MediaWiki is licensed under the GNU General Public License and it is used by all Wikimedia projects, as well as many other wiki projects. Originally, Wikipedia ran on UseModWiki written in Perl by Clifford Adams (Phase I), which initially required CamelCase for article hyperlinks; the present double bracket style was incorporated later. Starting in January 2002 (Phase II), Wikipedia began running on a PHP wiki engine with a MySQL database; this software was custom-made for Wikipedia by Magnus Manske . The Phase II software was repeatedly modified to accommodate the exponentially increasing demand. In July 2002 (Phase III), Wikipedia shifted to the third-generation software, MediaWiki, originally written by Lee Daniel Crocker . Several MediaWiki extensions are installed to extend the functionality of MediaWiki software. In April 2005, a Lucene extension [52] [53] was added to MediaWiki's built-in search and Wikipedia switched from MySQL to Lucene for searching. Currently Lucene Search 2.1, [54] which is written in Java and based on Lucene library 2.3, [55] is used. Wikimedia Foundation also uses CiviCRM [56] and WordPress . [57]
The Foundation published official Wikipedia mobile apps for Android and iOS devices and in March 2015, the apps were updated to include mobile user friendly features. [58]

Finances

In general
The Wikimedia Foundation relies on public contributions and grants to fund its mission. [59] It is exempt from federal income tax [59] [60] and from state income tax. [59] [61] It is not a private foundation, and contributions to it qualify as tax-deductible charitable contributions. [59]
The continued technical and economic growth of each of the Wikimedia projects is dependent mostly on donations but the Wikimedia Foundation also increases its revenue by alternative means of funding such as grants , sponsorship, services and brand merchandising. The Wikimedia OAI-PMH update feed service, targeted primarily at search engines and similar bulk analysis and republishing, has been a source of revenue for several years, [59] but is no longer open to new customers. [62] DBpedia was given access to this feed free of charge. [63] In July 2014, the Foundation announced it would be accepting Bitcoin donations. [64]
Since the end of fiscal year ended 2004, the Foundation's net assets have grown from US$57,000 [65] to US$53.5 million at the end of fiscal year ended June 30, 2014. [66] Under the leadership of Sue Gardner, who joined the Wikimedia Foundation in 2007, the Foundation's staff levels, number of donors and revenue have seen very significant growth. [67]
In 2007, Charity Navigator gave Wikimedia an overall rating of three out of four possible stars [68] Charity Navigator gave three out of four possible stars in overall rating for fiscal years 2008 and 2009 which improved to four-stars in 2010. [69] As of December 2016, the current overall rating was four stars. [70]

Grants
In March 2008, the Foundation announced a large donation, at the time its largest donation yet: a three-year, US$3 million grant from the Alfred P. Sloan Foundation . [71]
In 2009, the Foundation received four grants – the first grant was a US$890,000 Stanton Foundation grant which was aimed to help study and simplify user interface for first-time authors of Wikipedia. [72] The second was a US$300,000 Ford Foundation Grant, given in July 2009, for Wikimedia Commons that aimed to improve the interfaces and workflows for multimedia uploading on Wikimedia websites. [73] In August 2009, the Foundation received a US$500,000 grant from The William and Flora Hewlett Foundation . [74] Lastly, in August 2009, the Omidyar Network issued a potential [ clarification needed ] US$2 million in "grant" funding to Wikimedia. [75]
In 2010, the Google corporation donated US$2 million to the Foundation. [76] The Stanton Foundation granted $1.2 million to fund the Public Policy Initiative, a pilot program for what would later become the Wikipedia Education Program (and the spinoff Wiki Education Foundation ). [77] [78] [79] Also in 2010, the William and Flora Hewlett Foundation pledged a US$800,000 grant and all was funded during 2011. [ citation needed ]
In March 2011, the Alfred P. Sloan Foundation authorized another US$3 million grant to continue to develop and maintain the Foundation's mission. The grant was to be funded over three years with the first US$1 million funded in July 2011 and the remaining US$2 million was scheduled to be funded in August 2012 and 2013. In August 2011, the Stanton Foundation pledged to fund a US$3.6 million grant of which US$1.8 million was funded and the remaining was due to be funded in September 2012. As of 2011, this was the largest grant received by the Wikimedia Foundation to-date. [80] In November 2011, the Foundation received a US$500,000 donation from Google co-founder Sergey Brin and his wife. [81] [82]
In 2012, the Foundation was awarded a grant of US$1.25 million from the historians Lisbet Rausing [81] and Peter Baldwin through Charities Aid Foundation , scheduled to be funded in five equal installments. The first installment of US$250,000 was received in April 2012 and the remaining were to be funded in December 2012 through 2015. In 2014, the Foundation received the largest single gift in its history, a $5 million unrestricted donation from an anonymous donor supporting $1 million worth of expenses annually for the next five years. [83]
In 2015, a grant agreement was reached with the John S. and James L. Knight Foundation to build a search engine called the " Knowledge Engine ". [84] [85]

Financial summary

Governance

Board of Trustees
The Board of Trustees has ultimate authority of all the businesses and affairs of the Foundation. It is composed of ten members:
Three permanent entities support the board on its mission and responsibilities: an executive director, who leads and oversees the operational arm of the foundation; an advisory board composed of individuals selected by the board itself that advise the board on different matters; and standing committees to which the board delegates certain matters while retaining ultimate authority. The board has also at times created other orthodox entities [ clarification needed ] to support itself, such as executive secretaries and ad-hoc committees established for specific tasks.
The current board comprises Christophe Henner as chairman and María Sefidari as vice-chairman, together with Alice Wiegand, Nataliia Tymkiv, Kelly Battles , Dariusz Jemielniak as members at-large, and Jimmy Wales as founder's seat (installed as "Community Founder Trustee Position" to the WMF bylaws in August 2008). [95] [96] There are three vacant seats, most recently occupied by Arnnon Geshuri , Denny Vrandečić and Guy Kawasaki .
In a high-profile decision of 2015, James Heilman was removed from the board, [97] [98] with little explanation. [97] In January 2016, Arnnon Geshuri stepped down from the board following a controversy about an agreement he executed when at Google , violating United States antitrust law . The participating companies paid US$415 million in a class action suit on behalf of affected employees. [99] [100]

Advisory board
The Advisory Board, according to the Wikimedia Foundation, is an international network of experts who have agreed to give the foundation meaningful help on a regular basis in many different areas, including law, organizational development, technology, policy, and outreach. [101]

Staff

First appointments
In 2004, the foundation appointed Tim Starling as developer liaison to help improve the MediaWiki software, Daniel Mayer as chief financial officer ( finance , budgeting , and coordination of fund drives), and Erik Möller as content partnership coordinator. In May 2005, the foundation announced seven more official appointments. [102]
In January 2006, the foundation created several committees, including the Communication Committee, in an attempt to further organize activities essentially handled by volunteers at that time. [103] Starling resigned that month to spend more time on his PhD program.

Employees
The foundation's functions were, for the first few years, executed almost entirely by volunteers. In 2005, it had only two employees, Danny Wool, a coordinator, and Brion Vibber, a software manager.
As of October 4, 2006 [update] , the foundation had five paid employees: [104] two programmers, an administrative assistant, a coordinator handling fundraising and grants, and an interim executive director , [105] Brad Patrick, previously the foundation's general counsel . Patrick ceased his activity as interim director in January 2007, and then resigned from his position as legal counsel, effective April 1, 2007. He was replaced by Mike Godwin , who served as general counsel and legal coordinator from July 2007 [106] until 2010.
In January 2007, Carolyn Doran was named chief operating officer and Sandy Ordonez joined as head of communications . [107] Doran began working as a part-time bookkeeper in 2006 after being sent by a temporary agency . Doran, found to have had a long criminal record, [108] left the foundation in July 2007, and Sue Gardner was hired as consultant and special advisor (later CEO). Doran's departure from the organization was cited by Florence Devouard as one of the reasons the foundation took about seven months to release its fiscal 2007 financial audit. [109]
Danny Wool, officially the grant coordinator but also largely involved in fundraising and business development, resigned in March 2007. He accused Wales of misusing the foundation's funds for recreational purposes, and said that Wales had his Wikimedia credit card taken away in part because of his spending habits, a claim Wales denied. [110] In February 2007, the foundation added a new position, chapters coordinator, and hired Delphine Ménard, [111] who had been occupying the position as a volunteer since August 2005. Cary Bass was hired in March 2007 in the position of volunteer coordinator. Oleta McHenry was brought in as accountant in May 2007, through a temporary placement agency and made the official full-time accountant in August 2007. In January 2008, the foundation appointed Veronique Kessler as the new chief financial and operating officer, Kul Wadhwa as head of business development, and Jay Walsh as head of communications.
By early 2015, the foundation had well over 200 employees.

Disputes and lawsuits
Many disputes have resulted in litigation [112] [113] [114] [115] while others have not. [116] Attorney Matt Zimmerman stated, "Without strong liability protection, it would be difficult for Wikipedia to continue to provide a platform for user-created encyclopedia content." [117]
In December 2011, the Foundation hired Washington, DC lobbyist Dow Lohnes Government Strategies LLC to lobby the United States Congress with regard to "Civil Rights/Civil Liberties" and "Copyright/Patent/Trademark." [118] At the time of the hire the Foundation was concerned specifically about a bill known as the Stop Online Piracy Act . [119]
In October 2013, a German Court ruled that the Wikimedia Foundation can be held liable for content added to Wikipedia – however, this applies only when there has been a specific complaint; otherwise, the Wikimedia Foundation does not check any of the content published on Wikipedia and has no duty to do so. [120]
In June 2014, a copyright infringement lawsuit was filed by Bildkonst Upphovsrätt i Sverige against Wikimedia Sweden. [121]
On June 20, 2014, a defamation lawsuit (Law Division civil case No. L-1400-14) involving Wikipedia editors was filed with the Mercer County Superior Court in New Jersey seeking, inter alia, compensatory and punitive damages. [122] [123]
In a March 10, 2015, op-ed for The New York Times , Wales and Tretikov announced the Foundation was filing a lawsuit against the National Security Agency , calling into question its practice of mass surveillance , which they argued infringed the constitutional rights of the Foundation's readers, editors and staff. [124] [125] [126] On October 23, 2015, the United States District Court for the District of Maryland dismissed the suit Wikimedia Foundation v. NSA on grounds of standing . US District Judge T. S. Ellis III ruled that the plaintiffs could not plausibly prove they were subject to upstream surveillance , and that their argument is riddled with assumptions, speculations and mathematical gymnastics. [127] [128] The plaintiffs filed an appeal with the United States Court of Appeals for the Fourth Circuit on February 17, 2016. [129]
In February 2016, Lila Tretikov announced her resignation as executive director, as a result of the WMF's controversial Knowledge Engine project and disagreements with the staff. [130] [131]
WebPage index: 00121
Christopher Caldwell
Christopher Caldwell (born 1962) is an American journalist and senior editor at The Weekly Standard , as well as a regular contributor to the Financial Times and Slate . His writing also frequently appears in The Wall Street Journal , The New York Times , where he is a contributing editor to the paper's magazine, and The Washington Post . He was also a regular contributor to The Atlantic Monthly and The New York Press and the assistant managing editor of The American Spectator .
Caldwell was born in Lynn, Massachusetts, and is a graduate of Harvard College , where he studied English literature. His wife Zelda is the daughter of journalist Robert Novak . [1] He has five children.
Caldwell's 2009 book Reflections on the Revolution In Europe , which deals with increased Muslim immigration to Europe, received mixed reactions. The Economist newspaper called it "an important book as well as a provocative one: the best statement to date of the pessimist’s position on Islamic immigration in Europe." [2] The Marxist historian Perry Anderson , though critical of his arguments, nonetheless called it "the most striking single book to have appeared, in any language, on immigration in Western Europe". [3] . Others were more blunt, accusing Caldwell of stoking what The Guardian referred to as a " culture of fear ". [4] [5] [6] Caldwell insists that he is "instinctively pro-immigration" and conscious of the media tendency to "sensationalise stories against Muslims". [7]

Books
WebPage index: 00122
Andrew Orlowski
Andrew Orlowski (born 1966) is a British columnist, an investigative journalist and the executive editor of the IT news and opinion website The Register . [1] [2]

Journalism career
In his youth, Orlowski had been involved in a school magazine called Within These Walls , and a fanzine named Paradise Demise . [3] Moving from Northallerton , Yorkshire, to Manchester in 1984, he studied at University of Manchester and then took a course in computer programming . [3] He worked as a programmer in Altrincham in the early 1990s, and later said that he "found that a lot less creative than I'd expected, and this being my first proper job I soon got disillusioned." [3]
Orlowski wrote reviews for Manchester's City Life magazine from 1988, and in 1992 started an alternative newspaper called Badpress in Manchester . [3] In 1994 he became computer correspondent at Private Eye magazine. [3] [4] In the late 1990s, he wrote for PC Pro [5] and was news editor at IT Week . [6] Today, Orlowski is a columnist and the executive editor of IT news and opinion website The Register ; he was based in San Francisco for five years in the early 2000s, reporting for The Register , but returned to England in 2006. [1] [7]

"Googlewashing"
In 2003, Orlowski coined the term googlewashing to describe the potential for accidental or intentional censorship of concepts through the way search engines like Google Search operate. [8] An article in The New York Times [9] commenting on worldwide anti-war demonstrations had stated that "there may still be two superpowers on the planet: the United States and world public opinion", and the term "the Second Superpower " suddenly acquired widespread currency. [8] However, within a few weeks, most of the top search engine results for the term had come to be about something else, because a prominent blogger had used the same term in what Orlowski described as a "plea for net users to organize themselves as a 'superpower'." [8] [10] The blogger's piece was so well linked and so widely commented upon online that the first few pages of Google hits in a search for "the second superpower" all were about his new meaning, with the original anti-war meaning relegated to "other links not shown because they are deemed to be irrelevant." [8] Even the term googlewashing itself almost came to be "googlewashed" in a similar manner, with Orlowski's original definition temporarily disappearing from the top Google search results for the term. [8] [11] [12]

Writings on techno-utopianism
Orlowski is a frequent writer on techno-utopianism . [13] Concerning the political influence of Google , Orlowski has said, "The web is a secular religion at the moment and politicians go to pray at events like the Google Zeitgeist conference. Any politician who wants to brand himself as a forward-looking person will get himself photographed with the Google boys. [...] It's the big regulatory issue of the next 10 years: how politicians deal with Google. If the web is as important as the politicians say, it seems odd that one company sets the price and defines the terms of business." [14]
Commenting on the vision of the technological singularity , a future time when people and machines would combine to form a new superintelligence, and at least a part of humanity might overcome biological limitations like death and disease, he has stated that "The Singularity is not the great vision for society that Lenin had or Milton Friedman might have. It is rich people building a lifeboat and getting off the ship." [13]
In December 2004, Orlowski was invited to a discussion panel on techno-utopianism at Harvard Law School 's Berkman Center for Internet and Society . [15] He was Assistant Producer of Adam Curtis ' 2011 BBC TV series on techno-utopianism, All Watched Over By Machines of Loving Grace . [16]

English Wikipedia criticism
Orlowski takes a critical view of English Wikipedia , noting in 2005, "Readability, which wasn't great to begin with, has plummeted. Formerly coherent and reasonably accurate articles in the technical section have gotten worse as they've gotten longer." [17] [18] In a 2005 BBC article, Bill Thompson said Orlowski was "scathing in his dismissal of the site as a cult-like organisation where faith triumphs rationality, and even suggests we look at English Wikipedia as 'a massively scalable, online role-playing game' where 'players can assume fictional online identities and many "editors" do just that'." [19]
WebPage index: 00123
Coordinated Universal Time
Coordinated Universal Time ( French : Temps universel coordonné ), abbreviated to UTC , is the primary time standard by which the world regulates clocks and time. It is within about 1 second of mean solar time at 0° longitude; [1] it does not observe daylight saving time . It is one of several closely related successors to Greenwich Mean Time (GMT). For most purposes, UTC is considered interchangeable with GMT, but GMT is no longer precisely defined by the scientific community.
The first Coordinated Universal Time was informally adopted on 1 January 1960. [2]
The system was adjusted several times, including a brief period where time coordination radio signals broadcast both UTC and "Stepped Atomic Time (SAT)" until a new UTC was adopted in 1970 and implemented in 1972. This change also adopted leap seconds to simplify future adjustments. This CCIR Recommendation 460 "stated that (a) carrier frequencies and time intervals should be maintained constant and should correspond to the definition of the SI second; (b) step adjustments, when necessary, should be exactly 1 s to maintain approximate agreement with Universal Time (UT); and (c) standard signals should contain information on the difference between UTC and UT." [2]
A number of proposals have been made to replace UTC with a new system that would eliminate leap seconds, but no consensus has yet been reached.
The current version of UTC is defined by International Telecommunications Union Recommendation (ITU-R TF.460-6), Standard-frequency and time-signal emissions [3] and is based on International Atomic Time (TAI) with leap seconds added at irregular intervals to compensate for the slowing of Earth's rotation . [4] Leap seconds are inserted as necessary to keep UTC within 0.9 seconds of universal time, UT1 . [5] See the " Current number of leap seconds " section for the number of leap seconds inserted to date.

Etymology
The official abbreviation for Coordinated Universal Time is UTC . This abbreviation arose from a desire by the International Telecommunication Union and the International Astronomical Union to use the same abbreviation in all languages. English speakers originally proposed CUT (for "coordinated universal time"), while French speakers proposed TUC (for " temps universel coordonné "). The compromise that emerged was UTC , [6] which conforms to the pattern for the abbreviations of the variants of Universal Time (UT0, UT1, UT2, UT1R, etc.). [7]

Uses
Time zones around the world are expressed using positive or negative offsets from UTC , as in the list of time zones by UTC offset .
The westernmost time zone uses UTC−12 , being twelve hours behind UTC; the easternmost time zone, theoretically, uses UTC+12 , being twelve hours ahead of UTC. In 1995, the island nation of Kiribati moved those of its atolls in the Line Islands from UTC-10 to UTC+14 so that Kiribati would all be on the same day.
UTC is used in many internet and World Wide Web standards. The Network Time Protocol , designed to synchronise the clocks of computers over the internet, encodes times using the UTC system. [8] Computer servers, online services and other entities that rely on having a universally accepted time use UTC as it is more specific than GMT. If only limited precision is needed, clients can obtain the current UTC from a number of official internet UTC servers. For sub-microsecond precision, clients can obtain the time from satellite signals.
UTC is also the time standard used in aviation , [9] e.g., for flight plans and air traffic control clearances. Weather forecasts and maps all use UTC to avoid confusion about time zones and daylight saving time. The International Space Station also uses UTC as a time standard.
Amateur radio operators often schedule their radio contacts in UTC, because transmissions on some frequencies can be picked up by many time zones. [10]
UTC is also used in digital tachographs used on large goods vehicles (LGV) under EU and AETR rules.

Mechanism
UTC divides time into days, hours, minutes and seconds. Days are conventionally identified using the Gregorian calendar , but Julian day numbers can also be used. Each day contains 24 hours and each hour contains 60 minutes. The number of seconds in a minute is usually 60, but with an occasional leap second, it may be 61 or 59 instead. [11] Thus, in the UTC time scale, the second and all smaller time units (millisecond, microsecond, etc.) are of constant duration, but the minute and all larger time units (hour, day, week, etc.) are of variable duration. Decisions to introduce a leap second are announced at least six months in advance in "Bulletin C" produced by the International Earth Rotation and Reference Systems Service . [12] [13] The leap seconds cannot be predicted far in advance due to the unpredictable rate of rotation of the Earth. [14]
Nearly all UTC days contain exactly 86,400 SI seconds with exactly 60 seconds in each minute. However, because the mean solar day is slightly longer than 86,400 SI seconds, occasionally the last minute of a UTC day is adjusted to have 61 seconds. The extra second is called a leap second. It accounts for the grand total of the extra length (about 2 milliseconds each) of all the mean solar days since the previous leap second. The last minute of a UTC day is permitted to contain 59 seconds to cover the remote possibility of the Earth rotating faster, but that has not yet been necessary. The irregular day lengths mean that fractional Julian days do not work properly with UTC.
Since 1972, UTC is calculated by subtracting the accumulated leap seconds from International Atomic Time (TAI), which is a coordinate time scale tracking notional proper time on the rotating surface of the Earth (the geoid ). In order to maintain a close approximation to UT1 (equivalent to GMT ), UTC occasionally has discontinuities where it changes from one linear function of TAI to another. These discontinuities take the form of leap seconds implemented by a UTC day of irregular length. Discontinuities in UTC have occurred only at the end of June or December, although there is provision for them to happen at the end of March and September as well as a second preference. [15] [16] The International Earth Rotation and Reference Systems Service (IERS) tracks and publishes the difference between UTC and Universal Time, DUT1 = UT1 − UTC, and introduces discontinuities into UTC to keep DUT1 in the interval (−0.9 s, +0.9 s).
As with TAI, UTC is only known with the highest precision in retrospect. Users who require an approximation in real time must obtain it from a time laboratory, which disseminates an approximation using techniques such as GPS or radio time signals . Such approximations are designated UTC( k ), where k is an abbreviation for the time laboratory. [17] The time of events may be provisionally recorded against one of these approximations; later corrections may be applied using the International Bureau of Weights and Measures (BIPM) monthly publication of tables of differences between canonical TAI/UTC and TAI( k )/UTC( k ) as estimated in real time by participating laboratories. [18] (See the article on International Atomic Time for details.)
Because of time dilation , a standard clock not on the geoid, or in rapid motion, will not maintain synchronicity with UTC. Therefore, telemetry from clocks with a known relation to the geoid is used to provide UTC when required, on locations such as those of spacecraft.
It is not possible to compute the exact time interval elapsed between two UTC timestamps without consulting a table that describes how many leap seconds occurred during that interval. By extension, it is not possible to compute the duration of a time interval that ends in the future and may encompass an unknown number of leap seconds (for example, the number of TAI seconds between "now" and 2099-12-31 23:59:59). Therefore, many scientific applications that require precise measurement of long (multi-year) intervals use TAI instead. TAI is also commonly used by systems that cannot handle leap seconds. GPS time always remains exactly 19 seconds behind TAI (neither system is affected by the leap seconds introduced in UTC).
For most common and legal-trade purposes, the fractional second difference between UTC and UT ( GMT ) is inconsequentially small. Greenwich Mean Time is the legal standard in Britain during the winter, and this notation is familiar to and used by the population. [19]

Time zones
Time zones are usually defined as differing from UTC by an integer number of hours, [20] although the laws of each jurisdiction would have to be consulted if sub-second accuracy was required. Several jurisdictions have established time zones that differ by an integer number of half-hours or quarter-hours from UT1 or UTC.
Current civil time in a particular time zone can be determined by adding or subtracting the number of hours and minutes specified by the UTC offset , which ranges from UTC−12:00 in the west to UTC+14:00 in the east (see List of UTC time offsets ).
The time zone using UTC is sometimes denoted UTC±00:00 or by the letter Z —a reference to the equivalent nautical time zone (GMT), which has been denoted by a Z since about 1950. Time zones were identified by successive letters of the alphabet and the Greenwich time zone was marked by a Z as it was the point of origin. The letter also refers to the "zone description" of zero hours, which has been used since 1920 (see time zone history ). Since the NATO phonetic alphabet word for Z is "Zulu", UTC is sometimes known as "Zulu time". This is especially true in aviation, where "Zulu" is the universal standard. [21] This ensures all pilots regardless of location are using the same 24-hour clock , thus avoiding confusion when flying between time zones. [22] See the list of military time zones for letters used in addition to Z in qualifying time zones other than Greenwich.
On electronic devices that only allow the current time zone to be configured using maps or city names, UTC can be selected indirectly by selecting Reykjavík , Iceland , which is always on UTC and does not use daylight saving time. [23]

Daylight saving time
UTC does not change with a change of seasons, but local time or civil time may change if a time zone jurisdiction observes daylight saving time (summer time). For example, local time on the east coast of the United States is five hours behind UTC during winter, but four hours behind while daylight saving is observed there. [24]

History
At the 1884 International Meridian Conference held in Washington, D.C., the local mean solar time at the Royal Observatory, Greenwich in England was chosen to define the Universal day, counted from 0 hours at mean midnight. This agreed with civil Greenwich Mean Time (GMT), used on the island of Great Britain since 1847. In contrast, astronomical GMT began at mean noon, 12 hours after mean midnight of the same date until 1 January 1925, whereas nautical GMT began at mean noon, 12 hours before mean midnight of the same date, at least until 1805 in the Royal Navy , but persisted much later elsewhere because it was mentioned at the 1884 conference. In 1884, the Greenwich Meridian was used for two-thirds of all charts and maps as their Prime Meridian . [25] In 1928, the term Universal Time (UT) was introduced by the International Astronomical Union to refer to GMT, with the day starting at midnight. [26] Until the 1950s, broadcast time signals were based on UT, and hence on the rotation of the Earth.
In 1955, the caesium atomic clock was invented. This provided a form of timekeeping that was both more stable and more convenient than astronomical observations. In 1956, the U.S. National Bureau of Standards and U.S. Naval Observatory started to develop atomic frequency time scales; by 1959, these time scales were used in generating the WWV time signals, named for the shortwave radio station that broadcasts them. In 1960, the U.S. Naval Observatory, the Royal Greenwich Observatory, and the UK National Physical Laboratory coordinated their radio broadcasts so time steps and frequency changes were coordinated, and the resulting time scale was informally referred to as "Coordinated Universal Time". [27]
In a controversial decision, the frequency of the signals was initially set to match the rate of UT, but then kept at the same frequency by the use of atomic clocks and deliberately allowed to drift away from UT. When the divergence grew significantly, the signal was phase shifted (stepped) by 20 ms to bring it back into agreement with UT. Twenty-nine such steps were used before 1960. [28]
In 1958, data was published linking the frequency for the caesium transition , newly established, with the ephemeris second. The ephemeris second is the duration of time that, when used as the independent variable in the laws of motion that govern the movement of the planets and moons in the solar system, cause the laws of motion to accurately predict the observed positions of solar system bodies. Within the limits of observing accuracy, ephemeris seconds are of constant length, as are atomic seconds. This publication allowed a value to be chosen for the length of the atomic second that would work properly with the celestial laws of motion. [29]
In 1961, the Bureau International de l'Heure began coordinating the UTC process internationally (but the name Coordinated Universal Time was not adopted by the International Astronomical Union until 1967). [30] [31] Time steps occurred every few months thereafter, and frequency changes at the end of each year. The jumps increased in size to 100 ms. This UTC was intended to permit a very close approximation to UT2. [27]
In 1967, the SI second was redefined in terms of the frequency supplied by a caesium atomic clock. The length of second so defined was practically equal to the second of ephemeris time. [32] This was the frequency that had been provisionally used in TAI since 1958. It was soon recognised that having two types of second with different lengths, namely the UTC second and the SI second used in TAI, was a bad idea. It was thought that it would be better for time signals to maintain a consistent frequency, and that that frequency should match the SI second. Thus it would be necessary to rely on time steps alone to maintain the approximation of UT. This was tried experimentally in a service known as "Stepped Atomic Time" (SAT), which ticked at the same rate as TAI and used jumps of 200 ms to stay synchronised with UT2. [33]
There was also dissatisfaction with the frequent jumps in UTC (and SAT). In 1968, Louis Essen , the inventor of the caesium atomic clock, and G. M. R. Winkler both independently proposed that steps should be of 1 s only. [34] This system was eventually approved, along with the idea of maintaining the UTC second equal to the TAI second. At the end of 1971, there was a final irregular jump of exactly 0.107758 TAI seconds, so that 1 January 1972 00:00:00 UTC was 1 January 1972 00:00:10 TAI exactly, making the difference between UTC and TAI an integer number of seconds. At the same time, the tick rate of UTC was changed to exactly match TAI. UTC also started to track UT1 rather than UT2. Some time signals started to broadcast the DUT1 correction (UT1 − UTC) for applications requiring a closer approximation of UT1 than UTC now provided. [35] [36]

Current number of leap seconds
The first leap second occurred on 30 June 1972. Since then, leap seconds have occurred on average about once every 19 months, always on 30 June or 31 December. As of January 2017, there have been 27 leap seconds in total, all positive, putting UTC 37 seconds behind TAI. [37]

Rationale
Earth's rotational speed is very slowly decreasing because of tidal deceleration ; this increases the length of the mean solar day . The length of the SI second was calibrated on the basis of the second of ephemeris time [29] [32] and can now be seen to have a relationship with the mean solar day observed between 1750 and 1892, analysed by Simon Newcomb . As a result, the SI second is close to 1/86400 of a mean solar day in the mid‑19th century. [38] In earlier centuries, the mean solar day was shorter than 86,400 SI seconds, and in more recent centuries it is longer than 86,400 seconds. Near the end of the 20th century, the length of the mean solar day (also known simply as "length of day" or "LOD") was approximately 86,400.0013 s. [39] For this reason, UT is now "slower" than TAI by the difference (or "excess" LOD) of 1.3 ms/day.
The excess of the LOD over the nominal 86,400 s accumulates over time, causing the UTC day, initially synchronised with the mean sun, to become desynchronised and run ahead of it. Near the end of the 20th century, with the LOD at 1.3 ms above the nominal value, UTC ran faster than UT by 1.3 ms per day, getting a second ahead roughly every 800 days. Thus, leap seconds were inserted at approximately this interval, retarding UTC to keep it synchronised in the long term. [40] The actual rotational period varies on unpredictable factors such as tectonic motion and has to be observed, rather than computed.
Just as adding a leap day every four years does not mean the year is getting longer by one day every four years, the insertion of a leap second every 800 days does not indicate that the mean solar day is getting longer by a second every 800 days. It will take about 50,000 years for a mean solar day to lengthen by one second (at a rate of 2 ms/cy, where cy means century). This rate fluctuates within the range of 1.7–2.3 ms/cy. While the rate due to tidal friction alone is about 2.3 ms/cy, the uplift of Canada and Scandinavia by several metres since the last Ice Age has temporarily reduced this to 1.7 ms/cy over the last 2,700 years. [41] The correct reason for leap seconds, then, is not the current difference between actual and nominal LOD, but rather the accumulation of this difference over a period of time: Near the end of the 20th century, this difference was about 1/800 of a second per day; therefore, after about 800 days, it accumulated to 1 second (and a leap second was then added).
In the graph of DUT1 above, the excess of LOD above the nominal 86,400 s corresponds to the downward slope of the graph between vertical segments. (The slope became shallower in the 2000s (decade), because of a slight acceleration of Earth's crust temporarily shortening the day.) Vertical position on the graph corresponds to the accumulation of this difference over time, and the vertical segments correspond to leap seconds introduced to match this accumulated difference. Leap seconds are timed to keep DUT1 within the vertical range depicted by this graph. The frequency of leap seconds therefore corresponds to the slope of the diagonal graph segments, and thus to the excess LOD.

Future
As the Earth's rotation continues to slow, positive leap seconds will be required more frequently. The long-term rate of change of LOD is approximately +1.7 ms per century. At the end of the 21st century, LOD will be roughly 86,400.004 s, requiring leap seconds every 250 days. Over several centuries, the frequency of leap seconds will become problematic.
Some time in the 22nd century, two leap seconds will be required every year. The current use of only the leap second opportunities in June and December will be insufficient, and the March and September options will have to be used. In the 25th century, four leap seconds will be required every year, so the current quarterly options will be insufficient. Thereafter there will need to be the possibility of leap seconds at the end of any month. In about two thousand years, even that will be insufficient, and there will have to be leap seconds that are not at the end of a month. [42] In a few tens of thousands of years (the timing is uncertain), LOD will exceed 86,401 s, causing UTC to require more than one leap second per day.
In April 2001, Rob Seaman of the National Optical Astronomy Observatory proposed that leap seconds be allowed to be added monthly rather than twice yearly. [43]
There is a proposal to redefine UTC and abolish leap seconds, such that sundials would slowly get further out of sync with civil time. [44] The resulting gradual shift of the sun's movements relative to civil time is analogous to the shift of seasons relative to the yearly calendar that results from the calendar year not precisely matching the tropical year length. This would be a major practical change in civil timekeeping, but would take effect slowly over several centuries. UTC (and TAI) would be more and more ahead of UT; it would coincide with local mean time along a meridian drifting slowly eastward (reaching Paris and beyond). [45] Thus, the time system would lose its fixed connection to the geographic coordinates based on the IERS meridian . The difference between UTC and UT could reach 0.5 hour after the year 2600 and 6.5 hours around 4600. [42]
ITU‑R Study Group 7 and Working Party 7A were unable to reach consensus on whether to advance the proposal to the 2012 Radiocommunications Assembly; the chairman of Study Group 7 elected to advance the question to the 2012 Radiocommunications Assembly (20 January 2012), [46] but consideration of the proposal was postponed by the ITU until the World Radio Conference in 2015, convening on 2 November. [47]
The possibility of suppressing the leap second was considered in November 2015 at the World Radiocommunication Conference (WRC-15), which is the international regulatory body which defines Coordinated Universal Time. [48] No decision to suppress leap seconds was reached; the issue will be studied further and reconsidered in 2023. [49]

See also
WebPage index: 00124
The Journal of American History
The Journal of American History is the official academic journal of the Organization of American Historians . It covers the field of American history and was established in 1914 as the Mississippi Valley Historical Review , the official journal of the Mississippi Valley Historical Association. After the publication of its fiftieth volume, the recognition of a shift in the direction of the membership and its scholarship led to the name change in 1964.
The journal is headquartered in Bloomington, Indiana , where it has close ties to the History Department at Indiana University . It is published quarterly, in March, June, September, and December.

List of editors

Proceedings of the Mississippi Valley Historical Association

Mississippi Valley Historical Review

Journal of American History

Further reading

External links
WebPage index: 00125
The World and Wikipedia
The World and Wikipedia: How We are Editing Reality is a book written by the British linguist Andrew Dalby and published by Siduri Books in 2009. [1]
The author provides a context for the birth and growth of Wikipedia through an examination of the wider encyclopedia tradition. The work and community behaviour of its expert and non-expert contributors are discussed, as are the question of reliability and the problem of vandalism. Dalby covers numerous incidents from English, French and German Wikipedias and closes with an optimistic outlook on the central and responsible role he believes Wikipedia will assume in the media. [2]
The book follows an "anecdotal approach" to argue that "disproportionate emphasis on popular culture [...] does happen but that over time substance is added and entries are extended" and why "we will come to rely on it more and more and that it will come to serve us better than its predecessors." [3] He "claims Roman naturalist, Pliny the Elder , as a proto-Wikipedian", and makes the case "that Wikipedia [...] has become more reliable as more people use it". [4]

See also
WebPage index: 00126
Sheizaf Rafaeli
Sheizaf Rafaeli ( Hebrew : שיזף רפאלי ‎‎), is an Israeli researcher, scholar of computer-mediated communication , computer scientist, and newspaper columnist. He is Professor and Dean at the School of Management (Graduate School of Business Administration) Haifa GSB , University of Haifa Israel and additionally Director of the Center for Internet Research (Formerly known as the Center for the Study of the Information Society) and the Games for Managers Project . In the 1980s and 1990s he served as head of the Information Systems area at the Graduate School of Business in the Hebrew University of Jerusalem .

Biography
He was born in Kibbutz Maagan Michael, Israel, June 7, 1955. He served as an officer in the Israeli military in combat units; he was discharged in 1977. He received his B.A. from the University of Haifa , M.A. from Ohio State University , M.A., and Ph.D., Stanford University . Was educational director of the cadet school of the Hebrew Reali School in Haifa. Rafaeli has written software and books on graphics, electronic spreadsheets and statistical analysis, and a textbook on information systems for the Open University . He is co-editor, (with Fay Sudweeks and Margaret McLaughlin), of Network and NetPlay: Virtual Groups on the Internet published by MIT Press , 1998. He served as co-coordinator of the international ProjectH. He served as founder and co-editor of The Journal of Computer-Mediated Communication , and initiated the SHIL (Citizen's Advice Board) online service. He is a member of several journal editorial boards, including those of JCMC, ITSharenet and IJKL. Rafaeli is a director of NPTech Israel, and of StartUpSeeds . He is also a member of the board at the Wikimedia foundation.
Sheizaf is a member of the Stockholm International Challenge Jury for Information Systems' Projects. Sheizaf has held visiting research and teaching positions at Ohio State University, Michigan State University , IBM , Stanford University, Technion , Israeli College of Management , and the University of Michigan . His work on Interactivity and Virtual Community , published by MIT Press, JCMC, and Oxford University Press is widely cited in the Information, Computer-Mediated Communication, Internet and Communication Research literatures. Rafaeli's research covers issues of the Value of Information, Information Overload, Social Networks and Network Analysis, Information Sharing, and digital life.
As of October 2006, he serves as the chair of the School of Management (Business Administration), at the University of Haifa . Rafaeli is a member of the Scientific Management of the Learning in a Networked Society (LINKS) national Center of Research Excellence (ICORE), where he studies the role of online tools in learning, teaching and education.
He also writes weekly columns for the Calcalist and Globes financial and business daily newspapers in Israel and the YNet news site.
Sheizaf is married to Anat Rafaeli , they have three sons and live in Haifa , Israel .

Visiting Professor Appointments

Awards

Press Coverage

External links
WebPage index: 00127
L. Gordon Crovitz
Louis Gordon Crovitz is an American media executive and advisor to media and technology companies. He is a former publisher of The Wall Street Journal who also served as executive vice-president of Dow Jones and launched the company's Consumer Media Group, which under his leadership integrated the global print, online, digital, TV and other editions of The Wall Street Journal , MarketWatch.com and Barron's across news, advertising, marketing and other functions. He stepped down from those positions in December 2007, when News Corp. completed its acquisition of Dow Jones. He writes a weekly column in The Wall Street Journal, titled "Information Age."
Crovitz is a Phi Beta Kappa graduate of the University of Chicago . [1] He received a law degree as a Rhodes Scholar from Wadham College of Oxford University and later a law degree from Yale Law School . [1]
In 1981, he started working as an editorial writer for The Wall Street Journal . The following year he became the founding editorial page editor for The Wall Street Journal Europe , based in Brussels. In 1986 he was appointed to The Wall Street Journal's editorial board. In 1992 he became the publisher for the Dow Jones 's Far Eastern Economic Review in Hong Kong and in 1996 was named the managing director for Dow Jones Telerate's Asia/Pacific region as well as chairman of Dow Jones in Asia. In 1997-98 he was named vice president of planning and development for Dow Jones. [2]
Since leaving Dow Jones, he has co-founded and sold a start-up technology company and has become a director and advisor to several companies, including technology-based media companies. He is a co-founder of Journalism Online, whose Press+ service enables news publishers to generate subscription revenues for their content on web sites and through tablets, e-readers and mobile devices. [3] Journalism Online, founded in 2009, was sold to RR Donnelley in 2011 for a reported $45 million. [4] Google had launched a product in 2011 to compete with Press+, called Google One Pass, but shut the service down in April, 2012, with Press+ agreeing to grandfather its former customers. [5]
While at Dow Jones, he led the redesign of The Wall Street Journal in January 2007, repositioning the print edition to focus on "what the news means," with the web edition addressing "what's happening right now," with the aim of rethinking what a newspaper should be in the Digital Age. He turned around the financial performance of the Journal to become strongly profitable after earlier losing money. He also led the creation of the online news service Factiva , which he chaired for several years, and initiated the acquisition of publicly traded MarketWatch as well as specialist services Private Equity Analyst, VentureOne and VentureWire, London-based news franchise eFinancial News and Frankfurt-based newswire VWD. He oversaw the growth of The Wall Street Journal Online to the world's largest paid subscription news web site, with over one million paying subscribers at the end of 2007. Earlier in his career at Dow Jones, he served as the corporate vice president for planning and strategy; in 1998, he helped sell the Telerate division and helped craft a three-year plan for the company focused on growing Internet revenues. He was editor and publisher of the Far Eastern Economic Review in Hong Kong, doubling revenues, and at age of 22 years, was founding editorial page editor of the Wall Street Journal Europe in Brussels. [ citation needed ]
He married Anne Alstott (a professor at Yale Law School) on December 7, 1986. [1] He is married to Minky Worden , media director for Human Rights Watch ; they have three sons. [6]
Crovitz has written many controversial editorials. In July 2012, he argued that Xerox-Parc's development of the Ethernet protocol meant that the private sector, not the government, created the Internet. [7] Crovitz cited book by Michael Hiltzik to support this argument but Hiltzik himself rebutted the claim. [8]

Notes

External links
WebPage index: 00128
CBC Radio One
CBC Radio One is the English-language news and information radio network of the publicly owned Canadian Broadcasting Corporation . It is commercial -free and offers local and national programming. It is available on AM and FM to 98 per cent of Canadians, and overseas through Radio Canada International , over the Internet, and through mobile apps.
A modified version of CBC Radio One, with local content replaced by additional airings of national programming, is available on Sirius XM Satellite Radio channel 169. It is downlinked to subscribers via Sirius XM Canada and its U.S.-based counterpart, Sirius XM Satellite Radio .
In 2010, CBC Radio One reached 4.3 million listeners each week. It was the largest radio network in Canada. [1]

History
CBC Radio began in 1936, and is the oldest branch of the corporation. In 1949, the facilities and staff of the Broadcasting Corporation of Newfoundland were transferred to CBC upon Newfoundland 's entry into Canadian Confederation .
Beginning in 1944, the CBC operated two English-language radio services: the original network became the Trans-Canada Network , and a second network, the Dominion Network , was established with CJBC in Toronto as its flagship. With the exception of CJBC, all 35 stations on the CBC Dominion Network were privately owned affiliates. Its programming tended to be lighter than that of the Trans-Canada Network, carrying more American programming in its schedule. The Dominion Network operated only in the evenings, freeing affiliates to air local programming during the day.
Until 1958, the CBC was a broadcaster, and the principal broadcast regulator in Canada. It used this dual role to take most of Canada's clear-channel frequencies on the AM dial.
In 1962, the Dominion Network was dissolved and within a few years CJBC became a French-language station broadcasting the programming of Radio-Canada .
In 1960, the CBC began running distinct programming on its three existing FM English-language stations, which had been providing simulcasts of programming on its AM stations. The stations, located in Toronto, Ottawa and Montreal, broadcast a monoaural FM signal. Programming consisted mostly of classical music. The stations were linked by CN/CP Telecommunications via land-line and microwave. This service was discontinued in 1962, but resumed in 1964 in stereo. Eventually, a national satellite-distributed network of stereo FM stations was established. In 1975, the FM network was called CBC Stereo, and the AM service was designated CBC Radio.
In the late 1960s and early 1970s, CBC Radio increased its current affairs and documentary content with an initiative known as the "Radio Revolution", using more ambitious, live coverage of news and current affairs including listeners as well as experts. The change began with national shows such as As It Happens . [2] The change spread to CBC regional morning shows which developed three hours of live radio combining "survival information", about news, weather and traffic, with interviews and documentaries about local and national issues. CBC Radio Winnipeg was the first to embrace the format followed by Information Morning in Halifax, a move which increased audience and attracted coverage in Time Magazine . [3]
CBC Radio stopped running commercial advertising in 1974. Until 1995, the network signed off the air between 1 a.m. and 6 a.m. daily – in that year, it launched an overnight program, CBC Radio Overnight , which airs international news and documentary programs.
In the early 1990s, the CBC began offering selected programs on the Internet . [4] In September 1996, the network formally launched live audio streaming of both CBC Radio and CBC Stereo. [4]
In the 1990s, many of the CBC's AM stations moved to FM in response to complaints of poor AM reception. This meant that the old distinction between the AM "Radio" network and the FM "Stereo" network was no longer accurate, even though many of the FM "Radio" stations broadcast in mono only. As a result, in 1997 CBC Radio became CBC Radio One and CBC Stereo became CBC Radio 2 . Although some Radio One stations still broadcast on AM as of 2016, because of issues with urban reception of AM radio signals many of the remaining AM stations have added FM rebroadcasters in major urban centres within their broadcast area.
The channel was added to the Sirius lineup in 2005 and the XM lineup in 2013.

CBC Radio One today
From 2004 until early 2007, CBC Radio One promotional spots were announced by Canadian actress Shauna MacDonald , also known as "Promo Girl". Toronto-born Jeremy Harris took over from MacDonald. Until fall 2005, promos ended with one of two slogans: either "Because sometimes a picture needs a thousand words" or "Hear the big picture". Until early 2015, the slogan was "Canada Lives Here." The slogan was not replaced.
Some CBC Radio One programs, such as As It Happens , air in the United States on some stations associated with Public Radio International . Definitely Not the Opera , Quirks & Quarks , The Vinyl Cafe and Q are heard on some public stations in the northern United States. Some CBC-SRC programs are relayed on Radio Canada International for listeners abroad and others, such as the 2010 summer program Promised Land , have aired on Sirius Satellite Radio 169

CBC Radio One stations
Only stations which are licensed as separate broadcast undertakings are listed below. Most of these stations are a primary production centre, producing at least one local program . Stations not considered primary production centres may have local content which is limited to local news updates. Each station also has a significant number of rebroadcasters in smaller communities within its service area; those are listed in each primary station's article.

CBC Radio One schedule
Most schedules include hourly news readings that run from 6–12 minutes on the top of the hour except for major programming like the 6 p.m. news show and Cross Country Checkup . Some mid-day programs include only brief 90-second "information updates".
On statutory holidays , local programming is replaced by special provincial programming or regional programs are broadcast provincewide on a rotating basis. In the summer months of July and August, some programming is temporarily shortened and/or replaced by special summer series. During the CBC's labour dispute, [ when? ] most of the schedule was temporarily replaced by a mix of repeat airings of recent CBC programs, BBC World news programming and music from the CBC service Galaxie .
Stations in the Canadian territories air a significantly different schedule with expanded local programming that includes a number of programs in local Aboriginal languages. They air most of the core CBC Radio One schedule, although some programs may air in abbreviated versions. See CBC North for further information.
On January 17, 2007, the CBC announced some changes to the network's schedule to begin in April. Among them, Freestyle and The Arts Tonight were merged into Q , an arts magazine show hosted by Jian Ghomeshi , Global Village was discontinued and some of its features were merged into Dispatches , and Between the Covers moved exclusively online as a podcast . [5] Reasons given for the schedule changes are said to be based on audience research, however some negative reaction has been seen. [6] [7]
It was announced in March 2009 that The Inside Track , Outfront , The Point and In the Key of Charles would be cancelled, and that the noontime local shows would be reduced to one hour. [8]
The network also airs some programming syndicated from American public broadcasting services such as National Public Radio , Public Radio International and Public Radio Exchange , including This American Life , [9] Radiolab and the news series The World and The State We're In .

Sirius XM
The Radio One feed on Sirius XM Satellite Radio largely follows the Eastern Time schedule, and has no local programming, with repeats of other shows in time slots that would normally be occupied by local programming. As a consequence of using a single feed, most national programming outside the Eastern Time Zone is heard earlier or later than the regional outlet on terrestrial radio - for example: The World at Six is heard on Sirius XM as early as 3 p.m. Pacific Time in Vancouver, and as late as 7:30 p.m. Newfoundland Time in St. John's.
Programs produced by NPR and PRI are not heard on CBC Radio One's Sirius XM service, as these are covered by channels programmed by NPR and PRI. In addition, the programs featured on CBC Radio Overnight are not heard on the Sirius XM feed. In these cases, as with the regional programming slots, repeats of earlier national programs are heard, as well as some CBC Radio 2 programming (such as Deep Roots ).

Podcasting
Many CBC Radio programs are also distributed in podcast versions. In addition, the service has also created several programs which are distributed exclusively as podcasts. Current original podcasts include Campus , a program devoted to stories about college and university student life, and Back Story , in which foreign correspondents talk about the news stories they have covered. [10] Selected episodes from the podcast programs may also sometimes air terrestrially on CBC Radio One as substitute programs, such as when a regularly scheduled program is preempted due to a statutory holiday .

Schedule
The network's base schedule is noted here, and applies only to CBC Radio One's regional outlets. Scheduling of weekend programs highlighted in red varies from station to station due to time zone differences created by the fact that Cross-Country Checkup airs live across Canada.

Other schedule notes

Shortwave relays of Radio One
Two CBC Radio One stations operate shortwave relay transmitters:
Both transmitters broadcast 1 kW ERP signals on a fixed frequency of 6160 kHz. Some DXers have been able to log both transmitters simultaneously, but this is a rare occurrence due to the distance between the transmitters.
The objective of the CBC transmissions on SW is also provide information to listeners in isolated and distant parts of the country which other usual forms of broadcast or communications are not well covered. During appropriated periods of radio propagation, the signals can reach other countries, as well the reception can turn difficult in dense populated areas due Electromagnetic interference .

Notes and references

See also

External links

Live streams
WebPage index: 00129
The Phoenix (newspaper)
The Phoenix (stylized as The Phœnix ) is the name of several alternative weekly periodicals published in the United States of America by Phoenix Media/Communications Group of Boston , Massachusetts , including the Portland Phoenix and the now-defunct Boston Phoenix , Providence Phoenix and Worcester Phoenix . These publications emphasize local arts and entertainment coverage as well as lifestyle and political coverage.
The papers are somewhat similar in format and editorial content to the Village Voice . [1]

History

Origin
The Phoenix was founded in 1965 by Joe Hanlon, a former editor at MIT 's student newspaper, The Tech . Since many Boston-area college newspapers were printed at the same printing firm, Hanlon's idea was to do a four-page single-sheet insert with arts coverage and ads. He began with the Harvard Business School 's newspaper The Harbus News . A student there, James T. Lewis, became Hanlon's advertising manager.
Boston After Dark began March 2, 1966. Theater enthusiast Larry Stark began contributing theater reviews with the second issue. When the insert idea did not pan out, the trio continued Boston After Dark as a weekly free paper.
A year after the launch, Hanlon sold off his half to Lewis. For three years, Boston After Dark kept the four-page format, with Lewis as publisher, Jane Steidemann as editor, Stephen M. Mindich as ad salesman and Stark as full-time theater critic and copy editor, plus film reviews by Deac Rossell, who later went on to become head of programming at London 's National Film Theatre .

Expansion
As the paper expanded, Mindich acquired a half interest. Stark quit in 1972 and began reviewing for the rival Cambridge Phoenix , which had begun October 9, 1969, started by Jeffrey Tarter. The first managing editor of the Cambridge Phoenix was April Smith, who later became a novelist ( Good Morning, Killer ) and TV writer-producer ( Cagney & Lacey , Lou Grant , Nightmares & Dreamscapes ). [2]
Following a two-week writers' strike in August 1972, the Cambridge Phoenix was sold to Boston After Dark . Mindich's merger then became known as The Boston Phoenix , with Boston After Dark used as the name for the paper's arts and entertainment section, as well as the nameplate for a free edition of the Phoenix distributed on college campuses in Boston. In the conflicts between writers and management, ousted writers immediately started another weekly, The Real Paper (which began August 2, 1972 and continued until 1981), while management continued the Boston Phoenix .
In 1988, the company that owns the Phoenix , Phoenix Media/Communications Group , bought a similar publication in neighboring Rhode Island called the NewPaper , which is now the Providence Phoenix . In 1999, PM/CG branched out into Portland , Maine by creating the Portland Phoenix . That same year the nameplate changed from Phoenix B.A.D. to The Boston Phoenix . From 1992 through 2000, there was also a Worcester Phoenix , but it folded due to Worcester's dwindling arts market.
In 2005, the Phoenix underwent a major redesign, switching from a broadsheet / Berliner format to a tabloid format and introduced a new logo in order to increase its appeal to younger readers. [3]
Towards the end of its existence, The Phoenix had a weekly circulation of 253,000, and its website featured 90% of the paper's content, as well as extra content not included in the paper. [4]

Mergers, closures and ownership change
On August 1, 2012, it was announced that Stuff Magazine and the Boston Phoenix newspaper would merge and the result would be a weekly magazine to be called The Phoenix , to debut in the fall of 2012. [5] The first issue of the new, glossy-paper Phoenix had a cover date of September 21, 2012. [6] On March 14, 2013, the publisher announced that the Boston Phoenix would fold effective as of the March 15, 2013 print edition, though the Portland and Providence papers would be unaffected. [7] In October 2014, The Phoenix announced that their Providence paper would also cease publication, with last issue being the October 17 issue. [8]
The Boston Phoenix published its last issue on March 14, 2013. A statement from publisher Mindich in that issue blamed the 2007 financial crisis and changes in the media business, particularly the downturn in print advertising revenue, as the reasons for the closing. [9]
In November 2014, Mindich sold the Portland Phoenix to the Portland News Club LLC, publishers of The Portland Daily Sun . [10] Although the Daily Sun would cease publication one month later, the Portland Phoenix continues to be published by the new owners weekly as of 2017. The current editors at the Portland Phoenix are Francis Flisiuk and Nicholas Schroeder, two alums from the University of Southern Maine.

Archiving
After the closing of the Boston Phoenix and the Providence Phoenix , Mindich reassured the public that the websites would be maintained, and the online and print archives would be preserved. Sometime in 2014, the websites ceased to function and when they did start to come back in 2015, the sites responded slowly and intermittently.
In November 2015, The Boston Globe announced that Mindich, with the help of former Phoenix columnist and current Northeastern University journalism professor Dan Kennedy, [11] had donated the Phoenix's archives to Northeastern University’s Snell Library Archives and Special Collections. [12] [13] The gift also included other publications associated with the Phoenix including Boston After Dark, the Portland, Providence and Worcester Phoenix editions; Stuff and Stuff at Night magazines, and early issues of The Real Paper ; The eventual goal is to digitize all issues beginning in 1965 and make the text searchable online as well as give access to the websites. Hard copies of the publications are currently available to the public at Snell Library. [12] [14]
Records from WFNX were also donated to Northeastern University’s [15] Snell Library Archives and Special Collections. [12] [13]

Radio
Over the years, PMCG acquired radio stations in Boston, Portland and Providence, notably the Boston alternative rock radio station WFNX . The company owned stations serving Metro Boston, New Hampshire, and Maine. The radio stations covered the same music , arts and political scene as the paper and sold to many of the same advertisers. The Maine station, WPHX , was sold to the owner of WXEX in 2011, while on May 16, 2012, the over the air signal and broadcast tower for the Boston station WFNX was sold to Clear Channel Communications and New Hampshire station WFEX has been sold to Blount Communications, the latter two transactions subject to FCC approval. Following FCC approval of the sale, WFNX stopped broadcasting on Tuesday, July 24, 2012; the webcast ended in May 2013. Former WFNX DJs and personalities Julie Kramer, Adam 12, Henry Santoro, and Paul Driscoll joined Boston.com and formed Radio BDC, another internet radio station.
Currently the WFNX call letters belong to the former WXRG in Athol, MA; the station simulcasts WXRV-FM 92.5 from Haverhill, MA.
Records from WFNX were also donated to Northeastern University’s Snell Library Archives and Special Collections. [16] [13]

Awards
The Phoenix received many awards for excellence in journalism , including honors from the New England Press Association , the Penny-Missouri Newspaper Awards, the American Bar Association Gavel Awards, Michael J. Metcalfe Diversity in Media Awards and the ASCAP -Deems Taylor Awards.
In 1994, Phoenix classical music writer Lloyd Schwartz was awarded a Pulitzer Prize for Criticism . [17]

Notes
WebPage index: 00130
Cato Institute
The Cato Institute is an American libertarian think tank headquartered in Washington, D.C. It was founded as the Charles Koch Foundation in 1974 by Ed Crane , Murray Rothbard , and Charles Koch , [6] chairman of the board and chief executive officer of the conglomerate Koch Industries . [nb 1] In July 1976, the name was changed to the Cato Institute. [6] [7] Cato was established to have a focus on public advocacy , media exposure and societal influence. [8] According to the 2014 Global Go To Think Tank Index Report ( Think Tanks and Civil Societies Program , University of Pennsylvania ), Cato is number 16 in the "Top Think Tanks Worldwide" and number 8 in the "Top Think Tanks in the United States". [9] Cato also topped the 2014 list of the budget-adjusted ranking of international development think tanks. [10]

History
The institute was founded in December 1974 in Wichita, Kansas as the Charles Koch Foundation and initially funded by Charles Koch. [nb 2] [11] The other members of the first board of directors included co-founder Murray Rothbard , libertarian scholar Earl Ravenal , and businessmen Sam H. Husbands Jr. and David H. Padden. [6] [12] At the suggestion of Rothbard, [12] the institute changed its name in 1976 to Cato Institute after Cato's Letters , a series of British essays penned in the early 18th century by John Trenchard and Thomas Gordon . [13] [14]
Cato relocated first to San Francisco , California in 1977, then to Washington, D.C. in 1981, settling initially in a historic house on Capitol Hill . [15] (p446) The Institute moved to its current location on Massachusetts Avenue in 1993. Cato Institute was named the fifth-ranked think tank in the world for 2009 in a study of think tanks by James G. McGann, PhD of the University of Pennsylvania , based on a criterion of excellence in "producing rigorous and relevant research, publications and programs in one or more substantive areas of research". [16]

Activities
Various Cato programs were favorably ranked in a survey published by the University of Pennsylvania in 2012. [9]

Publications
The Cato Institute publishes numerous policy studies, briefing papers, periodicals, and books. Peer-reviewed academic journals include the Cato Journal [17] [18] [19] and Regulation . [20] [21] [22] Other periodicals include Cato's Letter , [23] Cato Supreme Court Review , [24] and Cato Policy Report . [25] Cato published Inquiry Magazine from 1977 to 1982 (before transferring it to the Libertarian Review Foundation ) [26] and Literature of Liberty from 1978 to 1979 (before transferring it to the Institute for Humane Studies ). [27]
Notable books from Cato and Cato scholars include:

Web projects
In addition to maintaining its own website in English and Spanish, [28] Cato maintains websites focused on particular topics:
Social media sponsored by Cato includes "Daily Podcasts" (through iTunes and RSS feeds), plus pages on Facebook , Twitter , Google+ , and YouTube . [31]

Conferences
Speakers at Cato have included Federal Reserve Chairmen Alan Greenspan and Ben Bernanke , and International Monetary Fund Managing Director Rodrigo de Rato . [32] [33] [34] In 2009 Czech Republic President Václav Klaus spoke at a conference. [35]

Ideological relationships

Libertarianism, classical liberalism, and conservatism
Many Cato scholars advocate support for civil liberties, liberal immigration policies, [36] drug liberalization, [37] and the repeal of Don't Ask Don't Tell and laws restricting consensual sexual activity. [38] [39] The Cato Institute officially resists being labeled as part of the conservative movement because "'conservative' smacks of an unwillingness to change, of a desire to preserve the status quo". [40]
In 2006, Markos Moulitsas of the Daily Kos proposed the term " Libertarian Democrat " to describe his particular liberal position, suggesting that libertarians should be allies of the Democratic Party. Replying, Cato vice president for research Brink Lindsey agreed that libertarians and liberals should view each other as natural ideological allies, [41] and noted continuing differences between mainstream liberal views on economic policy and Cato's " Jeffersonian philosophy ". Cato has stated on its "About Cato" page: "The Jeffersonian philosophy that animates Cato's work has increasingly come to be called 'libertarianism' or 'market liberalism.' It combines an appreciation for entrepreneurship, the market process, and lower taxes with strict respect for civil liberties and skepticism about the benefits of both the welfare state and foreign military adventurism." [42]
Some Cato scholars disagree with conservatives on neo-conservative foreign policy, albeit that this has not always been uniform. [43]

Objectivism
The relationship between Cato and the Ayn Rand Institute (ARI) improved with the nomination of Cato's new president John A. Allison IV in 2012. He is a former ARI board member and is reported to be an "ardent devotee" of Rand who has promoted reading her books to colleges nationwide. [44] In March 2015 Allison retired and was replaced by Peter Goettler. Allison remains on the Cato Institute's board [45]

Cato positions on political issues and policies
The Cato Institute advocates policies that advance "individual liberty , limited government , free markets , and peace ". They are libertarian in their policy positions, typically advocating diminished government intervention in domestic, social, and economic policies and decreased military and political intervention worldwide. Cato was cited by columnist Ezra Klein as nonpartisan, saying that it is “the foremost advocate for small-government principles in American life" and it "advocates those principles when Democrats are in power, and when Republicans are in power". [46] Eric Lichtblau called Cato "one of the country’s most widely cited research organizations". [47]

On domestic issues
Cato scholars have consistently called for the privatization of many government services and institutions, including NASA , Social Security , the United States Postal Service , the Transportation Security Administration , public transportation systems, and public broadcasting . [48] [49] [50] [51] [52] [53] [54] [55] The institute opposes minimum wage laws, saying that they violate the freedom of contract and thus private property rights, and increase unemployment. [56] [57] It is opposed to expanding overtime regulations, arguing that it will benefit some employees in the short term, while costing jobs or lowering wages of others, and have no meaningful long-term impact. [58] [59] It opposes child labor prohibitions. [60] [61] [62] It opposes public sector unions and supports right-to-work laws . [63] [64] It opposes universal health care , arguing that it is harmful to patients and an intrusion onto individual liberty. [65] [66] It is against affirmative action . [67] It has also called for total abolition of the welfare state , and has argued that it should be replaced with reduced business regulations to create more jobs, and argues that private charities are fully capable of replacing it. [68] [69] Cato has also opposed antitrust laws. [70] [71]
Cato is an opponent of campaign finance reform , arguing that government is the ultimate form of potential corruption and that such laws undermine democracy by undermining competitive elections. Cato also supports the repeal of the Federal Election Campaign Act . [72] [73]
Cato has published strong criticisms of the 1998 settlement which many U.S. states signed with the tobacco industry . [74] In 2004, Cato scholar Daniel Griswold wrote in support of President George W. Bush's failed proposal to grant temporary work visas to otherwise undocumented laborers which would have granted limited residency for the purpose of employment in the U.S. [75]
The Cato Institute published a study proposing a Balanced Budget Veto Amendment to the United States Constitution . [76]
In 2003, Cato filed an amicus brief in support of the Supreme Court's decision in Lawrence v. Texas , which struck down the remaining state laws that made private, non-commercial homosexual relations between consenting adults illegal. Cato cited the 14th Amendment , among other things, as the source of their support for the ruling. The amicus brief was cited in Justice Kennedy's majority opinion for the Court. [77]
In 2006, Cato published a Policy Analysis criticising the Federal Marriage Amendment as unnecessary, anti-federalist, and anti-democratic. [78] The amendment would have changed the United States Constitution to prohibit same-sex marriage ; the amendment failed in both houses of Congress.
Cato scholars have been sharp critics of current U.S. drug policy and the perceived growing militarization of U.S. law enforcement. [79] Additionally, the Cato Institute opposes smoking bans [80] and mandatory use of safety belts . [81]

Criticism of corporate welfare
In 2004, the Institute published a paper arguing in favor of "drug re-importation". [82] Cato has published numerous studies criticizing what it calls "corporate welfare", the practice of public officials funneling taxpayer money, usually via targeted budgetary spending, to politically connected corporate interests. [83] [84] [85] [86]
Cato president Ed Crane and Sierra Club executive director Carl Pope co-wrote a 2002 op-ed piece in the Washington Post calling for the abandonment of the Republican energy bill, arguing that it had become little more than a gravy train for Washington, D.C. lobbyists. [87] Again in 2005, Cato scholar Jerry Taylor teamed up with Daniel Becker of the Sierra Club to attack the Republican Energy Bill as a give-away to corporate interests. [88]

On copyright issues
A 2006 study criticized the Digital Millennium Copyright Act . [89]

On foreign policy
Cato's non-interventionist foreign policy views, and strong support for civil liberties, have frequently led Cato scholars to criticize those in power, both Republican and Democratic. Cato scholars opposed President George H. W. Bush 's 1991 Gulf War operations (a position which caused the organization to lose nearly $1 million in funding), [15] (p454) President Bill Clinton 's interventions in Haiti and Kosovo , President George W. Bush's 2003 invasion of Iraq , and President Barack Obama's 2011 military intervention in Libya . [90] As a response to the September 11 attacks , Cato scholars supported the removal of al Qaeda and the Taliban regime from power , but are against an indefinite and open-ended military occupation of Afghanistan. [91] Cato scholars criticized U.S. involvement in Saudi Arabian-led intervention in Yemen . [90]
Ted Galen Carpenter, Cato's Vice President for Defense and Foreign Policy Studies, criticized many of the arguments offered to justify the 2003 invasion of Iraq. One of the war's earliest critics, Carpenter wrote in January 2002: "Ousting Saddam would make Washington responsible for Iraq's political future and entangle the United States in an endless nation-building mission beset by intractable problems." [92] Carpenter also predicted: "Most notably there is the issue posed by two persistent regional secession movements: the Kurds in the north and the Shiites in the south." [92] Cato's Director of Foreign Policy Studies, Christopher Preble, argues in The Power Problem: How American Military Dominance Makes Us Less Safe, Less Prosperous, and Less Free , that America's position as an unrivaled superpower tempts policymakers to constantly overreach and to redefine ever more broadly the "national interest". [93]
Christopher Preble has said that the "scare campaign" to protect military spending from cuts under the Budget Control Act of 2011 has backfired. [94]

On environmental policy
Cato scholars have written about the issues of the environment, including global warming, environmental regulation, and energy policy.
PolitiFact.com and Scientific American have criticized Cato's work on global warming. [95] [96] A December 2003 Cato panel included Patrick Michaels , Robert Balling and John Christy . [ citation needed ] Michaels, Balling and Christy agreed that global warming is related at least some degree to human activity but that some scientists and the media have overstated the danger. [ citation needed ] The Cato Institute has also criticized political attempts to stop global warming as expensive and ineffective:
Cato scholars have been critical of the Bush administration's views on energy policy. In 2003, Cato scholars Jerry Taylor and Peter Van Doren said the Republican Energy Bill was "hundreds of pages of corporate welfare, symbolic gestures, empty promises, and pork-barrel projects". [98] They also spoke out against the former president's calls for larger ethanol subsidies. [99]
With regard to the "Takings Clause" of the United States Constitution and environmental protection, libertarians associated with Cato contend that the Constitution is not adequate to guarantee the protection of private property rights. [100]

Other commentaries of presidential administrations

George W. Bush administration
Cato scholars were critical of George W. Bush 's Republican administration (2001–2009) on several issues, including education, [101] and excessive government spending . [102] On other issues, they supported Bush administration initiatives, most notably health care, [103] Social Security , [104] [105] global warming , [97] tax policy , [106] and immigration . [75] [107] [108] [109]

2008 election campaign commentaries
During the 2008 U.S. presidential election , Cato scholars criticized both major-party candidates, John McCain and Barack Obama . [110] [111]

Barack Obama administration
Cato has criticized President Obama's stances on policy issues such as fiscal stimulus , [112] healthcare reform , [113] foreign policy , [114] and drug-related matters, [37] while supporting his stance on the repeal of Don't Ask, Don't Tell [39] and the DREAM Act . [36]

Donald Trump administration
Cato was strongly critical of Trump's immigration ban, which was enacted in January 2017. [115]

Funding, tax status, and corporate structure
The Cato Institute is classified as a 501(c) (3) organization under U.S. Internal Revenue Code . For revenue, the Institute is largely dependent on private contributions. The Cato Institute reported fiscal year 2015 revenue of $37.3 million and expenses of $29.4 million. [5] According to the organization's annual report, $32.1 million came from individual donors, $2.9 million came from foundations, $1.2 million came from program revenue and other income, and $1 million came from corporations. [5]
Sponsors of Cato have included FedEx , Google , CME Group and Whole Foods Market . [116] The Nation reported support for Cato from the tobacco industry in a 2012 story. [117]

Funding details
Net assets as of FYE March 2015: $70,186,000.

Shareholder dispute
According to an agreement signed in 1977, there were to be four shareholders of the Cato Institute. They were Charles and David Koch , Ed Crane, [118] and William A. Niskanen . Niskanen died in October 2011. [119] In March 2012, a dispute broke out over the ownership of Niskanen's shares. [118] [119] Charles and David Koch filed suit in Kansas, seeking to void his shareholder seat. The Kochs argued that Niskanen’s shares should first be offered to the board of the Institute, and then to the remaining shareholders. [120] Crane contended that Niskanen's share belonged to his widow, Kathryn Washburn, and that the move by the Kochs was an attempt to turn Cato into "some sort of auxiliary for the G.O.P.... It's detrimental to Cato, it's detrimental to Koch Industries, it's detrimental to the libertarian movement." [47]
In June 2012, Cato announced an agreement in principle to settle the dispute by changing the institute's governing structure. Under the agreement, a board replaced the shareholders and Crane, who at the time was also Chief Executive Officer , retired. Former BB&T bank CEO John A. Allison IV replaced him. [121] [122] The Koch brothers agreed to drop two lawsuits. [123]

Associates in the news

Nobel laureates at Cato
The following Nobel Memorial Prize in Economic Sciences laureates have worked with Cato: [127]

Milton Friedman Prize
Since 2002, the Cato Institute has awarded the Milton Friedman Prize for Advancing Liberty every two years to "an individual who has made a significant contribution to advancing human freedom." [128] The prize comes with a cash award of US$250,000. [129]

Board of directors
As of 2016: [3]

Notable Cato experts
Notable scholars associated with Cato include the following: [138]

Policy scholars

Adjunct scholars

Fellows

Affiliations
The Cato Institute is an associate member of the State Policy Network , a U.S. national network of free-market oriented think tanks. [139] [140]

See also

Notes
WebPage index: 00131
Wikipedia administrators
On Wikipedia , trusted users may be appointed as administrators (also known as admins, sysops , and janitors), [1] :327 following a successful request for adminship. There are 1,259 administrators on the English Wikipedia [2] (as of May 2017). Administrators have additional technical privileges compared to other editors.
On Wikipedia, becoming an admin is often referred to as being "given [or taking up] the mop", [2] a term which has also been used elsewhere. [3] In 2006, The New York Times reported that administrators on Wikipedia, of whom there were then about 1,000, were "geographically diverse". [4] In July 2012, it was widely reported that Wikipedia was "running out of administrators", because in 2005 and 2006, 40 to 50 people were often appointed administrators each month, but in the first half of 2012, only nine in total were appointed. [5] [6] However, Jimmy Wales , Wikipedia's co-founder, denied that this was a crisis or that Wikipedia was running out of admins, saying, "The number of admins has been stable for about two years, there's really nothing going on." [7] Wales had previously (in a message sent to the English Wikipedia mailing list on February 11, 2003) stated that being an admin is "not a big deal", and that "It's merely a technical matter that the powers given to sysops are not given out to everyone." [8]
In his book Wikipedia – The Missing Manual , John Broughton states that while many people think of administrators on Wikipedia as judges, that is not the purpose of the role. Instead, he says, admins usually "delete pages" and "protect pages involved in edit wars". [9]

Requests for adminship
While the first Wikipedia administrators were appointed by Jimmy Wales himself in October 2001, [10] administrator privileges on Wikipedia are now granted through a process known as requests for adminship (RfA). [1] Any registered editor may nominate themselves, or may request another editor to do so. The process has been said to be "akin to putting someone through the Supreme Court" by Andrew Lih , a scientist and professor who is himself an administrator on the English Wikipedia . Lih also said, "It's pretty much a hazing ritual at this point", in contrast to how the process worked early in Wikipedia's history, when all one had to do to become an admin was "prove you weren't a bozo". [5] Candidacy for the role is normally considered only after "extensive work on the wiki". [1] While any editor may vote in an RfA, the outcome is not determined by a majority vote, but rather by whether or not consensus has been reached that the candidate would make a good administrator, a decision which can only be made by a bureaucrat, a Wikipedia editor who is also appointed by the community through a "request" process, though the process is much stricter for them than for administrators. [11] This may have been implemented as a result of RfAs attracting increasing levels of attention: Stvilia et al. quoted that "Prior to mid-2005, RfAs typically did not attract much attention. Since then, it has become quite common for RfAs to attract huge numbers of RfA groupies who all support one another". [12]

Role
Once granted administrator privileges, a user has access to additional functions in order to perform certain duties. [5] These include "messy cleanup work", [1] deletion of articles deemed unsuitable, protecting pages (restricting editing privileges to that page), [13] :66 and blocking the accounts of disruptive users. [1] [5] Blocking a user must be done according to Wikipedia's policies and a reason must be stated for the block, which will be permanently logged by the software. [1] :401 [13] :120 Use of this privilege to "gain editing advantages" is considered inappropriate. [1]

Scientific studies
A scientific paper by researchers from Virginia Tech and Rensselaer Polytechnic Institute found that after editors are promoted to administrator status, they often focus more on articles about controversial topics than they did before. The researchers also proposed an alternative method for choosing administrators, in which more weight is given to the votes of experienced editors. [14] Another paper, presented at the 2008 Conference on Human Factors in Computing Systems , analyzed data from all 1,551 requests for adminship from January 2006 to October 2007, with the goal of determining which (if any) of the criteria recommended in Wikipedia's Guide to requests for adminship [15] page were the best predictors of whether the user in question would actually become an admin. [3] In December 2013, a similar study was published by researchers from the Polish-Japanese Institute of Information Technology in Warsaw which aimed to model the results of requests for adminship on the Polish Wikipedia using a model derived from Wikipedia's edit history. They found that they could "classify the votes in the RfA procedures using this model with an accuracy level that should be sufficient to recommend candidates." [16]
WebPage index: 00132
Erik Möller
Erik Möller (born 1979) is a German freelance journalist , [2] software developer , [3] author, and former deputy director of the Wikimedia Foundation (WMF), based in San Francisco. [4] Möller additionally works as a web designer and previously managed his own web hosting service, myoo.de. [4] [5]

Published work
Möller is the author of the book Die heimliche Medienrevolution – Wie Weblogs, Wikis und freie Software die Welt verändern ("The secret media revolution: How weblogs, wikis and free software change the world"). [6] In the book, Möller discusses the development of a journalistic equivalent to the open-source movement in citizen media and blogging, though pointing out that most blogs do not compete with mainstream media. [7] The book was first published in 2005 by Heinz Heise and a second edition was published in 2006, [6] with updated and revised chapters. [8] A review in Berliner Literaturkritik's saw practical tips but claimed the book focused too much on technical details. [9] Möller's book is cited in the 2006 book Wiki: Web collaboration , in a section discussing "Wikis as an Engine for Social Change", and his term "secret media revolution" is used. [10] The authors comment: "Möller provides a comprehensive look at the problems and possible solutions in dealing with difficult controversies and vandalism in blog and wiki environments." [10]
In his earlier research on Wikipedia, Möller found in 2003 that Wikipedia's open-source nature garners interest from many individuals, but also leads to gaps in topics of interest to experts. [11] Some of his research was published in Telepolis , where he compared Wikipedia to the digital multimedia encyclopedia Microsoft Encarta . [12] In his 2003 article Das Wiki-Prinzip: Tanz der Gehirne ("The Wiki principle: Dance of the brain"), he gives some background of Wikipedia and wikis, as well as on what he sees as the benefits of the project, ways to prevent vandalism to articles, and the etiquette of Wikipedia users. [13]

Web-based projects
Möller, who holds a diploma degree in computer science ( Dipl.-Inform. FH ), [4] is the owner and creator of the Infoanarchy website which has information on P2P and file-sharing technologies. [14] He has also been involved in the development of the FreedomDefined website . [15]
At a 2005 blogger conference in Berlin , Möller gave a lecture on the Open Source Initiative , free knowledge and Wikinews , discussing the latter in the context of other models used by Slashdot , Kuro5hin , Daily Kos and others. [16] At an Austrian conference on wikis in Vienna in 2005, Möller discussed the advantages of using wikis to compile statistical data, stating that wikis encourage internal transparency and greater participation among coworkers. [17]

Wikimedia Foundation
Möller has been involved with the Wikimedia Foundation projects including Wikipedia since 2001 both as an editor, as a developer of the MediaWiki software and of Wikinews . [18] He drafted the initial project proposal for Wikinews (using the username Eloquence), [2] [19] and also was instrumental in developing Wikimedia Commons . [20] He first proposed the idea for Wikimedia Commons in March 2004. [21] Möller described a difference between Wikipedia and Wikinews to The New York Times by saying: "Wikinews articles are short-lived, so there is a reduced feeling of contributing to a knowledge base that will last a lifetime." [2] "We are the new media. We make our own rules," [22] explained Möller at a 2005 Citizen Reporters' Forum in Seoul . [23] He stated that Wikinews publishes a daily print edition and is working on other formats including an audio version of articles. [22] Möller was interviewed by Journalism.co.uk on the eightfold increase in traffic to Wikinews on the day of the 7 July 2005 London bombings , and on the effects of free news. [24] "While Wikinews is still much, much smaller than Wikipedia, the potential for news coverage goes far beyond what Wikipedia is currently doing," said Möller. [24] He gave periodic "State of the Wiki" reports at Wikinews , where he defended the project's use of both original material and information synthesized from other media sources. [25]

Deputy director
Möller was appointed the chief research officer of the WMF in June 2005 but resigned in August that year, citing personal differences with members of the Board. [26] [27] He had been chief technology officer of Stichting Open Progress, [28] the not-for-profit legal arm of OmegaWiki , based in the Netherlands. [20] At Stichting Open Progress Möller was the manager of a group of developers who worked on the implementation of OmegaWiki. [20] Möller also hosted other wiki communities such as WikiEducator.org. [20]
He was elected in September 2006 to replace Angela Beesley on the Board of the Wikimedia Foundation , [29] [30] and in October 2006 he became executive secretary. [31] [32] In December 2007 he resigned from the Board and was named deputy director, [33] effective as of 10 January 2008. [34] In this role Möller was involved with financing analysis for the Foundation, and with executive director Sue Gardner gave a presentation to Sun Microsystems in an attempt to gain funding from the company for WMF. [35] This presentation was later leaked to Wikinews . [35]
As deputy director, Möller was responsible for managing and implementing the technical strategy of the organization. [20] [36] Möller explained to the Los Angeles Times that the foundation needed to be careful with the kinds of deals they wanted to make, and said: "We don't want to endanger the mission by entering into deals that would conflict with it." [37] Möller is the Wikimedia Foundation's representative on the institutional council of the Encyclopedia of Life . [38] Through this contact, Möller helped convince the Alfred P. Sloan Foundation (a backer of the Encyclopedia of Life) to donate $3 million to Wikimedia, the single largest donation Wikimedia has received to date. [39]
In 2014 Möller's account was blocked on the German Wikipedia because he created, implemented and used "superprotect" rights to overrule the German Wikipedia's decision to not enable a new mechanism to view images until legal and technical problems were fixed. [40] [41]
Möller left the WMF on 30 April 2015. [42] [43]
WebPage index: 00133
Wikipedia Seigenthaler biography incident
In May 2005, an anonymous editor posted a hoax article in the online encyclopedia Wikipedia about journalist John Seigenthaler . [1] The article falsely stated that Seigenthaler had been a suspect in the assassinations of U.S. President John F. Kennedy and U.S. Attorney General Robert F. Kennedy . The then-78-year-old Seigenthaler, a friend and aide to Robert Kennedy, characterized the Wikipedia article about him as "Internet character assassination". [2]
The hoax was not discovered and corrected until September of that year, after which Seigenthaler wrote about his experience in USA Today . The incident raised questions about the reliability of Wikipedia and other websites with user-generated content that lack the legal accountability of traditional newspapers and published materials. [3] In a December 13 interview, [4] co-founder Jimmy Wales expressed his undiminished support for Wikipedia policy allowing articles to be edited by anonymous users – describing the participation of editors in China and Iran in terms of privacy issues – but announced plans to roll back their article creation privileges as part of a vandalism-control strategy: "...we've decided that we want to slow down...so starting in January we're preventing unregistered users from creating new pages, because so often those have to be deleted...". [4]

Hoax
The author of the hoax article was later identified as Brian Chase, an operations manager of Rush Delivery, a delivery service company in Nashville, Tennessee . [5] On May 26, 2005, Chase added a new article that contained, in its entirety, the following text:

Detection and correction
In September, Victor S. Johnson, Jr. , a friend of Seigenthaler's, discovered the article. [6] After Johnson alerted him to the article, Seigenthaler e-mailed his friends and colleagues about it. On September 23, 2005, colleague Eric Newton copied Seigenthaler's official biography from the Freedom Forum web site into Wikipedia. The following day, this biography was removed by a Wikipedia editor due to copyright violation , and was replaced with a short original biography. [7] Newton informed Seigenthaler of his action when he ran into Seigenthaler in November in New York at the Committee to Protect Journalists dinner.
In October 2005, Seigenthaler contacted the Chair of the Board of Trustees of the Wikimedia Foundation, Jimmy Wales , who hid affected versions of the article history from public view in the Wikipedia version logs, in effect removing them from all but Wikipedia administrators ' view. [8] In 2013, the hoax article was undeleted and archived to Wikipedia:List of hoaxes on Wikipedia . Some mirror websites not controlled by Wikipedia continued to display the older and inaccurate article for several weeks until the new version of the article was propagated to these other websites. [9]

Anonymous editor identified
Seigenthaler wrote an op-ed article describing the particulars of the incident, which appeared in USA Today , of which he had been the founding editorial director. [2] The article was published on November 29, 2005. In the article, he included a verbatim reposting of the false statements and called Wikipedia a "flawed and irresponsible research tool." An expanded version was published several days later in The Tennessean , a daily newspaper in Nashville, Tennessee, where Seigenthaler had served in various capacities from beat reporter to chairman. In the article, Seigenthaler detailed his own failed attempts to identify the anonymous person who posted the inaccurate biography. He reported that he had asked the poster's Internet service provider , BellSouth , to identify its user from the user's IP address . BellSouth refused to identify the user without a court order, suggesting that Seigenthaler file a John Doe lawsuit against the user, which Seigenthaler declined to do.
Daniel Brandt, a San Antonio activist who had started the anti-Wikipedia site "Wikipedia Watch" in response to objections he had to his eponymous article, looked up the IP address in Seigenthaler's article, and found that it related to "Rush Delivery", a company in Nashville. He contacted Seigenthaler and the media, and posted this information on his website. [10]
On December 9, Brian Chase admitted he had posted the false biography to Wikipedia because he believed Wikipedia to be "some sort of joke Web site." [11] After confessing, Chase was fired from his job at Rush Delivery. Seigenthaler received a hand-written apology [ clarification needed ] and spoke with Chase on the phone. Seigenthaler confirmed – as he had previously stated – that he would not file a lawsuit in relation to the incident, and urged Rush Delivery to rehire Chase, which it did. Seigenthaler commented: "I'm glad this aspect of it is over." He stated that he was concerned that "every biography on Wikipedia is going to be hit by this stuff – think what they'd do to Tom DeLay and Hillary Clinton , to mention two. My fear is that we're going to get government regulation of the Internet as a result." [12]

Reactions

Seigenthaler's public reaction
In his November 29, 2005, USA Today editorial, Seigenthaler criticized Congress for Section 230 of the Communications Decency Act , which protects ISPs and web sites from being held legally responsible for content posted by their customers and users: [2]
On December 5, 2005, Seigenthaler and Wales appeared jointly on CNN to discuss the matter. On December 6, 2005, the two were interviewed on National Public Radio 's Talk of the Nation radio program. Wales described a new policy that he had implemented in order to prevent unregistered users from creating new articles on the English-language Wikipedia, though their ability to edit existing articles was retained.
In the CNN interview, Seigenthaler also raised the spectre of increased government regulation of the Web:
In the December 6 joint NPR interview, Seigenthaler said that he did not want to have anything to do with Wikipedia because he disapproved of its basic assumptions. In an article Seigenthaler wrote for USA Today in late 2005, he said, "I am interested in letting many people know that Wikipedia is a flawed and irresponsible research tool." [2] He also pointed out that the false information had been online for over four months before he was aware of it, and that he had not been able to edit the article to correct it. After speaking with Wikipedia co-founder, Jimmy Wales, Seigenthaler said: "My 'biography' was posted May 26. On May 29, one of Wales' volunteers 'edited' it only by correcting the misspelling of the word 'early.' For four months, Wikipedia depicted me as a suspected assassin before I erased it from the website's history Oct. 5. The falsehoods remained on Answers.com and Reference.com for three more weeks." [2] Editing Wikipedia, he suggested, would lend it his sanction or approval, and he stated his belief that editing the article was not enough and instead he wanted to expose "incurable flaws" in the Wikipedia process and ethos.
On December 9, Seigenthaler appeared on C-SPAN 's Washington Journal with Brian Lamb hosting. He said he was concerned that other pranksters would try to spoof members of Congress or other powerful figures in government, which may then prompt a backlash and turn back First Amendment rights on the Web.
In the June 2007 issue of Reason magazine, Seigenthaler also expressed concern about the lack of transparency underlined by Wales' removal of the hoax pages from the article's history page. He has also stated that many of the comments left by users in the edit summaries are things he would not want his nine-year-old grandson to see. [13]

Wikimedia Foundation reaction
In an interview with BusinessWeek on December 13, 2005, Wales discussed the reasons the hoax had gone undetected and steps being taken to address them. [4] He stated that one problem was that Wikipedia's use had grown faster than its self-monitoring system could comfortably handle, and that therefore new page creation would be deliberately restricted to account-holders only, addressing one of Seigenthaler's main criticisms.
He also gave his opinion that encyclopedias as a whole (whether print or online) were not usually appropriate for primary sources and should not be relied upon as authoritative (as some were doing), but that nonetheless Wikipedia was more reliable as "background reading" on subjects than most online sources. He stated that Wikipedia was a "work in progress". [4]
A variety of changes were also made to Wikipedia's software and working practices, to address some of the issues arising. A new policy, ' biographies of living persons ', was created on December 17, 2005; editorial restrictions, including reference requirements, were introduced on the creation of new Wikipedia articles; and new tracking categories for the biographies of living people were implemented. [14]
The Foundation added a new level of "oversight" features to the MediaWiki software, [15] accessible as of May 16, 2012 to around 37 experienced editors and Wikimedia staff members nominated by either Wales or the Arbitration Committee . This originally allowed for specific historical versions to be hidden from everyone (including Oversight editors), which then become unable to be viewed by anyone except developers via manual intervention, though the feature was later changed so that other Oversighters could view these revisions to monitor the tool's use. Currently such procedures are standardized by the 'Office actions' policy which states: "Sometimes the Wikimedia Foundation has to delete, protect or blank a page without going through the normal site/community process(es). These edits are temporary measures to prevent legal trouble or personal harm and should not be undone by any user." [16]

Other reactions
In reaction to the controversy, The New York Times business editor Larry Ingrassia sent out a memo to his entire staff commenting on the reliability of Wikipedia and writing, "We shouldn't be using it to check any information that goes into the newspaper." [17] Several other publications commented on the incident, often criticizing Wikipedia and its open editing model as unreliable, citing the Seigenthaler incident as evidence.
The scientific journal Nature conducted a study comparing the accuracy of Wikipedia and the Encyclopædia Britannica in 42 hard sciences related articles in December 2005. The Wikipedia articles studied were found to contain four serious errors and 162 factual errors, omissions or misleading statements, while the Encyclopædia Britannica also contained four serious errors and 123 factual errors, omissions or misleading statements. [18] Referring to the Seigenthaler incident and several other controversies, the authors wrote that the study "suggests that such high-profile examples are the exception rather than the rule."

See also
WebPage index: 00134
Hillsborough Wikipedia posts
On 24 April 2014, Oliver Duggan, in the Liverpool Echo , reported that users of computers that used IP addresses registered to the Government Secure Intranet (which is used by many of the United Kingdom 's government departments ) had added derogatory and offensive material to Wikipedia articles, particularly the article about the Hillsborough disaster . [1] The vandalism was quickly re-reported by other media, and subsequent reports have highlighted other acts of vandalism , on various articles, originated by computers using those IP addresses. After an investigation by The Daily Telegraph and Wikipediocracy the person behind the edits was identified as a "junior civil servant" within the UK government and was dismissed.

Hillsborough disaster
The issue first emerged when it was reported that the entry about the Hillsborough disaster, in which 96 people died at a football match at the Hillsborough Stadium in 1989, had been altered, briefly, in 2009, [2] with a similar alteration to the Anfield article in 2012. [3] The report suggested that the edits could have been made from the Department for Culture, Media and Sport , Her Majesty's Treasury or the Office of the Solicitor General [1] since those departments use the Government Secure Intranet. However, the Cabinet Office has stated that "At this time, we have no reason to suspect that the Hillsborough edits involve any particular department, nor more than one or two individuals in 2009 and 2012." [4]
The details of the two IP addresses (195.92.40.49 and 62.25.106.209 [5] [6] ) used by computers on the Government Secure Intranet came from then-Treasury minister Angela Eagle in a reply to a parliamentary question in 2008. [1] [5] The edits, which were made in 2009 (on the disaster's 20th anniversary) and 2012, included the addition of "Blame Liverpool Fans" to the Hillsborough disaster page and adding the phrases "You'll Never Walk Again" and "yet nothing for the victims of the Heysel Stadium disaster " to mentions of the Hillsborough memorial in the Anfield article. [7]
The Cabinet Office responded to the news by saying that they were making "urgent inquiries" into these reports, and that the claims made in them were being treated with "the utmost seriousness". [8] The office also warned, however, that it might not be possible to determine exactly who used the government's computers to make the edits, saying, "As the first incident happened five years ago and there are hundreds of thousands of people on the government's network, it may prove challenging to identify who was involved, but we are exhausting every option." [4] [9] The inquiry was scheduled to be overseen—but not led—by Andy Burnham . [10] On 20 May, Burnham said the investigation had identified "strong leads" into determining who made the edits. [11]
In 2016, after the second verdict of the Hillsborough inquiry proved unlawful killing of the 96 dead due to gross negligence , the Liverpool Echo reported that edits from an IP associated with Warwickshire County Council (WCC) added the phrase "You'll never walk again" eight times in the lead of the Hillsborough disaster page. [12] A WCC spokesperson told the newspaper: "WCC IP addresses also include our publicly used machines in libraries that can be used by members of the public. The information has been passed onto the head of our IT team and we are going to be investigating." [13]

Other articles
On 26 April, the Belfast Telegraph reported that one of the edits made via a government IP address (to the Wikipedia entry for Howick Falls ) had mentioned "killing or enslaving" black people and suggested that they believe "hearsay and myth". [14]
The Daily Telegraph reported on 27 April that government computers had been used to maliciously alter articles about prominent people, including falsifying the death of television sports presenter Des Lynam . Other public figures targeted include Michael Grade and Chris Evans . [15] On the same day, The Herald in Glasgow reported that the articles for Clydebank and Barlanark , had been vandalized by government computers. [16] Also that day, the National Post reported that a government computer had also targeted the page about Canadian author David Gilmour , which was vandalized to describe him as a "misogynist, homophobe [and] racist". [17]
On 29 April, the BBC reported the results of its investigation into the edits carried out by computers using the two IP addresses. It found more than one hundred edits that it categorised as "inappropriate editing, vandalism and deletion". The BBC gave no time scale for these edits but did reveal that edits were made in 2005 and 2006 and that "several of the offensive messages were made prior to the government IP addresses being disclosed in 2008".
The most serious edit was a change to the veil article, in October 2006, which included the phrase "all Muslims are terrorists". [18] This change was removed six minutes later. Also highlighted was the removal of details, in October 2005, of the controversy regarding flat purchases by Cherie Blair . Other edits mentioned by the BBC were the editing of the 7 July 2005 London bombings article to add conspiracy theories; and the vandalism, usually with insults and sometimes with page blanking, of the Tony Blair , Richard Littlejohn , Jamie Oliver , Libertines , Wayne Rooney , Christopher Byrne , Peter Levy and Arsène Wenger articles.
Regarding the edits, while stating that the vandalism was appalling, a spokesman for Wikimedia UK pointed out that, "Edits of this nature are removed very quickly by the volunteers who write and edit Wikipedia, often in a matter of minutes." He also expanded on the nature of the editing process, saying "Wikipedia is the encyclopaedia that anyone can edit. This openness has led to an enormous reference work of great value. While vandalism does occasionally happen we are grateful to the many thousands of volunteers who write, edit and organise the content." [6]

Reactions
Jon Davies, chief executive of Wikimedia UK , said it was "appalled by such vandalism" but added that, "In this case, none of the offensive comments were up for more than a couple of hours, and most were removed in a few minutes." [8]
The Cabinet Office described the edits in question as "sickening". "The behaviour is in complete contravention of the Civil Service Code . It is entirely unacceptable," they added. [6]
Sheila Coleman of the Hillsborough Justice Campaign called the edits "absolutely disgusting" and said the relatives of the Hillsborough disaster victims would demand a formal inquiry. [1]
A critic of Wikipedia , Nigel Scott, writing in Spiked , sought to place the incident in the context of what he sees as Wikipedia's structural flaws, saying, "Wikipedia is not blameless in this. It allows misinformation to flourish and provides it with a cloak of respectability. It is under-resourced and is unable to police itself adequately." However, the main focus of his argument was other Wikipedia controversies , including the creation of the Bicholim conflict article, accusations of editing on behalf of Chuka Umunna and the Wiki-PR editing of Wikipedia . [19]

Result of the investigation
From May to June 2014, Wikipediocracy , a website critical of Wikipedia, as well as The Daily Telegraph identified the culprit behind the offending edits to Wikipedia. Using the results of the investigation published in the Telegraph , the UK government identified and took action against the suspect. [20] In June 2014, an unnamed 24-year-old civil servant , who was born in London but lives in Liverpool, was sacked for posting offensive comments about the disaster on Wikipedia. [21] After the sacking, the United Kingdom government issued new rules for its civil servants with regard to editing Wikipedia. The guidelines include the statement that anyone making inappropriate edits will be disciplined. [22]
WebPage index: 00135
Princess of Asturias Awards
The Princess of Asturias Awards [1] (Spanish: Premios Princesa de Asturias , Asturian : Premios Princesa d'Asturies ), formerly the Prince of Asturias Awards from 1981–2014 (Spanish: Premios Príncipe de Asturias ) are a series of annual prizes awarded in Spain by the Princess of Asturias Foundation (previously the Prince of Asturias Foundation) to individuals, entities or organizations from around the world who make notable achievements in the sciences, humanities, and public affairs.
The prize was established on 24 September 1980 by the then twelve-year-old Felipe, Prince of Asturias , heir to the throne of Spain , "to consolidate links between the Principality and the Prince of Asturias, and to contribute to, encourage and promote scientific, cultural and humanistic values that form part of mankind's universal heritage." [2] The awards are presented at the Campoamor Theatre in Oviedo , the capital of the Principality of Asturias . A sculpture, expressly created for the prize by Spanish sculptor Joan Miró , is presented yearly to the recipients of the prize.
Following the accession of Felipe VI as King of Spain on 19 June 2014, it was announced that, beginning in 2015, the foundation and the awards are to be renamed the Princess of Asturias Awards to reflect the new heir presumptive to the Spanish throne, Leonor, Princess of Asturias . [3] King Felipe will continue to preside over the awards ceremony until the Princess of Asturias reaches majority age on 31 October 2023. In 2015, Wikipedia won the prize in the International Cooperation category. [4]

Categories

Arts (Artes)

Communications and Humanities (Comunicación y Humanidades)

International Cooperation (Cooperación Internacional)

Literature (Letras)

Social Sciences (Ciencias Sociales)

Sports (Deportes)

Technical and Scientific Research (Investigación Científica y Técnica)

Concord (Concordia)

Exemplary Town of Asturias (Pueblo Ejemplar de Asturias)
Every year, a town or community organization in the Principality of Asturias is chosen to receive this award, a royal visit, and a prize of €25,000. [5]

See also
WebPage index: 00136
List of Wikipedia mobile applications
A number of organizations within the Wikimedia movement including the Wikimedia Foundation publishes official Wikipedia mobile apps for using Wikipedia on multiple mobile device operating systems . All are available for free via the appropriate app store : Android (via Google Play ), iOS (via App Store ), Firefox OS (via Firefox Marketplace), and Windows 8 (via Windows Store ). They can also be downloaded independently of any third party store, from the Wikimedia Foundation's " releases " website, which also keeps old and beta versions .
Independent developers have also released many unofficial apps for reading Wikipedia articles. Some apps load content from the Wikipedia site and process it; other apps use the MediaWiki API . Some only display Wikipedia content, usually omitting some features such as categories and talk pages. Some allow editing.

Official apps

Wikimedia Foundation
Wikipedia apps from the Wikimedia Foundation are called "Wikipedia", except for the iOS version which is called "Wikipedia Mobile".

Wikimedia Switzerland
Wikimedia CH , the Swiss chapter of the Wikimedia movement, has developed a number of offline apps based on Wikipedia content.

Unassociated apps
These apps were mainly developed to display articles and are often used on platforms for which an official Wikipedia app is not available, such as Windows Phone . Typical features include searching for articles, bookmarks , sharing, or enlarging images .

Related apps
A number of apps for Wikipedia's sister projects exist. These include the Wiki Loves Monuments app, written for a 2012 photo contest, is an aid for Wikiphotographers. It shows a map of nearby national heritage register items, indicating whether Wikipedia had a photo for the site, and enabling quick and easy photo uploads for camera phones. It is not integrated with the official article display app. [15]
There are also an iOS and Android app for Wikimedia Commons [16] and an Android app for Wiktionary . [17]
WebPage index: 00137
WikiReader
WikiReader is a project to deliver an offline, text-only version of Wikipedia on a mobile device. [1] The project is sponsored by Openmoko and its source code has been released. [2]
The project debuted an offline portable reader for Wikipedia in October 2009. [1] Updates in multiple languages are available online; [3] Wikireader versions of the English Wikipedia, Wiktionary, Wikiquote and Project Gutenberg can be installed together on a user-supplied 16 GB Micro SDHC Memory Card. Unlike Wikipedia itself, the device features parental controls . [4]
The device can also run programs written in Forth ; a simple calculator program is included. [5]
In late 2014, the WikiReader website and project itself were shut down and abandoned for unknown reasons. Their website now redirects to the GitHub page that contains the WikiReader source code. Existing WikiReaders no longer receive updates to their database. Devices and homegrown updates are only available from the secondary markets.

Specifications

Limitations

See also
WebPage index: 00138
Magna Carta (An Embroidery)
Magna Carta (An Embroidery) is a 2015 work by English installation artist Cornelia Parker . [1] The artwork is an embroidered representation of the complete text and images of an online encyclopedia article for Magna Carta , as it appeared in English Wikipedia on 15 June 2014 , the 799th anniversary of the document. [1]
The hand-stitched embroidery is 1.5 metres wide and nearly 13 metres long. It is a response to the legacy of Magna Carta in the digital era and Parker has referred to it as "a snapshot of where the debate is right now", the result of all open edits by English Wikipedians up to that date. [1] It was commissioned by the Ruskin School of Art at the University of Oxford in partnership with the British Library, [2] after being chosen from proposals from a shortlist of artists in February 2014. [3]
Parker used a screenshot from the 15 June 2014 English Wikipedia article for Magna Carta and printed it onto fabric. Like English Wikipedia, the embroidery was created through the collaboration of many individuals. It was divided in 87 sections and sent to 200 individuals who each hand-stitched portions of the artwork. She sought the collaboration of people and groups that have been affected by and associated with Magna Carta. [4] The majority of the text was sewn by prisoners. [5] Members of the Embroiderers' Guild stitched the images, with at least one embroiderer selected from each region of the UK. [6] Many celebrities and public figures also contributed, stitching phrases or words of special significance to them. [7] Parker has represented the work as "Echoing the communal activity that resulted in the Bayeux Tapestry , but on this occasion placing more emphasis on the word rather than the image, I wanted to create an artwork that is a contemporary interpretation of Magna Carta." [1]
The work includes a tea stain from a prisoner and a spot of blood from Guardian editor Alan Rusbridger , who accidentally pricked his finger while sewing. [7]
Magna Carta (An Embroidery) is part of an exhibition celebrating the 800th anniversary of Magna Carta. It was displayed in the Entrance Hall of the British Library from 15 May until 24 July 2015, [1] at the Whitworth Gallery August - November 2016, and in the Blackwell Hall of the Bodleian Library , Oxford from 11 November 2015 to 3 January 2016, touring other United Kingdom locations in the rest of 2016 and 2017. [8]

Embroiderers
Parker invited some 200 people to hand-stitch portions of the work including prison inmates, civil rights campaigners, MPs, lawyers, barons and artists. [1] Much of the work was done by 36 prisoners from 13 different prisons in England, under the supervision of the social enterprise Fine Cell Work. [9] Members of the Embroiderers' Guild contributed the images as did students from the Royal School of Needlework and the embroidery company Hand & Lock.
Six students from La Retraite Roman Catholic Girls' School , London were the youngest contributors to the work. [10]
Parker invited royalty to contribute to the work, but they declined. She said that right-wing people were more likely to decline; both Gordon Brown and Alex Salmond also declined to contribute. [11]
WebPage index: 00139
List of wiki software
This is a list of notable wiki software applications. For a comparative table of such software, see Comparison of wiki software . For a list of wikis , or websites using wiki software, see List of wikis .

Standard wiki programs, by programming language

JavaScript-based

Java-based

Perl-based

PHP-based

Python-based

Ruby-based

Other languages

Personal wiki software

Hosted-only software

Content management/social software with wiki functionality

Java-based

Perl-based

PHP-based

Other languages

Project management software with wiki functionality

See also
WebPage index: 00140
Aaron Halfaker
Aaron Halfaker ( / ˈ h æ f eɪ k ər / ) is an American computer scientist and the Wikimedia Foundation 's principal research scientist. [4] [5]

Education and career
Halfaker earned a B.S. in computer science from the College of St. Scholastica in 2006, where he started off as a physical therapy major but switched to computer science after taking a programming class with associate professor Diana Johnson. [6] He later earned a Ph.D. in computer science from the GroupLens research lab at the University of Minnesota in 2013. He is known for his research on Wikipedia and the decrease in the number of active editors of the site. [7] [8] [9] He has said that Wikipedia began a "decline phase" around 2007 and has continued to decline since then. [10] [11] Halfaker has also studied automated accounts on Wikipedia, known as bots , [12] and the way they affect new contributors to the site. [4] While a graduate student, he, along with Stuart Geiger , developed a tool for Wikipedia editing called " Snuggle ", the goal of which is to eliminate vandalism and spam, and to also highlight constructive contributions by new editors. [13] [14] He has also built an artificial intelligence engine known as "Objective Revision Evaluation Service" (or ORES for short), used to identify vandalism on Wikipedia and distinguish it from good faith edits. [15] [16]
WebPage index: 00141
Bishakha Datta
Bishakha Datta is an Indian film maker, activist and a former journalist. [1] She is the co-founder and executive director of Point of View , based in Mumbai, a non-profit working in the area of gender, sexuality and women's rights. [2] She also serves on the board of nonprofit organizations including Creating Resources for Empowerment in Action and the Wikimedia Foundation (2010-2014), [3] where she was the first Indian to serve on the board of trustees . [1] [4]

Life and works
In 1998, Datta edited And Who Will Make the Chapatis? , an overview of the all-women political panchayats formed in Maharashtra , India. [5] In 2003, her documentary In the Flesh: three lives in prostitution was released. [6] [7]
WebPage index: 00142
Wikisource
Wikisource is an online digital library of free content textual sources on a wiki , operated by the Wikimedia Foundation . Wikisource is the name of the project as a whole and the name for each instance of that project (each instance usually representing a different language); multiple Wikisources make up the overall project of Wikisource. The project's aims are to host all forms of free text, in many languages, and translations. Originally conceived as an archive to store useful or important historical texts (its first text was the Déclaration universelle des Droits de l'Homme ), it has expanded to become a general-content library. The project officially began in November 24, 2003 under the name Project Sourceberg . The name Wikisource was adopted later that year and it received its own domain name seven months later. The project has come under criticism for lack of reliability but it is also cited by organisations such as the National Archives and Records Administration . [3]
The project holds works that are either in the public domain or freely licensed ; professionally published works or historical source documents, not vanity products ; and are verifiable. Verification was initially made offline, or by trusting the reliability of other digital libraries. Now works are supported by online scans via the ProofreadPage extension, which ensures the reliability and accuracy of the project's texts.
Some individual Wikisources, each representing a specific language, now only allow works backed up with scans. While the bulk of its collection are texts, Wikisource as a whole hosts other media, from comics to film to audio books . Some Wikisources allow user-generated annotations, subject to the specific policies of the Wikisource in question.

History
Wikisource's early (2003–2005) history included several changes of name and location ( URL ), and the move to language subdomains in 2005.

Early history
The original concept for Wikisource was as storage for useful or important historical texts. These texts were intended to support Wikipedia articles, by providing primary evidence and original source texts, and as an archive in its own right. The collection was initially focused on important historical and cultural material, distinguishing it from other digital archives such as Project Gutenberg. [2]
The project was originally called Project Sourceberg during its planning stages (a play on words for Project Gutenberg ). [2]
In 2001, there was a dispute on Wikipedia regarding the addition of primary source material, leading to edit wars over their inclusion or deletion. Project Sourceberg was suggested as a solution to this. In describing the proposed project, user The Cunctator said, "It would be to Project Gutenberg what Wikipedia is to Nupedia ," [4] soon clarifying the statement with "we don't want to try to duplicate Project Gutenberg's efforts; rather, we want to complement them. Perhaps Project Sourceberg can mainly work as an interface for easily linking from Wikipedia to a Project Gutenberg file, and as an interface for people to easily submit new work to PG." [5] Initial comments were sceptical, with Larry Sanger questioning the need for the project, writing "The hard question, I guess, is why we are reinventing the wheel, when Project Gutenberg already exists? We'd want to complement Project Gutenberg--how, exactly?", [6] and Jimmy Wales adding "like Larry, I'm interested that we think it over to see what we can add to Project Gutenberg. It seems unlikely that primary sources should in general be editable by anyone -- I mean, Shakespeare is Shakespeare, unlike our commentary on his work, which is whatever we want it to be." [7]
The project began its activity at ps.wikipedia.org. The contributors understood the "PS" subdomain to mean either "primary sources" or Project Sourceberg. [4] However, this resulted in Project Sourceberg occupying the subdomain of the Pashto Wikipedia (the ISO language code of the Pashto language is "ps").
Project Sourceberg officially launched on November 24, 2003 when it received its own temporary URL, at sources.wikipedia.org, and all texts and discussions hosted on ps.wikipedia.org were moved to the temporary address. A vote on the project's name changed it to Wikisource on December 6, 2003. Despite the change in name, the project did not move to its permanent URL (at http://wikisource.org/ ) until July 23, 2004. [8]

Logo and slogan
Since Wikisource was initially called "Project Sourceberg", its first logo was a picture of an iceberg . [2] Two votes conducted to choose a successor were inconclusive, and the original logo remained until 2006. Finally, for both legal and technical reasons – because the picture's license was inappropriate for a Wikimedia Foundation logo and because a photo cannot scale properly – a stylized vector iceberg inspired by the original picture was mandated to serve as the project's logo.
The first prominent use of Wikisource's slogan — The Free Library — was at the project's multilingual portal , when it was redesigned based upon the Wikipedia portal on August 27, 2005, (historical version). [9] As in the Wikipedia portal the Wikisource slogan appears around the logo in the project's ten largest languages.
Clicking on the portal's central images (the iceberg logo in the center and the "Wikisource" heading at the top of the page) links to a list of translations for Wikisource and The Free Library in 60 languages.

Tools built
A MediaWiki extension called ProofreadPage was developed for Wikisource by developer ThomasV to improve the vetting of transcriptions by the project. This displays pages of scanned works side-by-side with the text relating to that page, allowing the text to be proofread and its accuracy later verified independently by any other editor. [10] [11] [12] Once a book, or other text, has been scanned, the raw images can be modified with image processing software to correct for page rotations and other problems. The retouched images can then be converted into a PDF or DjVu file and uploaded to either Wikisource or Wikimedia Commons . [10]
This system assists editors in ensuring the accuracy of texts on Wikisource. The original page scans of completed works remain available to any user so that errors may be corrected later and readers may check texts against the originals. ProofreadPage also allows greater participation, since access to a physical copy of the original work is not necessary to be able to contribute to the project once images have been uploaded. Thus it enhances the project's commitment to the Wikimedia principle that anyone can contribute.
ThomasV built other tools as well: when the choice of whether publishing annotations or not was discussed, he made a gadget to offer the choice between texts alone or annotated texts. When the choice of modernizing or not the texts was discussed, he made another gadget to modernize the original text only when it was wished, so that it could be decided then that the texts themselves would be the original ones.

Milestones
Within two weeks of the project's official start at sources.wikipedia.org, over 1,000 pages had been created, with approximately 200 of these being designated as actual articles. On January 4, 2004, Wikisource welcomed its 100th registered user. In early July, 2004 the number of articles exceeded 2,400, and more than 500 users had registered. On April 30, 2005, there were 2667 registered users (including 18 administrators) and almost 19,000 articles. The project passed its 96,000th edit that same day. [ citation needed ]
On November 27, 2005, the English Wikisource passed 20,000 text-units in its third month of existence, already holding more texts than did the entire project in April (before the move to language subdomains). On February 14, 2008, the English Wikisource passed 100,000 text-units with Chapter LXXIV of Six Months at the White House , a memoir by painter Francis Bicknell Carpenter . [13] In November, 2011, 250,000 text-units milestone was passed. But counting was difficult because what a text-unit is, could not be clearly defined.
On May 10, 2006, the first Wikisource Portal was created.

Library contents
Wikisource collects and stores in digital format previously published texts; including novels, non-fiction works, letters, speeches, constitutional and historical documents, laws and a range of other documents. All texts collected are either free of copyright or released under the Creative Commons Attribution/Share-Alike License . [2] Texts in all languages are welcome, as are translations. In addition to texts, Wikisource hosts material such as comics, films, recordings and spoken-word works. [2] All texts held by Wikisource must have been previously published; the project does not host " vanity press " books or documents produced by its contributors. [2] [14] [15] [16] [17]
A scanned source is preferred on many Wikisources and required on some. Most Wikisources will, however, accept works transcribed from offline sources or acquired from other digital libraries . [2] The requirement for prior publication can also be waived in a small number of cases if the work is a source document of notable historical importance. The legal requirement for works to be licensed or free of copyright remains constant.
The only original pieces accepted by Wikisource are annotations and translations. [18] Wikisource, and its sister project Wikibooks , has the capacity for annotated editions of texts. On Wikisource, the annotations are supplementary to the original text, which remains the primary objective of the project. By contrast, on Wikibooks the annotations are primary, with the original text as only a reference or supplement, if present at all. [17] Annotated editions are more popular on the German Wikisource. [17] The project also accommodates translations of texts provided by its users. A significant translation on the English Wikisource is the Wiki Bible project, intended to create a new, "laissez-faire translation" of The Bible . [19]

Structure

Language subdomains
A separate Hebrew version of Wikisource ( he.wikisource.org ) was created in August 2004. The need for a language-specific Hebrew website derived from the difficulty of typing and editing Hebrew texts in a left-to-right environment (Hebrew is written right-to-left). In the ensuing months, contributors in other languages including German requested their own wikis, but a December vote on the creation of separate language domains was inconclusive. Finally, a second vote that ended May 12, 2005, supported the adoption of separate language subdomains at Wikisource by a large margin, allowing each language to host its texts on its own wiki.
An initial wave of 14 languages was set up by Brion Vibber on August 23, 2005. [20] The new languages did not include English, but the code en: was temporarily set to redirect to the main website ( wikisource.org ).
At this point the Wikisource community, through a mass project of manually sorting thousands of pages and categories by language, prepared for a second wave of page imports to local wikis. On September 11, 2005, the wikisource.org wiki was reconfigured to enable the English version , along with 8 other languages that were created early that morning and late the night before. [21]
Three more languages were created on March 29, 2006, [22] and then another large wave of 14 language domains was created on June 2, 2006. [23] Currently, there are individual subdomains for Wikisources in more than 60 languages, [24] besides the additional languages hosted at wikisource.org , which serves as an incubator or a home for languages without their own subdomains (31 languages are currently hosted locally )

wikisource.org
During the move to language subdomains, the community requested that the main wikisource.org website remain a functioning wiki, in order to serve three purposes:
The idea of a project-specific coordination wiki, first realized at Wikisource, also took hold in another Wikimedia project, namely at Wikiversity 's Beta Wiki . Like wikisource.org, it serves Wikiversity coordination in all languages, and as a language incubator. But unlike Wikisource, its Main Page does not serve as its multilingual portal [26] (which is not a wiki page).

Reception
Larry Sanger has criticised Wikisource, and sister project Wiktionary , because the collaborative nature and technology of these projects means there is no oversight by experts and therefore their content is not reliable. [27]
Bart D. Ehrman , a New Testament scholar and professor of religious studies at the University of North Carolina at Chapel Hill , has criticised the English Wikisource's project to create a user-generated translation of The Bible saying "Democratization isn't necessarily good for scholarship." [19] Richard Elliott Friedman , an Old Testament scholar and professor of Jewish studies at the University of Georgia , has identified errors in the translation of the Book of Genesis . [19]
In 2010, Wikimedia France signed an agreement with the Bibliothèque nationale de France (National Library of France) to add scans from its own Gallica digital library to French Wikisource. 1,400 public domain French texts were added to the Wikisource library as a result via upload to the Wikimedia Commons . The quality of the transcriptions, previously automatically generated by optical character recognition (OCR), were expected to be improved by Wikisource's human proofreaders. [28] [29] [30]
In 2011, the English Wikisource received many high-quality scans of documents from the National Archives and Records Administration (NARA) as part of their efforts "to increase the accessibility and visibility of its holdings." Processing and upload to Commons of these documents, along with many images from the NARA collection, was facilitated by a NARA Wikimedian in residence , Dominic McDevitt-Parks. Many of these documents have been transcribed and proofread by the Wikisource community and are featured as links in the National Archives' own online catalog. [31]

See also
WebPage index: 00143
Finnish Wikipedia
The Finnish Wikipedia ( Suomenkielinen Wikipedia ) is the edition of Wikipedia in the Finnish language . By article count, it is the 22th largest Wikipedia with about 414,000 articles as of May 2017. [1] Wikipedia is the only encyclopedia in Finnish which is still updated. [2]
The Finnish language project was started in late 2002, but it remained at a very primitive stage until well into 2003. The speed of development picked up somewhat after the MediaWiki software was upgraded to Phase III in late November, 2003, and continued to increase steadily through 2004.
Despite the small number of native Finnish speakers and the high number of Finnish speakers who are also fluent in English , the Finnish Wikipedia is currently the 20th largest Wikipedia with over 250,000 articles. The ratio of Finnish language Wikipedia articles to the number of Finnish speakers is the 16th-largest at 82.7 articles per 1000 speakers. [3] These figures were based on Ethnologue 's estimate of 5,009,390 Finnish-speakers.
In 2013 the reliability of the Finnish Wikipedia was investigated by the newspaper Helsingin Sanomat . The researchers used experts to evaluate quality of randomly selected 134 articles and found that 70% of the articles scored well for accuracy. [2] [4]

Milestones

Notes

External links
WebPage index: 00144
Romanian Wikipedia
The Romanian Wikipedia (abr. ro.wiki or ro.wp ; [1] in Romanian: Wikipedia în limba română ) is the Romanian language edition of Wikipedia , the free encyclopedia . Started in July 2003, as of 24 May 2017 this edition has about 376,511 articles and is the 25th largest Wikipedia edition. [2] In December 2004, users on the Romanian Wikipedia started to talk about founding a local chapter of Wikimedia, Asociaţia Wikimedia România .

History
The first articles in the Romanian Wikipedia were written in July 2003, with the first version of the main page being drafted on 12 July. The user interface, initially in English, started being translated into Romanian by Bogdan Stăncescu (registered with the username Gutza) as soon as he was given sysop rights. [3] The same user subsequently contacted several Romanian universities that were available on the internet, as well as the Romanian Academy , in order to attract new contributors. His efforts were soon remarked by the Romanian media, who invited him on several occasions to introduce the project to the public. [4] [5] By the end of 2003, the Romanian Wikipedia had exceeded 3,000 articles, ranking 16th among all Wikipedias. The 10,000th article was written on 13 December 2004, and the 50,000th on 5 January 2007.
In April 2004, the Romanian Wikipedia supported the launch of the Aromanian Wikipedia (see Aromanian language ).
In June 2004, the Romanian Wikipedia encountered problems concerning its division and the creation of a separate Moldovan Wikipedia (see Moldovan language ). A Moldovan language version of Wikipedia exists as it was created automatically together with a larger number of other Wikipedias, because the language had been assigned a separate ISO 639 code ( mo/mol —which were deprecated in November 2008 by the ISO authorities [6] ). At its beginnings, it worked as a portal redirecting to the Romanian Wikipedia, but in March 2005, it eventually began allowing content (although only intended for Cyrillic Moldovan/Romanian as it was used before 1989 in the Moldavian SSR and remains in use only in Transnistria ), starting big editing wars and endless discussion. Starting from December 2006 it is frozen and editing is no longer permitted. This question is still raised from time to time, although users on Wikipedia voted on its closure. [7]
The Romanian Wikipedia reached the 100,000 article milestone on 11 January 2008. As of April 2015, it has 300,000 articles and 330,000 registered users, of which 21 are administrators.

Peculiarities
The logo of the Romanian Wikipedia was slightly different from the logos of other Wikipedias. The letter И in the logo was replaced with the Romanian letter Ă (A-breve), further adapting this Wikipedia to the local readership. [8]
Articles can contain small spelling variations, mostly regarding the use of the letters â and î , both used for the close central unrounded vowel /ɨ/ (cf. Romanian alphabet ). According to the 1993 spelling rules promoted by the Romanian Academy , /ɨ/ is transcribed as either î , when used as the first or last letter of words, or â , when it occurs in the middle of the word (with some exceptions). Still, between 1953 and 1993, the Romanian language only used î - after 1964 an exception was made for derivations of the words România ("Romania"), român ("Romanian") and related words. The Academy rules are mandatory in government organisations and in state schools in Romania . Moldova adopted the Latin alphabet for the Romanian language before the spelling reform in 1993, and it didn't switch to the new spelling up until 2001, using the letter î before exclusively (exceptions were made for România and the other related words, spelled with â ). In practice, either usage is acceptable in both countries, and indeed there are publishing houses and printed magazines that use either or both of the two rules. Vojvodina uses the new Romanian spelling. Other spelling differences include sunt / sînt or niciun / nici un . The Romanian Wikipedia community adopted a language policy stating that both pre-1993 and post-1993 spelling norms are permitted, and editing an article just to switch it from one norm to the other is not acceptable; switching is allowed if the article is significantly expanded or rewritten. [9]
Concerning the addressing policy, Romanian Wikipedia uses the polite forms of the personal pronouns and verbs. A policy on this was discussed in early 2006, and consensus was reached for the use of dumneavoastră (polite "you") instead of tu (familiar "you") on its pages. [10]

Timeline
Ref. [19]
WebPage index: 00145
Malay Wikipedia
Malay Wikipedia ( Malay : Wikipedia Bahasa Melayu , Jawi script : ويکيڤيديا بهاس ملايو , abbreviation : mswiki ) is the Malay edition of Wikipedia . This edition was started in October 26, 2002 and has about 178,000 articles in February 2013 and is the 30th largest Wikipedia. The system was activated by Wikipedia administrator Brion Vibber. [1] [2]
Despite the similarities between Malay and Indonesian , the Malay Wikipedia and Indonesian Wikipedia were started separately by two different user groups. The Indonesian Wikipedia was started about six months after the Malay Wikipedia was. As of 2009, the Indonesian Wikipedia had three times the number of active editors and articles the Malay Wikipedia had. In 2009 Andrew Lih wrote "Because these groups are drawn on national boundaries, merging is not likely to happen soon." [3]

Milestones

Gallery
WebPage index: 00146
List of Wikipedias
This is a list of the different language editions of Wikipedia ; as of 25 May 2017 there are 296 Wikipedias of which 285 are active.

Wikipedia edition codes
Each Wikipedia has a code, which is used as a subdomain below wikipedia.org. Interlanguage links are sorted by that code. The codes represent the language codes defined by ISO 639-1 and ISO 639-3 , and the decision of which language code to use is usually determined by the IETF language tag policy. Wikipedias also vary by how thinly they slice dialects and variants; for example, the English Wikipedia includes most modern varieties of English (American English, Indian English, South African English, etc.), but does not include other related languages such as Scots , or Anglo-Saxon , all of which have separate Wikipedias. The Spanish Wikipedia includes both Peninsular Castilian and Latin American Spanish ; Malay Wikipedia includes a large number of Malay languages; and so on.
Differences between the ISO mappings and Wikipedia codes include:
Additionally, Wikipedias vary in wikt:orthography at times. Chinese Wikipedia automatically translates from modern Mandarin Chinese into four standard forms: Mainland China and Singapore in simplified Chinese characters, and Taiwan and Hong Kong / Macau in traditional Chinese characters. Belarussian , however, has a separate Wikipedia for the 'normative' orthography (be) and Taraškievica (be-tarask).

List
An approximation to the number of active users is given in powers of ten (see common logarithm ): so "5" means at least 10,000, "4" means at least 1000, "3" means at least 100, and so on.

Detailed list

Notes

Grand total

See also
WebPage index: 00147
Croatian Wikipedia
The Croatian Wikipedia ( Croatian : Wikipedija na hrvatskom jeziku ) is the Croatian version of Wikipedia , the free encyclopedia , started on February 16, 2003. [1] This version has 173,838 articles and a total of 5.06 million edits have been made (live count). It has 178,505 registered user accounts, out of which 470 are active (defined as having performed an action on Wikipedia in the last 30 days), and the number of administrators is 25.
In late 2013, the Croatian Wikipedia received attention from international media for promoting a fascist worldview as well as bias against Serbs of Croatia and anti-LGBT propaganda by the means of historical revisionism and by negating or diluting the severity of crimes committed by the Ustaše regime.
Throughout 2014, fewer than two dozen editors made more than 100 edits a month; around 150 made more than 5 edits a month. [2] Over 500 articles are ranked as featured ( Croatian : Izabrani članci ). [3]

2011 reliability analysis
In a study by Kubelka and Šoštarić from 2011, the reliability of the Croatian Wikipedia was compared to the Croatian Encyclopedia - the Croatian national encyclopedia. [4] Twenty-four reviewers, experts in specific fields, analyzed a representative selection of articles according to the parameters of informativeness, accuracy of presented information, sufficiency, direction and objectivity. Articles were analyzed in 11 thematic categories: arts and culture; history and biographies; medicine and health; technology and applied science; geography; religion; science; mathematics and logic; philosophy; sport and society; and social sciences. Articles were sorted into categories using machine learning techniques, and feature weight statistics were calculated using tf–idf . A total of 500 articles in 250 pairs were randomly chosen and sorted into categories to serve as representative samples . [5]
In both samples facts were manually enumerated - 3015 from the Croatian Encyclopedia and 3315 from Croatian Wikipedia. Comparison for factual accuracy showed that for every error in the Croatian Encyclopedia 2.25 errors were found in Croatian Wikipedia. [6] Analysis by individual categories showed that most errors in Croatian Wikipedia were in the philosophy category, where on average two errors in ten articles were found. The only category where the Croatian Encyclopedia had more errors was natural sciences, where the ratio was 1.25:0.75 in favor of Croatian Wikipedia. [7] Of those factual errors, the ratio was 21:12 for major errors, and 34:23 for minor errors. The overall ratio for minor factual errors was thus lower, the only exception being the society and social sciences category, where the minor error ratio was 3:1.
The reliability analysis for Croatian Wikipedia indicated that 74% of articles were error-free, and 11% had minor errors. Major factual errors were found in 5% of articles, while 4% of articles had both major and minor errors. Overall 85% of articles were deemed "satisfactory" (error-free and containing minor errors), while in comparison 92% of articles in the Croatian Encyclopedia achieved the same rating. [8] Forty percent of articles in Croatian Wikipedia were assessed as sufficiently informative, as opposed to sixty-two percent of articles in the Croatian Encyclopedia . Sixteen percent of Croatian Wikipedia articles were assessed as "insufficiently informative", as opposed to five percent of articles from the Croatian Encyclopedia . [9] The criterion of objectivity measured the neutral point of view in articles; 91% of Croatian Wikipedia articles were assessed as being neutral, as opposed to 98% in the Croatian Encyclopedia . Two percent of Croatian Wikipedia articles were assessed as non-neutral, as opposed to zero in the Croatian Encyclopedia . [9] According to their subjective preference, reviewers chose 53% of articles in the Croatian Encyclopedia as their preferred article version, while only 19.5% of Wikipedia articles were preferred, with 27% of articles being assessed as equal in quality. [10]

2013 controversy about right-wing bias

Media reports about bias
In September 2013, complaints about right-wing bias of administrators and editors on the Croatian Wikipedia began to receive attention by the media, following the launch of a Facebook page titled Razotkrivanje sramotne hr.wikipedije ( Exposing the Disgraceful hr.Wikipedia ) which was created with the intent of bringing attention to the issues. [11] Reported examples of bias include historical revisionism such as watering-down and denial of the crimes committed by the Ustaše regime, and equating anti-fascism with forms of totalitarianism . [12] Other issues included the bias against Serbs of Croatia and the LGBT population. [13] [14] Editors who tried to remove the biased sections were reportedly being harassed by administrators and quickly received permanent blocks under various pretexts. [15] The issue was reported by Croatia's daily Jutarnji list and even made its print edition's front page on 11 September 2013. [16]

Statements by Željko Jovanović
Two days later, Croatia's Minister of Science, Education and Sports, Željko Jovanović , called for pupils and students in Croatia to avoid using the Croatian Wikipedia. [17] In an interview given to Novi list , Jovanović said that "the idea of openness and relevance as a knowledge source that Wikipedia could and should represent has been completely discredited – which, for certain, has never been the goal of Wikipedia's creators nor the huge number of people around the world who share their knowledge and time using that medium. Croatian pupils and students have been wronged by this, so we have to warn them, unfortunately, that a large part of the content of the Croatian version of Wikipedia is not only dubious but also [contains] obvious forgeries, and therefore we invite them to use more reliable sources of information, which include Wikipedia in English and in other major languages of the world." [17] Jovanović has also commented on the Croatian Wikipedia editors – calling them a "minority group that has usurped the right to edit the Croatian-language Wikipedia". [17]

Interviews with historians
In an interview given to Index.hr , Robert Kurelić, a professor of history at the Juraj Dobrila University of Pula , has commented that "the Croatian Wikipedia is only a tool used by its administrators to promote their own political agendas, giving false and distorted facts". [18] As two particularly prominent examples he listed the Croatian Wikipedia's coverage of the term Istrijanstvo ( Istrian regionalism ), defined as a "movement fabricated to reduce the number of Croats", and antifašizam ( anti-fascism ), which according to him is defined as the opposite of what it really means. [18] Kurelić further advised "that it would be good if a larger number of people got engaged and started writing on Wikipedia", because "administrators want to exploit high-school and university students, the most common users of Wikipedia, to change their opinions and attitudes, which presents a serious issue". [18]
Snježana Koren, a historian at the Faculty of Humanities and Social Sciences, University of Zagreb , has judged the disputed articles as "biased and malicious, partly even illiterate", in an interview with Croatian news agency HINA . [19] She further added that "These are the types of articles you can find on the pages of fringe organizations and movements, but there should be no place for that on Wikipedia", expressing doubts on the ability of its authors to distinguish good from evil. [19] Koren concludes that the ulterior motive of such writings is to rehabilitate the Independent State of Croatia , a Nazi Germany puppet state , and that "there is no other way to characterize such efforts than as Ustashi movement ". [19]

Milestones
WebPage index: 00148
Galician Wikipedia
The Galician Wikipedia ( Galician : Wikipedia, A enciclopedia libre en galego ; also shortened to Galipedia ), is the Galician version of Wikipedia , the free encyclopedia . It all began on 8 March 2003. This version now has 122.978 articles (as of June 2015). The milestone of 100,000 was achieved on 4 March 2013, four days before its tenth anniversary.
For a detailed chronological list of significant Galipedia events, consult Current events (in Galician). Other pages relay project statistics, including Statistics and Wikipedia statistics (also in Galician).

History
Wikipedia appeared in Galician on 8 March 2003. ILVI, the first user, registered on this same day. Axiña began work on what would become the first version of the portal. It took four more days until the first article would be created in the database: ou. Other entries would soon follow like calcium hydroxide , experimental science, social science, mysticism, applied science and botanics. Months later Agremon registered and become the first Galician administrator at Galipedia . Agremon was the person who put forward the name of Galipedia to refer to the Galician project, which was still under a year old. Soon afterwards, Galipedia would be quoted on newspaper websites, and other media, by those interested in the work undertaken.

Characteristics
Galipedia is a collective Galician language encyclopedia open to global contributors, as long as they remain open minded about others contributions. There is a wide range of subjects, ranging from Galician sports and cuisine to the biographies of personalities from physics, astronomy, linguistics and history. Galipedia differs from traditional encyclopedias in two ways. First, by its incredible growth and second by its ability to absorb and shape information almost immediately. For example, the obituaries section or regional news can be absorbed as articles quickly, in many cases becoming part of Wikipedia in a matter of hours or even minutes. This has become possible thanks to contact with the rest of Wikipedia, from where models and translations are provided. The license used is called the GNU General Public License. At the beginning of 2011, almost 30% of Galipedia articles were categorised or subcategorised inside the Galicia category.

Images
Galipedia has access to image sources beyond those provided by Wikimedia Commons . This is not the case with all other Wikipedia languages. At present, 9,645 files have been loaded, most of them local file images. In early February 2013, 244226 different images had been used across the project (including duplicate images). This did not include icons, banners, etc. The image 'Concellos_menos_poboados_de_Galiza.PNG' was used 1284 times and 'Piazza_del_Campidoglio.jpg' was used 1082 times.

Edits
The number of active editors in 2009 ranged from approximately 260 to 330. Of these, approximately twenty are little active and between 0 and 3 provide in general the bulk of monthly updates. Average article creation since the project began in April 2002 is 8,250 per year; however, for the period of 2007 to 2010, this average increases to 11,400 new articles. Around 35% of these articles were created by the ten most active editors. By category, this approaches 100% for both articles and pictures.

Quality Articles
Galipedia has 44 high quality articles. The first to receive this distinction was the Club Balconcesto Breogán article from June 2010. Soon afterwards, articles for Castelao , Ramón Piñeiro , Lugo , hórreo galego , the Kingdom of Galicia , the 1936 Statute of Autonomy of Galicia , Valentin Paz-Andrade , and the Easter Rising would make the list.

Human Factor
Galipedia has given rise to a community of contributors with common goals despite differences of origin, age, geography or ideology. To this end, there is already a group of collaborators formed around the encyclopedia, which has given rise to groups on social networks like Facebook and Twitter . It is worth noting that female editors of Galipedia, and for that matter Wikipedia, are still largely in the minority. In addition to contributing to Wikipedia over the internet, discuss wikis and encyclopedias at lectures and meetings to promote their use. On 15 January 2011 (the 10th anniversary of Wikipedia), there was a meeting in Culleredo and another in Ribadeo . In September of that same year, a workshop in the City of Culture was launched. In 2011, on January 15 (anniversary of Wikipedia) and March 8 (anniversary of Galipedia) editing standards were seen to have reached new levels. In January it was proposed that 5,000 edits be accomplished per day (4,500 were met) and in March 500 new articles a day were targeted (around 450 were achieved). Throughout its history Galipedia's activity has included interviews with various forms of media such as TVG , Radio Galega and articles in the Xornal de Galicia or Vieiros .

External links
WebPage index: 00149
List of Wikipedias
This is a list of the different language editions of Wikipedia ; as of 24 May 2017 there are 296 Wikipedias of which 285 are active.

Wikipedia edition codes
Each Wikipedia has a code, which is used as a subdomain below wikipedia.org. Interlanguage links are sorted by that code. The codes represent the language codes defined by ISO 639-1 and ISO 639-3 , and the decision of which language code to use is usually determined by the IETF language tag policy. Wikipedias also vary by how thinly they slice dialects and variants; for example, the English Wikipedia includes most modern varieties of English (American English, Indian English, South African English, etc.), but does not include other related languages such as Scots , or Anglo-Saxon , all of which have separate Wikipedias. The Spanish Wikipedia includes both Peninsular Castilian and Latin American Spanish ; Malay Wikipedia includes a large number of Malay languages; and so on.
Differences between the ISO mappings and Wikipedia codes include:
Additionally, Wikipedias vary in wikt:orthography at times. Chinese Wikipedia automatically translates from modern Mandarin Chinese into four standard forms: Mainland China and Singapore in simplified Chinese characters, and Taiwan and Hong Kong / Macau in traditional Chinese characters. Belarussian , however, has a separate Wikipedia for the 'normative' orthography (be) and Taraškievica (be-tarask).

List
An approximation to the number of active users is given in powers of ten (see common logarithm ): so "5" means at least 10,000, "4" means at least 1000, "3" means at least 100, and so on.

Detailed list

Notes

Grand total

See also
WebPage index: 00150
Tamil Wikipedia
The Tamil Wikipedia ( Tamil : தமிழ் விக்கிப்பீடியா ) is the Tamil language edition of Wikipedia , run by the Wikimedia Foundation . [1] It was established in September 2003 and crossed 91,000 articles on March 2017. The Tamil Wikipedia is the 59th largest Wikipedia and the second largest Wikipedia among Indian languages by article count. [1] It is also the first Wikipedia of Dravidian origin to possess more than 10,000 articles. The project is one of the leading Wikipedia among other South Asian language Wikipedia's in various quality matrices. [2] It has more than 91,610 articles and 109,691 registered users as of March 2017 [update] . [3] It crossed 100,000 articles on May 2017. [4]

Cultural Significance
Contrary to common academic criticism of Wikipedia in the Western countries, the Tamil Wikipedia is widely regarded as an important source of information in the Tamil language on the Internet. [5] The encyclopedia undergoes far less vandalism compared to larger Wikipedia projects, largely because the project has slower growth, mainly due to the lack of computers or Internet service in rural areas of Tamil Nadu and Sri Lanka . Most of the project's development comes from the overseas Tamil diaspora . [5] [6]
In April 2010, the Tamil Internet Conference held a contest for college students across the state of Tamil Nadu, India for increasing content on the Tamil Wikipedia. [7] The contest was made with regards to the World Classical Tamil Conference 2010 , a meeting of Tamil scholars across the world who discuss modern development of the language. With over 2000 contestants enrolled, the contest concluded with the creation of 1,200 new academically reviewed articles on the Tamil Wikipedia in various subjects. [8]
In September 2013, The Tamil Wikipedia celebrated its 10th year anniversary. [9]

Users and editors

See also
WebPage index: 00151
Latvian Wikipedia
The Latvian Wikipedia ( Latvian : Vikipēdija latviešu valodā [ˈvikipɜːdija] ( listen ) ) is the Latvian-language edition of the free online encyclopedia Wikipedia . It was created on 6 June 2003. [2] [3] [4] With about 77,000 articles, it is currently the 64th-largest Wikipedia as measured by the number of articles [5] and the second-largest Wikipedia in a Baltic language . [6]

History
The Latvian Wikipedia was created alongside the Serbian , Kannada , Walloon , Wolof , and Xhosa Wikipedias. [3] The oldest article is "Psihologija", which was published on 6 June 2003 and redirected to "Psiholoģija" (psychology) on 7 December 2004. [7] The main page was added four months after the first article, on 6 October 2003. [8]
The edition's initial growth was slow and some articles about important aspects of Latvian culture were missing at first. [2] The article about Jāņi , for instance, was not written until March 2008. [9] The Latvian Wikipedia's growth rate has been very stable since 2006. [10]
On 30 September 2013, the VisualEditor was made available to logged-in users, and by 7 October 2013, it was available to all users on the Latvian Wikipedia. [11]
The Latvian Wikipedia turned 10 years old on 6 June 2013. A commemorative logo was uploaded for the occasion, and small parties among the community's "Wikiholics" ensued, as it is customary whenever a new milestone is reached. [12] The edition surpassed 50,000 articles on 17 August 2013. [4]
As of July 2014 [update] , according to the list of Wikipedias by sample of articles at Meta-Wiki, which is based on the list of articles every Wikipedia should have , the Latvian Wikipedia ranks 52nd out of 287 editions, with a score of 20.83/100. It lacks almost no article from the list of vital articles, but contains generally short articles.

Name and logo
On 22 September 2004, the first Latvian "Wikipēdija" logo was uploaded, and on 1 June 2005, the name was changed to "Vikipēdija". [13] In Latvian media, the words "Wikipedia" and "Vikipēdija" are used interchangeably to refer to both Wikipedia in general and to the Latvian edition specifically, but "Vikipēdija" is more common. [14] [15]
In response to the Zolitūde shopping centre roof collapse disaster of 21 November 2013, the Latvian Wikipedia, just as several other Latvian websites, changed its logo for three days to include black and the image of a candle.

Related projects
A separate Latgalian Wikipedia ( ltg ) has been created on 18 March 2011. [16] Latgalian is spoken in Latgale , the eastern part of Latvia, and its standardized form is recognized and protected as a variety of Latvian language by Latvian law, [17] although it is debated whether it is a dialect of Latvian or a separate language. [18]

Milestones

Latvian Wikipedia Marathon
Latvian Wikipedia Marathon ( Latvian : Latvijas Vikipēdijas maratons ) is a project that brings together the Latvian Wikipedia community with several private partners in joint effort with the aim of expanding the Latvian Wikipedia to activate the usability of the Latvian language in the learning process, cognition and research work.

Policies
Since 31 October 2012, the Latvian Wikipedia displays a notice encouraging users to sign a petition on the Latvian social initiative platform ManaBalss.lv in an effort to change the Latvian copyright law, which permits taking pictures of architectural works and monuments, but only for non-commercial purposes. According to the petition, "such restrictions are not reasonable for buildings, monuments, sculptures and other three-dimensional works that cannot be fully reproduced in two dimensions". [2] [19] If the law changed, pictures of Latvian public buildings would become valid on Wikimedia Commons.

Images
The Latvian Wikipedia has an Exemption Doctrine Policy ( Godprātīga lietošana ) that allows local uploads of non-free, fair use images and audio/video files (with copyright restrictions). However, users are encouraged to release their work under a Creative Commons license and upload it on Wikimedia Commons instead, thus making it accessible throughout all editions of Wikipedia. This stance is similar to the English Wikipedia's, and in contrast to some other editions, which rely strictly on Wikimedia Commons for images, sound, and other media files, including i.a. the Spanish , Swedish , Polish , Basque , Czech , Danish , Volapük and Latin Wikipedias. [5] [22] [23]
Content and images from the Latvian Wikipedia often appear on Latvian news websites. [24] [25] [26] [27]

Statistics
As of May 2017, the Latvian Wikipedia's 77,000 articles [5] account for approximately 28% of all the articles written in a Baltic language, making it the second-largest edition in the family after Lithuanian, which accounts for 66%. [6] The most popular articles are " Latvija " (Latvia), " Eiropa " (Europe), and " Latvijas vēsture " (History of Latvia). [2] [28] [29]
In terms of quality, as of July 2014 [update] , the Latvian Wikipedia has 49 featured articles ( vērtīgi raksti ), [30] 76 good articles ( labi raksti ), [31] 19 featured lists ( vērtīgi saraksti ), [32] and an average ratio of 0.9 featured articles per 1000 articles; on par with the Bulgarian , Spanish , and English Wikipedias. It currently has a high depth indicator of 82.2, [b] which is not only greater than those of all other Wikipedias in the language family combined, [c] but also than some of the largest editions such as German (97.9), Polish (25), and Dutch (13.2). As of March 2015 [update] , there are 17 Wikiprojects ( Vikiprojekts ) on the Latvian Wikipedia, [33] and 81 approved bots , assisting users in the editing process. [34]

Community
The Latvian Wikipedia is the third most read edition in Latvia , after the English Wikipedia and the Russian Wikipedia . [35] It is also the seventh most read edition on the island of Guernsey , [35] where there is an emerging Latvian diaspora of approximately 1,500 to 2,000 migrant workers. [36] Despite Latvian having less than 2 million speakers, the edition enjoys a relatively high level of community participation, with 54 editors per million speakers, even though there is still no Wikimedia chapter in Latvia. [37] At around 38.6 articles per speaker, the Latvian Wikipedia has an above-average number of articles per speaker. [38] These figures were based on an estimate of 1.8 million speakers of Latvian. [39] Its editing community currently consists of 13 administrators (4.63% of all active users) and 281 active contributors, of which on average between 12 and 20 are very active every month, [d] and there are in total 62 users with over 1,000 edits (excluding bots). [40] [41] Around 90% of both views and edits originate from Latvia, where Wikipedia is the 14th most popular website. [42]

Gallery

See also

Notes
WebPage index: 00152
Tagalog Wikipedia
The Tagalog Wikipedia ( Tagalog : Wikipediyang Tagalog ) is the Tagalog language edition of Wikipedia , which was launched on December 1, 2003. It has 69,612 articles and is the 68th largest Wikipedia according to the number of articles as of May 22, 2017. [1] This has fewer articles than the Cebuano Wikipedia , the largest Philippine -based language version of Wikipedia, which currently has more than 4,495,000 articles and the Waray Wikipedia , which has more than 1,263,000 articles. [2] [3]
However, the Tagalog Wikipedia has an article depth of 33.52, compared to 3.57 for the Waray Wikipedia and 1.11 for the Cebuano Wikipedia, as of May 22, 2017. [4]
By active users, it has 98, compared to 143 for the Cebuano Wikipedia and 72 for the Waray language edition.

History
The Tagalog Wikipedia was launched on December 1, 2003 as the first Wikipedia in a language of the Philippines requested at the Wikimedia Incubator , where potential Wikimedia project wikis in new language versions can be proposed.
As of February 3, 2011, it has more than 50,000 articles . [5] Bantayan, Cebu became the 10,000th article on October 20, 2007 while Pasko sa Pilipinas ( Christmas in the Philippines ) became the 15,000th article on December 24, 2007. [6] Localization of software messages through the Betawiki (or translatewiki.net ) was finished on February 6, 2009. [7]
In 2011, the Tagalog Wikipedia was part of the WikiHistories fellowship research project of the Wikimedia Foundation . The project tries to capture the triumphs, failures, and daily struggles of the editors working to make the dream of globally shared knowledge a reality. [8]

Statistics

First steps of Tagalog Wikipedia
The very first article created in the Tagalog Wikipedia (aside from Unang Pahina or the main page) is about Wikipedia . It was created on March 25, 2004. During the times when Tagalog Wikipedia's standards on articles were not strict, the very first featured article was Livestrong wristband , but this was replaced by the article kimika ( chemistry ) in line with the revised standards. [20] But kimika along with the second featured article wiki were eventually replaced by a review process. [21] [22] Technically, the very first featured article that survived the review process is about keso ( cheese ). [23]
The File:Flutterbye.jpg was the first featured picture for the article paru-parong Viceroy ( Viceroy butterfly ). Because the file was deleted, it was replaced by File:St Vitus stained glass.jpg for the article Katedral ng San Vitus ( St. Vitus Cathedral ). [24] Although the featured picture archive lists File:Viceroy Butterfly.jpg as the first featured picture.
The first three articles that appeared in Alam Ba Ninyo? ( Did you know? ) were web browser ( en ), Wikang Bulgaro ( Bulgarian language ) and Pilipinas ( Philippines ). [25] There was a section entitled On This Day at the main page in April 2, 2008, but this was hidden on May 3, 2008 because of lack of contributors of this section. [26] [27]

Characteristics
The Tagalog Wikipedia has several characteristics which define it differently from other language editions of Wikipedia. According to Michael Tan , a Filipino anthropologist and Philippine Daily Inquirer columnist, the Tagalog Wikipedia greatly depends on the UP Diksyonaryong Filipino for basic definitions. [28] Though focused on the Tagalog language, it has pages that helps non-Tagalog speakers on anything related about the online project. [29]

Coverage
The Tagalog Wikipedia has significant coverage of topics related to the Philippines, as well as anime and manga -related topics. In 2010, GMA News and Public Affairs released a report criticizing the Tagalog Wikipedia's lack of science-related articles. [30]

Project name
According to Wikipedians from the Tagalog and English Wikipedias, the Tagalog Wikipedia also represents the Filipino language . [31] [32] [33] According to the Vibal Foundation, a foundation that started WikiPilipinas , the Tagalog Wikipedia is different from WikiFilipino, the wiki that they manage because WikiFilipino uses Filipino language while Tagalog Wikipedia uses Tagalog language. [34] The difference or sameness of Tagalog and Filipino sparked a debate among Tagalog Wikipedians about the name of the project. This debate was mentioned in an article by DILA ( Defenders of the Indigenous Languages of the Archipelago ), [35] an organization that defends indigenous languages of the Philippines.
WebPage index: 00153
Breton Wikipedia
The Breton Wikipedia ( Breton : Wikipedia e brezhoneg ) is the Breton language version of Wikipedia , run by the Wikimedia Foundation . It was established in June 2004; as of August 2008 it had over 20,000 articles, making it the 56th largest Wikipedia by article count. It reached 30,000 articles [1] milestone on October 25, 2009 ranking 51st out of 250 languages Wikipedias; as of February 2010 it had over 31,000 articles, making it the 52nd largest Wikipedia by article count and as April 2011 it had over 37,000 articles, making it the 52nd largest Wikipedia by article count. In July 2014 the encyclopedia reached 50,000 articles, becoming the 71st largest Wikipedia by article count.
On January 1, 2017, it had just over 60,000 articles, making it the 73rd largest Wikipedia by article count. It is also the second largest Wikipedia edition in a Celtic language , after the Welsh Wikipedia but ahead of the Irish Wikipedia (even though that language has far more speakers).
The articles are written in the Peurunvan orthography. Some Diwan students contributed [2] founding Wikipedian clubs.

See also
WebPage index: 00154
Javanese Wikipedia
Javanese Wikipedia ( Javanese Wikipedia basa Jawa ) is the edition of Wikipedia in the Javanese language . Started on 8 March 2004, the Javanese Wikipedia reached 10,000 articles on 3 May 2007. As of December 27, 2014, it has more than 48,000 articles. [1] The Indonesian media has discussed the Javanese Wikipedia. [2] Although the Wikipedia logo was written in the Javanese script since the beginning of the edition, the articles themselves could only be written in the Roman script until 2013. [3]

Milestones

See also
WebPage index: 00155
Afrikaans Wikipedia
The Afrikaans Wikipedia ( Afrikaans : Afrikaanse Wikipedia ) is an Afrikaans edition of the Web -based free-content encyclopedia Wikipedia . The project was started on 16 November 2001, and was the 11th Wikipedia to be created. [1] In December 2016 it was the 84th largest Wikipedia by number of articles. Apart from South Africa and Namibia , the Afrikaans Wikipedia is used and maintained by users in Europe , North America and Oceania . As of May 2013, it was the second-largest African language Wikipedia, after Malagasy . [2]

Visits and edits
The Afrikaans Wikipedia makes up 0.008% of all Wikipedia searches. In the period of time between 1 July 2009 and 30 September 2013, the Afrikaans Wikipedia was visited the most by
South Africa ( 64.0% ) USA ( 5.5% ) Germany ( 4.1% ) World ( 26.4% )
The Afrikaans Wikipedia makes up 2.2% of all searches in South Africa, after the 92.7% of the English Wikipedia. In Namibia, the Afrikaans Wikipedia is used 1.2% of the time, after the English (85.3%), German (5.7%) and Portuguese (1.5%) Wikipedias. [3]
0.1% of all German, 0.3% of all Belgian and 24.4% of all South African edits take place on the Afrikaans Wikipedia. [4] Netherlands and Belgium's involvement in the Afrikaans Wikipedia is most likely due to the language relationship between Afrikaans and Dutch.

Milestones
According to statistics, [5] the following milestones were reached by the Afrikaans Wikipedia:
WebPage index: 00156
Burmese Wikipedia
The Burmese Wikipedia ( Burmese : မြန်မာဝီကီပီးဒီးယား pronounced: [mjəmà wɪkɨˈpiːdiə] ) is the Burmese language edition of the free online encyclopedia Wikipedia . This edition was started in July 2004, and has about 36,000 articles as of May 2017.
As of May 2017, there are 43,000 users, 5 admins and 3,481 files on the Myanmar Wikipedia [1] ranking 85th by article count.

History

Timeline

Events and promotions
Myanmar Computer Professionals Association had launched Wikipedia Myanmar project with the aim of expanding Wikipedia in 2010. [2]
Burmese Wikipedia community had held their first joint workshop in Yangon , Burma (Myanmar) with the help of Telenor Myanmar in June 2014 to recruite new volunteers. [3] The Burmese Wikipedia Forum was held at Dagon University in July 2014 attracting over 2,000 people, including students. [4]

Challenges
The majority of Burmese internet users use the non-Unicode Zawgyi font so they have difficulty viewing Burmese Wikipedia. [2] [4] [5]
WebPage index: 00157
Nepal Bhasa Wikipedia
The Nepal Bhasa Wikipedia , is the Newar-language version of Wikipedia , run by the Wikimedia Foundation . Nepal Bhasa Wikipedia has currently 70,000 articles. [1] Nepal bhasa is the mother tongue language of Newars of Nepal. Newars are culturally rich ethnic group in Nepal.
WebPage index: 00158
Alemannic Wikipedia
The Alemannic Wikipedia (Alemannic: Alemannischi Wikipedia ) is the Alemannic language edition of the Web -based free-content encyclopedia Wikipedia . The project was started on November 13, 2003 as an Alsatian language edition. A year later it was expanded to encompass all Alemannic dialects because of low activity in the first year. Since 2004 all Alemannic dialects are accepted on als:wp.
As of May 2017, this edition has about 22,800 articles [1] and is the 108th largest Wikipedia by number of articles. [2] Contributors and users include people from Germany , Switzerland , Austria , France , Liechtenstein , and even a few Walser people from Italy . [ citation needed ]

Language

Articles and article titles
A peculiarity of the Alemannic Wikipedia is the wide range of dialects permitted; all varieties of Alemannic, including Swiss German , Swabian , Alsatian , and all others are accepted. Authors may not normally alter the dialect used by another contributor, though exceptions are made for local topics, in which modifying the text to reflect the local variety is encouraged. Articles may thus be written in a mix of different varieties. Since there is no standardized orthography for Alemannic, spelling rules are quite relaxed. However, contributors are encouraged to adhere to spelling conventions found in the Alemannic-language literature, and introducing new symbols is not tolerated. [3]
Article titles are in Standard German, but display is frequently manipulated to show Alemannic text.

Language codes
The code als was used because in 2003 there had been no language code for Alsatian. ISO 639-3 gives four codes for several Alemannic dialects:
As all of these four dialects are accepted on the Alemannic Wikipedia, it was decided not to move the Alemannic Wikipedia to gsw.wikipedia.org, even though the code als stands for Tosk Albanian in ISO 639-3. To solve this problem a request for a superior code for all Alemannic dialects has been submitted to SIL International by Alemannic Wikipedians. [4]
Despite the existence of dedicated ISO 639-3 codes and the possibility of more specific marking with country code subtags, all pages use 'gsw' in the HTML language tag.

List of dialects that are used on single-dialect pages
Below is a list of dialects that have a category in als:Kategorie:Wikipedia:Dialekt and where that category contains at least one article.

Other Wikipedias in German dialect
Alemannic Wikipedia was the first Wikipedia in a German dialect, followed by the Bavarian Wikipedia and the Ripuarian Wikipedia .

Alemannic in other Wikimedia projects
Other Wikimedia projects in Alemanic have also been created, such as an Alemannic Wiktionary, an Alemannic Wikiquote, and an Alemannic Wikibooks. As activity in these projects was low even after years, the community of the Alemannic Wikipedia decided to merge all Alemannic projects and import all contents of the other projects into the Alemannic Wikipedia. Since April 2008 these projects are separate namespaces within the Alemannic Wikipedia. Also an Alemannic Wikisource and an Alemannic Wikinews have been created as separate namespaces within als:wp.
Wikidata supports one language with code 'gsw' and name 'Swiss German'. A proposal to remove it has not been adopted. [1] .

Milestones

See also
WebPage index: 00159
Yiddish Wikipedia
Yiddish Wikipedia is the Yiddish -language version of Wikipedia . It was founded on March 3, 2004, [1] and the first article was written November 28 of that year.

Current status
The Yiddish Wikipedia now has 13,906 articles. There are 26,364 registered users (including bots); 39 are active, including 3 administrators.
Like all Wikipedias it generates hits from Yiddish words typed in Google, with Wikipedia articles appearing at the top of the results for that word.
In accordance with the norms for the Yiddish language, it is written almost exclusively in Hebrew script, and not in Latin script.

Milestones
The Yiddish Wikipedia reached 6000 articles on March 8, 2009. The 6000th article is יהושע העשיל תאומים-פרענקל , a rabbi. The 7000th article is חנינא סגן הכהנים , a page about the tanna Hanina Segan ha-Kohanim created on December 24, 2009.

Point of view
Combined, the different Hasidic groups form the largest Yiddish-speaking community in the world today. Most new articles are about Hasidic rabbis. [2]
WebPage index: 00160
Northern Sami Wikipedia
The Northern Sami Wikipedia is the edition of Wikipedia in the Northern Sami language . [1]
It was used as one example of how Wikipedia's categories system works (in the context of social ontologies ). [2]

Statistics
It started in 2004 and has over 7000 articles, ranking in the middle of all Wikipedias.
As for readers: it is 134th of about 290 in number of page requests: half a million page requests per month, but not possible to know how many human readers.
As for content: it is 137th of about 290 in number of articles (there are 7,283); articles are about 500 characters long on average with approximately 400 000 words in total. It's above average in terms of editors/speakers and articles/speakers, there are many articles about towns around the world (mostly automated creations).
As for activity: there were almost no new articles in 2008-2011, new articles usually come in bursts; in 2013 editing activity was lower than in previous years with fewer than 10 active editors per month making fewer than 100 edits per month. [3] There are currently 18 active users and activity is still low.

Notes

External links
WebPage index: 00161
Crimean Tatar Wikipedia
The Crimean Tatar Wikipedia ( Crimean Tatar : Qırımtatar Vikipediyası ) is the Crimean Tatar language edition of the free online encyclopedia Wikipedia . The articles were originally written in Wikimedia Incubator, and the Crimean Tatar Wikipedia was created on January 12, 2008. [1] [2] Currently (May 2017), Crimean Tatar has 5239 articles.

Statistics
As of May 2017, Crimean Tatar Wikipedia has 5239 articles. [4] [5]
The main problem of the project is a lack of volunteers. The vast majority of edits are made by several volunteers, none of whom is a native speaker. [6]

Milestones
WebPage index: 00162
Tulu Wikipedia
The Tulu Wikipedia is the Tulu language edition of Wikipedia , run by the Wikimedia Foundation . [1] It currently has over 1,000 articles. It is the 23rd language of India to get a Wikipedia. [2] This followed eight years in incubation. [3]

History
Katherine Maher , the executive director of Wikimedia Foundation announced the launch of Tulu Wikipedia as a full site at the WIkiConference 2016 . [1] It was in incubation since 2008. As of August 2016, it had 200 registeted editors with 10 of them being active, and over 1000 articles. [4]

Users and editors

See also
WebPage index: 00163
Bambara Wikipedia
The Bambara Wikipedia is the edition of Wikipedia in the Bambara language , spoken in Mali , Burkina Faso and Senegal . This edition of Wikipedia contains 425 articles.

History
The Wikipedia was started in the beginning of 2005, along with the Wolof Wikipedia and the Fula Wikipedia . Kasper Souren, a Dutchman who worked with Geekcorps , established this Wikipedia while working in a mission in Mali . [1] In December 2007 the Bambara Wikipedia had 142 articles and the Wikipedia in Fula had 28 articles. [1] According to Souren, he was volunteering in Mali in 2005 when he first encountered the Bambara language. [2]
Souren wrote in a report to an open source conference a Geekcorps Mali volunteer had created a side project where a person who wrote for the Wikipedia received $1 U.S. per article. [1] Souren went to Bamako and met people at a community center. He paid each person willing to write an article $1 U.S. The authors had no internet connections and no Wikipedia usernames. They wrote articles in Microsoft Word and gave the files to Souren. Souren uploaded each article and credited the authors. Souren wrote "I can’t understand 100 percent of what they wrote, but I could estimate that it was right. It is a Wikipedia anyway, so I hope they can correct it." [2]
The total expenses of the project amounted to fewer than $100 U.S. [1] In regards to the payment, Ndesanjo Macha, a Wikipedian who speaks Swahili, argued that it's unnecessary to pay editors for their efforts, and he believed he was speaking for everyone in Africa. Noam Cohen of The New York Times wrote "Most of the people who have heard about Mr. Souren’s decision to pay for entries lauded his goal but questioned his tactics, saying that they undercut the Wikipedia spirit, and that, ultimately, a Bambara Wikipedia would work only if there was a voluntary community to support it." [2] This project resulted in the partial translation of the interfaces of the Bambara and Fula Wikipedias and the creation of some articles for those Wikipedias. Souren wrote that after 2005 the Bambara and Fula Wikipedias had "only sparse activity". [1] In December 2007 the Bambara Wikipedia had 142 articles and the Wikipedia in Fula had 28 articles. [1]
In 2013 Valentin Vydrin, author of "Bamana Reference Corpus (BRC)", wrote that "The Bambara Wikipedia counts a couple of hundred entries, most of them rudimentary and often written without any respect for the rules of orthography." [3]

Notes
WebPage index: 00164
International Standard Name Identifier
The International Standard Name Identifier ( ISNI ) is an identifier for uniquely identifying the public identities of contributors to media content such as books, television programmes, and newspaper articles. Such an identifier consists of 16 digits. It can optionally be displayed as divided into four blocks.
It was developed under the auspices of the International Organization for Standardization (ISO) as Draft International Standard 27729; the valid standard was published on 15 March 2012. The ISO technical committee 46, subcommittee 9 ( TC 46/SC 9 ) is responsible for the development of the standard.
ISNI can be used to disambiguate names that might otherwise be confused, and links the data about names that are collected and used in all sectors of the media industries.

Uses of an ISNI
The ISNI allows a single identity (such as an author's pseudonym or the imprint used by a publisher ) to be identified using a unique number. This unique number can then be linked to any of the numerous other identifiers that are used across the media industries to identify names and other forms of identity.
An example of the use of such a number is the identification of a musical performer who is also a writer both of music and of poems. Where he or she might currently be identified in many different databases using numerous private and public identification systems, under the ISNI system, he or she would have a single linking ISNI record. The many different databases could then exchange data about that particular identity without resorting to messy methods such as comparing text strings. An often quoted example in the English language world is the difficulty faced when identifying 'John Smith' in a database. While there may be many records for 'John Smith', it is not always clear which record refers to the specific 'John Smith' that is required.
If an author has published under several different names or pseudonyms, each such name will receive its own ISNI.
ISNI can be used by libraries and archives when sharing catalogue information; for more precise searching for information online and in databases, and it can aid the management of rights across national borders and in the digital environment.

ORCID
ORCID (Open Researcher and Contributor ID) identifiers consist of a reserved block of ISNI identifiers for scholarly researchers [1] and administered by a separate organisation. [1] Individual researchers can create and claim their own ORCID identifier. [2] The two organisations coordinate their efforts. [1] [2]

ISNI governance
ISNI is governed by an 'International Agency', commonly known as the ISNI-IA. [3] [4] This UK registered, not-for-profit company has been founded by a consortium of organisations consisting of the Confédération Internationale des Sociétés d´Auteurs et Compositeurs (CISAC), the Conference of European National Librarians (CENL), the International Federation of Reproduction Rights Organisations (IFRRO), the International Performers Database Association (IPDA), the Online Computer Library Center (OCLC) and ProQuest . It is managed by directors nominated from these organisations and, in the case of CENL, by representatives of the Bibliothèque nationale de France and the British Library .

ISNI assignment
ISNI-IA uses an assignment system comprising a user interface, data-schema , disambiguation algorithms , and database that meets the requirements of the ISO standard, while also using existing technology where possible. The system is based primarily on the Virtual International Authority File (VIAF) service, which has been developed by OCLC for use in the aggregation of library catalogues.
Access to the assignment system and database, and to the numbers that are generated as the output of the process, are controlled by independent bodies known as 'registration agencies'. These registration agencies deal directly with customers, ensuring that data is provided in appropriate formats and recompensing the ISNI-IA for the cost of maintaining the assignment system. Registration agencies are appointed by ISNI-IA but will be managed and funded independently.

See also
WebPage index: 00165
Definition of Free Cultural Works
The Definition of Free Cultural Works is a definition of free content from 2006. The project evaluates and recommends compatible free content licenses .

History
The Open Content Project by David A. Wiley in 1998 was a predecessor project which defined open content . In 2003 Wiley joined the Creative Commons as "Director of Educational Licenses" and announced the Creative Commons and their licenses as successor to his Open Content project . [2] [3]
Therefore, Creative Commons' Erik Möller [4] in collaboration with Richard Stallman , Lawrence Lessig , Benjamin Mako Hill , [4] Angela Beesley, [4] and others started in 2006 the Free Cultural Works project for defining free content . The first draft of the Definition of Free Cultural Works was published 3 April 2006. [5] The 1.0 and 1.1 versions were published in English and translated into some languages. [6]
The Definition of Free Cultural Works is used by the Wikimedia Foundation . [7] In 2008, the Attribution and Attribution-ShareAlike Creative Commons licenses were marked as "Approved for Free Cultural Works". [8]
Following in June 2009, Wikipedia migrated to use two licenses : the Creative Commons Attribution-ShareAlike as main license, additionally to the previously used GNU Free Documentation License (which was made compatible [9] ). [10] An improved license compatibility with the greater free content ecosystem was given as reason for the license change. [11] [12]
In October 2014 the Open Knowledge Foundation 's Open Definition 2.0 for Open Works and Open Licenses described "open" as synonymous to the definition of free in the "Definition of Free Cultural Works" (and also the Open Source Definition and Free Software Definition ). [13] A distinct difference is the focus given to the public domain and that it focuses also on the accessibility (" Open access ") and the readability (" open formats "). The same three creative commons licenses are recommended for open content ( CC BY , CC BY-SA , and CC0 [14] [15] [16] ) as additionally three for open data intended own licenses, the Open Data Commons Public Domain Dedication and Licence (PDDL), the Open Data Commons Attribution License (ODC-BY) and the Open Data Commons Open Database License (ODbL).

"Free cultural works" approved licenses

See also
WebPage index: 00166
Definition of Free Cultural Works
The Definition of Free Cultural Works is a definition of free content from 2006. The project evaluates and recommends compatible free content licenses .

History
The Open Content Project by David A. Wiley in 1998 was a predecessor project which defined open content . In 2003 Wiley joined the Creative Commons as "Director of Educational Licenses" and announced the Creative Commons and their licenses as successor to his Open Content project . [2] [3]
Therefore, Creative Commons' Erik Möller [4] in collaboration with Richard Stallman , Lawrence Lessig , Benjamin Mako Hill , [4] Angela Beesley, [4] and others started in 2006 the Free Cultural Works project for defining free content . The first draft of the Definition of Free Cultural Works was published 3 April 2006. [5] The 1.0 and 1.1 versions were published in English and translated into some languages. [6]
The Definition of Free Cultural Works is used by the Wikimedia Foundation . [7] In 2008, the Attribution and Attribution-ShareAlike Creative Commons licenses were marked as "Approved for Free Cultural Works". [8]
Following in June 2009, Wikipedia migrated to use two licenses : the Creative Commons Attribution-ShareAlike as main license, additionally to the previously used GNU Free Documentation License (which was made compatible [9] ). [10] An improved license compatibility with the greater free content ecosystem was given as reason for the license change. [11] [12]
In October 2014 the Open Knowledge Foundation 's Open Definition 2.0 for Open Works and Open Licenses described "open" as synonymous to the definition of free in the "Definition of Free Cultural Works" (and also the Open Source Definition and Free Software Definition ). [13] A distinct difference is the focus given to the public domain and that it focuses also on the accessibility (" Open access ") and the readability (" open formats "). The same three creative commons licenses are recommended for open content ( CC BY , CC BY-SA , and CC0 [14] [15] [16] ) as additionally three for open data intended own licenses, the Open Data Commons Public Domain Dedication and Licence (PDDL), the Open Data Commons Attribution License (ODC-BY) and the Open Data Commons Open Database License (ODbL).

"Free cultural works" approved licenses

See also
WebPage index: 00167
Monopoly
A monopoly (from Greek μόνος mónos ("alone" or "single") and πωλεῖν pōleîn ("to sell")) exists when a specific person or enterprise is the only supplier of a particular commodity. This contrasts with a monopsony which relates to a single entity's control of a market to purchase a good or service, and with oligopoly which consists of a few sellers dominating a market). [2] Monopolies are thus characterized by a lack of economic competition to produce the good or service , a lack of viable substitute goods , and the possibility of a high monopoly price well above the seller's marginal cost that leads to a high monopoly profit . [3] The verb monopolise or monopolize refers to the process by which a company gains the ability to raise prices or exclude competitors. In economics, a monopoly is a single seller. In law, a monopoly is a business entity that has significant market power, that is, the power to charge overly high prices . [4] Although monopolies may be big businesses, size is not a characteristic of a monopoly. A small business may still have the power to raise prices in a small industry (or market). [4]
A monopoly is distinguished from a monopsony, in which there is only one buyer of a product or service; a monopoly may also have monopsony control of a sector of a market. Likewise, a monopoly should be distinguished from a cartel (a form of oligopoly), in which several providers act together to coordinate services, prices or sale of goods. Monopolies, monopsonies and oligopolies are all situations in which one or a few entities have market power and therefore interact with their customers (monopoly or oligopoly), or suppliers (monopsony) in ways that distort the market. [ citation needed ]
Monopolies can be established by a government, form naturally , or form by integration.
In many jurisdictions, competition laws restrict monopolies. Holding a dominant position or a monopoly in a market is often not illegal in itself, however certain categories of behavior can be considered abusive and therefore incur legal sanctions when business is dominant. A government-granted monopoly or legal monopoly , by contrast, is sanctioned by the state, often to provide an incentive to invest in a risky venture or enrich a domestic interest group . Patents , copyrights , and trademarks are sometimes used as examples of government-granted monopolies. The government may also reserve the venture for itself, thus forming a government monopoly . [ citation needed ]

Market structures
In economics, the idea of monopoly is important in the study of management structures, which directly concerns normative aspects of economic competition, and provides the basis for topics such as industrial organization and economics of regulation . There are four basic types of market structures in traditional economic analysis: perfect competition, monopolistic competition , oligopoly and monopoly. A monopoly is a structure in which a single supplier produces and sells a given product. If there is a single seller in a certain market and there are no close substitutes for the product, then the market structure is that of a "pure monopoly". Sometimes, there are many sellers in an industry and/or there exist many close substitutes for the goods being produced, but nevertheless companies retain some market power. This is termed monopolistic competition, whereas in oligopoly the companies interact strategically.
In general, the main results from this theory compare price-fixing methods across market structures, analyze the effect of a certain structure on welfare, and vary technological/demand assumptions in order to assess the consequences for an abstract model of society. Most economic textbooks follow the practice of carefully explaining the perfect competition model, mainly because this helps to understand "departures" from it (the so-called imperfect competition models).
The boundaries of what constitutes a market and what does not are relevant distinctions to make in economic analysis. In a general equilibrium context, a good is a specific concept including geographical and time-related characteristics ("grapes sold during October 2009 in Moscow" is a different good from "grapes sold during October 2009 in New York"). Most studies of market structure relax a little their definition of a good, allowing for more flexibility in the identification of substitute goods.

Characteristics

Sources of monopoly power
Monopolies derive their market power from barriers to entry – circumstances that prevent or greatly impede a potential competitor's ability to compete in a market. There are three major types of barriers to entry: economic, legal and deliberate. [6]
In addition to barriers to entry and competition, barriers to exit may be a source of market power. Barriers to exit are market conditions that make it difficult or expensive for a company to end its involvement with a market. High liquidation costs are a primary barrier to exiting. [13] Market exit and shutdown are sometimes separate events. The decision whether to shut down or operate is not affected by exit barriers. [ citation needed ] A company will shut down if price falls below minimum average variable costs.

Monopoly versus competitive markets
While monopoly and perfect competition mark the extremes of market structures [14] there is some similarity. The cost functions are the same. [15] Both monopolies and perfectly competitive (PC) companies minimize cost and maximize profit. The shutdown decisions are the same. Both are assumed to have perfectly competitive factors markets. There are distinctions, some of the more important of which are as follows:
The most significant distinction between a PC company and a monopoly is that the monopoly has a downward-sloping demand curve rather than the "perceived" perfectly elastic curve of the PC company. [26] Practically all the variations mentioned above relate to this fact. If there is a downward-sloping demand curve then by necessity there is a distinct marginal revenue curve. The implications of this fact are best made manifest with a linear demand curve. Assume that the inverse demand curve is of the form x = a − by. Then the total revenue curve is TR = ay − by 2 and the marginal revenue curve is thus MR = a − 2by. From this several things are evident. First the marginal revenue curve has the same y intercept as the inverse demand curve. Second the slope of the marginal revenue curve is twice that of the inverse demand curve. Third the x intercept of the marginal revenue curve is half that of the inverse demand curve. What is not quite so evident is that the marginal revenue curve is below the inverse demand curve at all points. [26] Since all companies maximise profits by equating MR and MC it must be the case that at the profit-maximizing quantity MR and MC are less than price, which further implies that a monopoly produces less quantity at a higher price than if the market were perfectly competitive.
The fact that a monopoly has a downward-sloping demand curve means that the relationship between total revenue and output for a monopoly is much different than that of competitive companies. [27] Total revenue equals price times quantity. A competitive company has a perfectly elastic demand curve meaning that total revenue is proportional to output. [27] Thus the total revenue curve for a competitive company is a ray with a slope equal to the market price. [27] A competitive company can sell all the output it desires at the market price. For a monopoly to increase sales it must reduce price. Thus the total revenue curve for a monopoly is a parabola that begins at the origin and reaches a maximum value then continuously decreases until total revenue is again zero. [28] Total revenue has its maximum value when the slope of the total revenue function is zero. The slope of the total revenue function is marginal revenue. So the revenue maximizing quantity and price occur when MR = 0. For example, assume that the monopoly’s demand function is P = 50 − 2Q. The total revenue function would be TR = 50Q − 2Q 2 and marginal revenue would be 50 − 4Q. Setting marginal revenue equal to zero we have
So the revenue maximizing quantity for the monopoly is 12.5 units and the revenue maximizing price is 25.
A company with a monopoly does not experience price pressure from competitors, although it may experience pricing pressure from potential competition. If a company increases prices too much, then others may enter the market if they are able to provide the same good, or a substitute, at a lesser price. [29] The idea that monopolies in markets with easy entry need not be regulated against is known as the "revolution in monopoly theory". [30]
A monopolist can extract only one premium, [ clarification needed ] and getting into complementary markets does not pay. That is, the total profits a monopolist could earn if it sought to leverage its monopoly in one market by monopolizing a complementary market are equal to the extra profits it could earn anyway by charging more for the monopoly product itself. However, the one monopoly profit theorem is not true if customers in the monopoly good are stranded or poorly informed, or if the tied good has high fixed costs.
A pure monopoly has the same economic rationality of perfectly competitive companies, i.e. to optimise a profit function given some constraints. By the assumptions of increasing marginal costs, exogenous inputs' prices, and control concentrated on a single agent or entrepreneur, the optimal decision is to equate the marginal cost and marginal revenue of production. Nonetheless, a pure monopoly can – unlike a competitive company – alter the market price for its own convenience: a decrease of production results in a higher price. In the economics' jargon, it is said that pure monopolies have "a downward-sloping demand". An important consequence of such behaviour is worth noticing: typically a monopoly selects a higher price and lesser quantity of output than a price-taking company; again, less is available at a higher price. [31]

The inverse elasticity rule
A monopoly chooses that price that maximizes the difference between total revenue and total cost. The basic markup rule (as measured by the Lerner index ) can be expressed as P − M C P = − 1 E d {\displaystyle {\frac {P-MC}{P}}={\frac {-1}{E_{d}}}} , where E d {\displaystyle E_{d}} is the price elasticity of demand the firm faces. [32] The markup rules indicate that the ratio between profit margin and the price is inversely proportional to the price elasticity of demand. [32] The implication of the rule is that the more elastic the demand for the product the less pricing power the monopoly has.

Market power
Market power is the ability to increase the product's price above marginal cost without losing all customers. [33] Perfectly competitive (PC) companies have zero market power when it comes to setting prices. All companies of a PC market are price takers. The price is set by the interaction of demand and supply at the market or aggregate level. Individual companies simply take the price determined by the market and produce that quantity of output that maximizes the company's profits. If a PC company attempted to increase prices above the market level all its customers would abandon the company and purchase at the market price from other companies. A monopoly has considerable although not unlimited market power. A monopoly has the power to set prices or quantities although not both. [34] A monopoly is a price maker. [35] The monopoly is the market [36] and prices are set by the monopolist based on their circumstances and not the interaction of demand and supply. The two primary factors determining monopoly market power are the company's demand curve and its cost structure. [37]
Market power is the ability to affect the terms and conditions of exchange so that the price of a product is set by a single company (price is not imposed by the market as in perfect competition). [38] [39] Although a monopoly's market power is great it is still limited by the demand side of the market. A monopoly has a negatively sloped demand curve, not a perfectly inelastic curve. Consequently, any price increase will result in the loss of some customers.

Price discrimination
Price discrimination allows a monopolist to increase its profit by charging higher prices for identical goods to those who are willing or able to pay more. For example, most economic textbooks cost more in the United States than in developing countries like Ethiopia . In this case, the publisher is using its government-granted copyright monopoly to price discriminate between the generally wealthier American economics students and the generally poorer Ethiopian economics students. Similarly, most patented medications cost more in the U.S. than in other countries with a (presumed) poorer customer base. Typically, a high general price is listed, and various market segments get varying discounts. This is an example of framing to make the process of charging some people higher prices more socially acceptable. [ citation needed ] Perfect price discrimination would allow the monopolist to charge each customer the exact maximum amount he would be willing to pay. This would allow the monopolist to extract all the consumer surplus of the market. While such perfect price discrimination is a theoretical construct, advances in information technology and micromarketing may bring it closer to the realm of possibility.
It is very important to realize that partial price discrimination can cause some customers who are inappropriately pooled with high price customers to be excluded from the market. For example, a poor student in the U.S. might be excluded from purchasing an economics textbook at the U.S. price, which the student may have been able to purchase at the Ethiopian price'. Similarly, a wealthy student in Ethiopia may be able to or willing to buy at the U.S. price, though naturally would hide such a fact from the monopolist so as to pay the reduced third world price. These are deadweight losses and decrease a monopolist's profits. As such, monopolists have substantial economic interest in improving their market information and market segmenting . [ citation needed ]
There is important information for one to remember when considering the monopoly model diagram (and its associated conclusions) displayed here. The result that monopoly prices are higher, and production output lesser, than a competitive company follow from a requirement that the monopoly not charge different prices for different customers. That is, the monopoly is restricted from engaging in price discrimination (this is termed first degree price discrimination , such that all customers are charged the same amount). If the monopoly were permitted to charge individualised prices (this is termed third degree price discrimination ), the quantity produced, and the price charged to the marginal customer, would be identical to that of a competitive company, thus eliminating the deadweight loss ; however, all gains from trade (social welfare) would accrue to the monopolist and none to the consumer. In essence, every consumer would be indifferent between (1) going completely without the product or service and (2) being able to purchase it from the monopolist. [ citation needed ]
As long as the price elasticity of demand for most customers is less than one in absolute value , it is advantageous for a company to increase its prices: it receives more money for fewer goods. With a price increase, price elasticity tends to increase, and in the optimum case above it will be greater than one for most customers. [ citation needed ]
A company maximizes profit by selling where marginal revenue equals marginal cost. A company that does not engage in price discrimination will charge the profit maximizing price, P*, to all its customers. In such circumstances there are customers who would be willing to pay a higher price than P* and those who will not pay P* but would buy at a lower price. A price discrimination strategy is to charge less price sensitive buyers a higher price and the more price sensitive buyers a lower price. [40] Thus additional revenue is generated from two sources. The basic problem is to identify customers by their willingness to pay.
The purpose of price discrimination is to transfer consumer surplus to the producer. [41] Consumer surplus is the difference between the value of a good to a consumer and the price the consumer must pay in the market to purchase it. [42] Price discrimination is not limited to monopolies.
Market power is a company’s ability to increase prices without losing all its customers. Any company that has market power can engage in price discrimination. Perfect competition is the only market form in which price discrimination would be impossible (a perfectly competitive company has a perfectly elastic demand curve and has zero market power). [41] [43] [44] [45]
There are three forms of price discrimination. First degree price discrimination charges each consumer the maximum price the consumer is willing to pay. Second degree price discrimination involves quantity discounts. Third degree price discrimination involves grouping consumers according to willingness to pay as measured by their price elasticities of demand and charging each group a different price. Third degree price discrimination is the most prevalent type. [ citation needed ]
There are three conditions that must be present for a company to engage in successful price discrimination. First, the company must have market power. [46] Second, the company must be able to sort customers according to their willingness to pay for the good. [47] Third, the firm must be able to prevent resell.
A company must have some degree of market power to practice price discrimination. Without market power a company cannot charge more than the market price. [48] Any market structure characterized by a downward sloping demand curve has market power – monopoly, monopolistic competition and oligopoly. [46] The only market structure that has no market power is perfect competition. [48]
A company wishing to practice price discrimination must be able to prevent middlemen or brokers from acquiring the consumer surplus for themselves. The company accomplishes this by preventing or limiting resale. Many methods are used to prevent resale. For example, persons are required to show photographic identification and a boarding pass before boarding an airplane. Most travelers assume that this practice is strictly a matter of security. However, a primary purpose in requesting photographic identification is to confirm that the ticket purchaser is the person about to board the airplane and not someone who has repurchased the ticket from a discount buyer. [ citation needed ]
The inability to prevent resale is the largest obstacle to successful price discrimination. [43] Companies have however developed numerous methods to prevent resale. For example, universities require that students show identification before entering sporting events. Governments may make it illegal to resale tickets or products. In Boston, Red Sox baseball tickets can only be resold legally to the team.
The three basic forms of price discrimination are first, second and third degree price discrimination. In first degree price discrimination the company charges the maximum price each customer is willing to pay. The maximum price a consumer is willing to pay for a unit of the good is the reservation price. Thus for each unit the seller tries to set the price equal to the consumer’s reservation price. [49] Direct information about a consumer’s willingness to pay is rarely available. Sellers tend to rely on secondary information such as where a person lives (postal codes); for example, catalog retailers can use mail high-priced catalogs to high-income postal codes. [50] [51] First degree price discrimination most frequently occurs in regard to professional services or in transactions involving direct buyer/seller negotiations. For example, an accountant who has prepared a consumer's tax return has information that can be used to charge customers based on an estimate of their ability to pay. [52]
In second degree price discrimination or quantity discrimination customers are charged different prices based on how much they buy. There is a single price schedule for all consumers but the prices vary depending on the quantity of the good bought. [53] The theory of second degree price discrimination is a consumer is willing to buy only a certain quantity of a good at a given price. Companies know that consumer’s willingness to buy decreases as more units are purchased [ citation needed ] . The task for the seller is to identify these price points and to reduce the price once one is reached in the hope that a reduced price will trigger additional purchases from the consumer. For example, sell in unit blocks rather than individual units.
In third degree price discrimination or multi-market price discrimination [54] the seller divides the consumers into different groups according to their willingness to pay as measured by their price elasticity of demand. Each group of consumers effectively becomes a separate market with its own demand curve and marginal revenue curve. [44] The firm then attempts to maximize profits in each segment by equating MR and MC, [46] [55] [56] Generally the company charges a higher price to the group with a more price inelastic demand and a relatively lesser price to the group with a more elastic demand. [57] Examples of third degree price discrimination abound. Airlines charge higher prices to business travelers than to vacation travelers. The reasoning is that the demand curve for a vacation traveler is relatively elastic while the demand curve for a business traveler is relatively inelastic. Any determinant of price elasticity of demand can be used to segment markets. For example, seniors have a more elastic demand for movies than do young adults because they generally have more free time. Thus theaters will offer discount tickets to seniors. [58]

Example
Assume that by a uniform pricing system the monopolist would sell five units at a price of $10 per unit. Assume that his marginal cost is $5 per unit. Total revenue would be $50, total costs would be $25 and profits would be $25. If the monopolist practiced price discrimination he would sell the first unit for $50 the second unit for $40 and so on. Total revenue would be $150, his total cost would be $25 and his profit would be $125.00. [59] Several things are worth noting. The monopolist acquires all the consumer surplus and eliminates practically all the deadweight loss because he is willing to sell to anyone who is willing to pay at least the marginal cost. [59] Thus the price discrimination promotes efficiency. Secondly, by the pricing scheme price = average revenue and equals marginal revenue. That is the monopolist behaving like a perfectly competitive company. [60] Thirdly, the discriminating monopolist produces a larger quantity than the monopolist operating by a uniform pricing scheme. [61]

Classifying customers
Successful price discrimination requires that companies separate consumers according to their willingness to buy. Determining a customer's willingness to buy a good is difficult. Asking consumers directly is fruitless: consumers don't know, and to the extent they do they are reluctant to share that information with marketers. The two main methods for determining willingness to buy are observation of personal characteristics and consumer actions. As noted information about where a person lives (postal codes), how the person dresses, what kind of car he or she drives, occupation, and income and spending patterns can be helpful in classifying. [ citation needed ]

Monopoly and efficiency
According to the standard model, in which a monopolist sets a single price for all consumers, the monopolist will sell a lesser quantity of goods at a higher price than would companies by perfect competition . Because the monopolist ultimately forgoes transactions with consumers who value the product or service more than its price, monopoly pricing creates a deadweight loss referring to potential gains that went neither to the monopolist nor to consumers. Given the presence of this deadweight loss, the combined surplus (or wealth) for the monopolist and consumers is necessarily less than the total surplus obtained by consumers by perfect competition. Where efficiency is defined by the total gains from trade, the monopoly setting is less efficient than perfect competition. [63]
It is often argued that monopolies tend to become less efficient and less innovative over time, becoming "complacent", because they do not have to be efficient or innovative to compete in the marketplace. Sometimes this very loss of psychological efficiency can increase a potential competitor's value enough to overcome market entry barriers, or provide incentive for research and investment into new alternatives. The theory of contestable markets argues that in some circumstances (private) monopolies are forced to behave as if there were competition because of the risk of losing their monopoly to new entrants. This is likely to happen when a market's barriers to entry are low. It might also be because of the availability in the longer term of substitutes in other markets. For example, a canal monopoly, while worth a great deal during the late 18th century United Kingdom , was worth much less during the late 19th century because of the introduction of railways as a substitute. [ citation needed ]

Natural monopoly
A natural monopoly is an organization that experiences increasing returns to scale over the relevant range of output and relatively high fixed costs. [64] A natural monopoly occurs where the average cost of production "declines throughout the relevant range of product demand". The relevant range of product demand is where the average cost curve is below the demand curve. [65] When this situation occurs, it is always cheaper for one large company to supply the market than multiple smaller companies; in fact, absent government intervention in such markets, will naturally evolve into a monopoly. An early market entrant that takes advantage of the cost structure and can expand rapidly can exclude smaller companies from entering and can drive or buy out other companies. A natural monopoly suffers from the same inefficiencies as any other monopoly. Left to its own devices, a profit-seeking natural monopoly will produce where marginal revenue equals marginal costs. Regulation of natural monopolies is problematic. [ citation needed ] Fragmenting such monopolies is by definition inefficient. The most frequently used methods dealing with natural monopolies are government regulations and public ownership. Government regulation generally consists of regulatory commissions charged with the principal duty of setting prices. [66]
To reduce prices and increase output, regulators often use average cost pricing. By average cost pricing, the price and quantity are determined by the intersection of the average cost curve and the demand curve. [67] This pricing scheme eliminates any positive economic profits since price equals average cost. Average-cost pricing is not perfect. Regulators must estimate average costs. Companies have a reduced incentive to lower costs. Regulation of this type has not been limited to natural monopolies. [67] Average-cost pricing does also have some disadvantages. By setting price equal to the intersection of the demand curve and the average total cost curve, the firm's output is allocatively inefficient as the price is less than the marginal cost (which is the output quantity for a perfectly competitive and allocatively efficient market).

Government-granted monopoly
A government-granted monopoly (also called a "de jure monopoly") is a form of coercive monopoly by which a government grants exclusive privilege to a private individual or company to be the sole provider of a commodity; potential competitors are excluded from the market by law , regulation , or other mechanisms of government enforcement. [ citation needed ]
Samuel Insull , a British-born American electrical industry business magnate invented regulated monopoly. This came from a combination of his business persona and his political one. On the one hand, he abhorred the waste of competing power producers, whose inefficiency would often double the cost of production. On the other hand, he believed in the citizen's right to fair treatment. So while he bought up rival companies and created a monopoly, he kept his prices low and campaigned vigorously for regulation. [68]

Monopolist shutdown rule
A monopolist should shut down when price is less than average variable cost for every output level [69] – in other words where the demand curve is entirely below the average variable cost curve. [69] Under these circumstances at the profit maximum level of output (MR = MC) average revenue would be less than average variable costs and the monopolists would be better off shutting down in the short term. [69]

Breaking up monopolies
In a free market, monopolies can be ended at any time by new competition, breakaway businesses, or consumers seeking alternatives. [ citation needed ] In a highly regulated market environment a government will often either regulate the monopoly, convert it into a publicly owned monopoly environment, or forcibly fragment it (see Antitrust law and trust busting ). Public utilities , often being naturally efficient with only one operator and therefore less susceptible to efficient breakup, are often strongly regulated or publicly owned. American Telephone & Telegraph (AT&T) and Standard Oil are debatable examples of the breakup of a private monopoly by government: When AT&T, a monopoly previously protected by force of law, was broken up into various components in 1984, MCI , Sprint , and other companies were able to compete effectively in the long distance phone market. [ citation needed ]

Law
The existence of a very high market share does not always mean consumers are paying excessive prices since the threat of new entrants to the market can restrain a high-market-share company's price increases. Competition law does not make merely having a monopoly illegal, but rather abusing the power a monopoly may confer, for instance through exclusionary practices (i.e. pricing high just because you are the only one around.) It may also be noted that it is illegal to try to obtain a monopoly, by practices of buying out the competition, or equal practices. If one occurs naturally, such as a competitor going out of business, or lack of competition, it is not illegal until such time as the monopoly holder abuses the power.
First it is necessary to determine whether a company is dominant, or whether it behaves "to an appreciable extent independently of its competitors, customers and ultimately of its consumer". [70] As with collusive conduct, market shares are determined with reference to the particular market in which the company and product in question is sold. The Herfindahl-Hirschman Index (HHI) is sometimes used to assess how competitive an industry is. [71] In the US, the merger guidelines state that a post-merger HHI below 1000 is viewed as unconcentrated while HHIs above that will provoke further review. [72]
By European Union law, very large market shares raise a presumption that a company is dominant, [73] which may be rebuttable. [74] If a company has a dominant position, then there is "a special responsibility not to allow its conduct to impair competition on the common market". [75] The lowest yet market share of a company considered "dominant" in the EU was 39.7%. [76]
Certain categories of abusive conduct are usually prohibited by a country's legislation. [77] The main recognised categories are:
Despite wide agreement that the above constitute abusive practices, there is some debate about whether there needs to be a causal connection between the dominant position of a company and its actual abusive conduct. Furthermore, there has been some consideration of what happens when a company merely attempts to abuse its dominant position.

Historical monopolies

Origin
The term "monopoly" first appears in Aristotle 's Politics . Aristotle describes Thales of Miletus 's cornering of the market in olive presses as a monopoly ( μονοπωλίαν ). [78] [79]
The meaning and understanding of the English word 'monopoly' has changed over the years. [80]

Monopolies of resources

Salt
Vending of common salt ( sodium chloride ) was historically a natural monopoly. Until recently, a combination of strong sunshine and low humidity or an extension of peat marshes was necessary for producing salt from the sea, the most plentiful source. Changing sea levels periodically caused salt " famines " and communities were forced to depend upon those who controlled the scarce inland mines and salt springs, which were often in hostile areas (e.g. the Sahara desert ) requiring well-organised security for transport, storage, and distribution.
The Salt Commission was a legal monopoly in China. Formed in 758, the Commission controlled salt production and sales in order to raise tax revenue for the Tang Dynasty .
The " Gabelle " was a notoriously high tax levied upon salt in the Kingdom of France . The much-hated levy had a role in the beginning of the French Revolution , when strict legal controls specified who was allowed to sell and distribute salt. First instituted in 1286, the Gabelle was not permanently abolished until 1945. [81]

Coal
Robin Gollan argues in The Coalminers of New South Wales that anti-competitive practices developed in the coal industry of Australia's Newcastle as a result of the business cycle . The monopoly was generated by formal meetings of the local management of coal companies agreeing to fix a minimum price for sale at dock. This collusion was known as "The Vend". The Vend ended and was reformed repeatedly during the late 19th century, ending by recession in the business cycle. "The Vend" was able to maintain its monopoly due to trade union assistance, and material advantages (primarily coal geography). During the early 20th century, as a result of comparable monopolistic practices in the Australian coastal shipping business, the Vend developed as an informal and illegal collusion between the steamship owners and the coal industry, eventually resulting in the High Court case Adelaide Steamship Co. Ltd v. R. & AG. [82]

Petroleum
Standard Oil was an American oil producing, transporting, refining, and marketing company. Established in 1870, it became the largest oil refiner in the world. [83] John D. Rockefeller was a founder, chairman and major shareholder. The company was an innovator in the development of the business trust . The Standard Oil trust streamlined production and logistics, lowered costs, and undercut competitors. " Trust-busting " critics accused Standard Oil of using aggressive pricing to destroy competitors and form a monopoly that threatened consumers. Its controversial history as one of the world's first and largest multinational corporations ended in 1911, when the United States Supreme Court ruled that Standard was an illegal monopoly. The Standard Oil trust was dissolved into 33 smaller companies; two of its surviving "child" companies are ExxonMobil and the Chevron Corporation .

Steel
U.S. Steel has been accused of being a monopoly. J. P. Morgan and Elbert H. Gary founded U.S. Steel in 1901 by combining Andrew Carnegie 's Carnegie Steel Company with Gary's Federal Steel Company and William Henry "Judge" Moore 's National Steel Company. [84] [85] At one time, U.S. Steel was the largest steel producer and largest corporation in the world. In its first full year of operation, U.S. Steel made 67 percent of all the steel produced in the United States. However, U.S. Steel's share of the expanding market slipped to 50 percent by 1911, [86] and anti-trust prosecution that year failed.

Diamonds
De Beers settled charges of price fixing in the diamond trade in the 2000s. De Beers is well known for its monopoloid practices throughout the 20th century, whereby it used its dominant position to manipulate the international diamond market. The company used several methods to exercise this control over the market. Firstly, it convinced independent producers to join its single channel monopoly, it flooded the market with diamonds similar to those of producers who refused to join the cartel, and lastly, it purchased and stockpiled diamonds produced by other manufacturers in order to control prices through limiting supply.
In 2000, the De Beers business model changed due to factors such as the decision by producers in Russia, Canada and Australia to distribute diamonds outside the De Beers channel, as well as rising awareness of blood diamonds that forced De Beers to "avoid the risk of bad publicity" by limiting sales to its own mined products. De Beers' market share by value fell from as high as 90% in the 1980s to less than 40% in 2012, having resulted in a more fragmented diamond market with more transparency and greater liquidity.
In November 2011 the Oppenheimer family announced its intention to sell the entirety of its 40% stake in De Beers to Anglo American plc thereby increasing Anglo American's ownership of the company to 85%.[30] The transaction was worth £3.2 billion ($5.1 billion) in cash and ended the Oppenheimer dynasty's 80-year ownership of De Beers.

Utilities
A public utility (or simply "utility") is an organization or company that maintains the infrastructure for a public service or provides a set of services for public consumption. Common examples of utilities are electricity , natural gas , water , sewage , cable television , and telephone . In the United States, public utilities are often natural monopolies because the infrastructure required to produce and deliver a product such as electricity or water is very expensive to build and maintain. [87]
Western Union was criticized as a " price gouging " monopoly in the late 19th century. [88]
American Telephone & Telegraph was a telecommunications giant. AT&T was broken up in 1984.
In the case of Telecom New Zealand , local loop unbundling was enforced by central government.
Telkom is a semi-privatised, part state-owned South African telecommunications company.
Deutsche Telekom is a former state monopoly, still partially state owned. Deutsche Telekom currently monopolizes high-speed VDSL broadband network. [89]
The Long Island Power Authority (LIPA) provided electric service to over 1.1 million customers in Nassau and Suffolk counties of New York , and the Rockaway Peninsula in Queens .
The Comcast Corporation is the largest mass media and communications company in the world by revenue. [90] It is the largest cable company and home Internet service provider in the United States, and the nation's third largest home telephone service provider . Comcast has a monopoly in Boston , Philadelphia , Chicago , and many other small towns across the US. [ citation needed ]

Transportation
The United Aircraft and Transport Corporation was an aircraft manufacturer holding company that was forced to divest itself of airlines in 1934.
Iarnród Éireann , the Irish Railway authority, is a current monopoly as Ireland does not have the size for more companies.
The Long Island Rail Road (LIRR) was founded in 1834, and since the mid-1800s has provided train service between Long Island and New York City . In the 1870s, LIRR became the sole railroad in that area through a series of acquisitions and consolidations. In 2013, the LIRR's commuter rail system is the busiest commuter railroad in North America, serving nearly 335,000 passengers daily. [91]

Foreign trade
Dutch East India Company was created as a legal trading monopoly in 1602. The Vereenigde Oost-Indische Compagnie enjoyed huge profits from its spice monopoly through most of the 17th century. [92]
The British East India Company was created as a legal trading monopoly in 1600. The East India Company was formed for pursuing trade with the East Indies but ended up trading mainly with the Indian subcontinent , North-West Frontier Province , and Balochistan . The Company traded in basic commodities, which included cotton , silk , indigo dye , salt , saltpetre , tea and opium .

Professional sports
Major League Baseball survived U.S. anti-trust litigation in 1922, though its special status is still in dispute as of 2009.
The National Football League survived anti-trust lawsuit in the 1960s but was convicted of being an illegal monopoly in the 1980s.

Other examples of monopolies

Countering monopolies
According to professor Milton Friedman , laws against monopolies cause more harm than good, but unnecessary monopolies should be countered by removing tariffs and other regulation that upholds monopolies.
However, professor Steve H. Hanke believes that although private monopolies are more efficient than public ones, often by a factor of two, sometimes private natural monopolies, such as local water distribution, should be regulated (not prohibited) by, e.g., price auctions. [98]
Thomas DiLorenzo asserts, however, that during the early days of utility companies where there was little regulation, there were no natural monopolies and there was competition. [99] Only when companies realized that they could gain power through government did monopolies begin to form.

See also

Notes and references
WebPage index: 00168
The Open Source Definition
The Open Source Definition is a document published by the Open Source Initiative , to determine whether a software license can be labeled with the open-source certification mark. [1]
The definition was based on the Debian Free Software Guidelines , written and adapted primarily by Bruce Perens with input from Eric S. Raymond and others. [2]

Definition
Introduction
Open source doesn't just mean access to the source code. The distribution terms of open-source software must comply with the following criteria:

Reception

FSF position
The open source movement 's definition of open source software by the Open Source Initiative and the official definitions of free software by the Free Software Foundation basically refer to the same software licenses (with a few minor exceptions see Comparison of free and open-source software licenses ), both definitions stand therefore for the same qualities and values. [3] Despite that, FSF founder Richard Stallman stresses underlying philosophical differences when he comments: "The term “open source” software is used by some people to mean more or less the same category as free software. It is not exactly the same class of software: they accept some licenses that we consider too restrictive, and there are free software licenses they have not accepted. However, the differences in extension of the category are small: nearly all free software is open source, and nearly all open source software is free." [4]

Open Knowledge
Open Knowledge International ( OKI ) [5] described in their Open Definition for open content , open data , and open licenses , "open/free" as synonymous in the definitions of open/free in the Open Source Definition , the Free Software Definition and the Definition of Free Cultural Works : "This essential meaning matches that of “open” with respect to software as in the Open Source Definition and is synonymous with “free” or “libre” as in the Free Software Definition and Definition of Free Cultural Works." [6]

See also
WebPage index: 00169
Copying
Copying is the duplication of information or an artifact based only on an instance of that information or artifact, and not using the process that originally generated it. With analog forms of information, copying is only possible to a limited degree of accuracy , which depends on the quality of the equipment used and the skill of the operator. There is some inevitable deterioration and accumulation of " noise " (random small changes, not sound) from original to copy; when successive generations of copy are made, this deterioration accumulates with each generation. With digital forms of information, copying is perfect. Copy and paste is frequently used for information a computer user selects and copies to an area he or she wishes.
Most high-accuracy copying techniques use the principle that there will be only one type of possible interpretation for each reading of data, and only one possible way to write an interpretation of data. [ clarification needed ]

In art
In visual art, copying the works of the masters is a standard way that students learn to paint and sculpt. In sculpture, copies have often been made using devices such as the pointing machine , the pantograph or, more recently, computer guided router systems that scan [1] a model and can produce it in a variety of materials and in any desired size. [2] Another way of copying three-dimensional works is by lost-wax casting and other forms of molding and casting .

In literature
Prior to the invention of the printing press , the only way to obtain a copy of a book was to copy it out by hand (see scrivener ). Throughout the Middle Ages, monks copied entire texts as a way of disseminating and preserving literary, philosophical and religious texts.

In office work
Offices need more than one copy of a document in a number of situations. They usually need a copy of outgoing correspondence for their records. Sometimes they want to circulate copies of documents they create to several interested parties.
Until the late 18th century, if an office wanted to keep a copy of an outgoing letter, a clerk had to write out the copy by hand. This technology continued to be prevalent through most of the 19th century. For this purpose offices employed copy clerks, also known as copyists, scribes, and scriveners.
A few alternatives to hand copying were invented between the mid-17th century and the late 18th century, but none had a significant impact in offices. In 1780 James Watt obtained a patent for letter copying presses, which James Watt & Co . produced beginning in that year. Letter copying presses were used by the early 1780s by the likes of Benjamin Franklin , George Washington , and Thomas Jefferson . In 1785, Jefferson was using both stationary and portable presses made by James Watt & Co.
During the 19th century a host of competing technologies were introduced to meet office copying needs. The technologies that were most commonly used in 1895 are identified in an 1895 description of the New York Business College's course program: "All important letters or documents are copied in a letter-book or carbon copies [are] made, and instruction is also given in the use of the mimeograph and other labor-saving office devices." [3]

Biological copying
Organically, copying of genetic information can take place using DNA replication , which is able to copy and replicate the data with a high degree of accuracy, but mistakes are common, and occur in the form of mutations . However, in the process of DNA repair , many of the mistakes are resolved by checking the copied data against the original data.

Digital copying
This principle is applied digitally, such as in hard disks , but in a different form. The magnetised data on the disk consists of 1s and 0s. Unlike DNA, it only has two types of information, rather than four types, however, it still has a polar concept of transfer. In this case, the read-write head acts as an intermediary. A data section reading "1", can only trigger one type of response, and "0" for the other. These responses from reading are converted into an electrical form that gets carried through the circuits. Although this can be later converted and processed for other ways of using the data, which can be modified, if a file were being copied from one hard disk to another, the principle ensures that the data is transferred with high fidelity, because only each type of signal can only trigger one type of data write, in this case a 1 or a 0. This excludes exceptions where the data was written incorrectly or the existing data has been corrupted while on the disk such that no distinction can be made, but usually the hard disk returns the area as unreadable. The other concept that using digital copying is website copy [1] , digital copying has more interpretation than just the basic concept of disk read and write itself. Digital Copy is a sample of interpretation of digital copying.

Copying rights
The concept of copying has a particular significance in certain areas of law . In each of the primary areas of intellectual property law, a number of cases have refined the question of what exactly constitutes the kind of copying prohibited by law, especially in areas such as copyright law .
A related concept is plagiarism , copying others' work and passing it off as one's own.

See also
WebPage index: 00170
Engineering
Engineering is the application of mathematics and scientific , economic , social, and practical knowledge in order to invent , innovate , design , build, maintain , research , and improve structures , machines , tools , systems , components , materials , processes , solutions, and organizations .
The discipline of engineering is extremely broad and encompasses a range of more specialized fields of engineering , each with a more specific emphasis on particular areas of applied science, technology and types of application.
The term Engineering is derived from the Latin ingenium , meaning "cleverness" and ingeniare , meaning "to contrive, devise". [1]

Definition
The American Engineers' Council for Professional Development (ECPD, the predecessor of ABET ) [2] has defined "engineering" as:

History
Engineering has existed since ancient times as humans devised fundamental inventions such as the wedge, lever, wheel and pulley. Each of these inventions is essentially consistent with the modern definition of engineering.
The term engineering is derived from the word engineer , which itself dates back to 1390 when an engine'er (literally, one who operates an engine ) originally referred to "a constructor of military engines." [5] In this context, now obsolete, an "engine" referred to a military machine, i.e. , a mechanical contraption used in war (for example, a catapult ). Notable examples of the obsolete usage which have survived to the present day are military engineering corps, e.g. , the U.S. Army Corps of Engineers .
The word "engine" itself is of even older origin, ultimately deriving from the Latin ingenium (c. 1250), meaning "innate quality, especially mental power, hence a clever invention." [6]
Later, as the design of civilian structures such as bridges and buildings matured as a technical discipline, the term civil engineering [4] entered the lexicon as a way to distinguish between those specializing in the construction of such non-military projects and those involved in the older discipline of military engineering .

Ancient era
The Pharos of Alexandria , the pyramids in Egypt , the Hanging Gardens of Babylon , the Acropolis and the Parthenon in Greece , the Roman aqueducts , Via Appia and the Colosseum , Teotihuacán and the cities and pyramids of the Mayan , Inca and Aztec Empires, the Great Wall of China , the Brihadeeswarar Temple of Thanjavur and Indian Temples , among many others, stand as a testament to the ingenuity and skill of the ancient civil and military engineers.
The earliest civil engineer known by name is Imhotep . [4] As one of the officials of the Pharaoh , Djosèr , he probably designed and supervised the construction of the Pyramid of Djoser (the Step Pyramid ) at Saqqara in Egypt around 2630 – 2611 BC . [7] Ancient Greece developed machines in both civilian and military domains. The Antikythera mechanism , the first known mechanical computer , [8] [9] and the mechanical inventions of Archimedes are examples of early mechanical engineering. Some of Archimedes' inventions as well as the Antikythera mechanism required sophisticated knowledge of differential gearing or epicyclic gearing , two key principles in machine theory that helped design the gear trains of the Industrial Revolution, and are still widely used today in diverse fields such as robotics and automotive engineering . [10]
Chinese, Greek, Roman and Hungarian armies employed complex military machines and inventions such as artillery which was developed by the Greeks around the 4th century B.C., [11] the trireme , the ballista and the catapult . In the Middle Ages, the trebuchet was developed.

Renaissance era
The first steam engine was built in 1698 by Thomas Savery . [12] The development of this device gave rise to the Industrial Revolution in the coming decades, allowing for the beginnings of mass production .
With the rise of engineering as a profession in the 18th century, the term became more narrowly applied to fields in which mathematics and science were applied to these ends. Similarly, in addition to military and civil engineering, the fields then known as the mechanic arts became incorporated into engineering.

Modern era
The inventions of Thomas Newcomen and the Scottish engineer James Watt gave rise to modern mechanical engineering . The development of specialized machines and machine tools during the industrial revolution led to the rapid growth of mechanical engineering both in its birthplace Britain and abroad. [4]
John Smeaton was the first self-proclaimed civil engineer and is often regarded as the "father" of civil engineering . He was an English civil engineer responsible for the design of bridges , canals , harbours , and lighthouses . He was also a capable mechanical engineer and an eminent physicist . Smeaton designed the third Eddystone Lighthouse (1755–59) where he pioneered the use of ' hydraulic lime ' (a form of mortar which will set under water) and developed a technique involving dovetailed blocks of granite in the building of the lighthouse. His lighthouse remained in use until 1877 and was dismantled and partially rebuilt at Plymouth Hoe where it is known as Smeaton's Tower . He is important in the history, rediscovery of, and development of modern cement , because he identified the compositional requirements needed to obtain "hydraulicity" in lime; work which led ultimately to the invention of Portland cement .
The United States census of 1850 listed the occupation of "engineer" for the first time with a count of 2,000. [13] There were fewer than 50 engineering graduates in the U.S. before 1865. In 1870 there were a dozen U.S. mechanical engineering graduates, with that number increasing to 43 per year in 1875. In 1890 there were 6,000 engineers in civil, mining, mechanical and electrical. [14]
There was no chair of applied mechanism and applied mechanics established at Cambridge until 1875, and no chair of engineering at Oxford until 1907. Germany established technical universities earlier. [15]
The foundations of electrical engineering in the 1800s included the experiments of Alessandro Volta , Michael Faraday , Georg Ohm and others and the invention of the electric telegraph in 1816 and the electric motor in 1872. The theoretical work of James Maxwell (see: Maxwell's equations ) and Heinrich Hertz in the late 19th century gave rise to the field of electronics . The later inventions of the vacuum tube and the transistor further accelerated the development of electronics to such an extent that electrical and electronics engineers currently outnumber their colleagues of any other engineering specialty. [4] Chemical engineering developed in the late nineteenth century. [4] Industrial scale manufacturing demanded new materials and new processes and by 1880 the need for large scale production of chemicals was such that a new industry was created, dedicated to the development and large scale manufacturing of chemicals in new industrial plants. [4] The role of the chemical engineer was the design of these chemical plants and processes. [4]
Aeronautical engineering deals with aircraft design process design while aerospace engineering is a more modern term that expands the reach of the discipline by including spacecraft design. Its origins can be traced back to the aviation pioneers around the start of the 20th century although the work of Sir George Cayley has recently been dated as being from the last decade of the 18th century. Early knowledge of aeronautical engineering was largely empirical with some concepts and skills imported from other branches of engineering. [16]
The first PhD in engineering (technically, applied science and engineering ) awarded in the United States went to Josiah Willard Gibbs at Yale University in 1863; it was also the second PhD awarded in science in the U.S. [17]
Only a decade after the successful flights by the Wright brothers , there was extensive development of aeronautical engineering through development of military aircraft that were used in World War I . Meanwhile, research to provide fundamental background science continued by combining theoretical physics with experiments.
In 1990, with the rise of computer technology, the first search engine was built by computer engineer Alan Emtage .

Main branches of engineering
Engineering is a broad discipline which is often broken down into several sub-disciplines. These disciplines concern themselves with differing areas of engineering work. Although initially an engineer will usually be trained in a specific discipline, throughout an engineer's career the engineer may become multi-disciplined, having worked in several of the outlined areas. Engineering is often characterized as having four main branches: [18] [19] [20]
Beyond these "Big Four", a number of other branches are recognized. Historically, naval engineering and mining engineering were major branches. Other engineering fields sometimes included as major branches [ citation needed ] are manufacturing engineering , acoustical engineering , corrosion engineering , instrumentation and control , aerospace , automotive , computer , electronic , petroleum , environmental , systems , audio , software , architectural , agricultural , biosystems , biomedical , [21] geological , textile , industrial , materials , [22] and nuclear engineering. [23] These and other branches of engineering are represented in the 36 licensed member institutions of the UK Engineering Council .
New specialties sometimes combine with the traditional fields and form new branches – for example, Earth systems engineering and management involves a wide range of subject areas including anthropology , engineering studies , environmental science , ethics and philosophy of engineering . A new or emerging area of application will commonly be defined temporarily as a permutation or subset of existing disciplines; there is often gray area as to when a given sub-field warrants classification as a new "branch." One key indicator of such emergence is when major universities start establishing departments and programs in the new field.
For each of these fields, there exists considerable overlap, especially in the areas of the application of fundamental sciences to their disciplines such as physics, chemistry, and mathematics. As a result, there are many different types of engineering degrees available. In the past, engineering could be divided into four major branches: mechanical, chemical, civil and electrical, with sub-branches of each discipline. Today, however, the number of engineering degrees available have increased dramatically.

Practice
One who practices engineering is called an engineer , and those licensed to do so may have more formal designations such as Professional Engineer , Chartered Engineer , Incorporated Engineer , Ingenieur , European Engineer , or Designated Engineering Representative . In the UK many skilled trades are called "Engineer" including gas, telephone, photocopy, maintenance, plumber-heating, drainage, sanitary, auto mechanic, TV, Refrigerator, electrician, washing machine, TV antenna installer (satellite) and many others.

Methodology
Engineers apply mathematics and sciences such as physics to find novel solutions to problems or to improve existing solutions. More than ever, engineers are now required to have a proficient knowledge of relevant sciences for their design projects. As a result, many engineers continue to learn new material throughout their career.
If multiple solutions exist, engineers weigh each design choice based on their merit and choose the solution that best matches the requirements. The crucial and unique task of the engineer is to identify, understand, and interpret the constraints on a design in order to yield a successful result. It is generally insufficient to build a technically successful product, rather, it must also meet further requirements.
Constraints may include available resources, physical, imaginative or technical limitations, flexibility for future modifications and additions, and other factors, such as requirements for cost, safety , marketability, productivity, and serviceability . By understanding the constraints, engineers derive specifications for the limits within which a viable object or system may be produced and operated.
A general methodology and epistemology of engineering can be inferred from the historical case studies and comments provided by Walter Vincenti. [24] Though Vincenti's case studies are from the domain of aeronautical engineering, his conclusions can be transferred into many other branches of engineering, too.
According to Billy Vaughn Koen, the " engineering method is the use of heuristics to cause the best change in a poorly understood situation within the available resources." Koen argues that the definition of what makes one an engineer should not be based on what he produces, but rather how he goes about it. [25]

Problem solving
Engineers use their knowledge of science , mathematics , logic , economics , and appropriate experience or tacit knowledge to find suitable solutions to a problem. Creating an appropriate mathematical model of a problem allows them to analyze it (sometimes definitively), and to test potential solutions.
Usually, multiple reasonable solutions exist, so engineers must evaluate the different design choices on their merits and choose the solution that best meets their requirements. Genrich Altshuller , after gathering statistics on a large number of patents , suggested that compromises are at the heart of " low-level " engineering designs, while at a higher level the best design is one which eliminates the core contradiction causing the problem.
Engineers typically attempt to predict how well their designs will perform to their specifications prior to full-scale production. They use, among other things: prototypes , scale models , simulations , destructive tests , nondestructive tests , and stress tests . Testing ensures that products will perform as expected.
Engineers take on the responsibility of producing designs that will perform as well as expected and will not cause unintended harm to the public at large. Engineers typically include a factor of safety in their designs to reduce the risk of unexpected failure. However, the greater the safety factor, the less efficient the design may be.
The study of failed products is known as forensic engineering and can help the product designer in evaluating his or her design in the light of real conditions. The discipline is of greatest value after disasters, such as bridge collapses , when careful analysis is needed to establish the cause or causes of the failure.

Computer use
As with all modern scientific and technological endeavors, computers and software play an increasingly important role. As well as the typical business application software there are a number of computer aided applications ( computer-aided technologies ) specifically for engineering. Computers can be used to generate models of fundamental physical processes, which can be solved using numerical methods .
One of the most widely used design tools in the profession is computer-aided design (CAD) software like CATIA , Autodesk Inventor , DSS SolidWorks or Pro Engineer which enables engineers to create 3D models, 2D drawings, and schematics of their designs. CAD together with digital mockup (DMU) and CAE software such as finite element method analysis or analytic element method allows engineers to create models of designs that can be analyzed without having to make expensive and time-consuming physical prototypes.
These allow products and components to be checked for flaws; assess fit and assembly; study ergonomics; and to analyze static and dynamic characteristics of systems such as stresses, temperatures, electromagnetic emissions, electrical currents and voltages, digital logic levels, fluid flows, and kinematics. Access and distribution of all this information is generally organized with the use of product data management software. [26]
There are also many tools to support specific engineering tasks such as computer-aided manufacturing (CAM) software to generate CNC machining instructions; manufacturing process management software for production engineering; EDA for printed circuit board (PCB) and circuit schematics for electronic engineers; MRO applications for maintenance management; and AEC software for civil engineering.
In recent years the use of computer software to aid the development of goods has collectively come to be known as product lifecycle management (PLM). [27]

Social context
The engineering profession engages in a wide range of activities, from large collaboration at the societal level, and also smaller individual projects. Almost all engineering projects are obligated to some sort of financing agency: a company, a set of investors, or a government. The few types of engineering that are minimally constrained by such issues are pro bono engineering and open-design engineering.
By its very nature engineering has interconnections with society, culture and human behavior. Every product or construction used by modern society is influenced by engineering. The results of engineering activity influence changes to the environment, society and economies, and its application brings with it a responsibility and public safety. Many engineering societies have established codes of practice and codes of ethics to guide members and inform the public at large.
Engineering projects can be subject to controversy. Examples from different engineering disciplines include the development of nuclear weapons , the Three Gorges Dam , the design and use of sport utility vehicles and the extraction of oil . In response, some western engineering companies have enacted serious corporate and social responsibility policies.
Engineering is a key driver of innovation and human development. Sub-Saharan Africa, in particular, has a very small engineering capacity which results in many African nations being unable to develop crucial infrastructure without outside aid. [ citation needed ] The attainment of many of the Millennium Development Goals requires the achievement of sufficient engineering capacity to develop infrastructure and sustainable technological development. [28]
All overseas development and relief NGOs make considerable use of engineers to apply solutions in disaster and development scenarios. A number of charitable organizations aim to use engineering directly for the good of mankind:
Engineering companies in many established economies are facing significant challenges with regard to the number of professional engineers being trained, compared with the number retiring. This problem is very prominent in the UK where engineering has a poor image and low status. [30] There are many negative economic and political issues that this can cause, as well as ethical issues [31] It is widely agreed that the engineering profession faces an "image crisis", [32] rather than it being fundamentally an unattractive career. Much work is needed to avoid huge problems in the UK and other western economies.

Relationships with other disciplines

Science
There exists an overlap between the sciences and engineering practice; in engineering, one applies science. Both areas of endeavor rely on accurate observation of materials and phenomena. Both use mathematics and classification criteria to analyze and communicate observations. [ citation needed ]
Scientists may also have to complete engineering tasks, such as designing experimental apparatus or building prototypes. Conversely, in the process of developing technology engineers sometimes find themselves exploring new phenomena, thus becoming, for the moment, scientists or more precisely "engineering scientists". [ citation needed ]
In the book What Engineers Know and How They Know It , [36] Walter Vincenti asserts that engineering research has a character different from that of scientific research. First, it often deals with areas in which the basic physics or chemistry are well understood, but the problems themselves are too complex to solve in an exact manner.
There is a "real and important" difference between engineering and physics as similar to any science field has to do with technology. [37] [38] Physics is an exploratory science that seeks knowledge of principles while Engineering uses knowledge for practical applications of principles. The former equates an understanding into a mathematical principle while the latter measures variables involved and creates technology. [39] [40] [41] For technology, physics is an auxiliary and in a way technology is considered as applied physics. [42] Though Physics and Engineering are interrelated it doesn't mean a Physicist is sufficient where an Engineer is required. For this mobility, a physicist to work as an engineer requires additional and relevant specialized training. [43] Physicists and engineers engage in different lines of work. [44] But PhD physicists who specialize in sectors of technology and applied science are titled as Technology officer, R&D Engineers and System Engineers. [45] Though as an engineer, role of a physicist is limited. [46] Physicists in their field, work in theoretical analysis and experimental research. [47]
An example of this is the use of numerical approximations to the Navier–Stokes equations to describe aerodynamic flow over an aircraft, or the use of Miner's rule to calculate fatigue damage. Second, engineering research employs many semi- empirical methods that are foreign to pure scientific research, one example being the method of parameter variation. [ citation needed ]
As stated by Fung et al. in the revision to the classic engineering text Foundations of Solid Mechanics :
Although engineering solutions make use of scientific principles, engineers must also take into account safety, efficiency, economy, reliability, and constructability or ease of fabrication as well as the environment, ethical and legal considerations such as patent infringement or liability in the case of failure of the solution. [ citation needed ]

Medicine and biology
The study of the human body, albeit from different directions and for different purposes, is an important common link between medicine and some engineering disciplines. Medicine aims to sustain, repair, enhance and even replace functions of the human body , if necessary, through the use of technology .
Modern medicine can replace several of the body's functions through the use of artificial organs and can significantly alter the function of the human body through artificial devices such as, for example, brain implants and pacemakers . [50] [51] The fields of bionics and medical bionics are dedicated to the study of synthetic implants pertaining to natural systems.
Conversely, some engineering disciplines view the human body as a biological machine worth studying and are dedicated to emulating many of its functions by replacing biology with technology. This has led to fields such as artificial intelligence , neural networks , fuzzy logic , and robotics . There are also substantial interdisciplinary interactions between engineering and medicine. [52] [53]
Both fields provide solutions to real world problems. This often requires moving forward before phenomena are completely understood in a more rigorous scientific sense and therefore experimentation and empirical knowledge is an integral part of both.
Medicine, in part, studies the function of the human body. The human body, as a biological machine, has many functions that can be modeled using engineering methods. [54]
The heart for example functions much like a pump, [55] the skeleton is like a linked structure with levers, [56] the brain produces electrical signals etc. [57] These similarities as well as the increasing importance and application of engineering principles in medicine, led to the development of the field of biomedical engineering that uses concepts developed in both disciplines.
Newly emerging branches of science, such as systems biology , are adapting analytical tools traditionally used for engineering, such as systems modeling and computational analysis, to the description of biological systems. [54]

Art
There are connections between engineering and art; [58] they are direct in some fields, for example, architecture , landscape architecture and industrial design (even to the extent that these disciplines may sometimes be included in a university's Faculty of Engineering); and indirect in others. [58] [59] [60] [61]
The Art Institute of Chicago , for instance, held an exhibition about the art of NASA 's aerospace design. [62] Robert Maillart 's bridge design is perceived by some to have been deliberately artistic. [63] At the University of South Florida , an engineering professor, through a grant with the National Science Foundation , has developed a course that connects art and engineering. [59] [64]
Among famous historical figures, Leonardo da Vinci is a well-known Renaissance artist and engineer, and a prime example of the nexus between art and engineering. [49] [65]

Business Engineering and Engineering Management
Business Engineering deals with the relationship between professional engineering, IT systems, business administration and change management . Engineering management or "Management engineering" is a specialized field of management concerned with engineering practice or the engineering industry sector. The demand for management-focused engineers (or from the opposite perspective, managers with an understanding of engineering), has resulted in the development of specialized engineering management degrees that develop the knowledge and skills needed for these roles. During an engineering management course, students will develop industrial engineering skills, knowledge, and expertise, alongside knowledge of business administration, management techniques, and strategic thinking. Engineers specializing in change management must have in-depth knowledge of the application of industrial and organizational psychology principles and methods. Professional engineers often train as certified management consultants in the very specialized field of management consulting applied to engineering practice or the engineering sector. This work often deals with large scale complex business transformation or Business process management initiatives in aerospace and defence, automotive, oil and gas, machinery, pharmaceutical, food and beverage, electrical & electronics, power distribution & generation, utilities and transportation systems. This combination of technical engineering practice, management consulting practice, industry sector knowledge, and change management expertise enables professional engineers who are also qualified as management consultants to lead major business transformation initiatives. These initiatives are typically sponsored by C-level executives.

Other fields
In other fields not associated with professional engineering the word "engineer" and or "engineering" has been adapted to mean design, develop, contrive, manipulate, implement an outcome. [ citation needed ] In political science , the term engineering has been borrowed for the study of the subjects of social engineering and political engineering , which deal with forming political and social structures using engineering methodology coupled with political science principles. Financial engineering has similarly borrowed the term.

See also
WebPage index: 00171
Free and open-source software
Free and open-source software ( FOSS ) is computer software that can be classified as both free software and open-source software . [a] That is, anyone is freely licensed to use, copy, study, and change the software in any way, and the source code is openly shared so that people are encouraged to voluntarily improve the design of the software. [3] This is in contrast to proprietary software , where the software is under restrictive copyright and the source code is usually hidden from the users.
The benefits of using FOSS can include decreasing software costs, increasing security and stability (especially in regard to malware ), protecting privacy , and giving users more control over their own hardware. Free, open-source operating systems such as Linux and descendents of BSD are widely utilized today, powering millions of servers , desktops , smartphones (e.g. Android ), and other devices. [4] [5] Free software licenses and open-source licenses are used by many software packages .

History
.
In the 1950s, 1960s, and 1970s to 1980s, it was common for computer users to have the source code for all programs they used, and the permission and ability to modify it for their own use. Software , including source code, was commonly shared by individuals who used computers. Most companies had a business model based on hardware sales, and provided or bundled software with hardware, free of charge. [ citation needed ] Organizations of users and suppliers were formed to facilitate the exchange of software; see, for example, SHARE and DECUS .
By the late 1960s, the prevailing business model around software was changing. A growing and evolving software industry was competing with the hardware manufacturer's bundled software products; rather than funding software development from hardware revenue, these new companies were selling software directly. Leased machines required software support while providing no revenue for software, and some customers able to better meet their own needs did not want the costs of software bundled with hardware product costs. In United States vs. IBM , filed 17 January 1969, the government charged that bundled software was anticompetitive. [6] While some software might always be free, there would be a growing amount of software that was for sale only. In the 1970s and early 1980s, some parts of the software industry began using technical measures (such as only distributing binary copies of computer programs ) to prevent computer users from being able to use reverse engineering techniques to study and customize software they had paid for. In 1980, the copyright law was extended to computer programs in the United States [7] —previously, computer programs could be considered ideas, procedures, methods, systems, and processes, which are not copyrightable. [8] [9]
In 1983, Richard Stallman , longtime member of the hacker community at the MIT Artificial Intelligence Laboratory , announced the GNU project , saying that he had become frustrated with the effects of the change in culture of the computer industry and its users. [10] Software development for the GNU operating system began in January 1984, and the Free Software Foundation (FSF) was founded in October 1985. An article outlining the project and its goals was published in March 1985 titled the GNU Manifesto . The manifesto included significant explanation of the GNU philosophy, Free Software Definition and " copyleft " ideas.
The Linux kernel , started by Linus Torvalds , was released as freely modifiable source code in 1991. Initially, Linux was not released under a free or open-source software license. However, with version 0.12 in February 1992, he relicensed the project under the GNU General Public License . [11] Much like Unix, Torvalds' kernel attracted the attention of volunteer programmers. [ citation needed ]
FreeBSD and NetBSD (both derived from 386BSD ) were released as free software when the USL v. BSDi lawsuit was settled out of court in 1993. OpenBSD forked from NetBSD in 1995. Also in 1995, The Apache HTTP Server , commonly referred to as Apache, was released under the Apache License 1.0 .
In 1997, Eric Raymond published The Cathedral and the Bazaar , a reflective analysis of the hacker community and free software principles. The paper received significant attention in early 1998, and was one factor in motivating Netscape Communications Corporation to release their popular Netscape Communicator Internet suite as free software . This code is today better known as Mozilla Firefox and Thunderbird .
Netscape's act prompted Raymond and others to look into how to bring the FSF's free software ideas and perceived benefits to the commercial software industry. They concluded that FSF's social activism was not appealing to companies like Netscape, and looked for a way to rebrand the free software movement to emphasize the business potential of sharing and collaborating on software source code. The new name they chose was "open source", and quickly Bruce Perens , publisher Tim O'Reilly , Linus Torvalds , and others signed on to the rebranding. The Open Source Initiative was founded in February 1998 to encourage use of the new term and evangelize open-source principles. [12]
While the Open Source Initiative sought to encourage the use of the new term and evangelize the principles it adhered to, commercial software vendors found themselves increasingly threatened by the concept of freely distributed software and universal access to an application's source code . A Microsoft executive publicly stated in 2001 that "open source is an intellectual property destroyer. I can't imagine something that could be worse than this for the software business and the intellectual-property business." [13] This view perfectly summarizes the initial response to FOSS by some software corporations. [ citation needed ] However, while FOSS has historically played a role outside of the mainstream of private software development, companies as large as Microsoft have begun to develop official open-source presences on the Internet. IBM, Oracle, Google and State Farm are just a few of the companies with a serious public stake in today's competitive open-source market. There has been a significant shift in the corporate philosophy concerning the development of free and open-source software (FOSS). [14]

GPLv3 controversy
While copyright is the primary legal mechanism that FOSS authors use to ensure license compliance for their software, other mechanisms such as legislation, patents, and trademarks have implications as well. In response to legal issues with patents and the Digital Millennium Copyright Act (DMCA), the Free Software Foundation released version 3 of its GNU Public License in 2007 that explicitly addressed the DMCA and patent rights.
After the development of the GNU GPLv3 in 2007, the FSF (as copyright holder of many pieces of the GNU system) updated many [ citation needed ] of the GNU programs' licenses from GPLv2 to GPLv3. On the other hand, the adoption of the new GPL version was heavily discussed in the FOSS ecosystem, [15] several projects decided against upgrading. For instance the linux kernel , [16] [17] the BusyBox [18] [19] project, AdvFS , [20] Blender , [21] and as also the VLC media player decided against adopting the GPLv3. [22]
Apple , a user of GCC and a heavy user of both DRM and patents, switched the compiler in its Xcode IDE from GCC to Clang , which is another FOSS compiler [23] but is under a permissive license . [24] LWN speculated that Apple was motivated partly by a desire to avoid GPLv3. [23] The Samba project also switched to GPLv3, so Apple replaced Samba in their software suite by a closed-source, proprietary software alternative. [25]

Commercial ownership of open-source software
Mergers have affected major open-source software. Sun Microsystems (Sun) acquired MySQL AB , owner of the popular open-source MySQL database, in 2008. [26]
Oracle in turn purchased Sun in January, 2010, acquiring their copyrights, patents, and trademarks. Thus, Oracle became the owner of both the most popular proprietary database and the most popular open-source database. Oracle's attempts to commercialize the open-source MySQL database have raised concerns in the FOSS community. [27] Partly in response to uncertainty about the future of MySQL, the FOSS community forked the project into new database systems outside of Oracle's control. These include MariaDB , Percona , and Drizzle . [28] All of these have distinct names; they are distinct projects and can not use the trademarked name MySQL. [29]

Legal cases

Oracle v. Google
In August, 2010, Oracle sued Google , claiming that its use of Java in Android infringed on Oracle's copyrights and patents. The Oracle v. Google case ended in May 2012, with the finding that Google did not infringe on Oracle's patents, and the trial judge ruled that the structure of the Java APIs used by Google was not copyrightable. The jury found that Google infringed a small number of copied files, but the parties stipulated that Google would pay no damages. [30] Oracle appealed to the Federal Circuit , and Google filed a cross-appeal on the literal copying claim. [31] Oracle won the appeal, but Google won a subsequent retrial in 2016. [ citation needed ]

Overview
Free and open source software is an umbrella term for software that is either free software , open source software , or as is often the case, both. In practice, free and open source software is usually provided free of charge, allows the user to inspect the source code, and provides a relatively high level of control of the software's function compared to proprietary software .
There is little practical distinction between the two terms, as the primary license difference between free software and open source is one of philosophy. According to the Free Software Foundation, "Nearly all open source software is free software. The two terms describe almost the same category of software, but they stand for views based on fundamentally different values." [32] Thus, the Open Source Initiative considers many free software licenses to also be open-source. These include the latest versions of the FSF's three main licenses: the GPL, the Lesser General Public License (LGPL), and the GNU Affero General Public License (AGPL). [33] Thus, terminology of free and open source software is intended to be neutral on these philosophical disagreements.
There are a number of related terms and abbreviations for free and open source software (FOSS or F/OSS) or free/libre and open source software (FLOSS). (see: Alternative terms for free software )

Free software
Richard Stallman's Free Software Definition , adopted by the Free Software Foundation (FSF), defines free software as a matter of liberty, not price. [34] The earliest known publication of the definition of his free software idea was in the February 1986 edition [35] of the FSF's now-discontinued GNU's Bulletin publication. The canonical source for the document is in the philosophy section of the GNU Project website. As of April 2008, it is published there in 39 languages. [36]

Open source
The Open Source Definition is used by the Open Source Initiative to determine whether a software license qualifies for the organization's insignia for open-source software . The definition was based on the Debian Free Software Guidelines , written and adapted primarily by Bruce Perens . [37] [38] Perens did not base his writing on the four freedoms of free software from the Free Software Foundation , which were only later available on the web. [39] Perens later stated that he felt Eric Raymond's promotion of open source unfairly overshadowed the Free Software Foundation's efforts and reaffirmed his support for free software. [40] In the following 2000s he spoke about Open source again. [41] [42]

Adoption

Adoption by governments
The Government of Kerala , India, announced its official support for free/open-source software in its State IT Policy of 2001, [45] [ discuss ] which was formulated after the first-ever free software conference in India, Freedom First! , held in July 2001 in Trivandrum, the capital of Kerala. In 2009, Government of Kerala started the International Centre for Free and Open Source Software ( ICFOSS ). [46] In March 2015 the Indian government announced a policy on adoption of open source software. [47] [48]
In the German City of Munich , conversion of 15,000 PCs and laptops from Microsoft Windows-based operating systems to a Debian -based Linux environment called LiMux spanned the ten years of 2003 to 2013. After successful completion of the project, more than 80% of all computers were running Linux. [49]
In 2004, a law in Venezuela (Decree 3390) went into effect, mandating a two-year transition to open source in all public agencies. As of June 2009, this ambitious transition was still under way. [50] [51] Malaysia launched the "Malaysian Public Sector Open Source Software Program", saving millions on proprietary software licenses until 2008. [52] [53]
In 2005 the Government of Peru voted to adopt open source across all its bodies. [54] The 2002 response to Microsoft's critique is available online. In the preamble to the bill, the Peruvian government stressed that the choice was made to ensure that key pillars of democracy were safeguarded: "The basic principles which inspire the Bill are linked to the basic guarantees of a state of law." [55] In September, the Commonwealth of Massachusetts announced its formal adoption of the OpenDocument standard for all Commonwealth entities. [56]
In 2006, the Brazilian government has simultaneously encouraged the distribution of cheap computers running Linux throughout its poorer communities by subsidizing their purchase with tax breaks. [56]
In April 2008, [57] Ecuador passed a similar law, Decree 1014, designed to migrate the public sector to Libre Software. [58]
In February 2009, the United States White House moved its website to Linux servers using Drupal for content management. [59]
In March 2009, the French Gendarmerie Nationale announced it will totally switch to Ubuntu by 2015. The Gendarmerie began its transition to open source software in 2005 when it replaced Microsoft Office with OpenOffice.org across the entire organization. [60]
In January 2010, the Government of Jordan announced a partnership with Ingres Corporation (now named Actian), an open source database management company based in the United States, to promote open-source software use, starting with university systems in Jordan. [61]
In September 2014, the Uganda National Information Technology Authority (NITA-U) announced a call for feedback on an Open Source Strategy & Policy [62] at a workshop in conjunction with the ICT Association of Uganda (ICTAU).
In August 2016, the United States government announced a new federal source code policy which mandates that at least 20% of custom source code developed by or for any agency of the federal government be released as open-source software (OSS). [63] In addition, the policy requires that all source code be shared between agencies. The public release is under a three-year pilot program and agencies are obliged to collect data on this pilot to gauge its performance. The overall policy aims to reduce duplication, avoid vendor 'lock-in', and stimulate collaborative development. A new website code .gov provides "an online collection of tools, best practices, and schemas to help agencies implement this policy", the policy announcement stated. It also provides the "primary discoverability portal for custom-developed software intended both for Government-wide reuse and for release as OSS". [63] As yet unspecified OSS licenses will be added to the code. [64]
In 2017, the European Commission stated that «EU institutions should become open source software users themselves, even more than they already are» and listed open source software as one of the nine key drivers of innovation, together with big data , mobility, cloud computing and the internet of things . [65]

FOSS and Benkler's new economy
According to Yochai Benkler , Jack N. and Lillian R. Berkman Professor for Entrepreneurial Legal Studies at Harvard Law School , free software is the most visible part of a new economy of commons-based peer production of information, knowledge, and culture. As examples, he cites a variety of FOSS projects, including both free software and open-source. [66]
This new economy is already under development. To commercialize FOSS, many companies move towards advertisement-supported software. In such a model, the only way to increase revenue is to make the advertisement more valuable. Facebook was criticized in 2011 for using novel methods of tracking users to accomplish this. [67]
This new economy has alternatives. Apple's App Stores have proven very popular with both users and developers. The Free Software Foundation considers Apple's App Stores to be incompatible with its GPL and complained that Apple was infringing on the GPL with its iTunes terms of use. Rather than change those terms to comply with the GPL, Apple removed the GPL-licensed products from its App Stores. [68]

See also

Notes

Citations
WebPage index: 00172
Open design
Open design is the development of physical products, machines and systems through use of publicly shared design information. Open design involves the making of both free and open-source software (FOSS) as well as open-source hardware . The process is generally facilitated by the Internet and often performed without monetary compensation. The goals and philosophy are identical to that of the open-source movement , but are implemented for the development of physical products rather than software. [5] Open design is a form of co-creation , where the final product is designed by the users, rather than an external stakeholder such as a private company.

History

Sources of the open-design movement
Sharing of manufacturing information can be traced back to the 18th and 19th century. [6] [7] Aggressive patenting put an end to that period of extensive knowledge sharing. [8] More recently, principles of open design have been related to the free software and open source movements. [9] In 1997 Eric S. Raymond , Tim O'Reilly and Larry Augustin established "open source" as an alternative expression to "free software," and in 1997 Bruce Perens published the Open Source Definition . In late 1998, Dr. Sepehr Kiani (a PhD in mechanical engineering from MIT) realized that designers could benefit from open source policies, and in early 1999 he convinced Dr. Ryan Vallance and Dr. Samir Nayfeh of the potential benefits of open design in machine design applications. [10] Together they established the Open Design Foundation (ODF) as a non-profit corporation, and set out to develop an Open Design Definition. [10]
The idea of open design was taken up, either simultaneously or subsequently, by several other groups and individuals. The principles of open design are closely similar to those of open-source hardware design, which emerged in March 1998 when Reinoud Lamberts of the Delft University of Technology proposed on his “Open Design Circuits” website the creation of a hardware design community in the spirit of free software. [11]
Ronen Kadushin coined the title "Open Design" in his 2004 Master’s thesis, and the term was later formalized in the 2010 Open Design Manifesto. [12]

Current directions of the open-design movement
The open-design movement currently unites two trends. On one hand, people apply their skills and time on projects for the common good , perhaps where funding or commercial interest is lacking, for developing countries or to help spread ecological or cheaper technologies. On the other hand, open design may provide a framework for developing advanced projects and technologies that might be beyond the resource of any single company or country and involve people who, without the copyleft mechanism, might not collaborate otherwise. There is now also a third trend, where these two methods come together to use high-tech open-source (e.g. 3D printing) but customized local solutions for sustainable development . [13]

Open machine design as compared to open-source software
The open-design movement is currently fairly nascent but holds great potential for the future. In some respects design and engineering are even more suited to open collaborative development than the increasingly common open-source software projects, because with 3D models and photographs the concept can often be understood visually. It is not even necessary that the project members speak the same languages to usefully collaborate.
However, there are certain barriers to overcome for open design when compared to software development where there are mature and widely used tools available and the duplication and distribution of code cost next to nothing. Creating, testing and modifying physical designs is not quite so straightforward because of the effort, time and cost required to create the physical artefact; although with access to emerging flexible computer-controlled manufacturing techniques the complexity and effort of construction can be significantly reduced (see tools mentioned in the fab lab article).

Open-design organizations
Open design is currently a fledgling movement consisting of several unrelated or loosely related initiatives. [14] Many of these organizations are single, funded projects, while a few organizations are focusing on an area needing development. In some cases (e.g. Thingiverse for 3D printable designs or Appropedia for open source appropriate technology ) organizations are making an effort to create a centralized open source design repository as this enables innovation. [15] Notable organizations include:

See also
WebPage index: 00173
Research
Research comprises "creative work undertaken on a systematic basis in order to increase the stock of knowledge , including knowledge of humans, culture and society, and the use of this stock of knowledge to devise new applications." [1] It is used to establish or confirm facts, reaffirm the results of previous work, solve new or existing problems, support theorems , or develop new theories . A research project may also be an expansion on past work in the field. Research projects can be used to develop further knowledge on a topic, or in the example of a school research project, they can be used to further a student's research prowess to prepare them for future jobs or reports. To test the validity of instruments, procedures, or experiments, research may replicate elements of prior projects or the project as a whole. The primary purposes of basic research (as opposed to applied research ) are documentation , discovery , interpretation , or the research and development (R&D) of methods and systems for the advancement of human knowledge. Approaches to research depend on epistemologies , which vary considerably both within and between humanities and sciences. There are several forms of research: scientific , humanities , artistic , economic , social , business , marketing , practitioner research , life , technological ,etc.

Etymology
The word research is derived from the Middle French " recherche ", which means "to go about seeking", the term itself being derived from the Old French term " recerchier " a compound word from "re-" + "cerchier", or "sercher", meaning 'search'. [3] The earliest recorded use of the term was in 1577. [3]

Definitions
Research has been defined in a number of different ways.
A broad definition of research is given by Godwin Colibao : "In the broadest sense of the word, the definition of research includes any gathering of data, information, and facts for the advancement of knowledge." [4]
Another definition of research is given by John W. Creswell, who states that "[r]esearch is a process of steps used to collect and analyze information to increase our understanding of a topic or issue". It consists of three steps: pose a question, collect data to answer the question, and present an answer to the question. [5]
The Merriam-Webster Online Dictionary defines research in more detail as "a studious inquiry or examination; especially investigation or experimentation aimed at the discovery and interpretation of facts, revision of accepted theories or laws in the light of new facts, or practical application of such new or revised theories or laws". [3]

Forms of research
Original research is research that is not exclusively based on a summary, review or synthesis of earlier publications on the subject of research. This material is of a primary source character. The purpose of the original research is to produce new knowledge , rather than to present the existing knowledge in a new form ( e.g. , summarized or classified). [6] [7]
Original research can take a number of forms, depending on the discipline it pertains to. In experimental work, it typically involves direct or indirect observation of the researched subject(s), e.g., in the laboratory or in the field, documents the methodology, results, and conclusions of an experiment or set of experiments, or offers a novel interpretation of previous results. In analytical work, there are typically some new (for example) mathematical results produced, or a new way of approaching an existing problem. In some subjects which do not typically carry out experimentation or analysis of this kind, the originality is in the particular way existing understanding is changed or re-interpreted based on the outcome of the work of the researcher . [8]
The degree of originality of the research is among major criteria for articles to be published in academic journals and usually established by means of peer review . [9] Graduate students are commonly required to perform original research as part of a dissertation . [10]
Scientific research is a systematic way of gathering data and harnessing curiosity . This research provides scientific information and theories for the explanation of the nature and the properties of the world. It makes practical applications possible. Scientific research is funded by public authorities, by charitable organizations and by private groups, including many companies. Scientific research can be subdivided into different classifications according to their academic and application disciplines. Scientific research is a widely used criterion for judging the standing of an academic institution, but some argue that such is an inaccurate assessment of the institution, because the quality of research does not tell about the quality of teaching (these do not necessarily correlate). [11]
Research in the humanities involves different methods such as for example hermeneutics and semiotics . Humanities scholars usually do not search for the ultimate correct answer to a question, but instead, explore the issues and details that surround it. Context is always important, and context can be social, historical, political, cultural, or ethnic. An example of research in the humanities is historical research, which is embodied in historical method . Historians use primary sources and other evidence to systematically investigate a topic, and then to write histories in the form of accounts of the past. Other studies aim to merely examine the occurrence of behaviours in societies and communities, without particularly looking for reasons or motivations to explain these. These studies may be qualitative or quantitative, and can use a variety of approaches, such as queer theory or feminist theory. [12]
Artistic research , also seen as 'practice-based research', can take form when creative works are considered both the research and the object of research itself. It is the debatable body of thought which offers an alternative to purely scientific methods in research in its search for knowledge and truth.

Scientific research
Generally, research is understood to follow a certain structural process . Though step order may vary depending on the subject matter and researcher, the following steps are usually part of most formal research, both basic and applied:
A common misconception is that a hypothesis will be proven (see, rather, null hypothesis ). Generally, a hypothesis is used to make predictions that can be tested by observing the outcome of an experiment. If the outcome is inconsistent with the hypothesis, then the hypothesis is rejected (see falsifiability ). However, if the outcome is consistent with the hypothesis, the experiment is said to support the hypothesis. This careful language is used because researchers recognize that alternative hypotheses may also be consistent with the observations. In this sense, a hypothesis can never be proven, but rather only supported by surviving rounds of scientific testing and, eventually, becoming widely thought of as true.
A useful hypothesis allows prediction and within the accuracy of observation of the time, the prediction will be verified. As the accuracy of observation improves with time, the hypothesis may no longer provide an accurate prediction. In this case, a new hypothesis will arise to challenge the old, and to the extent that the new hypothesis makes more accurate predictions than the old, the new will supplant it. Researchers can also use a null hypothesis, which states no relationship or difference between the independent or dependent variables.

Historical research
The historical method comprises the techniques and guidelines by which historians use historical sources and other evidence to research and then to write history. There are various history guidelines that are commonly used by historians in their work, under the headings of external criticism, internal criticism, and synthesis. This includes lower criticism and sensual criticism. Though items may vary depending on the subject matter and researcher, the following concepts are part of most formal historical research: [13]

Artistic research
The controversial trend of artistic teaching becoming more academics-oriented is leading to artistic research being accepted as the primary mode of enquiry in art as in the case of other disciplines. [14] One of the characteristics of artistic research is that it must accept subjectivity as opposed to the classical scientific methods. As such, it is similar to the social sciences in using qualitative research and intersubjectivity as tools to apply measurement and critical analysis. [15]
Artistic research has been defined by the University of Dance and Circus (Dans och Cirkushögskolan, DOCH), Stockholm in the following manner - "Artistic research is to investigate and test with the purpose of gaining knowledge within and for our artistic disciplines. It is based on artistic practices, methods, and criticality. Through presented documentation, the insights gained shall be placed in a context." [16] Artistic research aims to enhance knowledge and understanding with presentation of the arts. [17] For a survey of the central problematics of today's Artistic Research, see Giaco Schiesser . [18]
According to artist Hakan Topal , in artistic research, "perhaps more so than other disciplines, intuition is utilized as a method to identify a wide range of new and unexpected productive modalities". [19] Most writers, whether of fiction or non-fiction books, also have to do research to support their creative work. This may be factual, historical, or background research. Background research could include, for example, geographical or procedural research. [20]
The Society for Artistic Research (SAR) publishes the triannual Journal for Artistic Research (JAR), [21] [22] an international, online, open access , and peer-reviewed journal for the identification, publication , and dissemination of artistic research and its methodologies, from all arts disciplines and it runs the Research Catalogue (RC), [23] [24] [25] a searchable, documentary database of artistic research, to which anyone can contribute.
Patricia Leavy addresses eight arts-based research (ABR) genres: narrative inquiry, fiction-based research, poetry, music, dance, theatre, film, and visual art. [26]
In 2016 ELIA (European League of the Institutes of the Arts) launched The Florence Principles' on the Doctorate in the Arts . [27] The Florence Principles relating to the Salzburg Principles and the Salzburg Recommendations of EUA (European University Association) name seven points of attention to specify the Doctorate / Ph.D. in the Arts compared to a scientific doctorate / Ph.D. The Florence Principles have been endorsed and are supported also by AEC , CILECT , CUMULUS and SAR .

Steps in conducting research
Research is often conducted using the hourglass model structure of research. [28] The hourglass model starts with a broad spectrum for research, focusing in on the required information through the method of the project (like the neck of the hourglass), then expands the research in the form of discussion and results. The major steps in conducting research are: [29]
The steps generally represent the overall process; however, they should be viewed as an ever-changing iterative process rather than a fixed set of steps. [31] Most research begins with a general statement of the problem, or rather, the purpose for engaging in the study. [32] The literature review identifies flaws or holes in previous research which provides justification for the study. Often, a literature review is conducted in a given subject area before a research question is identified. A gap in the current literature, as identified by a researcher, then engenders a research question. The research question may be parallel to the hypothesis . The hypothesis is the supposition to be tested. The researcher(s) collects data to test the hypothesis. The researcher(s) then analyzes and interprets the data via a variety of statistical methods, engaging in what is known as empirical research . The results of the data analysis in rejecting or failing to reject the null hypothesis are then reported and evaluated. At the end, the researcher may discuss avenues for further research. However, some researchers advocate for the reverse approach: starting with articulating findings and discussion of them, moving "up" to identification of a research problem that emerges in the findings and literature review. The reverse approach is justified by the transactional nature of the research endeavor where research inquiry, research questions, research method, relevant research literature, and so on are not fully known until the findings have fully emerged and been interpreted.
Rudolph Rummel says, "... no researcher should accept any one or two tests as definitive. It is only when a range of tests are consistent over many kinds of data, researchers, and methods can one have confidence in the results." [33]
Plato in Meno talks about an inherent difficulty, if not a paradox, of doing research that can be paraphrased in the following way, "If you know what you're searching for, why do you search for it?! [i.e., you have already found it] If you don't know what you're searching for, what are you searching for?!" [34]

Research methods
The goal of the research process is to produce new knowledge or deepen understanding of a topic or issue. This process takes three main forms (although, as previously discussed, the boundaries between them may be obscure):
There are two major types of empirical research design: qualitative research and quantitative research. Researchers choose qualitative or quantitative methods according to the nature of the research topic they want to investigate and the research questions they aim to answer:
The quantitative data collection methods rely on random sampling and structured data collection instruments that fit diverse experiences into predetermined response categories. [ citation needed ] These methods produce results that are easy to summarize, compare, and generalize. [ citation needed ] Quantitative research is concerned with testing hypotheses derived from theory and/or being able to estimate the size of a phenomenon of interest.
If the research question is about people, participants may be randomly assigned to different treatments (this is the only way that a quantitative study can be considered a true experiment). [ citation needed ] If this is not feasible, the researcher may collect data on participant and situational characteristics in order to statistically control for their influence on the dependent, or outcome, variable. If the intent is to generalize from the research participants to a larger population, the researcher will employ probability sampling to select participants. [37]
In either qualitative or quantitative research, the researcher(s) may collect primary or secondary data. Primary data is data collected specifically for the research, such as through interviews or questionnaires. Secondary data is data that already exists, such as census data, which can be re-used for the research. It is good ethical research practice to use secondary data wherever possible. [38]
Mixed-method research, i.e. research that includes qualitative and quantitative elements, using both primary and secondary data, is becoming more common. [39]
Big data has brought big impacts on research methods so that now many researchers do not put much effort into data collection; furthermore, methods to analyze easily available huge amounts of data have also been developed. [40]
Non-empirical ( theoretical ) research is an approach that involves the development of theory as opposed to using observation and experimentation. As such, non-empirical research seeks solutions to problems using existing knowledge as its source. This, however, does not mean that new ideas and innovations cannot be found within the pool of existing and established knowledge. Non-empirical research is not an absolute alternative to empirical research because they may be used together to strengthen a research approach. Neither one is less effective than the other since they have their particular purpose in science. Typically empirical research produces observations that need to be explained; then theoretical research tries to explain them, and in so doing generates empirically testable hypotheses; these hypotheses are then tested empirically, giving more observations that may need further explanation; and so on. See Scientific method .
A simple example of a non-empirical task is the prototyping of a new drug using a differentiated application of existing knowledge; another is the development of a business process in the form of a flow chart and texts where all the ingredients are from established knowledge. Much of cosmological research is theoretical in nature. Mathematics research does not rely on externally available data; rather, it seeks to prove theorems about mathematical objects .

Research method controversies
There have been many controversies about research methods stemming from the effort of philosophical positivism to distinguish science from other practices (especially religion) by its method. This promise leads to methodological hegemony and methodology wars where diverse researchers, often coming from opposing paradigms , try to impose their own methodology on the entire field or even on science practice in general as the only legitimate one. [ citation needed ]

Anti-methodology
According to this view, general scientific methodology does not exist and attempts to impose it on scientists are counterproductive. Each particular research project with its emerging particular inquiries requires and should produce its own way (method) of researching. Similar to art practice, the notion of methodology has to be replaced with the notion of research mastery. [41]

Problems in research

Methods of research
In many disciplines, Western methods of conducting research are predominant. [42] Researchers are overwhelmingly taught Western methods of data collection and study. The increasing participation of indigenous peoples as researchers has brought increased attention to the lacuna in culturally-sensitive methods of data collection. Non-Western methods of data collection may not be the most accurate or relevant for research on non-Western societies. For example, “ Hua Oranga ” was created as a criterion for psychological evaluation in Māori populations, and is based on dimensions of mental health important to the Māori people — "taha wairua (the spiritual dimension), taha hinengaro (the mental dimension), taha tinana (the physical dimension), and taha whanau (the family dimension)”. [43]

Linguicism
Periphery scholars face the challenges of exclusion and linguicism in research and academic publication. As the great majority of mainstream academic journals are written in English, multilingual periphery scholars often must translate their work in order to be accepted to elite Western-dominated journals. [44] Multilingual scholars’ influences from their native communicative styles can be assumed to be incompetence instead of difference. [45]

Publication
Publications from periphery countries rarely rise to the same elite status as those of North America and Europe, primarily [ citation needed ] because limitations on the availability of resources including high-quality paper and sophisticated image-rendering software and printing tools render these publications less able to satisfy standards currently carrying formal or informal authority in the publishing industry. [45] These limitations in turn result in the under-representation of scholars from periphery nations among the set of publications holding prestige status relative to the quantity and quality of those scholars' research efforts, and this under-representation in turn results in disproportionately reduced acceptance of the results of their efforts as contributions to the body of knowledge available worldwide.

Influence of the open-access movement
The open access movement assumes that all information generally deemed useful should be free and belongs to a “public domain”, that of “humanity”. [46] This idea gained prevalence as a result of Western colonial history and ignores alternative conceptions of knowledge circulation. For instance, most indigenous communities consider that access to certain information proper to the group should be determined by relationships. [46]
There is alleged to be a double standard in the Western knowledge system. On the one hand, “digital right management” used to restrict access to personal information on social networking platforms is celebrated as a protection of privacy, while simultaneously when similar functions are utilised by cultural groups (i.e. indigenous communities) this is denounced as “access control” and reprehended as censorship. [46]

Future perspectives
Even though Western dominance seems to be prominent in research, some scholars, such as Simon Marginson, argue for “the need [for] a plural university world”. [47] Marginson argues that the East Asian Confucian model could take over the Western model.
This could be due to changes in funding for research both in the East and the West. Focussed on emphasizing educational achievement, East Asian cultures, mainly in China and South Korea, have encouraged the increase of funding for research expansion. [47] In contrast, in the Western academic world, notably in the United Kingdom as well as in some state governments in the United States, funding cuts for university research have occurred, which some [ who? ] say may lead to the future decline of Western dominance in research.

Professionalisation 
In several national and private academic systems, the professionalisation of research has resulted in formal job titles .

In Russia
In present-day Russia , the former Soviet Union and in some post-Soviet states the term researcher ( Russian : Научный сотрудник , nauchny sotrudnik ) is both a generic term for a person who carried out scientific research, as well as a job position within the frameworks of the USSR Academy of Sciences , Soviet universities, and in other research-oriented establishments. The term is also sometimes translated as research fellow , research associate , etc.
The following ranks are known:

Publishing
Academic publishing is a system that is necessary in order for academic scholars to peer review the work and make it available for a wider audience. The system varies widely by field and is also always changing, if often slowly. Most academic work is published in journal article or book form. There is also a large body of research that exists in either a thesis or dissertation form. These forms of research can be found in databases explicitly for theses and dissertations. In publishing, STM publishing is an abbreviation for academic publications in science, technology, and medicine .
Most established academic fields have their own scientific journals and other outlets for publication, though many academic journals are somewhat interdisciplinary, and publish work from several distinct fields or subfields. The kinds of publications that are accepted as contributions of knowledge or research vary greatly between fields, from the print to the electronic format. A study suggests that researchers should not give great consideration to findings that are not replicated frequently. [49] It has also been suggested that all published studies should be subjected to some measure for assessing the validity or reliability of its procedures in order to prevent the publication of unproven findings. [50] Business models are different in the electronic environment. Since about the early 1990s, licensing of electronic resources, particularly journals, has been very common. Presently, a major trend, particularly with respect to scholarly journals, is open access . [51] There are two main forms of open access: open access publishing, in which the articles or the whole journal is freely available from the time of publication, and self-archiving , where the author makes a copy of their own work freely available on the web.

Research funding
Most funding for scientific research comes from three major sources: corporate research and development departments; private foundations , for example, the Bill and Melinda Gates Foundation ; and government research councils such as the National Institutes of Health in the USA [52] and the Medical Research Council in the UK. These are managed primarily through universities and in some cases through military contractors. Many senior researchers (such as group leaders) spend a significant amount of their time applying for grants for research funds. These grants are necessary not only for researchers to carry out their research but also as a source of merit.
The Social Psychology Network provides a comprehensive list of U.S. Government and private foundation funding sources.

See also
WebPage index: 00174
Research Councils UK
Established in 2002 following a Government review the Research Councils UK ( RCUK ) is a Non-Departmental Government Body whose purpose is to manage a strategic partnership between seven individual research councils that coordinate and fund research in the arts, humanities, science and engineering. It enables the Councils to work together more effectively to enhance the overall impact and effectiveness of their research, training, and innovation.
There are seven councils:

Function
RCUK adds value to individual Research Council activities by:
Each of the Research Councils is an equal partner in RCUK, and each uses its best endeavours to identify and pursue opportunities for mutually beneficial joint working with one or more of the other Councils.

Organisation
Research councils are non-departmental government bodies incorporated by Royal Charter . Each is governed by its own governing council comprising a mix of academic and non-academic members, appointed by the Secretary for Innovation, Universities and Skills following a public nomination. The councils receive public funds from the Department for Business, Innovation and Skills , and each reports annually to the British Parliament. In 2008 the combined annual budget was £3.5 billion, of which over £1 billion went to research grants and training at universities . This is one element of the UK's dual system of research funding, the other being block grants provided by the UK Funding Councils for higher education.
Research Council grants support around 50,000 researchers through 18,000 grants at any one time. About 8,000 PhDs are awarded annually as a result of their funding.
The Councils directly employ around 13,000 staff, 9,000 of whom are researchers and technicians at institutes such as the British Antarctic Survey , the Laboratory of Molecular Biology , the Roslin Institute , and the Rutherford Appleton Laboratory . However, in the UK funding system only a few permanent institutes that require permanent infrastructure are directly controlled or core-funded by the Councils. Most funding is allocated competitively and few awards last more than ten years, which allows the Councils to vary capacity to meet changing priorities and challenges.
Research council funding decisions are guided by the Haldane Principle , the idea that decisions are best made by researchers independently from government. Research council funding competitions use open peer review.

Councils
There are seven Research Councils:
The MRC 's headquarters is in central London and the other six research councils and the RCUK operate from a single complex in Swindon . The Research Councils also have a joint office in Brussels since 1984—the United Kingdom Research Office ( UKRO )—and in 2007 and 2008 established three additional foreign offices in Beijing , China ( [1] ), Washington, DC , ( [2] ), and New Delhi , India ( [3] ).
In 2007 the Government raised the status of the Technology Strategy Board (TSB) to become, in effect, a research council for industry. This was motivated by a concern that the seven research councils, with their emphasis on academic excellence, were giving insufficient attention to innovation through the application of research findings. The TSB has set up its headquarters next door to the Swindon offices of the research councils.

History
Government funding of science in the United Kingdom began in 1675 when the Royal Observatory was established in Greenwich . This trend continued in the 19th century with the creation of the British Geological Survey in 1832, and the allocation of funds in 1850 to the Royal Society to award individual grants.
By the First World War in 1915, claims about the poor state of British manufacturing compared to Germany's led to the Department of Scientific and Industrial Research (DSIR). It was a part of government, staffed by civil servants who distributed grants, operated laboratories, and made policy. Examples included the Radio Research Station , established in Ditton Park in 1924, which later became the Appleton Laboratory .
In 1918 Richard Haldane produced a report on the machinery of government that recommended that government departments undertake more research before making policy and that they should oversee that specific, policy-minded research, while more general research should be governed by autonomous councils free from political pressure. Lord Hailsham dubbed this separation of duties as "the Haldane principle " in 1964 when he was Minister of Science; it has remained a guiding principle ever since. [1]
Following the Haldane Report's recommendations, a Medical Research Council (MRC) was created in 1920 from a previous body called the Medical Research Committee that had been established in 1913 to distribute funds collected under the National Insurance Act 1911 . In contrast to DSIR, the MRC was not a government department, its staff were not civil servants, and it concentrated its resources in a small number of central laboratories and a large number of research units associated with universities and hospitals. [2]
In 1931 the Agricultural Research Council was established by incorporating 12 major agricultural research institutes that had been created in England and Wales in 1914.
In 1949 Nature Conservancy was established as a Research Council in all but name. The National Research Development Corporation (NRDC) was also created to provide financial assistance for the development of inventions.
In 1957 the National Institute for Research in Nuclear Science (NIRNS) was formed to operate the Rutherford High Energy Laboratory , and in 1962 the Daresbury Laboratory .
By 1964 there were 14,150 science and engineering graduates in the UK, up from 7,688 in 1955, and annual civil and military research expenditure had risen from £0.6 million in 1913 to £10 million in 1939 to £76 million in 1964. [3] To respond to this growth, in 1963 Sir Burke Trend chaired a committee to enquire into the organisation of civil science. [4] One major recommendation was that the unwieldy Department of Scientific and Industrial Research (DSIR) should be divided into a Science Research Council, a Natural Resources Research Council (NRDC), and an Industrial Research and Development Authority (IRDA) to address scientific research and industrial innovation, respectively, with the NRDC to be transferred to the Minister of Science's portfolio in order to ensure a smooth transition through the linear model of innovation .
After the national election , the government chose to align scientific research with education in a Department of Education and Science , while industrial innovation was assigned to a Ministry of Technology . This was seen as a barrier between research and innovation, and when he stepped down as Science Minister, Lord Hailsham argued, "Ever since 1915 it has been considered axiomatic that responsibility for industrial research and development is better exercised in conjunction with research in the medical, agricultural and other fields". [5] After 1967 it was relaxed by Solly Zuckerman , who chaired the Cabinet -level Central Advisory Council for Science and Technology and brought the Department of Education and Science and the Ministry of Technology together, but this conflict remains a regular point of contention.
Under the control of the Department of Education and Science , the Science & Technology Act of 1965 created both the Science Research Council (SRC) and the Natural Environment Research Council (NERC). The SRC incorporated most of the science part of DSIR, including the Appleton Laboratory, and both the Royal Greenwich Observatory and Royal Observatory Edinburgh , and took control of the Rutherford High Energy Laboratory and the Daresbury Laboratory from NIRNS. NERC incoporporated the Nature Conservancy and British Geological Survey .
Also founded in 1965 was the Social Sciences Research Council (later the ESRC ) bringing the number of Research Councils to five—Medicine, Agriculture, Natural Environment, Science, and Social Science—divided by disciplines that were not expected to collaborate.
In 1981, the emphasis in policy on innovation rather than pure science increased so the SRC became the Science and Engineering Research Council (SERC).
In 1983 the ARC also changed its focus to outputs rather than methods to become the Agricultural and Food Research Council (AFRC).
From 1992 the Research Councils reported to the Office of Science and Technology in the Cabinet Office as the making of government departmental policy by the Office of the Chief Scientific Adviser was merged with the making of national science policy by the Science Branch of the Department of Education and Science .
SERC struggled to combine three incompatible business models—administratively efficient short-term grant distribution, medium-term commitments to international agreements, and long-term commitments to staff and facilities. Given a lack of control over exchange rate fluctuations and the need to meet long-term commitments, cuts regularly fell on the short-term grants, thereby alienating the research community.
In 1994 SERC finally split into the EPSRC and PPARC to further separate innovation-orientated engineering from pure research into particle physics and astronomy . [6] In 1995, the CCLRC was spun out of the EPSRC, dividing responsibility for laboratories from those for the allocation of university research grants. [7]
In 1994 parts of the SERC and the AFRC were combined to form the Biotechnology and Biological Sciences Research Council (BBSRC).
From 1995 the Research Councils reported to the Office of Science and Technology in the Department of Trade and Industry as government science policy became more linked to industrial policy .
In 2002 Research Councils UK was created as a secretariat in order to bring together the Research Councils at a higher level to work together more effectively.
In 2005 the Arts and Humanities Research Council (AHRC) was established in order to bring research funding in the arts and humanities into line with that for other disciplines. It was created from the former Arts and Humanities Research Board, which had been managed by the British Academy since 1998.
From 2006 the Research Councils reported to the Office of Science and "Innovation" instead of "Technology", as the policy focus switched from technology objects to innovation process, although it was still within the Department of Trade and Industry .
In April 2007 PPARC and CCLRC were combined to form the Science and Technology Facilities Council (STFC) to create a single Research Council which provides access for UK scientists to national and international research facilities. [8] [9]
From June 2007 the Research Councils reported to the Department for Innovation, Universities and Skills as the making of innovation policy was merged with the making of policy for universities and skills training, and separated from industrial policy under the Department for Business, Enterprise and Regulatory Reform .
In 2008 RCUK Shared Services Centre Ltd (SSC) was created as a separate company to share administrative duties and cut costs.
From June 2009 the Research Councils reported to the Department for Business, Innovation and Skills as the making of higher education and innovation policy (from the Department for Innovation, Universities and Skills ) was merged back with business policy making ( Department for Business, Enterprise and Regulatory Reform ).

See also
WebPage index: 00175
Legislature
A legislature is a deliberative assembly with the authority to make laws for a political entity such as a country or city . Legislatures form important parts of most governments ; in the separation of powers model, they are often contrasted with the executive and judicial branches of government.
Laws enacted by legislatures are known as legislation . Legislatures observe and steer governing actions and usually have exclusive authority to amend the budget or budgets involved in the process.
The members of a legislature are called legislators . In a democracy , legislators are most commonly popularly elected , although indirect election and appointment by the executive are also used, particularly for bicameral legislatures featuring an upper chamber .

Internal organization
Each chamber of legislature consists of a number of legislators who use some form of parliamentary procedure to debate political issues and vote on proposed legislation. There must be a certain number of legislators present to carry out these activities; this is called a quorum .
Some of the responsibilities of a legislature, such as giving first consideration to newly proposed legislation, are usually delegated to committees made up of small selections of the legislators.
The members of a legislature usually represent different political parties ; the members from each party generally meet as a caucus to organize their internal affairs.
The internal organization of a legislature is also shaped by the informal norms that are shared by its members.

Power
Legislatures vary widely in the amount of political power they wield, compared to other political players such as judiciaries , militaries , and executives . In 2009, political scientists M. Steven Fish and Matthew Kroenig constructed a Parliamentary Powers Index in an attempt to quantify the different degrees of power among national legislatures. The German Bundestag , the Italian Parliament , and the Mongolian State Great Khural tied for most powerful, while Myanmar's House of Representatives and Somalia's Transitional Federal Assembly (since replaced by the Federal Parliament of Somalia ) tied for least powerful. [1]
Some political systems follow the principle of legislative supremacy , which holds that the legislature is the supreme branch of government and cannot be bound by other institutions, such as the judicial branch or a written constitution . Such a system renders the legislature more powerful.

Delegation
Legislatures will sometime delegate their legislative power to administrative or executive agencies . [2]

Members
Legislatures are made up of individual members, known as legislators , who vote on proposed laws. A legislature usually contains a fixed number of legislators; because legislatures usually meet in a specific room filled with seats for the legislators, this is often described as the number of "seats" it contains. For example, a legislature that has 100 "seats" has 100 members. By extension, an electoral district that elects a single legislator can also be described as a "seat", as, for, example, in the phrases " safe seat " and " marginal seat ".

Terminology
In parliamentary systems of government , the executive is responsible to the legislature which may remove it with a vote of no confidence . On the other hand, according to the separation of powers doctrine, the legislature in a presidential system is considered an independent and coequal branch of government along with both the judiciary and the executive. [3]
Names for national legislatures include " parliament ", " congress ", " diet " and " assembly ".

Chambers
A legislature may debate and vote upon bills as a single unit, or it may be composed of multiple separate assemblies , called by various names including legislative chambers , debate chambers , and houses , which debate and vote separately and have distinct powers. A legislature which operates as a single unit is unicameral , one divided into two chambers is bicameral , and one divided into three chambers is tricameral .
In bicameral legislatures, one chamber is usually considered the upper house , while the other is considered the lower house . The two types are not rigidly different, but members of upper houses tend to be indirectly elected or appointed rather than directly elected, tend to be allocated by administrative divisions rather than by population, and tend to have longer terms than members of the lower house. In some systems, particularly parliamentary systems , the upper house has less power and tends to have a more advisory role, but in others, particularly presidential systems , the upper house has equal or even greater power.
In federations , the upper house typically represents the federation's component states. This is a case with the supranational legislature of the European Union . The upper house may either contain the delegates of state governments – as in the European Union and in Germany and, before 1913, in the United States – or be elected according to a formula that grants equal representation to states with smaller populations, as is the case in Australia and the United States since 1913.
Tricameral legislatures are rare; the Massachusetts Governor's Council still exists, but the most recent national example existed in the waning years of Caucasian-minority rule in South Africa . Tetracameral legislatures no longer exist, but they were previously used in Scandinavia .

Size
Legislatures vary widely in their size. Among national legislatures , China's National People's Congress is the largest with 2 987 members, while Vatican City's Pontifical Commission is the smallest with 7. Neither legislature is democratically elected, and the National People's Congress has little independent power.
Legislative size is a tradeoff between efficiency and representation; the smaller the legislature, the more efficiently it can operate, but the larger the legislature, the better it can represent the political diversity of its constituents. Comparative analysis of national legislatures has found that size of a country's lower house tends to correspond to the cube root of its population ; that is, the size of the lower house tends to increase along with population, but much more slowly. [4]

See also
WebPage index: 00176
LexML Brasil
LexML Brasil (or LexML-BR or LexML Brazil ) is a project of Brazil 's Electronic Government initiative. Its objective is to establish open data systems, integrate work processes and share data, in the context of identifying and structuring executive , legislative and judiciary documents. The LexML-BR standards define a set of simple technology-neutral electronic protocols and representations, based on XML and HTTP ecossistem.
While the project was officially launched on June 30, 2009, Brazil has been participating in the LexML community since 2006. In 2009, LexML became an explicit national data standard in the " pt:e-PING ". [1] [2]
In May, 2012, Brazil's "Public Access to Information" law ( Lei de Acesso a Informações Públicas ) entered into force, [3] which strengthened the standing of LexML as a transparency tool that could assist in carrying out the obligation to publish government data in the areas of legislative and court documents.

Schema
LexML's technical standards allow efficient handling of an enormous quantity of legislative and court information available in Brasil . These include:

Dedicated resources
The main resources needed for the project are already in place:

History
An early development at Brazil occurred at 1997, in a scholar initiative, [11] with the modeling of the structure of Brazilians legislative documents, and the demonstration that all legislative documents can be automatically translated to HTML hypertext, with intra and inter links. The seminal algorithms (implemented [11] as Perl scripts and regular expressions ) was lost one decade, rediscovered during the development of an important LexML tool, the lexml-linker . [12] Some scholar studies continued, [13] and served as support to redirect the initial LexML-BR focus on XML schemas to metadata and URN schemas .
The LexML-BR Project was started in ~2006, and had the LexML-IT as an antecedent, [14] [15] as well public as consultings. [16] On June 30, 2009, it was launched officially. [17] [18] [19]
It is now a joint initiaitve of many administrative bodies, including Brazil's legislature, executive and judiciary branches, part of the IT Management Community , which combines the areas of legislative and court information.
The goals of the LexML Brazil project can be divided into two main areas:

Motivation
In addition to the legal requirements in Brazil for transparency and publication of government documents (see Motivations ), the sheer volume of legislation places a premium on digitization and better public access to digital forms of the law.
In 20 years, Brazil has produced approximately: [21]
There has been some research identifying this proliferation of laws and bureaucracy as partly responsible for many economic activities going 'underground'. [22] [23]

See also
WebPage index: 00177
Free culture movement
The free culture movement is a social movement that promotes the freedom to distribute and modify creative works in the form of free content [1] [2] or open content [3] [4] [5] by using the Internet and other forms of media.
The movement objects to over-restrictive copyright laws. Many members of the movement argue that such laws hinder creativity. [6] They call this system " permission culture ." [7]
Creative Commons is an organization started by Lawrence Lessig which provides licenses that permit sharing and remixing under various conditions, and also offers an online search of various Creative Commons-licensed works.
The free culture movement, with its ethos of free exchange of ideas, is aligned with the free and open source software movement .
Today, the term stands for many other movements, including open access (OA), the remix culture , the hacker culture , the access to knowledge movement , the Open Source Learning , the copyleft movement and the public domain movement. [ citation needed ]

History

Precursors
In the late 1960s, Stewart Brand founded the Whole Earth Catalog and argued that technology could be liberating rather than oppressing. [8] He coined the slogan Information wants to be free in 1984 [9] against limiting access to information by governmental control, preventing a public domain of information. [10]

Background of the formation of the Free Culture movement
In 1998, the United States Congress passed the Sonny Bono Copyright Term Extension Act which President Clinton signed into law. The legislation extended copyright protections for twenty additional years, resulting in a total guaranteed copyright term of seventy years after a creator's death. The bill was heavily lobbied by music and film corporations like Disney , and dubbed as the Mickey Mouse Protection Act. Lawrence Lessig claims copyright is an obstacle to cultural production, knowledge sharing and technological innovation, and that private interests – as opposed to public good – determine law. [11] He travelled the country in 1998, giving as many as a hundred speeches a year at college campuses, and sparked the movement. It led to the foundation of the first chapter of the Students for Free Culture at Swarthmore College .
In 1999, Lessig challenged the Bono Act, taking the case to the US Supreme Court . Despite his firm belief in victory, citing the Constitution's plain language about "limited" copyright terms, Lessig only gained two dissenting votes: from Justices Stephen Breyer and John Paul Stevens .

Foundation of the Creative Commons
In 2001, Lessig initiated Creative Commons , an alternative "some rights reserved" licensing system to the default "all rights reserved" copyright system. Lessig focuses on a fair balance between the interest of the public to use and participate into released creative works and the need of protection for a creator's work, which still enables a "read-write" remix culture . [6]
The term “free culture” was originally used since 2003 during the World Summit on Information Society [12] to present the first free license for artistic creation at large, initiated by the Copyleft attitude team in France since 2001 (named free art license ). It was then developed in Lawrence Lessig's book Free Culture in 2004. [13]
In August 2003 the Open Content Project , a 1998 Creative Commons precursor by David A. Wiley , announced the Creative Commons as successor project and Wiley joined as director. [14] [15]

"Free Cultural Works" Definition
In 2005/2006 within the free culture movement, Creative Commons has been criticized by Erik Möller [16] and Benjamin Mako Hill for lacking minimum standards for freedom. [17] Following this, the Definition of Free Cultural Works were created as collaborative work of many, including Erik Möller , Lawrence Lessig , Benjamin Mako Hill and Richard Stallman . [18] In February 2008, several Creative Commons licenses were "approved for free cultural works", namely the CC BY and CC BY-SA (later also the CC0 ). [19] Creative commons licenses with restrictions on commercial use or derivative works were not approved.
In October 2014 the Open Knowledge Foundation described their definition of "open", for open content and open knowledge , as synonymous to the definition of "free" in the "Definition of Free Cultural Works", noting that both are rooted in the Open Source Definition and Free Software Definition . [20] Therefore the same three creative commons licenses are recommended for open content and free content, CC BY , CC BY-SA , and CC0 . [21] [22] [23] The Open Knowledge foundation defined additionally three specialized licenses for data and databases, previously unavailable, the Open Data Commons Public Domain Dedication and Licence (PDDL), the Open Data Commons Attribution License (ODC-BY) and the Open Data Commons Open Database License (ODbL).

Organizations
The organization commonly associated with free culture is Creative Commons (CC), founded by Lawrence Lessig . CC promotes sharing creative works and diffusing ideas to produce cultural vibrance, scientific progress and business innovation.
QuestionCopyright.org is another organization whose stated mission is "to highlight the economic, artistic, and social harm caused by distribution monopolies, and to demonstrate how freedom-based distribution is better for artists and audiences." [24] QuestionCopyright may be best known for its association with artist Nina Paley , whose multi-award winning feature length animation Sita Sings The Blues has been held up as an extraordinarily successful [25] example of free distribution under the aegis of the "Sita Distribution Project". [26] The web site of the organization has a number of resources, publications, and other references related to various copyright, patent, and trademark issues.
The student organization Students for Free Culture is sometimes confusingly called "the Free Culture Movement," but that is not its official name. The organization is a subset of the greater movement. The first chapter was founded in 1998 at Swarthmore College, and by 2008, the organization had twenty-six chapters. [27]
The free culture movement takes the ideals of the free and open source software movement and extends them from the field of software to all cultural and creative works. Early in Creative Commons' life, Richard Stallman (the founder of the Free Software Foundation and the free software movement) supported the organization. He withdrew his support due to the introduction of several licenses including a developing nations and the sampling licenses [28] and later restored some support when Creative Commons retired those licenses.
The free music movement, a subset of the free culture movement, started out just as the Web rose in popularity with the Free Music Philosophy [29] by Ram Samudrala in early 1994. It was also based on the idea of free software by Richard Stallman and coincided with nascent open art and open information movements (referred to here as collectively as the "free culture movement"). The Free Music Philosophy used a three pronged approach to voluntarily encourage the spread of unrestricted copying, based on the fact that copies of recordings and compositions could be made and distributed with complete accuracy and ease via the Internet. The subsequent free music movement was reported on by diverse media outlets including Billboard , [30] Forbes , [31] Levi's Original Music Magazine , [32] The Free Radical , [33] Wired [34] [35] and The New York Times . [36] Along with the explosion of the Web driven by open source software and Linux , the rise of P2P and lossy compression , and despite the efforts of the music industry, free music became largely a reality in the early 21st century. [37] Organizations such as the Electronic Frontier Foundation and Creative Commons with free information champions like Lawrence Lessig were devising numerous licenses that offered different flavors of copyright and copyleft. The question was no longer why and how music should be free, but rather how creativity would flourish while musicians developed models to generate revenue in the Internet era. [38] [39] [40]

Reception

Skepticism from the FSF
Originally, Free Software Foundation founder Richard Stallman didn't see the same importance for free works beyond software. [41] For instance for manuals and books Stallman stated in the 1990s:
Similarly, in 1999 Stallman said that he sees "no social imperative for free hardware designs like the imperative for free software". [42] Other authors, such as Joshua Pearce , have argued that there is an ethical imperative for open-source hardware , specifically with respect to open-source-appropriate technology for sustainable development . [43]
Later, Richard Stallman changed his position slightly and advocated for free sharing of information in 2009. [44] But, in 2011 Stallman commented on the Megaupload founder's arrest, "I think all works meant for practical uses must be free, but that does not apply to music, since music is meant for appreciation, not for practical use." [45] In a follow up Stallman differentiated three classes: Works of practical use should be free, Works representing points of view should be shareable but not changeable and works of art or entertainment should be copyrighted (but only for 10 years). [46] In an essay in 2012 Stallman argued that video games as software should be free but not their artwork. [47] In 2015 Stallman advocated for free hardware designs. [48]

Copyright proponents
Vocal criticism against the free culture movement comes from copyright proponents.
Prominent technologist and musician Jaron Lanier discusses this perspective of Free Culture in his 2010 book You Are Not a Gadget . Lanier's concerns include the depersonalization of crowd-sourced anonymous media (such as Wikipedia) and the economic dignity of middle-class creative artists.
Andrew Keen , a critic of Web 2.0 , criticizes some of the Free Culture ideas in his book, Cult of the Amateur , describing Lessig as an "intellectual property communist." [49]
The decline of news media industry's market share is blamed on free culture but scholars like Clay Shirky claim that the market itself, not free culture, is what's killing the journalism industry. [13]

See also
WebPage index: 00178
Open publishing
Open publishing is a process of creating news or other content that is transparent to the readers. They can contribute a story and see it instantly appear in the pool of stories publicly available. Those stories are filtered as little as possible to help the readers find the stories they want. Readers can see editorial decisions being made by others. They can see how to get involved and help make editorial decisions. If they can think of a better way for the software to help shape editorial decisions, they can copy the software because it is free and open source to change it and start their own site. If they want to redistribute the news, they can, preferably on an open publishing site.
Internet sites run on open publishing software allow anyone with Internet access to visit the site and upload content directly without having to penetrate the filters of traditional media. Several fundamental principles tend to inform the organizations and sites dedicated to open publishing, though they do so to varying degrees. These principles include non-hierarchy, public participation, minimal editorial control, and transparency.
Open publishing idea embedded the same concept, although didn’t mention Eric S. Raymond 's major insight. In open publishing problematic content is shallow. Given a large enough audience, peers, readers and commentators, almost all problematic content will quickly be noticed, highlighted and fixed. Arnison's Law: "Given enough eyeballs, problematic content is shallow".
It should be distinguished from open access publishing – the publishing of material organized in such a way that there is no financial or other barrier to the user. (All or almost all open publishing is in fact also open access .)

Examples

See also

External links
WebPage index: 00179
Australia
Coordinates : 27°S 133°E ﻿ / ﻿ 27°S 133°E ﻿ / -27; 133
Australia ( i / ə ˈ s t r eɪ l i ə / , / ɒ - / , / - lj ə / ), [11] [12] officially the Commonwealth of Australia , [13] is a country comprising the mainland of the Australian continent , the island of Tasmania and numerous smaller islands . It is the world's sixth-largest country by total area . The neighbouring countries are Papua New Guinea , Indonesia and East Timor to the north; the Solomon Islands and Vanuatu to the north-east; and New Zealand to the south-east. Australia's capital is Canberra , and its largest urban area is Sydney .
For about 50,000 years [14] before the first British settlement in the late 18th century, [15] [16] Australia was inhabited by indigenous Australians , [17] who spoke languages classifiable into roughly 250 groups . [18] [19] After the European discovery of the continent by Dutch explorers in 1606, Australia's eastern half was claimed by Great Britain in 1770 and initially settled through penal transportation to the colony of New South Wales from 26 January 1788. The population grew steadily in subsequent decades, and by the 1850s most of the continent had been explored and an additional five self-governing crown colonies established. On 1 January 1901, the six colonies federated , forming the Commonwealth of Australia. Australia has since maintained a stable liberal democratic political system that functions as a federal parliamentary constitutional monarchy comprising six states and several territories . The population of 24 million [6] is highly urbanised and heavily concentrated on the eastern seaboard. [20]
Australia has the world's 13th-largest economy and ninth-highest per capita income (IMF). [21] With the second-highest human development index globally, the country ranks highly in quality of life, health, education, economic freedom , and civil liberties and political rights. [22] Australia is a member of the United Nations , G20 , Commonwealth of Nations , ANZUS , Organisation for Economic Co-operation and Development (OECD), World Trade Organization , Asia-Pacific Economic Cooperation , and the Pacific Islands Forum .

Name
The name Australia (pronounced [əˈstɹæɪljə, -liə] in Australian English [23] ) is derived from the Latin Terra Australis ("southern land") a name used for putative lands in the southern hemisphere since ancient times. [24] The earliest recorded use of the word Australia in English was in 1625 in "A note of Australia del Espíritu Santo, written by Sir Richard Hakluyt ", published by Samuel Purchas in Hakluytus Posthumus , a corruption of the original Spanish name "Austrialia del Espíritu Santo" (Southern Land of the Holy Spirit) [25] [26] [27] for an island in Vanuatu . [28] The Dutch adjectival form Australische was used in a Dutch book in Batavia ( Jakarta ) in 1638, to refer to the newly discovered lands to the south. [29] The first time that the name Australia appears to have been officially used was in a despatch to Lord Bathurst of 4 April 1817 in which Governor Lachlan Macquarie acknowledges the receipt of Matthew Flinders ' charts of Australia. [30] On 12 December 1817, Macquarie recommended to the Colonial Office that it be formally adopted. [31] In 1824, the Admiralty agreed that the continent should be known officially as Australia . [32] The first official published use of the term Australia came with the 1830 publication of "The Australia Directory". [33]

History

Prehistory
Human habitation of the Australian continent is estimated to have begun between 42,000 and 48,000 years ago, [34] [35] possibly with the migration of people by land bridges and short sea-crossings from what is now Southeast Asia . These first inhabitants may have been ancestors of modern Indigenous Australians. [36] At the time of European settlement in the late 18th century, most Indigenous Australians were hunter-gatherers , with a complex oral culture and spiritual values based on reverence for the land and a belief in the Dreamtime . The Torres Strait Islanders , ethnically Melanesian , were originally horticulturists and hunter-gatherers. [37] The northern coasts and waters of Australia were visited sporadically by fishermen from Maritime Southeast Asia . [38]

European arrival
The first recorded European sighting of the Australian mainland, and the first recorded European landfall on the Australian continent (in 1606), are attributed to the Dutch. The first ship and crew to chart the Australian coast and meet with Aboriginal people was the Duyfken captained by Dutch navigator, Willem Janszoon . [39] He sighted the coast of Cape York Peninsula in early 1606, and made landfall on 26 February at the Pennefather River near the modern town of Weipa on Cape York. [40] The Dutch charted the whole of the western and northern coastlines and named the island continent " New Holland " during the 17th century, but made no attempt at settlement. [40] William Dampier , an English explorer and privateer, landed on the north-west coast of New Holland in 1688 and again in 1699 on a return trip. [41] In 1770, James Cook sailed along and mapped the east coast, which he named New South Wales and claimed for Great Britain. [42]
With the loss of its American colonies in 1783, the British Government sent a fleet of ships, the " First Fleet ", under the command of Captain Arthur Phillip , to establish a new penal colony in New South Wales. A camp was set up and the flag raised at Sydney Cove , Port Jackson , on 26 January 1788, [16] a date which became Australia's national day, Australia Day , although the British Crown Colony of New South Wales was not formally promulgated until 7 February 1788. The first settlement led to the foundation of Sydney , and the exploration and settlement of other regions.
A British settlement was established in Van Diemen's Land , now known as Tasmania, in 1803, and it became a separate colony in 1825. [43] The United Kingdom formally claimed the western part of Western Australia (the Swan River Colony ) in 1828. [44] Separate colonies were carved from parts of New South Wales: South Australia in 1836, Victoria in 1851, and Queensland in 1859. [45] The Northern Territory was founded in 1911 when it was excised from South Australia. [46] South Australia was founded as a "free province"—it was never a penal colony. [47] Victoria and Western Australia were also founded "free", but later accepted transported convicts . [48] [49] A campaign by the settlers of New South Wales led to the end of convict transportation to that colony; the last convict ship arrived in 1848. [50]
The indigenous population, estimated to have been between 750,000 and 1,000,000 in 1788, [51] declined for 150 years following settlement, mainly due to infectious disease. [52] Thousands more died as a result of frontier conflict with settlers. [53] A government policy of "assimilation" beginning with the Aboriginal Protection Act 1869 resulted in the removal of many Aboriginal children from their families and communities—often referred to as the Stolen Generations —a practice which may also have contributed to the decline in the indigenous population. [54] As a result of the 1967 referendum , the Federal government's power to enact special laws with respect to a particular race was extended to enable the making of laws with respect to Aborigines. [55] Traditional ownership of land (" native title ") was not recognised in law until 1992, when the High Court of Australia held in Mabo v Queensland (No 2) that the legal doctrine that Australia had been terra nullius ("land belonging to no one") did not apply to Australia at the time of British settlement. [56]

Colonial expansion
A gold rush began in Australia in the early 1850s [57] and the Eureka Rebellion against mining licence fees in 1854 was an early expression of civil disobedience. [58] Between 1855 and 1890, the six colonies individually gained responsible government , managing most of their own affairs while remaining part of the British Empire . [59] The Colonial Office in London retained control of some matters, notably foreign affairs, [60] defence, [61] and international shipping.

Nationhood
On 1 January 1901, federation of the colonies was achieved after a decade of planning, consultation and voting. [62] This established the Commonwealth of Australia as a dominion of the British Empire. [63] [64] The Federal Capital Territory (later renamed the Australian Capital Territory) was formed in 1911 as the location for the future federal capital of Canberra. Melbourne was the temporary seat of government from 1901 to 1927 while Canberra was being constructed. [65] The Northern Territory was transferred from the control of the South Australian government to the federal parliament in 1911. [66] In 1914, Australia joined Britain in fighting World War I, with support from both the outgoing Commonwealth Liberal Party and the incoming Australian Labor Party . [67] [68] Australians took part in many of the major battles fought on the Western Front . [69] Of about 416,000 who served, about 60,000 were killed and another 152,000 were wounded. [70] Many Australians regard the defeat of the Australian and New Zealand Army Corps (ANZACs) at Gallipoli as the birth of the nation—its first major military action. [71] [72] The Kokoda Track campaign is regarded by many as an analogous nation-defining event during World War II. [73]
Britain's Statute of Westminster 1931 formally ended most of the constitutional links between Australia and the UK. Australia adopted it in 1942, [74] but it was backdated to 1939 to confirm the validity of legislation passed by the Australian Parliament during World War II. [75] [76] The shock of the United Kingdom's defeat in Asia in 1942 and the threat of Japanese invasion caused Australia to turn to the United States as a new ally and protector. [77] Since 1951, Australia has been a formal military ally of the US, under the ANZUS treaty. [78] After World War II Australia encouraged immigration from mainland Europe. Since the 1970s and following the abolition of the White Australia policy , immigration from Asia and elsewhere was also promoted. [79] As a result, Australia's demography, culture, and self-image were transformed. [80] The final constitutional ties between Australia and the UK were severed with the passing of the Australia Act 1986 , ending any British role in the government of the Australian States, and closing the option of judicial appeals to the Privy Council in London. [81] In a 1999 referendum , 55% of voters and a majority in every state rejected a proposal to become a republic with a president appointed by a two-thirds vote in both Houses of the Australian Parliament. Since the election of the Whitlam Government in 1972, [82] there has been an increasing focus in foreign policy on ties with other Pacific Rim nations, while maintaining close ties with Australia's traditional allies and trading partners. [83]

Geography

General characteristics
Australia's landmass of 7,617,930 square kilometres (2,941,300 sq mi) [84] is on the Indo-Australian Plate . Surrounded by the Indian and Pacific oceans, [N 4] it is separated from Asia by the Arafura and Timor seas, with the Coral Sea lying off the Queensland coast, and the Tasman Sea lying between Australia and New Zealand. The world's smallest continent [86] and sixth largest country by total area , [87] Australia—owing to its size and isolation—is often dubbed the "island continent", [88] and is sometimes considered the world's largest island . [89] Australia has 34,218 kilometres (21,262 mi) of coastline (excluding all offshore islands), [90] and claims an extensive Exclusive Economic Zone of 8,148,250 square kilometres (3,146,060 sq mi). This exclusive economic zone does not include the Australian Antarctic Territory. [91] Apart from Macquarie Island , Australia lies between latitudes 9° and 44°S , and longitudes 112° and 154°E .
The Great Barrier Reef , the world's largest coral reef, [92] lies a short distance off the north-east coast and extends for over 2,000 kilometres (1,240 mi). Mount Augustus , claimed to be the world's largest monolith, [93] is located in Western Australia. At 2,228 metres (7,310 ft), Mount Kosciuszko on the Great Dividing Range is the highest mountain on the Australian mainland. Even taller are Mawson Peak (at 2,745 metres or 9,006 feet), on the remote Australian territory of Heard Island , and, in the Australian Antarctic Territory, Mount McClintock and Mount Menzies , at 3,492 metres (11,457 ft) and 3,355 metres (11,007 ft) respectively. [94]
Australia's size gives it a wide variety of landscapes, with tropical rainforests in the north-east, mountain ranges in the south-east, south-west and east, and dry desert in the centre. [95] It is the flattest continent, [96] with the oldest and least fertile soils; [97] [98] desert or semi-arid land commonly known as the outback makes up by far the largest portion of land. [99] The driest inhabited continent, its annual rainfall averaged over continental area is less than 500 mm. [100] The population density , 2.8 inhabitants per square kilometre, is among the lowest in the world, [101] although a large proportion of the population lives along the temperate south-eastern coastline. [102]
Eastern Australia is marked by the Great Dividing Range , which runs parallel to the coast of Queensland, New South Wales and much of Victoria. The name is not strictly accurate, because parts of the range consist of low hills, and the highlands are typically no more than 1,600 metres (5,249 ft) in height. [103] The coastal uplands and a belt of Brigalow grasslands lie between the coast and the mountains, while inland of the dividing range are large areas of grassland. [103] [104] These include the western plains of New South Wales, and the Einasleigh Uplands , Barkly Tableland , and Mulga Lands of inland Queensland. The northernmost point of the east coast is the tropical-rainforested Cape York Peninsula . [105] [106] [107] [108]
The landscapes of the Top End and the Gulf Country —with their tropical climate—include forest, woodland , wetland, grassland , rainforest and desert. [109] [110] [111] At the north-west corner of the continent are the sandstone cliffs and gorges of The Kimberley , and below that the Pilbara . To the south of these and inland, lie more areas of grassland: the Ord Victoria Plain and the Western Australian Mulga shrublands . [112] [113] [114] At the heart of the country are the uplands of central Australia . Prominent features of the centre and south include Uluru (also known as Ayers Rock), the famous sandstone monolith, and the inland Simpson , Tirari and Sturt Stony , Gibson , Great Sandy, Tanami , and Great Victoria deserts, with the famous Nullarbor Plain on the southern coast. [115] [116] [117] [118]

Climate
The climate of Australia is significantly influenced by ocean currents, including the Indian Ocean Dipole and the El Niño–Southern Oscillation , which is correlated with periodic drought , and the seasonal tropical low-pressure system that produces cyclones in northern Australia. [119] [120] These factors cause rainfall to vary markedly from year to year. Much of the northern part of the country has a tropical, predominantly summer-rainfall (monsoon) [100] The south-west corner of the country has a Mediterranean climate . [121] The south-east ranges from oceanic (Tasmania and coastal Victoria) to humid subtropical (upper half of New South Wales). The interior is arid to semi-arid . [100]
According to the Bureau of Meteorology 's 2011 Australian Climate Statement, Australia had lower than average temperatures in 2011 as a consequence of a La Niña weather pattern; however, "the country's 10-year average continues to demonstrate the rising trend in temperatures, with 2002–2011 likely to rank in the top two warmest 10-year periods on record for Australia, at 0.52 °C (0.94 °F) above the long-term average". [122] Furthermore, 2014 was Australia's third warmest year since national temperature observations commenced in 1910. [123] [124] Water restrictions are frequently in place in many regions and cities of Australia in response to chronic shortages due to urban population increases and localised drought . [125] [126] Throughout much of the continent, major flooding regularly follows extended periods of drought, flushing out inland river systems, overflowing dams and inundating large inland flood plains, as occurred throughout Eastern Australia in 2010, 2011 and 2012 after the 2000s Australian drought .
Australia's carbon dioxide emissions per capita are among the highest in the world, lower than those of only a few other industrialised nations. [127] A carbon tax was introduced in 2012 and helped to reduce Australia's emissions but was scrapped in 2014 under the Liberal Government . [128] Since the carbon tax was repealed, emissions have again continued to rise. [129]

Biodiversity
Although most of Australia is semi-arid or desert, it includes a diverse range of habitats from alpine heaths to tropical rainforests , and is recognised as a megadiverse country . Fungi typify that diversity; an estimated 250,000 species—of which only 5% have been described—occur in Australia. [130] Because of the continent's great age, extremely variable weather patterns, and long-term geographic isolation, much of Australia's biota is unique. About 85% of flowering plants, 84% of mammals, more than 45% of birds , and 89% of in-shore, temperate-zone fish are endemic . [131] Australia has the greatest number of reptiles of any country, with 755 species. [132] Besides Antarctica, Australia is the only continent that developed without feline species. Feral cats may have been introduced in the 17th century by Dutch shipwrecks, and later in the 18th century by European settlers. They are now considered a major factor in the decline and extinction of many vulnerable and endangered native species. [133]
Australian forests are mostly made up of evergreen species, particularly eucalyptus trees in the less arid regions; wattles replace them as the dominant species in drier regions and deserts. [134] Among well-known Australian animals are the monotremes (the platypus and echidna ); a host of marsupials , including the kangaroo , koala , and wombat , and birds such as the emu and the kookaburra . [134] Australia is home to many dangerous animals including some of the most venomous snakes in the world. [135] The dingo was introduced by Austronesian people who traded with Indigenous Australians around 3000 BCE . [136] Many animal and plant species became extinct soon after first human settlement, [137] including the Australian megafauna ; others have disappeared since European settlement, among them the thylacine . [138] [139]
Many of Australia's ecoregions, and the species within those regions, are threatened by human activities and introduced animal, chromistan , fungal and plant species. [140] All these factors have led to Australia having the highest mammal extinction rate of any country in the world. [141] The federal Environment Protection and Biodiversity Conservation Act 1999 is the legal framework for the protection of threatened species. [142] Numerous protected areas have been created under the National Strategy for the Conservation of Australia's Biological Diversity to protect and preserve unique ecosystems; [143] [144] 65 wetlands are listed under the Ramsar Convention , [145] and 16 natural World Heritage Sites have been established. [146] Australia was ranked 3rd out of 178 countries in the world on the 2014 Environmental Performance Index . [147]

Government and politics
Australia is a federal parliamentary constitutional monarchy [148] with Elizabeth II at its apex as the Queen of Australia , a role that is distinct from her position as monarch of the other Commonwealth realms . The Queen is represented in Australia by the Governor-General at the federal level and by the Governors at the state level, who by convention act on the advice of her ministers. [149] [150] Thus, in practice the Governor-General has no actual decision-making or de facto governmental role, and merely acts as a legal figurehead for the actions of the Prime Minister and the Federal Executive Council . The Governor-General does have extraordinary reserve powers which may be exercised outside the Prime Minister's request in rare and limited circumstances, the most notable exercise of which was the dismissal of the Whitlam Government in the constitutional crisis of 1975 . [151]
The federal government is separated into three branches:
In the Senate (the upper house), there are 76 senators: twelve each from the states and two each from the mainland territories (the Australian Capital Territory and the Northern Territory). [153] The House of Representatives (the lower house) has 150 members elected from single-member electoral divisions, commonly known as "electorates" or "seats", allocated to states on the basis of population, [154] with each original state guaranteed a minimum of five seats. [155] Elections for both chambers are normally held every three years simultaneously; senators have overlapping six-year terms except for those from the territories, whose terms are not fixed but are tied to the electoral cycle for the lower house; thus only 40 of the 76 places in the Senate are put to each election unless the cycle is interrupted by a double dissolution . [153]
Australia's electoral system uses preferential voting for all lower house elections with the exception of Tasmania and the ACT which, along with the Senate and most state upper houses, combine it with proportional representation in a system known as the single transferable vote . Voting is compulsory for all enrolled citizens 18 years and over in every jurisdiction, [156] as is enrolment (with the exception of South Australia). [157] The party with majority support in the House of Representatives forms the government and its leader becomes Prime Minister. In cases where no party has majority support, the Governor-General has the constitutional power to appoint the Prime Minister and, if necessary, dismiss one that has lost the confidence of Parliament. [158]
There are two major political groups that usually form government, federally and in the states: the Australian Labor Party and the Coalition which is a formal grouping of the Liberal Party and its minor partner, the National Party . [159] [160] Within Australian political culture, the Coalition is considered centre-right and the Labor Party is considered centre-left . [161] Independent members and several minor parties have achieved representation in Australian parliaments, mostly in upper houses.
In September 2015, Malcolm Turnbull successfully challenged Abbott for leadership of the Coalition, and was sworn in as the 29th Prime Minister of Australia. [162] The most recent federal election was held on 2 July 2016 and resulted in the Coalition forming a majority government . [163]

States and territories
Australia has six states— New South Wales (NSW), Queensland (QLD), South Australia (SA), Tasmania (TAS), Victoria (VIC) and Western Australia (WA)—and two major mainland territories—the Australian Capital Territory (ACT) and the Northern Territory (NT). In most respects these two territories function as states, except that the Commonwealth Parliament has the power to modify or repeal any legislation passed by the territory parliaments. [164]
Under the constitution, the States essentially have plenary legislative power to legislate on any subject, whereas the Commonwealth (federal) Parliament may only legislate within the subject areas enumerated under section 51 . For example, State parliaments have the power to legislate with respect to education, criminal law and state police, health, transport, and local government, but the Commonwealth Parliament does not have any specific power to legislate in these areas. [165] However, Commonwealth laws prevail over State laws to the extent of the inconsistency. [166] In addition, the Commonwealth has the power to levy income tax which, coupled with the power to make grants to States , has given it the financial means to incentivize States to pursue specific legislative agendas within areas over which the Commonwealth does not have legislative power.
Each state and major mainland territory has its own parliament — unicameral in the Northern Territory, the ACT and Queensland, and bicameral in the other states. The states are sovereign entities, although subject to certain powers of the Commonwealth as defined by the Constitution. The lower houses are known as the Legislative Assembly (the House of Assembly in South Australia and Tasmania); the upper houses are known as the Legislative Council . The head of the government in each state is the Premier and in each territory the Chief Minister . The Queen is represented in each state by a Governor ; and in the Northern Territory, the Administrator . [167] In the Commonwealth, the Queen's representative is the Governor-General . [168]
The Commonwealth Parliament also directly administers the following external territories: Ashmore and Cartier Islands ; Australian Antarctic Territory ; Christmas Island ; Cocos (Keeling) Islands ; Coral Sea Islands ; Heard Island and McDonald Islands ; and Jervis Bay Territory , a naval base and sea port for the national capital in land that was formerly part of New South Wales. [152] The external territory of Norfolk Island previously exercised considerable autonomy under the Norfolk Island Act 1979 through its own legislative assembly and an Administrator to represent the Queen. [169] In 2015, the Commonwealth Parliament abolished self-government, integrating Norfolk Island into the Australian tax and welfare systems and replacing its legislative assembly with a council. [170] Macquarie Island is administered by Tasmania, and Lord Howe Island by New South Wales.

Foreign relations and military
Over recent decades, Australia's foreign relations have been driven by a close association with the United States through the ANZUS pact , and by a desire to develop relationships with Asia and the Pacific, particularly through ASEAN and the Pacific Islands Forum . In 2005 Australia secured an inaugural seat at the East Asia Summit following its accession to the Treaty of Amity and Cooperation in Southeast Asia , and in 2011 attended the Sixth East Asia Summit in Indonesia. Australia is a member of the Commonwealth of Nations , in which the Commonwealth Heads of Government meetings provide the main forum for co-operation. [171]
Australia has pursued the cause of international trade liberalisation . [172] It led the formation of the Cairns Group and Asia-Pacific Economic Cooperation . [173] [174] Australia is a member of the Organisation for Economic Co-operation and Development and the World Trade Organization , [175] [176] and has pursued several major bilateral free trade agreements, most recently the Australia–United States Free Trade Agreement [177] and Closer Economic Relations with New Zealand, [178] with another free trade agreement being negotiated with China—the Australia–China Free Trade Agreement —and Japan, [179] South Korea in 2011, [180] [181] Australia–Chile Free Trade Agreement , and as of November 2015 has put the Trans-Pacific Partnership before parliament for ratification. [182]
Along with New Zealand, the United Kingdom, Malaysia and Singapore, Australia is party to the Five Power Defence Arrangements , a regional defence agreement. A founding member country of the United Nations, Australia is strongly committed to multilateralism [183] and maintains an international aid program under which some 60 countries receive assistance. The 2005–06 budget provides A$2.5 billion for development assistance. [184] Australia ranks fifteenth overall in the Center for Global Development 's 2012 Commitment to Development Index . [185]
Australia's armed forces—the Australian Defence Force (ADF)—comprise the Royal Australian Navy (RAN), the Australian Army and the Royal Australian Air Force (RAAF), in total numbering 81,214 personnel (including 57,982 regulars and 23,232 reservists) as of November 2015. The titular role of Commander-in-Chief is vested in the Governor-General , who appoints a Chief of the Defence Force from one of the armed services on the advice of the government. [186] Day-to-day force operations are under the command of the Chief, while broader administration and the formulation of defence policy is undertaken by the Minister and Department of Defence .
In the 2015–16 budget, defence spending was A$31.9 billion or 1.92% of GDP, [187] representing the 13th largest defence budget . [188] Australia has been involved in UN and regional peacekeeping, disaster relief and armed conflict, including the 2003 invasion of Iraq ; it currently has deployed about 2,241 personnel in varying capacities to 12 international operations in areas including Iraq and Afghanistan . [189]

Economy
Australia is a wealthy country; it generates its income from various sources including mining-related exports, telecommunications, banking and manufacturing. [191] [192] [193] It has a market economy , a relatively high GDP per capita, and a relatively low rate of poverty. In terms of average wealth, Australia ranked second in the world after Switzerland in 2013, although the nation's poverty rate increased from 10.2% to 11.8%, from 2000/01 to 2013. [194] [195] It was identified by the Credit Suisse Research Institute as the nation with the highest median wealth in the world and the second-highest average wealth per adult in 2013. [194]
The Australian dollar is the currency for the nation, including Christmas Island, Cocos (Keeling) Islands, and Norfolk Island, as well as the independent Pacific Island states of Kiribati , Nauru , and Tuvalu . With the 2006 merger of the Australian Stock Exchange and the Sydney Futures Exchange, the Australian Securities Exchange became the ninth largest in the world. [196]
Ranked fifth in the Index of Economic Freedom (2017), [197] Australia is the world's twelfth largest economy and has the sixth highest per capita GDP (nominal) at US$ 56,291. [198] The country was ranked second in the United Nations 2016 Human Development Index . [199] All of Australia's major cities fare well in global comparative livability surveys; [200] Melbourne reached top spot for the fourth year in a row on The Economist ' s 2014 list of the world's most liveable cities , followed by Adelaide, Sydney, and Perth in the fifth, seventh, and ninth places respectively. [201] Total government debt in Australia is about $190 billion [202] – 20% of GDP in 2010. [203] Australia has among the highest house prices and some of the highest household debt levels in the world. [204]
An emphasis on exporting commodities rather than manufactured goods has underpinned a significant increase in Australia's terms of trade since the start of the 21st century, due to rising commodity prices. Australia has a balance of payments that is more than 7% of GDP negative, and has had persistently large current account deficits for more than 50 years. [206] Australia has grown at an average annual rate of 3.6% for over 15 years, in comparison to the OECD annual average of 2.5%. [206]
Australia was the only advanced economy not to experience a recession due to the global financial downturn in 2008–2009. [207] However, the economies of six of Australia's major trading partners have been in recession, which in turn has affected Australia, significantly hampering its economic growth in recent years. [208] [209] From 2012 to early 2013, Australia's national economy grew, but some non-mining states and Australia's non-mining economy experienced a recession. [210] [211] [212]
The Hawke Government floated the Australian dollar in 1983 and partially deregulated the financial system. [213] The Howard Government followed with a partial deregulation of the labour market and the further privatisation of state-owned businesses, most notably in the telecommunications industry. [214] The indirect tax system was substantially changed in July 2000 with the introduction of a 10% Goods and Services Tax (GST). [215] In Australia's tax system , personal and company income tax are the main sources of government revenue. [216]
In May 2012, there were 11,537,900 people employed (either full- or part-time), with an unemployment rate of 5.1%. [217] Youth unemployment (15–24) stood at 11.2%. [217] Data released in mid-November 2013 showed that the number of welfare recipients had grown by 55%. In 2007 228,621 Newstart unemployment allowance recipients were registered, a total that increased to 646,414 in March 2013. [218] According to the Graduate Careers Survey, full-time employment for newly qualified professionals from various occupations has declined since 2011 but it increases for graduates three years after graduation. [219] [220]
Since 2008, inflation has typically been 2–3% and the base interest rate 5–6%. The service sector of the economy, including tourism, education, and financial services, accounts for about 70% of GDP. [221] Rich in natural resources, Australia is a major exporter of agricultural products, particularly wheat and wool, minerals such as iron-ore and gold, and energy in the forms of liquified natural gas and coal. Although agriculture and natural resources account for only 3% and 5% of GDP respectively, they contribute substantially to export performance. Australia's largest export markets are Japan, China, the US, South Korea, and New Zealand. [222] Australia is the world's fourth largest exporter of wine, and the wine industry contributes $5.5 billion per year to the nation's economy. [223]

Demographics
Until the Second World War , the vast majority of settlers and immigrants came from the British Isles, and a majority of Australians have some British or Irish ancestry. In the 2011 Australian census, the most commonly nominated ancestries were English (36.1%), Australian (35.4%), [224] Irish (10.4%), Scottish (8.9%), Italian (4.6%), German (4.5%), Chinese (4.3%), Indian (2.0%), Greek (1.9%), and Dutch (1.7%). [225]
Australia's population has quadrupled since the end of World War I, [226] much of this increase from immigration . Following World War II and through to 2000, almost 5.9 million of the total population settled in the country as new immigrants, meaning that nearly two out of every seven Australians were born in another country. [227] Most immigrants are skilled, [228] but the immigration quota includes categories for family members and refugees . [228] By 2050, Australia's population is currently projected to reach around 42 million. [229] Nevertheless, its population density , 2.8 inhabitants per square kilometre, remains among the lowest in the world. [101]
In 2011, 24.6% of Australians were born elsewhere and 43.1% of people had at least one overseas-born parent; [230] the five largest immigrant groups were those from the United Kingdom , New Zealand, China, India, and Vietnam . [3] Following the abolition of the White Australia policy in 1973, numerous government initiatives have been established to encourage and promote racial harmony based on a policy of multiculturalism . [231] In 2005–06, more than 131,000 people emigrated to Australia, mainly from Asia and Oceania. [232] The migration target for 2012–13 is 190,000, [233] compared to 67,900 in 1998–99. [234]
The Indigenous population— Aborigines and Torres Strait Islanders —was counted at 548,370 (2.5% of the total population) in 2011, [235] a significant increase from 115,953 in the 1976 census. [236] The increase is partly due to many people with Indigenous heritage previously having been overlooked by the census due to undercount and cases where their Indigenous status had not been recorded on the form. Indigenous Australians experience higher than average rates of imprisonment and unemployment, lower levels of education, and life expectancies for males and females that are, respectively, 11 and 17 years lower than those of non-indigenous Australians. [222] [237] [238] Some remote Indigenous communities have been described as having " failed state "-like conditions. [239]
In common with many other developed countries, Australia is experiencing a demographic shift towards an older population, with more retirees and fewer people of working age. In 2004, the average age of the civilian population was 38.8 years. [240] A large number of Australians (759,849 for the period 2002–03; [241] 1 million or 5% of the total population in 2005 [242] ) live outside their home country.

Language
Although Australia has no official language, English has always been entrenched as the de facto national language. [2] Australian English is a major variety of the language with a distinctive accent and lexicon, [244] and differs slightly from other varieties of English in grammar and spelling. [245] General Australian serves as the standard dialect. According to the 2011 census, English is the only language spoken in the home for close to 81% of the population. The next most common languages spoken at home are Mandarin (1.7%), Italian (1.5%), Arabic (1.4%), Cantonese (1.3%), Greek (1.3%), and Vietnamese (1.2%); [3] a considerable proportion of first- and second-generation migrants are bilingual. A 2010–2011 study by the Australia Early Development Index found the most common language spoken by children after English was Arabic, followed by Vietnamese, Greek, Chinese, and Hindi. [246] [247]
Over 250 Indigenous Australian languages are thought to have existed at the time of first European contact, of which less than 20 are still in daily use by all age groups. [248] [249] About 110 others are spoken exclusively by older people. [249] At the time of the 2006 census, 52,000 Indigenous Australians, representing 12% of the Indigenous population, reported that they spoke an Indigenous language at home. [250] Australia has a sign language known as Auslan , which is the main language of about 5,500 deaf people. [251]

Religion
Australia has no state religion ; Section 116 of the Australian Constitution prohibits the federal government from making any law to establish any religion, impose any religious observance, or prohibit the free exercise of any religion. [252] In the 2011 census, 61.1% of Australians were counted as Christian , including 25.3% as Roman Catholic and 17.1% as Anglican ; 22.3% of the population reported having " no religion "; 7.2% identify with non-Christian religions, the largest of these being Buddhism (2.5%), followed by Islam (2.2%), Hinduism (1.3%) and Judaism (0.5%). The remaining 9.4% of the population did not provide an adequate answer. [3]
Before European settlement, the animist beliefs of Australia's indigenous people had been practised for many thousands of years. Mainland Aboriginal Australians ' spirituality is known as the Dreamtime and it places a heavy emphasis on belonging to the land. The collection of stories that it contains shaped Aboriginal law and customs. Aboriginal art , story and dance continue to draw on these spiritual traditions. The spirituality and customs of Torres Strait Islanders , who inhabit the islands between Australia and New Guinea, reflected their Melanesian origins and dependence on the sea. The 1996 Australian census counted more than 7000 respondents as followers of a traditional Aboriginal religion. [253]
Since the arrival of the First Fleet of British ships in 1788, Christianity has grown to be the major religion practised in Australia. Christian churches have played an integral role in the development of education, health and welfare services in Australia. For much of Australian history the Church of England (now known as the Anglican Church of Australia ) was the largest religious denomination. However, multicultural immigration has contributed to a decline in its relative position, and the Roman Catholic Church has benefitted from recent immigration to become the largest group. Similarly, Islam , Buddhism , Hinduism and Judaism have all grown in Australia over the past half-century. [254]
Australia has one of the lowest levels of religious adherence in the world. [255] In 2001, only 8.8% of Australians attended church on a weekly basis. [256]

Health
Australia has the third and seventh highest life expectancy of males and females respectively in the world. [257] Life expectancy in Australia in 2010 was 79.5 years for males and 84.0 years for females. [258] Australia has the highest rates of skin cancer in the world, [259] while cigarette smoking is the largest preventable cause of death and disease, responsible for 7.8% of the total mortality and disease. Ranked second in preventable causes is hypertension at 7.6%, with obesity third at 7.5%. [260] [261] Australia ranks 35th in the world [262] and near the top of developed nations for its proportion of obese adults [263] and nearly two thirds (63%) of its adult population is either overweight or obese. [264]
Total expenditure on health (including private sector spending) is around 9.8% of GDP. [265] Australia introduced universal health care in 1975. [266] Known as Medicare , it is now nominally funded by an income tax surcharge known as the Medicare levy , currently set at 1.5%. [267] The states manage hospitals and attached outpatient services, while the Commonwealth funds the Pharmaceutical Benefits Scheme (subsidising the costs of medicines) and general practice. [266]

Education
School attendance, or registration for home schooling, [269] is compulsory throughout Australia. Education is the responsibility of the individual states and territories [270] so the rules vary between states, but in general children are required to attend school from the age of about 5 until about 16. [271] [272] In some states (e.g., Western Australia, [273] the Northern Territory [274] and New South Wales [275] [276] ), children aged 16–17 are required to either attend school or participate in vocational training, such as an apprenticeship .
Australia has an adult literacy rate that was estimated to be 99% in 2003. [277] However, a 2011–12 report for the Australian Bureau of Statistics reported that Tasmania has a literacy and numeracy rate of only 50%. [278] In the Programme for International Student Assessment , Australia regularly scores among the top five of thirty major developed countries (member countries of the Organisation for Economic Co-operation and Development ). Catholic education accounts for the largest non-government sector.
Australia has 37 government-funded universities and two private universities, as well as a number of other specialist institutions that provide approved courses at the higher education level. [279] The OECD places Australia among the most expensive nations to attend university. [280] There is a state-based system of vocational training, known as TAFE , and many trades conduct apprenticeships for training new tradespeople. [281] About 58% of Australians aged from 25 to 64 have vocational or tertiary qualifications, [222] and the tertiary graduation rate of 49% is the highest among OECD countries. The ratio of international to local students in tertiary education in Australia is the highest in the OECD countries. [282] In addition, 38 percent of Australia's population has a university or college degree , which is among the highest percentages in the world. [283] [284]

Culture
Since 1788, the primary influence behind Australian culture has been Anglo-Celtic Western culture , with some Indigenous influences. [286] [287] The divergence and evolution that has occurred in the ensuing centuries has resulted in a distinctive Australian culture. [288] [289] Since the mid-20th century, American popular culture has strongly influenced Australia, particularly through television and cinema. [290] Other cultural influences come from neighbouring Asian countries, and through large-scale immigration from non-English-speaking nations. [290] [291]

Arts
Indigenous Australian rock art is the oldest and richest in the world, dating as far back as 60,000 years and spread across hundreds of thousands of sites. [292] Traditional designs, patterns and stories infuse contemporary Indigenous Australian art , "the last great art movement of the 20th century"; [293] its exponents include Emily Kame Kngwarreye . [294] During the first century of European settlement, colonial artists, trained in Europe, showed a fascination with the unfamiliar land. [295] The impressionistic works of Arthur Streeton , Tom Roberts and others associated with the 19th-century Heidelberg School —the first "distinctively Australian" movement in Western art—gave expression to a burgeoning Australian nationalism in the lead-up to Federation. [295] While the school remained influential into the new century, modernists such as Margaret Preston , and, later, Sidney Nolan and Arthur Boyd , explored new artistic trends. [295] The landscape remained a central subject matter for Fred Williams , Brett Whiteley and other post-World War II artists whose works, eclectic in style yet uniquely Australian, moved between the figurative and the abstract . [295] [296] The National Gallery of Australia and state galleries maintain collections of Australian and international art. [297] Australia has one of the world's highest attendances of art galleries and museums per head of population. [298]
Australian literature grew slowly in the decades following European settlement though Indigenous oral traditions , many of which have since been recorded in writing, are much older. [300] 19th-century writers such as Henry Lawson and Banjo Paterson captured the experience of the bush using a distinctive Australian vocabulary. Their works are still popular; Paterson's bush poem " Waltzing Matilda " (1895) is regarded as Australia's unofficial national anthem. [301] Miles Franklin is the namesake of Australia's most prestigious literary prize , awarded annually to the best novel about Australian life. [302] Its first recipient, Patrick White , went on to win the Nobel Prize in Literature in 1973. [303] Australian winners of the Booker Prize include Peter Carey , Thomas Keneally and Richard Flanagan . [304] Author David Malouf , playwright David Williamson and poet Les Murray are also renowned literary figures. [305] [306]
Many of Australia's performing arts companies receive funding through the federal government's Australia Council . [307] There is a symphony orchestra in each state, [308] and a national opera company, Opera Australia , [309] well known for its famous soprano Joan Sutherland . [310] At the beginning of the 20th century, Nellie Melba was one of the world's leading opera singers. [311] Ballet and dance are represented by The Australian Ballet and various state companies. Each state has a publicly funded theatre company. [312]

Media
The Story of the Kelly Gang (1906), the world's first feature length film, spurred a boom in Australian cinema during the silent film era. [313] After World War I, Hollywood monopolised the industry, [314] and by the 1960s Australian film production had effectively ceased. [315] With the benefit of government support, the Australian New Wave of the 1970s brought provocative and successful films, many exploring themes of national identity, such as Wake in Fright and Gallipoli , [316] while "Crocodile" Dundee and the Ozploitation movement's Mad Max series became international blockbusters. [317] In a film market flooded with foreign content, Australian films delivered a 7.7% share of the local box office in 2015. [318] The AACTAs are Australia's premier film and television awards, and notable Academy Award winners from Australia include Geoffrey Rush , Nicole Kidman , Cate Blanchett and Heath Ledger . [319]
Australia has two public broadcasters (the Australian Broadcasting Corporation and the multicultural Special Broadcasting Service ), three commercial television networks, several pay-TV services, [320] and numerous public, non-profit television and radio stations. Each major city has at least one daily newspaper, [320] and there are two national daily newspapers, The Australian and The Australian Financial Review . [320] In 2010, Reporters Without Borders placed Australia 18th on a list of 178 countries ranked by press freedom , behind New Zealand (8th) but ahead of the United Kingdom (19th) and United States (20th). [321] This relatively low ranking is primarily because of the limited diversity of commercial media ownership in Australia; [322] most print media are under the control of News Corporation and Fairfax Media . [323]

Cuisine
Most Indigenous Australian tribal groups subsisted on a simple hunter-gatherer diet of native fauna and flora, otherwise called bush tucker . [324] [325] The first settlers introduced British food to the continent, much of which is now considered typical Australian food, such as the Sunday roast . [326] [327] Multicultural immigration transformed Australian cuisine; post-World War II European migrants, particularly from the Mediterranean, helped to build a thriving Australian coffee culture , and the influence of Asian cultures has led to Australian variants of their staple foods, such as the Chinese -inspired dim sim and Chiko Roll . [328] Vegemite , pavlova , lamingtons and meat pies are regarded as iconic Australian foods. [329] Australian wine is produced mainly in the southern, cooler parts of the country.
Australia is also known for its cafe and coffee culture in urban centres , which has influenced coffee culture abroad, including New York City . [330] Australia and New Zealand were responsible for the flat white coffee.

Sport and recreation
About 24% of Australians over the age of 15 regularly participate in organised sporting activities. [222]
Australia is unique in that it has professional leagues for four football codes. Australian rules football , the world's oldest major football code and Australia's most popular sport in terms of revenue and spectatorship, originated in Melbourne in the late 1850s, and predominates in all states except New South Wales and Queensland, where rugby league holds sway, followed by rugby union . Soccer , while ranked fourth in popularity and resources, has the highest overall participation rates. [332]
Australia is a powerhouse in water-based sports, such as swimming and surfing. [333] The surf lifesaving movement originated in Australia, and the volunteer lifesaver is one of the country's icons. [334] Nationally, other popular sports include horse racing, basketball, and motor racing. The annual Melbourne Cup horse race and the Sydney to Hobart yacht race attract intense interest. [335] In 2016, the Australian Sports Commission revealed that swimming, cycling and soccer are the three most popular participation sports. [336] [337]
Australia is one of five nations to have participated in every Summer Olympics of the modern era, [338] and has hosted the Games twice: 1956 in Melbourne and 2000 in Sydney. [339] Australia has also participated in every Commonwealth Games , [340] hosting the event in 1938 , 1962 , 1982 , 2006 and will host the 2018 Commonwealth Games . [341] Australia made its inaugural appearance at the Pacific Games in 2015 . As well as being a regular FIFA World Cup participant, Australia has won the OFC Nations Cup four times and the AFC Asian Cup once – the only country to have won championships in two different FIFA confederations. [342] The country regularly competes among the world elite basketball teams as it is among the global top three teams in terms of qualifications to the Basketball Tournament at the Summer Olympics . Other major international events held in Australia include the Australian Open tennis grand slam tournament, international cricket matches, and the Australian Formula One Grand Prix . The highest-rating television programs include sports telecasts such as the Summer Olympics, FIFA World Cup, The Ashes , Rugby League State of Origin , and the grand finals of the National Rugby League and Australian Football League . [343] Skiing in Australia began in the 1860s and snow sports take place in the Australian Alps and parts of Tasmania .

See also

Notes
WebPage index: 00180
Mike Linksvayer
Mike Linksvayer is an intellectual freedom and commons proponent, known as a technology entrepreneur, developer and activist from co-founding Bitzi and leadership of Creative Commons . [1] [2]

Biography
Linksvayer holds a B.A. in economics from the University of Illinois at Urbana-Champaign and has experience as a Chief Technical Officer , Vice President , manager , software developer and consultant . [3] He joined Creative Commons as CTO in April 2003, [3] and held that position until April 2007 when he became vice president. [4] He also co-founded p2p file sharing company Bitzi , well known for its invention of magnet links . [3]
Former executive director of Creative Commons, Glenn Otis Brown, noted that Mike Linksvayer brought much-needed stability to the organization, comparing his role to that of a drummer in a band . [5]
Linksvayer encouraged NASA to use public APIs to share its data, which is already in public domain as government works. He also suggested that scientists and other planetary societies use Creative Commons licenses to disseminate photos and other works so that the public has better access. [6]
Following his tenure as vice president, in April 2012 Linksvayer became a part-time Senior Fellow at Creative Commons. [1] Linksvayer also serves on the boards of OpenHatch [7] and Software Freedom Conservancy [8] [9] and chairs the Open Definition Advisory Council. [10]

Writing
Linksvayer speaks internationally and writes broadly. On January 30, 2015 he co-authored a whitepaper, "Towards a Design Space for a Commons Provenance System" with Tessa Askamp, Paul Keller, Catharina Maracke, and Maarten Zeinstra. [11]
In 2012, he wrote an essay in the essay collection, The Wealth of the Commons: A World Beyond Market and State , edited by David Bollier [12] He contributed to Jono Bacon's O'Reilly book, The Art of Community: Building the New Age of Participation [13] and also wrote "Using and Sharing Data: the Black Letter, Fine Print, and Reality" for the The Data Journalism Handbook . [14] In 2010 he co-authored with Aleksandar Erkalovic, Adam Hyde, Michael Mandiberg, Marta Peirano, Sissu Tarka, Astra Taylor, Alan Toner, and Mushon Zer-Aviv, Collaborative Futures using the novel Booksprint method of producing and releasing an entire book in a week. [15]
In 2009, Linksvayer contributed an essay "Free Culture in Relation to Software Freedom" to FSCONS Free Beer , edited by Stian Rødven Eide. [16]
In 2008, while at Creative Commons, Linksvayer co-authored a technical document with Ben Adida, Hal Abelson, and Nathan Yergler, "ccREL: The Creative Commons Rights Expression Language." [17]

Personal life
Mike Linksvayer is a vegan and follows a low-calorie diet. He was featured in a news story carried by a number of sources suggesting that calorie-restricted diets may extend life span. [18]
He currently lives in Oakland, California. [19]
WebPage index: 00181
The Industry Standard
The Industry Standard is a U.S. news web site dedicated to technology business news, part of InfoWorld , a news website covering technology in general. It is a revival of a weekly magazine based in San Francisco which was published between 1998 and 2001.

Print magazine, 1998-2001
The Industry Standard called itself "the newsmagazine of the Internet economy", and it specialized in areas where business and the Internet overlapped. Like Wired , Red Herring , and (later) Business 2.0 , it was part of a breed of late 1990s publications that filled a gap in technology coverage left by mainstream media at the time.
The magazine, which was owned by the technology publishing company IDG , was in many ways the brainchild of John Battelle , who had been a journalist at Wired both in the United States and the United Kingdom . Jonathan Weber was its editor-in-chief. The magazine also ran a web site, thestandard.com.
Beginning in 1999, The Standard began selling a large number of advertising pages in the magazine, and began to be referred to as "the bible" of the Internet economy. In 2000, it sold more ad pages than any magazine in America, and launched that year a European edition. However, as the dot-com boom failed, sales of the magazine began to shrink, and it went into bankruptcy in August 2001. [1] One of The Standard's writer/editors, James Ledbetter , published a book in 2003 about the magazine's rise and fall; entitled Starving to Death on $200 Million: The Short, Absurd Life of The Industry Standard .

Website, 2008-present
IDG relaunched The Industry Standard as an online-only publication in 2008. [2] The site featured technology industry news and an interactive section where visitors could make predictions about the future of the tech industry. [3] In 2010, The Industry Standard became a "channel" within InfoWorld, another publication owned by IDG. [4]
WebPage index: 00182
The BMJ
The BMJ is a weekly peer-reviewed medical journal . It is one of the world's oldest general medical journals. Originally called the British Medical Journal , the title was officially shortened to BMJ in 1988, and then changed to The BMJ in 2014. The journal is published by BMJ Group , a wholly owned subsidiary of the British Medical Association . The editor in chief of The BMJ is Fiona Godlee , who was appointed in February 2005. [1]

Impact
In the 2016 Journal Citation Reports , The BMJ' s impact factor was 19.697 in 2015, [2] ranking it fourth among general medical journals. [3]

History
The journal began publishing on 3 October 1840 as the Provincial Medical and Surgical Journal and quickly attracted the attention of physicians around the world through its publication of high-impact original research articles and unique case reports. [4] The BMJ' s first editors were P. Hennis Green , lecturer on the diseases of children at the Hunterian School of Medicine , who also was its founder and Robert Streeten of Worcester, a member of the PMSA council.
The first issue of the British Medical Journal was 16 pages long and contained three simple woodcut illustrations. The longest items were the editors' introductory editorial and a report of the Provincial Medical and Surgical Association's Eastern Branch. Other pages included a condensed version of Henry Warburton 's medical reform bill, book reviews, clinical papers, and case notes. There were 2 1 ⁄ 2 columns of advertisements. Inclusive of stamp duty it cost 7d, a price which remained until 1844. In their main article, Green and Streeten noted that they had "received as many advertisements (in proportion to the quantity of letter press) for our first number, as the most popular Medical Journal, ( The Lancet ) after seventeen years of existence." [4]
In their introductory editorial and later statements, Green and Streeten defined "the main objects of promotion of which the Provincial Medical and Surgical Journal is established". Summarised, there were two clear main objectives: the advancement of the profession, especially in the provinces and the dissemination of medical knowledge. Green and Streeten also expressed interest in promoting public well-being as well as maintaining 'medical practitioners, as a class in that rank of society which, by their intellectual acquirements, by their general moral character, and by the importance of the duties entrusted to them, they are justly entitled to hold'. [4]
The BMJ published the first centrally randomised controlled trial. [5] The journal also carried the seminal papers on the causal effects of smoking on health [6] [7] and lung cancer and other causes of death in relation to smoking. [8]
For a long time, the journal's sole competitor was The Lancet , also based in the UK, but with increasing globalisation, The BMJ has faced tough competition from other medical journals, particularly The New England Journal of Medicine and the Journal of the American Medical Association . [9]

Editors

Journal content
The BMJ is an advocate of evidence-based medicine . It publishes research as well as clinical reviews, recent medical advances, editorial perspectives, among others.
The journal releases a number of "theme issues" every year, when it publishes research and review articles pertaining to the theme addressed. Some of the popular theme issues in recent [ when? ] years include "Health in Africa", " Management of Chronic Diseases ", and "Global Voices on the AIDS Catastrophe". [ citation needed ]
A special "Christmas Edition" is published annually on the Friday before Christmas. This edition is known for research articles which apply a serious academic approach to investigating less serious medical questions. [10] [11] [12] The results are often humorous and widely reported by the mainstream media. [11] [13]

Editions
The BMJ is principally an online journal, and it is only the website which carries the full text content of every article. However, a number of print editions are produced, targeting different groups of readers with selections of content, some of it abridged, and different advertising. [14] The print editions are:
In addition, a number of local editions of The BMJ are published in translation. There is also Student BMJ , an online resource for medical students, junior doctors and those applying to medical school, which also publishes three print editions a year.

Functioning of the journal
The BMJ has an open peer review system, wherein authors are told who reviewed their manuscript. About half the original articles are rejected after review in-house. [15] Manuscripts chosen for peer review are first reviewed by external experts, who comment on the importance and suitability for publication, before the final decision on a manuscript is made by the editorial ("hanging") committee. The acceptance rate is less than 7% for original research articles. [16]

Indexing and citations
The BMJ is included in the major indexes PubMed , MEDLINE , EBSCO , and the Science Citation Index . The journal has long criticised the misuse of the impact factor to award grants and recruit researchers by academic institutions. [17]
The five journals that as of 2008 [update] have cited The BMJ most often are (in order of descending citation frequency) The BMJ , Cochrane Database of Systematic Reviews , The Lancet , BMC Public Health , and BMC Health Services Research . [18]
As of 2008 [update] , the five journals that have been cited most frequently by articles published in The BMJ are The BMJ , The Lancet , The New England Journal of Medicine , Journal of the American Medical Association and Cochrane Database of Systematic Reviews . [18]

Most cited articles
According to the Web of Science , [18] the following articles have been cited the most often:

Most viewed articles
As of 2014, the most viewed article [19] on the The BMJ website is:

BMJ
The BMJ went fully online in 1995 and has archived all its issues on the web . In addition to the print content, supporting material for original research articles, additional news stories, and electronic letters to the editors are its principal attractions. The BMJ website has the policy of publishing most e-letters to the journal, called Rapid Responses, [20] and is shaped like a fully moderated Internet forum. As of January 2013 [update] there had been 88 500 rapid responses posted on the BMJ website. [21] Comments are screened for libellous and obscene content, however potential contributors are warned that once published, they will not have the right to remove or edit their response. [21]
From 1999, all content of The BMJ was freely available online; however, in 2006 this changed to a subscription model. Original research articles continue to be available freely, but from January 2006, all other 'added value' contents, including clinical reviews and editorials, require a subscription. The BMJ allows complete free access for visitors from economically disadvantaged countries as part of the HINARI initiative.
On 14 October 2008, The BMJ announced it would become an open access journal. This only refers to their research articles. To view other articles, a subscription is required. [22]

Other services
The BMJ offers several alerting services, free on request: [23]

BMJ
In January 2011, The BMJ launched an iPad app version of the journal. The app combines the weekly print journal selection of research, comment, and education, along with feeds of news, blogs, podcasts, and videos to appear on bmj.com.
WebPage index: 00183
Digital rights management
WebPage index: 00184
Mashup (web application hybrid)
A mashup (computer industry jargon ), in web development , is a web page , or web application , that uses content from more than one source to create a single new service displayed in a single graphical interface. For example, a user could combine the addresses and photographs of their library branches with a Google map to create a map mashup. [1] The term implies easy, fast integration, frequently using open application programming interfaces ( open API ) and data sources to produce enriched results that were not necessarily the original reason for producing the raw source data. The term mashup originally comes from British - West Indies slang meaning to be intoxicated, or as a description for something or someone not functioning as intended. In recent English parlance it can refer to music, where people seamlessly combine audio from one song with the vocal track from another—thereby mashing them together to create something new.
The main characteristics of a mashup are combination, visualization, and aggregation. It is important to make existing data more useful, for personal and professional use. To be able to permanently access the data of other services, mashups are generally client applications or hosted online.
In the past years, more and more Web applications have published APIs that enable software developers to easily integrate data and functions the SOA way, instead of building them by themselves. Mashups can be considered to have an active role in the evolution of social software and Web 2.0 . Mashup composition tools are usually simple enough to be used by end-users. They generally do not require programming skills and rather support visual wiring of GUI widgets , services and components together. Therefore, these tools contribute to a new vision of the Web , where users are able to contribute. [ clarification needed ]
The term "mashup" is not formally defined by any standard-setting body. [2]

History
The history of mashup can be backtracked by first understanding the broader context of the history of the Web. For Web 1.0 business model, companies stored consumer data on portals and updated them regularly. They controlled all the consumer data, and the consumer had to use their products and services to get the information.
With the advent of Web 2.0 a new proposition was created, using Web standards that were commonly and widely adopted across traditional competitors and unlocked the consumer data. At the same time, mashups emerged allowing mixing and matching competitor's API to create new services.
The first mashups used mapping services or photo services to combine these services with data of any kind and therefore create visualizations of the data. [3] In the beginning, most mashups were consumer-based, but recently the mashup is to be seen as an interesting concept useful also to enterprises. Business mashups can combine existing internal data with external services to create new views on the data.

Types of mashup
There are many types of mashup, such as business mashups, consumer mashups, and data mashups. [4] The most common type of mashup is the consumer mashup, aimed at the general public.

By API type
Mashups can also be categorized by the basic API type they use but any of these can be combined with each other or embedded into other applications.

Data types

Functions

Mashup enabler
In technology, a mashup enabler is a tool for transforming incompatible IT resources into a form that allows them to be easily combined, in order to create a mashup. Mashup enablers allow powerful techniques and tools (such as mashup platforms) for combining data and services to be applied to new kinds of resources. An example of a mashup enabler is a tool for creating an RSS feed from a spreadsheet (which cannot easily be used to create a mashup). Many mashup editors include mashup enablers, for example, Presto Mashup Connectors, Convertigo Web Integrator or Caspio Bridge .
Mashup enablers have also been described as "the service and tool providers, [sic] that make mashups possible". [ citation needed ]

History
Early mashups were developed manually by enthusiastic programmers. However, as mashups became more popular, companies began creating platforms for building mashups, which allow designers to visually construct mashups by connecting together mashup components.
Mashup editors have greatly simplified the creation of mashups, significantly increasing the productivity of mashup developers and even opening mashup development to end-users and non-IT experts. Standard components and connectors enable designers to combine mashup resources in all sorts of complex ways with ease. Mashup platforms, however, have done little to broaden the scope of resources accessible by mashups and have not freed mashups from their reliance on well-structured data and open libraries ( RSS feeds and public APIs ).
Mashup enablers evolved to address this problem, providing the ability to convert other kinds of data and services into mashable resources.

Web resources
Of course, not all valuable data is located within organizations. In fact, the most valuable information for business intelligence and decision support is often external to the organization. With the emergence of rich internet applications and online Web portals, a wide range of business-critical processes (such as ordering) are becoming available online. Unfortunately, very few of these data sources syndicate content in RSS format and very few of these services provide publicly accessible APIs. Mashup editors therefore solve this problem by providing enablers or connectors.

Data integration challenges
There are a number of challenges to address when integrating data from different sources. The challenges can be classified into four groups: text/data mismatch, object identifiers and schema mismatch, abstraction level mismatch, data accuracy. [6]

Text–data mismatch
A large portion of data is described in text. Human language is often ambiguous - the same company might be referred to in several variations (e.g. IBM, International Business Machines, and Big Blue). The ambiguity makes cross-linking with structured data difficult. In addition, data expressed in human language is difficult to process via software programs. One of the functions of a data integration system is to overcome the mismatch between documents and data. [6]

Object identity and separate schemata
Structured data are available in a plethora of formats. Lifting the data to a common data format is thus the first step. But even if all data is available in a common format, in practice sources differ in how they state what is essentially the same fact. The differences exist both on the level of individual objects and the schema level. As an example for a mismatch on the object level, consider the following: the SEC uses a so-called Central Index Key (CIK) to identify people (CEOs, CFOs), companies, and financial instruments while other sources, such as DBpedia (a structured data version of Wikipedia), use URIs to identify entities. In addition, each source typically uses its own schema and idiosyncrasies for stating what is essentially the same fact. Thus, Methods have to be in place for reconciling different representations of objects and schemata.

Abstraction levels
Data sources provide data at incompatible levels of abstraction or classify their data according to taxonomies pertinent to a certain sector. Since data is being published at different levels of abstraction (e.g. person, company, country, or sector), data aggregated for the individual viewpoint may not match data e.g. from statistical offices. Also, there are differences in geographic aggregation (e.g. region data from one source and country-level data from another). A related issue is the use of local currencies (USD vs. EUR) which have to be reconciled in order to make data from disparate sources comparable and amenable for analysis.

Data quality
Data quality is a general challenge when automatically integrating data from autonomous sources. In an open environment the data aggregator has little to no influence on the data publisher. Data is often erroneous, and combining data often aggravates the problem. Especially when performing reasoning (automatically inferring new data from existing data), erroneous data has potentially devastating impact on the overall quality of the resulting dataset. Hence, a challenge is how data publishers can coordinate in order to fix problems in the data or blacklist sites which do not provide reliable data. Methods and techniques are needed to: check integrity and accuracy; highlight, identify and corroborate evidence; assess the probability that a given statement is true; equate weight differences between market sectors or companies; establish clearing houses for raising and settling disputes between competing (and possibly conflicting) data providers; and interact with messy erroneous Web data of potentially dubious provenance and quality. In summary, errors in signage, amounts, labeling, and classification can seriously impede the utility of systems operating over such data.

Mashups versus portals
Mashups and portals are both content aggregation technologies. Portals are an older technology designed as an extension to traditional dynamic Web applications , in which the process of converting data content into marked-up Web pages is split into two phases: generation of markup "fragments" and aggregation of the fragments into pages. Each markup fragment is generated by a " portlet ", and the portal combines them into a single Web page. Portlets may be hosted locally on the portal server or remotely on a separate server.
Portal technology defines a complete event model covering reads and updates. A request for an aggregate page on a portal is translated into individual read operations on all the portlets that form the page (" render " operations on local, JSR 168 portlets or " getMarkup " operations on remote, WSRP portlets). If a submit button is pressed on any portlet on a portal page, it is translated into an update operation on that portlet alone ( processAction on a local portlet or performBlockingInteraction on a remote, WSRP portlet). The update is then immediately followed by a read on all portlets on the page.
Portal technology is about server-side, presentation-tier aggregation. It cannot be used to drive more robust forms of application integration such as two-phase commit .
Mashups differ from portals in the following respects:
The portal model has been around longer and has had greater investment and product research. Portal technology is therefore more standardized and mature. Over time, increasing maturity and standardization of mashup technology will likely make it more popular than portal technology because it is more closely associated with Web 2.0 and lately Service-oriented Architectures (SOA). [7] New versions of portal products are expected to eventually add mashup support while still supporting legacy portlet applications. Mashup technologies, in contrast, are not expected to provide support for portal standards.

Business mashups
Mashup uses are expanding in the business environment. Business mashups are useful for integrating business and data services, as business mashups technologies provide the ability to develop new integrated services quickly, to combine internal services with external or personalized information, and to make these services tangible to the business user through user-friendly Web browser interfaces. [8]
Business mashups differ from consumer mashups in the level of integration with business computing environments, security and access control features, governance, and the sophistication of the programming tools (mashup editors) used. Another difference between business mashups and consumer mashups is a growing trend of using business mashups in commercial software as a service (SaaS) offering.
Many of the providers of business mashups technologies have added SOA features.

Architectural aspects of mashups
The architecture of a mashup is divided into three layers:
Architecturally, there are two styles of mashups: Web-based and server-based. Whereas Web-based mashups typically use the user's web browser to combine and reformat the data, server-based mashups analyze and reformat the data on a remote server and transmit the data to the user's browser in its final form. [9]
Mashups appear to be a variation of a façade pattern . [10] That is: a software engineering design pattern that provides a simplified interface to a larger body of code (in this case the code to aggregate the different feeds with different APIs ).
Mashups can be used with software provided as a service ( SaaS ).
After several years of standards development, mainstream businesses are starting to adopt service-oriented architectures (SOA) to integrate disparate data by making them available as discrete Web services. Web services provide open, standardized protocols to provide a unified means of accessing information from a diverse set of platforms ( operating systems , programming languages , applications ). These Web services can be reused to provide completely new services and applications within and across organizations, providing business flexibility.

See also

Notes
WebPage index: 00185
Biological patent
A biological patent is a patent on an invention in the field of biology that by law allows the patent holder to exclude others from making, using, selling, or importing the protected invention for a limited period of time . The scope and reach of biological patents vary among jurisdictions, [1] and may include biological technology and products, genetically modified organisms and genetic material . The applicability of patents to substances and processes wholly or partially natural in origin is a subject of debate. [1]

Biological patents in different jurisdictions

Australia
In February 2013, Judge [Justice John Nicholas] ruled in the Federal Court of Australia in favour of a Myriad Genetics patent on the BRCA1 gene. [2] This was a landmark ruling, affirming the validity of patents on naturally occurring DNA sequences. However, the U.S. Supreme Court came to the opposite conclusion only a few months later. The Australian ruling has been appealed to the Full Bench of the Federal Court; submissions in the case include consideration of the U.S. Supreme Court ruling. [3] [4] This decision was decided in 2014, affirming Nicholas J's decision in favor of Myriad, confirming that isolated genetic material (genes) are valid subjects of patents. [5] As of June 2015 the case was pending hearing in the High Court of Australia. [6] In October 2015 the Australian high court ruled that naturally occurring genes cannot be patented. [7]

Europe
European Union directive 98/44/EC (the Biotech Directive ) reconciled the legislation of biological patents among certain countries under the jurisdiction of the European Patent Organisation . [1] It allows for the patenting of natural biological products, including gene sequences, as long as they are "isolated from [their] natural environment or produced by means of a technical process." [1]
The European Patent Office has ruled that European patents cannot be granted for processes that involve the destruction of human embryos. [8]

Japan
Under the umbrella of biotechnology, applications for patents on biological inventions are examined according to general guidelines for patents. In response to requests for additional clarity, the Japan Patent Office (JPO) set forth specific guidelines for biology-related inventions. Over the years, the JPO has continued to amend these guidelines to clarify their application to new technologies. These amendments have broadened the scope of patents within the biotechnology industry. The Japanese Patent Act requires that patented inventions be “industrially applicable”, i.e. they must have market or commercial potential. The JPO explicitly lists “medical activities” among inventions that fall outside the scope of industrially applicable inventions, meaning that methods of surgery, therapy, and the diagnosis of human diseases cannot be patented. [9]

United States
In the United States, up until 2013 natural biological substances themselves could have been patented (apart from any associated process or usage) if they were sufficiently "isolated" from their naturally occurring states. Prominent historical examples of such patents include those on adrenaline , [10] insulin , [11] vitamin B 12 , [12] and various genes. [13] A landmark ruling by the U.S. Supreme Court in June 2013 declared naturally occurring DNA sequences ineligible for patents. [14]

Ethics
The patenting of genes is a controversial issue in terms of bioethics . Some believe it is unethical to patent genetic material because it treats life as a commodity, or that it undermines the dignity of people and animals by allowing ownership of genes. [15] Some say that living materials occur naturally, and therefore cannot be patented. [16] The American Medical Association 's stance is that gene patents inhibit access to genetic testing for patients and hinder research on genetic disease. [17]
While some feel that a patent on living material is unethical, others [ who? ] believe that not allowing patents on biotechnological inventions would also be unethical. Supporters of this idea suggest that patents allow the public, as well as policy makers, to hold the owner of the patent(s) accountable. They favor biological patents because they require disclosure of information to the public. [18] Agreements such as the Agreement on Trade-related Aspects of Intellectual Property Rights (TRIPS) require members of the World Trade Organization (WTO) to have intellectual property protection laws in place for most biological innovation, making it unlikely that many countries will prohibit patents on genes altogether. [16]
Although some [ who? ] say that patenting a gene turns people into a commodity, others [ who? ] disagree. [ vague ] Some [ who? ] say that patenting genes only commodifies life if a patent applies to an entire human being, arguing that [ who? ] patents on single body parts do not violate human dignity. [19]
Another area of controversy in genetic patenting is how gene samples are obtained. Prior consent is required to collect genetic samples, and collection of samples from people requires consent at the national and community levels as well as the individual level. Conflicts have resulted when consent is not obtained at all three levels. The question of benefit sharing also arises when obtaining genetic samples, specifically the potential responsibility of the collector to share any benefits or profits of the discoveries with the population or person from whom the sample came. [16]
The last major ethical issue involving gene patents is how the patents are used post-issuance. A major concern [ who? ] is that the use of patented materials and processes will be very expensive or even prohibited to some degree by conditions the patent owner sets. [20] Limiting access like this would directly impact agricultural institutes and university researchers, among others. Some [ who? ] fear that holders of biotechnology patents would exploit their rights in order to make larger profits, at the potential expense of farmers, healthcare patients, and other users of patented technologies.
The ethics of using patents to increase profits are also debated. A typical argument in favor of biotech patents is that they enable companies to earn money that the companies in turn invest in further research. Without these patents, some worry that companies would no longer have the resources or motives to perform competitive, viable biotech research. [16]

See also
WebPage index: 00186
Copyright Alternatives
Various Copyright Alternatives in an alternative compensation systems ( ACS ) have been proposed as ways to allow the widespread reproduction of digital copyrighted works while still paying the authors and copyright owners of those works. This article only discusses those proposals which involve some form of government intervention. Other models, such as the street performer protocol or voluntary collective licenses , could arguably be called "alternative compensation systems" although they are very different and generally less effective at solving the free rider problem .
The impetus for these proposals has come from the widespread use of peer-to-peer file sharing networks. A few authors argue that an ACS is simply the only practical response to the situation. [1] But most ACS advocates go further, holding that P2P file sharing is in fact greatly beneficial, and that tax or levy funded systems are actually more desirable tools for paying artists than sales coupled with DRM copy prevention technologies.

Artistic Freedom Voucher
The artistic freedom voucher (AFV) proposal argues that the current copyright system providing a state enforced monopoly leads to “enormous inefficiencies and creates substantial enforcement problems”. Under the AFV proposed system, individuals would be allowed to contribute a refundable tax credit of approximately $100 to a “creative worker”, this contribution would act as a voucher that can only be used to support artistic or creative work.
Recipients of the AFV contribution would in turn be required to register with the government in similar fashion to that of religious or charitable institutions do so for tax-exempt status. The sole purpose of the registration would be to prevent fraud and would have no evaluation of the quality or work being produced. Alongside registration, artists would also now be ineligible for copyright protection for a set period of time (5 years for example) as the work is contributed to the public domain and allowed to be freely reproduced. The AFV would not affect creative workers ability to receive funds via live performances.
Proponents claim that this system could create up to $20 billion annually to pay artists, which is far greater than what currently flows to them through copyrighted material. At $100 per adult voucher, over 500,000 writers, musicians, singers, actors, or other creative workers could be paid some $40,000 a year. Baker also states that it is realistic to assume that the savings from the reduced expenditures on the copyrighted work would vastly exceed the cost of the AFV. The majority of these savings would come from individuals deciding to use AFV supported work in place of copyrighted work as well as lower advertising costs because the AFV material would be public domain. Copyright enforcement demand would also decrease as AFV material increased. The assumptions made are that in the low end direct costs to the public of copyrighted material would be reduced around 20 percent while in the high end all the way up to 60 percent. Over time it is also likely that the savings would increase due to the lesser costs of the system and brighter prospects. [2]
In a 2010 article critical of the AFV proposal, graphic designer Mark Stanley writes:
“Like school vouchers, the flat tax, and other pretenders, the AFV assumes the necessity of state intervention, and tries to bend liberty around such strictures. Freedom isn’t so forgiving to such manipulation.” [3]

Donation Based Record Labels
While the systematic restructuring of copyright laws proposed by AFV is far from being put into practice, the concept of paying artists with donations has been tested, with some success. In 2006, musician Jeff Rosenstock founded Quote Unquote Records , which advertised itself as the first donation based record label. Artists on this label make their music available to download for free, and invite listeners to make a small donation if they want to. Between donations and ticket sales for live shows, Quote Unquote Records has been successfully recording music and expanding the number of bands on their label for the past five years.

Architectural details

Where does the money come from
Proposals have included targeted levies on internet connections, blank CDs, digital media players, etc. (many of these goods are levied various countries' existing private copying schemes ); income taxation; or optional payments by users.
In terms of economic theory, consumer "opt in" regimes are very different from universal ones, but depending on how the scheme was administered, the differences might not be so large. For example, if the default option for ISP subscribers was to pay an ACS surcharge, which could be avoided by filing a signed commitment not to make unauthorised downloads from P2P networks, the effects might be quite similar. This scheme however is unsuitable for business owners who maintain free internet connections as incentive for customers. It would then be the responsibility of the business owner to monitor his or her customer's internet use.

Where does it go
Various proposals have been made to base the distribution of royalties on measures of consumer downloading, usage or voting.
The computer security issues to be addressed in collecting this data are considerable. The privacy and verifiability obstacles are very similar to those encountered in Internet voting ; they may be soluble, but only with hardware assistance not currently available on ordinary PCs. The most practical way to deploy an ACS in the short term would be to collect statistical samples from a much smaller population.
The actual distribution of royalties would likely be carried out by a copyright collecting society .

Advantages and disadvantages
Alternative compensation systems have two very significant advantages over digital copyright. They do not impose artificial scarcity on copyright works: everyone can download as many songs, ebooks and films as they want (in economic terns, ACS eliminate the deadweight loss of copyright monopolies). They also avoid the very high technological and social costs of digital copyright enforcement .
The two greatest drawbacks of ACSes are the excess burden of the taxation that is collected, and the need to decide what tax/levy rates to use for the system (although methods such as contingent valuation may help a little with that question).

Alternative compensation systems in practice
Canada's private copying levy had the unforeseen result of temporarily creating an ACS for some kinds of P2P downloading. [4] In BMG v. Doe , a dictum suggested that this should also apply to uploading; but the dictum was criticised on appeal.
In France, the December 2005 DADVSI amendments that were passed by the Senate would have created an ACS called a "global license". These amendments were removed before the bill finally became law.
In 2009, the German Social Democratic Party added a proposal for an ACS variant called a "cultural flat-rate" to its party platform. [5]

See also
WebPage index: 00187
Free software license
A free software license is a notice that grants the recipient of a piece of software extensive rights to modify and redistribute that software. These actions are usually prohibited by copyright law, but the rights-holder (usually the author) of a piece of software can remove these restrictions by accompanying the software with a software license which grants the recipient these rights. Software using such a license is free software (or free and open source software ) as conferred by the copyright holder. Free software licenses are applied to software in source code as also binary object code form, as the copyright law recognizes both forms. [3]

History

Pre 1980s
In the early times of software, sharing of software and source code was common in certain communities, for instance academic institutions. Before the US Commission on New Technological Uses of Copyrighted Works (CONTU) decided in 1974 that "computer programs, to the extent that they embody an author's original creation, are proper subject matter of copyright", [4] [5] software was not considered copyrightable. Therefore, software had no licenses attached and was shared as public domain software . The CONTU decision plus court decisions such as Apple v. Franklin in 1983 for object code , clarified that the Copyright Act gave computer programs the copyright status of literary works and started the licensing of software .
Free software licenses before the late 1980s were generally informal notices written by the developers themselves. These early licenses were of the " permissible " kind.

1980s
In the mid-1980s, the GNU project produced copyleft free software licenses for each of its software packages. An early such license (the "GNU Emacs Copying Permission Notice") was used for GNU Emacs in 1985, [6] with subsequent revisions in 1986, 1987 and 1988 taking the name of "GNU Emacs General Public License". [7] Likewise, the similar GCC General Public License was applied to the GNU Compiler Collection , which was initially published in 1987. [8] [9] The original BSD license is also one of the first free software licenses, dating to 1988. In 1989, version 1 of the GNU General Public License (GPL) was published. Version 2 of the GPL, released in 1991, went on to become the most widely used free software license. [10] [11] [12]

1990s to 2000s
Starting in the mid-1990s and until the mid-2000s, the open source movement pushed and focused the free software idea forward in the wider public and business perception. [13] In the Dot-com bubble time, Netscape Communications ' step to release its webbrowser under a FOSS license in 1998, [14] [15] inspired many other companies to adapt to the FOSS ecosystem. [16] In this trend companies and new projects ( Mozilla , Apache foundation , and Sun , see also this list ) wrote their own FOSS licenses, or adapted existing licenses. This License proliferation was later recognized as problem for the Free and open source ecosystem due to the increased complexity of license compatibility considerations. [17] While the creation of new licenses slowed down later, license proliferation and its impact are considered an ongoing serious challenge for the free and open source ecosystem.
From the free software licenses, the GNU GPL version 2 has been tested in to court, first in Germany in 2004 and later in the USA. In the German case the judge did not explicitly discuss the validity of the GPL's clauses but accepted that the GPL had to be adhered to: "If the GPL were not agreed upon by the parties, defendant would notwithstanding lack the necessary rights to copy, distribute, and make the software 'netfilter/iptables' publicly available." Because the defendant did not comply with the GPL, it had to cease use of the software. [18] The US case ( MySQL vs Progress) was settled before a verdict was arrived at, but at an initial hearing, Judge Saris "saw no reason" that the GPL would not be enforceable. [19]
Around 2004 lawyer Lawrence Rosen argued in the essay Why the public domain isn't a license software could not truly be waived into public domain and can't be interpreted as very permissive FOSS license, [20] a position which faced opposition by Daniel J. Bernstein and others. [21] In 2012 the dispute was finally resolved when Rosen accepted the CC0 as open source license , while admitting that contrary to his previous claims copyright can be waived away, backed by Ninth circuit decisions. [22]
In 2007, after years of draft discussion, the GPLv3 as major update of the GPLv2 was released. The release was controversial [23] due to the significant extended scope of the license, which made it incompatible with the GPLv2. [24] Several major FOSS projects ( Linux kernel , [25] [26] MySQL , [27] BusyBox , [28] [29] Blender , [30] VLC media player [31] ) decided against adopting the GPLv3. On the other hand, in 2009, two years after the release of the GPLv3, Google open-source programs office manager Chris DiBona reported that the number of open-source projects licensed software that had moved to GPLv3 from GPLv2 was 50%, counting the projects hosted at Google Code . [32]

2010s
In 2011, four years after the release of the GPLv3, 6.5% of all open-source licensed projects are GPLv3 while 42.5% are still GPLv2 according to Black Duck Software data. [26] [33] Following in 2011 451 Group analyst Matthew Aslett argued in a blog post that copyleft licenses went into decline and permissive licenses increased, based on statistics from Black Duck Software. [34] [35]
In 2015 according to Black Duck Software [36] and GitHub statistics, [37] the permissive MIT license dethroned the GPLv2 as most popular Free software license to the second place while the permissive Apache license follows already at third place. In June 2016 an analysis of Fedora Project 's packages revealed as most used licenses the GPL, MIT, BSD, and the LGPL. [38]

Definitions

OSI-approved "open source" licenses
The group Open Source Initiative (OSI) defines and maintains a list of approved open source licenses . OSI agrees with FSF on all widely used Free Software licenses, but differ from FSF's list, as it approves against the Open Source Definition rather than the Free Software Definition . It considers Free Software Permissive license group to be a reference implementation of a Free Software license. [ citation needed ] [ clarification needed ] Thus its requirements for approving licenses are different.

FSF-approved "free software" licenses
The Free Software Foundation , the group that maintains the Free Software Definition , maintains a non-exhaustive list of Free Software licences. [39]
The Free Software Foundation prefers copyleft ( share-alike ) Free Software licensing rather than permissive Free Software licensing for most purposes. Its list distinguishes between free software licenses that are compatible or incompatible with the FSF's copyleft GNU General Public License .

Conditions in free software licenses
There exists an ongoing debate within the free software community regarding the fine line between what restrictions can be applied and still be called "free". [ citation needed ]
Only " public domain software " and software under a public domain like license is restriction free. [ citation needed ] Examples of public domain-like licenses are, for instance, the WTFPL and the CC0 license. Permissive licenses might carry small obligations like attribution of the author but allow practically all code use cases. Certain licenses, namely the copyleft licenses , include intentionally stronger restrictions (especially on the distribution/distributor) in order to force derived projects to guarantee specific rights which can't be taken away.

Copyleft
The free software share-alike licenses written by Richard Stallman in the mid-1980s pioneered a concept known as "copyleft". Ensuing copyleft provisions stated that when modified versions of free software are distributed, they must be distributed under the same terms as the original software. Hence they are referred to as "share and share alike " or " quid pro quo ". This results in the new software being open source as well. Since copyleft ensures that later generations of the software grant the freedom to modify the code, this is "free software". Non-copyleft licenses do not ensure that later generations of the software will remain free.
Developers who use GPL code in their product must make the source code available to anyone when they share or sell the object code . In this case, the source code must also contain any changes the developers may have made. If GPL code is used but not shared or sold, the code is not required to be made available and any changes may remain private. This permits developers and organizations to use and modify GPL code for private purposes (that is, when the code or the project is not sold or otherwise shared) without being required to make their changes available to the public.
Supporters of GPL claim that by mandating that derivative works remain under the GPL, it fosters the growth of free software and requires equal participation by all users. Opponents of GPL claim [40] that "no license can guarantee future software availability" and that the disadvantages of GPL outweigh [41] its advantages. Some also argue that restricting distribution makes the license less free. Whereas proponents would argue that not preserving freedom during distribution would make it less free. For example, a non-copyleft license does not grant the author the freedom to see modified versions of his or her work if it get publicly published, whereas a copyleft license does grant that freedom.

Patent retaliation
During the 1990s, free software licenses began including clauses, such as patent retaliation , in order to protect against software patent litigation cases – a problem which had not previously existed. This new threat was one of the reasons for writing version 3 of the GNU GPL in 2006. [42] In recent years, a term coined tivoization describes a process where hardware restrictions are used to prevent users from running modified versions of the software on that hardware, in which the TiVo device is an example. It is viewed by the FSF as a way to turn free software to effectively non-free, and is why they have chosen to prohibit it in GPLv3 . [43] Most newly written free software licenses since the late 1990s include some form of patent retaliation clauses. These measures stipulate that one's rights under the license (such as to redistribution), may be terminated if one attempts to enforce patents relating to the licensed software, under certain circumstances. As an example, the Apple Public Source License may terminate a user's rights if said user embarks on litigation proceedings against them due to patent litigation. Patent retaliation emerged in response to proliferation and abuse of software patents .

Hardware restrictions
Version 3 of the GNU GPL includes specific language prohibiting additional restrictions being enforced by hardware restrictions and digital rights management (DRM) , a practice FSF calls tivoization after Tivo used GPL’d software on devices that disallowed user modification of that software.

Attribution, disclaimers and notices
The majority of free software licenses require that modified software not claim to be unmodified. Some licenses also require that copyright holders be credited. One such example is version 2 of the GNU GPL, which requires that interactive programs that print warranty or license information, may not have these notices removed from modified versions intended for distribution.

Practical problems with licenses

License compatibility
Licenses of software packages containing contradictory requirements, render it impossible to combine source code from such packages in order to create new software packages. [45] License compatibility between a copyleft license and another license is often only a one-way compatibility. [46] This "one-way compatibility" characteristic is, for instanced, criticized by the Apache Foundation , who provides the more permissive Apache license which doesn't have this characteristic. [47] Non-copyleft licenses, such as the FOSS permissive licenses , have a less complicated license interaction and normally exhibit better license compatibility. [48] [49] For example, if one license says "modified versions must mention the developers in any advertising materials", and another license says "modified versions cannot contain additional attribution requirements", then, if someone combined a software package which uses one license with a software package which uses the other, it would be impossible to distribute the combination because these contradictory requirements cannot be fulfilled simultaneously. Thus, these two packages would be license-incompatible. When it comes to copyleft software licenses, they are not inherently compatible with other copyleft licenses, even the GPLv2 is, by itself, not compatible with the GPLv3. [24] [50]

Purpose of use
Restrictions on use of a software ("use restrictions") are generally unacceptable according to the FSF, OSI , Debian , or the BSD-based distributions. Examples include prohibiting that the software be used for non-private applications, for military purposes, for comparison or benchmarking, for good use, [ clarification needed ] for ethically questionable means, [51] or in commercial organisations. [52]

Definition conflicts
As there are several defining organizations and groups who publish definitions and guidelines about FOSS licenses, notably the FSF, the OSI, the Debian project, and the BSDs, there are sometimes conflicting opinions and interpretations.

Permissive versus copyleft opinions
Many users and developers of BSD -based operating systems have a different position on licensing. The main difference is the belief that the copyleft licenses, particularly the GNU General Public License (GPL), are undesirably complicated and/or restrictive. [53] The GPL requires any derivative work to also be released according to the GPL while the BSD license does not. Essentially, the BSD license's only requirement is to acknowledge the original authors, and poses no restrictions on how the source code may be used.
As a result, BSD code can be used in proprietary software that only acknowledges the authors. For instance, Microsoft Windows NT 3.1 and macOS have proprietary IP stacks which are derived from BSD-licensed software. [54] In extreme cases, the sub- or relicensing possibilities with BSD or other permissive licenses might prevent further use in the open source ecosystem. For instance, MathWorks ' FileExchange repository offers the BSD license for user contributions but prevents with additional terms of use any usage beside their own proprietary MATLAB software, for instance with the FOSS GNU Octave software. [55] [56] [57]
On the positive side, as BSD-like permissive licenses have very limited restrictions (typically only attribution ), they also have excellent license compatibility , even with copyleft licenses. [48] [49]
Supporters of the BSD license argue that it is more free than the GPL because it grants the right to do anything with the source code, provided that the attribution is preserved. For example, users might incorporate the BSD-licensed code into proprietary products. The approach has led to BSD code being used in common, widely used proprietary software. In response, proponents of the GPL point out that once code becomes proprietary, users lack the freedoms that define free software. [58] As a result, they consider the BSD license less free than the GPL, and that freedom is more than a lack of restriction. Since the BSD license restricts the right of developers to have changes recontributed to the community, [ dubious – discuss ] neither it nor the GPL is "free" in the sense of "lacking any restrictions."
Code licensed under a permissive free software licence , such as the BSD license, can be incorporated into copylefted (for instance, GPL'd) projects. Such code is thus "GPL-compatible". There is no need to secure the consent of the original authors. In contrast, code under the GPL cannot be relicensed under the BSD license without securing the consent of all copyright holders. Thus the two licenses are compatible, but (unless such consent has been obtained) the combination as a whole must be distributed under the terms of the GPL and not the permissive license.
Existing free software BSD-licensed projects tend to avoid including software licensed under the GPL in the core operating system, or the base system , except as a last resort when alternatives are non-existent or vastly less capable, such as with GCC . For example, starting with FreeBSD 10.0, the GCC was replaced by the Clang / LLVM compiler, perhaps primarily for this reason. [ citation needed ] The OpenBSD project has acted to remove GPL-licensed tools in favor of BSD-licensed alternatives, some newly written and some adapted from older code. [59]

Debian
The Debian project uses the criteria laid out in its Debian Free Software Guidelines (DFSG). The only notable cases where Debian and Free Software Foundation disagree are over the Artistic License and the GNU Free Documentation License (GFDL). Debian accepts the original Artistic License as being a free software license, but FSF disagrees. This has very little impact however since the Artistic License is almost always used in a dual-license setup, along with the GNU General Public License .

Controversial borderline cases
The vast majority of free software uses undisputed free software licenses; however, there have been many debates over whether or not certain other licenses qualify for the definition.
Examples of licenses that provoked debate were the 1.x series of the Apple Public Source License , which were accepted by the Open Source Initiative but not by the Free Software Foundation or Debian and the RealNetworks Public Source License , which was accepted by Open Source Initiative and Free Software Foundation but not by Debian .
Also, the FSF recommended GNU Free Documentation License , [60] which is incompatible with the GPL, [61] was considered "non-free" by the Debian project around 2006, [62] Nathanael Nerode, [63] and Bruce Perens . [64] The FSF argues that documentation is qualitatively different from software and is subject to different requirements. Debian accepted, in a later resolution, that the GNU FDL complied with the Debian Free Software Guidelines when the controversial "invariant section" is removed, but considers it "still not free of trouble". [65] Notwithstanding, most GNU documentation includes "invariant sections". Similarly, the FLOSS Manuals foundation, an organization devoted to creating manuals for free software, decided to eschew the GFDL in favor of the GPL for its texts in 2007, citing the incompatibility between the two, difficulties in implementing the GFDL, and the fact that the GFDL "does not allow for easy duplication and modification", especially for digital documentation. [66]

Market share
While historically the most widely used FOSS license has been the GPLv2, in 2015, according to Black Duck Software [36] the permissive MIT license dethroned the GPLv2 to the second place while the permissive Apache license follows at third place. A study from 2012, which used publicly available data, criticized Black Duck Software for not publishing their methodology used in collecting statistics. [67] Daniel German, professor in the Department of Computer Science at the University of Victoria in Canada, presented a talk in 2013 about the methodological challenges in determining which are the most widely used free software licenses, and showed how he could not replicate the result from Black Duck Software. [68]
A GitHub study in 2015 on their statistical data also found the MIT license as most prominent FOSS license. [37]
In June 2016 an analysis of Fedora Project 's packages showed as most used licenses the GPL family, followed by MIT, BSD, the LGP family, Artistic (for Perl packages), LPPL (for texlive packages), and ASL. [38]

See also

Notes
WebPage index: 00188
Prizes as an alternative to patents
Some authors advocating patent reform have proposed the use of prizes as an alternative to patents . Critics of the current patent system, such as Joseph E. Stiglitz , say that patents fail to provide incentives for innovations which are not commercially marketable. Stiglitz provides the idea of prizes instead of patents to be awarded in order to further advance solutions to global problems such as AIDS .

Background
Patents essentially provide a temporary monopoly on a product to the first inventor or firm which comes up with the product. Patents vary in length but are designed to last long enough for the innovator to make a return on investment . The nature of patents makes them an incentive so long as the product being invented is distributed to consumers through markets. While patented products are in the market, the producer can place any price on the product, regardless of the price of production which typically dictates prices in markets. If a product is not being distributed through markets then a patent cannot provide proper incentive for innovation. Patents do however provide gain through the restriction of information to others. Stiglitz identifies this as a problem of patents for the innovation of drugs and other products being distributed not with the purpose of making a profit , but to solve global problems.
Offering a prize as opposed to a patent, according to Stiglitz, would address the lack of incentive for problems such as disease in developing countries , and it would provide products immediately affordable instead of pending a patent expiration. Awarding prizes offers a fixed amount appropriate for reimbursing research into drugs. Today, many drug companies spend much of money earned through patents on marketing and advertising as opposed to the research for the actual drugs [1]
Stiglitz goes on to assert that until generic versions of drugs reach the shelves, which occurs after a patent expires, the costs burden consumers due to prices not being dictated by the markets. [2] These burdens are overwhelming in developing countries and Stiglitz suggests they be lowered by offering prizes instead of patents. Stiglitz discusses the idea of using foreign aid assistance funds to finance prizes as it would provide greater foreign aid than what funds are being used for currently. [3]

United States
Senator Bernie Sanders of Vermont put forward legislation in the United States Senate in 2005 and 2007 under H.R. 417 and S.2210. [4] Sanders has been a longtime proponent of Stiglitz’ ideas, and favors a system of incentives for innovation in medicine and pharmaceuticals over a system of patents, which he asserts grant company monopolies on drugs and drive up pharmaceutical prices.

The Medical Innovation Prize Fund Act S1137 and S1138
The two bills proposed on May 26, 2011 by Senator Bernie Sanders would completely remove legal barriers to the manufacture and sale of generic drugs . The bills will give the government the right to set specific goals and direct research to certain areas of medicine. S1137 would apply to all prescription drugs, and S1138 is focused on HIV/AIDS medications. The bills call for both the government and private insurance companies to fund the "Medical Innovation Prize Fund". According to the S1137 bill, the innovation fund would create a fund of .55% of GDP, $80 billion of GDP based on 2010 numbers. S1138 calls for a .02% GDP fund for HIV/AIDS innovation prizes that amounts to about $3 billion a year. [5]
In a statement made at a subcommittee meeting, Senator Sanders said, "It simply blew me away — and would blow anyone’s mind away — that one drug, Atripla, costs $25,000 per year". He called this bill, “Fairly radical for the U.S. Congress.” According to estimates, proponents of the bill believe that the costs of the prizes would be offset by the introduction of generic drugs and the reduction of monopoly power in the pharmaceutical industry. Sanders believes that these bills will save private insurers, Medicaid, and other government assistance programs money. [6]
One of the goals of the bill is to "de-link research and development incentives from product prices" along with getting rid of patents and what the bill's author asserts to be monopoly power. It aims to free research and development by proposing a possible "Open Source Dividend" element. This means that a percentage of the prize money from the innovation funds would go to those persons or communities that allow access to knowledge, data, etc. to public domains and offer free access to patents.
Senator Sanders and other proponents of both bills [ who? ] assert that the prize funds will give incentives for manufacturers to seek innovative treatments for illnesses and diseases that are more important to society. In addition, they state that these funds will lower drugs prices, along with what they claim to be wasteful research and development costs. [5] This bill has been favored by Joseph Stiglitz. [ citation needed ]
The Bill & Melinda Gates Foundation have tried such a prize fund model. In their model, all applicants for funding from the Gates foundation must waive all claims to patents. “A World Health Organization (WHO) report, called 'Research and Development to Meet health Needs in Developing Countries', backs prize funds, saying it is a financially viable model” [7]
In 2012 the two bills were referred to the committee level in the Senate. They have not been put to a vote in either the Senate or the House. In 2009-2010 only 3% of all bills proposed in the senate were enacted. [8]

Other areas for prize models over patents
US President Barack Obama has pushed for prizes innovation sponsoring 150 contests across 40 agencies in 2010. [ citation needed ] NASA paid out $6 million in prizes to companies since 2005 for innovation. [ citation needed ] Between 2000-2007 certain groups put $250 million into technologies that range from robotic arms and tuberculosis tests, according to Brian Vastag of The Washington Post . [6]

Criticism
Criticisms of prize funds focus on the impact of prizes as limited by their size, scope, and nature. Prizes large enough to replace patents as incentives to develop innovative new products require large up-front costs for taxpayers. [ citation needed ] Research shows that it can cost $500–$800 million to just get FDA approval of new medical treatment. [ citation needed ] According to the Global Intellectual Property Center , studies show that prizes are better at proving a concept than bringing concrete, useful technologies into existence. [9] Another criticism made by the Global Intellectual Property Center is that prizes will never be enough to reward lucky breaks that have brought about the most important innovations. [ citation needed ] Also, the center argues that prizes do not create incentives to drive continuous cycle of advances and improvements because prizes are finite and limited. [9]
The Global Intellectual Property Center also believes that prizes focus narrowly on certain acts or on the "next new thing", and that prizes can act as distractions from more significant innovations. [9] They also assert that prizes do not hold researchers and inventors accountable for the findings of works or creations. [9] The center argues that prizes in turn give rights to a product to a government, who then gives rights to the entire public. In the future, if there are any problems or questions with the creation, or drug, it will be impossible to determine who is responsible for the flaw. [9]
Within the pharmaceutical industry, [ who? ] prize theory has gotten much criticism. One of the main criticisms is that giving rewards in the form of prize money to drug companies for producing innovative drugs will not be seen for many years while the drug is tested in the market, [ citation needed ] and that prize funds would not reward pharmaceuticals for producing different versions of drugs; “me-too” drugs. [ citation needed ] These variations are seen as part of the bigger problem by Senator Sanders. [6]

See also
WebPage index: 00189
Opposition to copyright
Opposition to copyright or anti-copyright refers to a movement dissenting the nature of current copyright law, often focusing on perceived negative philosophical, economical or social effects of such laws. Adherents advocate for complete or partial change or remission of current legislation.
Normally copyright is enforced within a framework of the Berne Convention , instituted by Victor Hugo and first enacted in 1886. Numerous international copyright treaties have since been passed, but copyright law is different in all countries.
A central anti-copyright argument is that copyright is not and has never been of net benefit to society and instead serves to enrich a few at the expense of creativity and widespread accessibility of works. The classic argument for copyright is that granting creators temporary monopolies over works—giving them an income will encourage producing future works as well.
In the context of the Internet and new technological advances, opponents argue that copyright law needs to be adapted to modern information technology .

Organisations and scholars

Groups advocating the abolition of copyright
Pirate Cinema and groups like The League of Noble Peers advance more radical arguments, opposing copyright per se. A number of anti-copyright groups have recently emerged in the argument over peer-to-peer file sharing , digital freedom , and freedom of information ; these include the Association des audionautes [1] [2] and the Kopimism Church of New Zealand . [3] [4]
In 2003, Eben Moglen , a professor of Law at Columbia University, published the dotCommunist Manifesto , which re-interpreted the Communist Manifesto by Marx in the light of the development of computer technology and the internet; much of the re-interpreted content discussed copyright law and privilege in Marxist terms. [5]
Recent developments related to BitTorrent and peer-to-peer file-sharing have been termed by media commentators as "copyright wars", with The Pirate Bay being referred to as "the most visible member of a burgeoning international anti-copyright—or pro-piracy—movement". [6] [7] One well-publicised instance of electronic civil disobedience (ECD) in the form of large scale intentional copyright infringement occurred on February 24, 2004, in an event called Grey Tuesday . Activists intentionally violated EMI 's copyright of The White Album by distributing MP3 files of a mashup album called The Grey Album , in an attempt to draw public attention to copyright reform issues and anti-copyright ideals. Reportedly over 400 sites participated including 170 that hosted the album with some protesters stating that The Grey Album illustrates a need for revisions in copyright law to allow sampling under fair use of copyrighted material, or proposing a system of fair compensation to allow for sampling. [8] [9]

Groups advocating changes to copyright law
French group Association des audionautes is not anti-copyright per se, but proposes a reformed system for copyright enforcement and compensation. Aziz Ridouan, co-founder of the group, proposes for France to legalise peer-to-peer file sharing and to compensate artists through a surcharge on Internet service provider fees (i.e. an alternative compensation system ). Reportedly, major music companies have equated Ridouan's proposal with legitimising piracy. [1] In January 2008, seven Swedish members of parliament from the Moderate Party (part of the governing coalition), authored a piece in a Swedish tabloid calling for the complete decriminalisation of filesharing ; they wrote that "Decriminalising all non-commercial file sharing and forcing the market to adapt is not just the best solution. It's the only solution, unless we want an ever more extensive control of what citizens do on the Internet." [10]
In June 2015 a WIPO article named " Remix Culture and Amateur Creativity: A Copyright Dilemma" [11] acknowledged the "age of remixing" and the need for a copyright reform while referring to recent law interpretations in Lenz v. Universal Music Corp and Canada's Copyright Modernization Act .

Groups advocating using existing copyright law
Groups that argue for using existing copyright legal framework with special licences to achieve their goals, include the copyleft movement [12] and Creative Commons . [13] Creative Commons is not anti-copyright per se, but argues for use of more flexible and open copyright licences within existing copyright law. [14] Creative Commons takes the position that there is an unmet demand for flexibility that allows the copyright owner to release work with only "some rights reserved" or even "no rights reserved." According to Creative Commons many people do not regard default copyright as helping them in gaining the exposure and widespread distribution they want. Creative Commons argue that their licences allow entrepreneurs and artists to employ innovative business models rather than all-out copyright to secure a return on their creative investment. [15]

Scholars and commentators
Scholars and commentators in this field include Lawrence Liang , [16] Jorge Cortell , [17] Rasmus Fleischer , [18] Stephan Kinsella , and Siva Vaidhyanathan .
Traditional anarchists , such as Leo Tolstoy , expressed their refusal to accept copyright. [19]

Economic arguments against copyright

Non-scarcity
There is an argument that copyright is invalid because, unlike physical property, intellectual property is not scarce and is a legal fiction created by the state. That is, infringing on copyright, unlike theft , does not deprive the victim of the original item, and so enforcement of copyright law constitutes aggression on the part of the state. [20]

Historical comparison
It is entirely unclear that copyright laws are economically useful, even for the majority of authors. Thus Höffner compared the economic effects copyright law had on authors and publishing in the United Kingdom to those in Germany in the first part of the nineteenth century when in Germany such laws had not been instituted, and found that more books were printed and read in Germany where authors, in general, also made more money. [21]

Information technology related concerns
One of the founders of Piratbyrån , Rasmus Fleischer , argues that copyright law simply seems unable to cope with the Internet, and hence is obsolete. He argues that the Internet, and particularly Web 2.0 have brought about the uncertain status of the very idea of "stealing" itself. He argues that in an attempt to rein in Web 2.0, copyright law in the 21st century is increasingly concerned with criminalising entire technologies, leading to recent attacks on different kinds of search engines , solely because they provide links to files which may be copyrighted. Fleischer points out that Google, while still largely uncontested, operates in a gray zone of copyright (e.g. the business model of Google Books is to display millions of pages of copyrighted and uncopyrighted books as part of a business plan drawing its revenue from advertising). In contrast, others have pointed out that Google Books blocks-out large sections of those same books, which motivates purchases, and supports the legitimate interests of rightsholders.
Fleischer's central argument is that copyright has become obsolete with regards to the Internet, that the cost of trying to enforce it is unreasonable, and that instead business models need to adapt to the reality of the darknet . [22]

Cultural arguments

Freedom of knowledge
Groups such as Hipatia advance anti-copyright arguments in the name of "freedom of knowledge" and argue that knowledge should be "shared in solidarity". Such groups may perceive "freedom of knowledge" as a right, and/or as fundamental in realising the right to education , which is an internationally recognised human right , as well as the right to a free culture and the right to free communication. They argue that current copyright law hinders the realisation of these rights in today's knowledge societies relying on new technological means of communication. [23]
Such groups see copyright law as preventing or slowing human progress. They argue that the current copyright system needs to be brought into line with reality and the needs of society. Hipatia argues that this would "provide the ethical principles which allow the individual to spread his/her knowledge, to help him/herself, to help his/her community and the whole world, with the aim of making society ever more free, more equal, more sustainable, and with greater solidarity." [23]

Authorship and creativity
Lawrence Liang , founder of the Alternative Law Forum, argues that current copyright is based on a too narrow definition of "author", which is assumed to be clear and undisputed. Liang observes that the concept of "the author" is assumed to make universal sense across cultures and across time. Instead, Liang argues that the notion of the author as a unique and transcendent being, possessing originality of spirit, was constructed in Europe after the industrial revolution , to distinguish the personality of the author from the expanding realm of mass-produced goods. Hence works created by "authors" were deemed original, and merges with the doctrine of property prevalent at the time. [24]
Liang argues that the concept of "author" is tied to the notion of copyright and emerged to define a new social relationship — the way society perceives the ownership of knowledge. The concept of "author" thus naturalised a particular process of knowledge production where the emphasis on individual contribution and individual ownership takes precedence over the concept of "community knowledge". [24] Relying on the concept of the author, copyright is based on the assumption that without an intellectual property rights regime, authors would have no incentive to further create, and that artists cannot produce new works without an economic incentive. Liang challenges this logic, arguing that "many authors who have little hope of ever finding a market for their publications, and whose copyright is, as a result, virtually worthless, have in the past, and even in the present, continued to write." [24] Liang points out that people produce works purely for personal satisfaction, or even for respect and recognition from peers. Liang argues that the 19th Century saw the prolific authorship of literary works in the absence of meaningful copyright that benefited the author. In fact, Liang argues, copyright protection usually benefited the publisher, and rarely the author. [24]

Ethical issues
The institution of copyright brings up several ethical issues. Selmer Bringsjord argues that all forms of copying are morally permissible (without commercial use), because some forms of copying are permissible and there is not a logical distinction between various forms of copying. [25]
Edwin Hettinger argues that natural rights arguments for intellectual property are weak and the philosophical tradition justifying property can not guide us in thinking about intellectual property. [26] [27]
Shelly Warwick believes that copyright law as currently constituted does not appear to have a consistent ethical basis. [28]
Andrew T. Forcehimes argues that the way we think about copyrights is inconsistent, because every argument for (physical) public libraries is also an argument for stealing ebooks and every argument against stealing ebooks would also be an argument against libraries. [29]

See also
WebPage index: 00190
Organization for Transformative Works
The Organization for Transformative Works ( OTW ) is a non-profit , fan activist organization. Its mission is to serve fans by preserving and encouraging transformative fan activity, known as " fanwork ", and by making fanwork widely accessible. [3]
OTW advocates for the transformative, legal, and legitimate nature of fan labor activities, including fan fiction , fan vids , fan art , anime music videos , podfic (audio recordings of fan fiction [4] ), and real person fiction . [5] [6] Its vision is to nurture fans and fan culture, and to protect fans' transformative work from legal snafus and commercial exploitation. [3] [7]
The Organization for Transformative Works offers the following services and platforms to fans in a myriad of fandoms :

Legal activism
The OTW provides legal assistance to the fandom community, addressing the legal issues with fan fiction and other fan works. Rebecca Tushnet , a noted legal scholar on fanfiction and fair use in copyright and trademark law, works with the OTW's legal project. In 2008, the OTW (in coordination with the Electronic Frontier Foundation ) successfully submitted requests to the Library of Congress for further exceptions to the Digital Millennium Copyright Act to allow the fair use of video clips for certain noncommercial uses such as video remixes, commentary, and education, as well as to protect technology used for such purposes. The exceptions were also successfully renewed in 2012. [12] [13]
The OTW has also submitted several amicus briefs to the courts in several cases involving intellectual property law:

Fandom archival projects
The OTW has also instituted several projects for preserving fan history and culture. One such project was the creation of Fanlore, a wiki for preserving fandom history. The Fanlore wiki was first revealed in beta in 2008, with a full release in December 2010. [16]
The OTW also has several "Open Doors" projects dedicated to the preservation of fannish historical artifacts. These projects include The Fan Culture Preservation Project, a joint venture between the OTW and the Special Collections department at the University of Iowa [17] to archive and preserve fanzines and other non-digital forms of fan culture, and The GeoCities Rescue Project, which attempted to preserve content originally hosted on Yahoo's GeoCities by transferring that content to new locations on the Archive of Our Own or within the Fanlore wiki. [18] Other miscellaneous artifacts and collections are stored on the OTW's main servers in the Special Collections gallery.

Archive of Our Own
Created by the OTW, the Archive of Our Own (AO3) is an open-source, non-commercial, non-profit archive for fan fiction and other transformative fanwork . The Archive is built and run entirely by volunteers, many without previous coding experience. [19] The Archive was publicly launched into open beta on 14 November 2009, [20] and has been growing steadily since. [21]
Time magazine included Archive of Our Own on its list of "50 Best Websites 2013". Time said that AO3 "serves all fandoms equally, from The A-Team to Zachary Quinto and beyond," and also called it "the most carefully curated, sanely organized, easily browsable and searchable nonprofit collection of fan fiction on the Web...". [22]
Fans post, tag and categorize their own works on AO3. [23] Volunteer "tag wranglers" link similar tags so readers can search for works in the categories and types they want. [24] The tagging system allows easy compilation of statistics (stats).
Fan fiction ranges in length, from fewer than one thousand words ( flash fiction , or one-hundred-word drabbles ) to novel-length works of hundreds of thousands of words. According to an article on fandom statistics published on the Daily Dot newspaper in 2013, AO3 hosts more very short works than long ones, but readers prefer the longer works. The average very short story received fewer than 150 hits, while novel-length works are more likely to receive around 1,500 hits. [25]
A writer who posts a story on AO3 can record its word count on the story’s header, along with other information such as the story’s fandom, romantic pairings, and other tropes. Some fan works are 'crossovers' that draw on two or more universes or characters. Writers can also note if their story is finished or a work in progress (WIP). [26]
As of 2016, the archive hosts more than 2 million works in more than 20,000 fandoms. [27] Destination Toast, fan and statistician, [28] compiles and analyzes fandom statistics, especially stats from Archive of Our Own, which she says is "the most easily searchable archive I know of." [29] In January 2016, she posted "2015: A (Statistical) Year in Fandom." It includes statistics from two other large fan fiction archives, FanFiction.Net (FFN) and Wattpad as well as the popular microblog platform Tumblr . The post shows that the most active fandoms on AO3 in 2015 were (largest first) Supernatural , Dragon Age , Harry Potter , The Avengers , Teen Wolf , and Sherlock . [30] Other media sources include movies, television shows, and books including Lord of the Rings , Doctor Who , and The Hunger Games .
WebPage index: 00191
Students for Free Culture
Students for Free Culture , formerly known as FreeCulture.org , is an international student organization working to promote free culture ideals, such as cultural participation and access to information. It was inspired by the work of former Stanford, now Harvard, law professor Lawrence Lessig , who wrote the book Free Culture , and it frequently collaborates with other prominent free culture NGOs , including Creative Commons , the Electronic Frontier Foundation , and Public Knowledge . Students for Free Culture has over 30 chapters on college campuses around the world, [2] and a history of grassroots activism.
Students for Free Culture is sometimes referred to as "FreeCulture", "the Free Culture Movement", and other variations on the "free culture" theme, but none of those are its official name. It is officially Students for Free Culture, as set for in the new bylaws that were ratified by its chapters on October 1, 2007, which changed its name from FreeCulture.org to Students for Free Culture. [3]

Goals
Students for Free Culture has stated its goals in a "manifesto":
It has yet to publish a more "official" mission statement, but some of its goals are:

Purpose
According to its website, [5] Students for Free Culture has four main functions within the free culture movement:

History

Initial stirrings at Swarthmore College
Students for Free Culture had its origins in the Swarthmore Coalition for the Digital Commons (SCDC, now Free Culture Swarthmore ), a student group at Swarthmore College which would eventually become the first Students for Free Culture chapter. The SCDC was founded in 2003 by students Luke Smith and Nelson Pavlosky , and was originally focused on issues related to free software , digital restrictions management , and treacherous computing , inspired largely by the Free Software Foundation . [6] After watching Lawrence Lessig 's OSCON 2002 speech entitled "free culture" [7] however, they expanded the club's scope to cover cultural participation in general (rather than just in the world of software and computers), and began tackling issues such as copyright reform.

OPG v. Diebold case
Within a couple of months of founding the SCDC, Smith and Pavlosky became embroiled in the controversy surrounding Diebold Election Systems (now Premier Election Solutions ), a voting machine manufacturer accused of making bug-ridden and insecure electronic voting machines. The SCDC had been concerned about electronic voting machines using proprietary software rather than open source software, and kept an eye on the situation. Their alarm grew when a copy of Diebold's internal e-mail archives leaked onto the Internet, revealing questionable practices at Diebold and possible flaws with Diebold's machines, and they were spurred into action when Diebold began sending legal threats to voting activists who posted the e-mails on their websites. Diebold was claiming that the e-mails were their copyrighted material, and that anyone who posted these e-mails online was infringing upon their intellectual property. The SCDC posted the e-mail archive on its website and prepared for the inevitable legal threats.
Diebold sent takedown notices under the DMCA to the SCDC's ISP , Swarthmore College. Swarthmore took down the SCDC website, and the SCDC co-founders sought legal representation. [8] They contacted the Electronic Frontier Foundation for help, and discovered that they had an opportunity to sign on to an existing lawsuit against Diebold, OPG v. Diebold , with co-plaintiffs from a non-profit ISP called the Online Policy Group who had also received legal threats from Diebold. With pro bono legal representation from EFF and the Stanford Cyberlaw Clinic , they sued Diebold for abusing copyright law to suppress freedom of speech online. After a year of legal battles, the judge ruled that posting the e-mails online was a fair use , and that Diebold had violated the DMCA by misrepresenting their copyright claims over the e-mails.
The network of contacts that Smith and Pavlosky built during the lawsuit, including dozens of students around the country who had also hosted the Diebold memos on their websites, gave them momentum they needed to found an international student movement based on the same free culture principles as the SCDC. They purchased the domain name Freeculture.org and began building a website, while contacting student activists at other schools who could help them start the organization.

FreeCulture.org launching at Swarthmore
On April 23, 2004, Smith and Pavlosky announced the official launch of FreeCulture.org, [9] in an event at Swarthmore College featuring Lawrence Lessig as the keynote speaker [10] [11] (Lessig had released his book Free Culture less than a month beforehand.) The SCDC became the first Freeculture.org chapter (beginning the process of changing its name to Free Culture Swarthmore), and students from other schools in the area who attended the launch went on to found chapters on their campuses, including Bryn Mawr College and Franklin and Marshall . [12]

Internet campaigns
FreeCulture.org began by launching a number of internet campaigns, in an attempt to raise its profile and bring itself to the attention of college students. These have covered issues ranging from defending artistic freedom ( Barbie in a Blender ) to fighting the Induce Act (Save The iPod), from celebrating Creative Commons licenses and the public domain ( Undead Art ) to opposing business method patents ( Cereal Solidarity ). While these one-shot websites succeeded in attracting attention from the press and encouraged students to get involved, they didn't directly help the local chapters, and the organization now concentrates less on web campaigns than it did in the past. However, their recent Down With DRM video contest was a successful "viral video" campaign against DRM , and internet campaigns remain an important tool in free culture activism.

Increased emphasis on local chapters
Today [ when? ] the organization focuses on providing services to its local campus chapters, including web services such as mailing lists and wikis, pamphlets and materials for tabling, and organizing conferences where chapter members can meet up. Active chapters are located at schools such as New York University (NYU), Harvard , MIT , Fordham Law , Dartmouth , University of Florida , Swarthmore , USC , Emory , Reed , and Yale .
The NYU chapter made headlines when it began protesting outside of record stores against DRM on CDs during the Sony rootkit scandal, [13] resulting in similar protests around New York and Philadelphia. [14]
In 2008, the MIT chapter developed and released YouTomb , a website to track videos removed by DMCA takedown from YouTube . [15]
Other activities at local chapters include:

Structure
Students for Free Culture began as a loose confederation of student groups on different campuses, but it has been moving towards becoming an official tax-exempt non-profit.
With the passage of official bylaws, Students for Free Culture now has a clear governance structure which makes it accountable to its chapters. The supreme decision-making body is the Board of Directors, which is elected once a year by the chapters, using a Schulze method for voting. It is meant to make long-term, high-level decisions, and should not meddle excessively in lower-level decisions. Practical everyday decisions will be made by the Core team, composed of any students who are members of chapters and meet the attendance requirements. Really low-level decisions and minutiae will be handled by a coordinator, who ideally will be a paid employee of the organization, and other volunteers and assistants. A new board of directors was elected in February 2008, [25] and a new Core Team was assembled shortly thereafter. There is no coordinator yet. [ when? ]
WebPage index: 00192
Peter Suber
Peter Dain Suber (born November 8, 1951) is a philosopher specializing in the philosophy of law and open access to knowledge. He is a Senior Researcher at the Berkman Klein Center for Internet & Society , Director of the Harvard Office for Scholarly Communication, [4] and Director of the Harvard Open Access Project (HOAP). [1] [5] [6] Suber is known as a leading voice in the open access movement, [7] [8] [9] [10] [11] [12] [13] [14] [15] [ excessive citations ] and as the creator of the game Nomic .

Education
Suber graduated from Earlham College in 1973, received a PhD degree in philosophy in 1978, writing a dissertation on Søren Kierkegaard [16] and a Juris Doctor degree in 1982, both from Northwestern University .

Career
Previously, Suber was senior research professor of philosophy at Earlham College , the open access project director at Public Knowledge , a senior researcher at Scholarly Publishing and Academic Resources Coalition (SPARC) ,. [17] He is a member of the Board of Enabling Open Scholarship , [18] the Advisory Boards at the Wikimedia Foundation , the Open Knowledge Foundation , and the advisory boards of other organizations devoted to open access and an information commons.
Suber worked as a stand-up comic from 1976 to 1981, including an appearance on The Tonight Show Starring Johnny Carson in 1976. Suber returned to Earlham College as a professor from 1982 to 2003 where he taught classes on philosophy, law , logic , and Kant 's Critique of Pure Reason , among other topics.
Suber participated in the 2001 meeting that led to the world's first major international open access initiative, the Budapest Open Access Initiative . He wrote Open Access News and the SPARC Open Access Newsletter , considered the most authoritative blog and newsletter on open access. He is also the founder of the Open Access Tracking Project , and co-founder, with Robin Peek, of the Open Access Directory .
In philosophy, Suber is the author of The Paradox of Self-Amendment , [19] the first book-length study of self-referential paradoxes in law, and The Case of the Speluncean Explorers: Nine New Opinions , [20] the first book-length "rehearing" of Lon Fuller's classic, fictional case . He has also written many articles on self-reference, ethics, formal and informal logic, the philosophy of law, and the history of philosophy. [21]
He has written many articles on open access to science and scholarship. [22] His 2012 book, Open Access , was published by MIT Press and released under a Creative Commons license . [2] His latest book is a collection of 44 of his most influential articles about open access, Knowledge Unbound: Selected Writings on Open Access, 2002–2010 , also published by MIT Press under a Creative Commons license . [23]

Honours and awards
Lingua Franca magazine named Suber one of Academia's 20 Most Wired Faculty in 1999. [24] Readers of The Charleston Advisor gave him a special Readers' Choice Award in October 2006, "Non-Librarian Working for Our Cause." [25] The American Library Association named him the winner of the Lyman Ray Patterson Copyright Award for 2011. [3] Choice named his book on Open Access [2] "an Outstanding Academic Title for 2013." [26]

Personal life
Suber is married to Liffey Thorpe, professor emerita of Classics at Earlham College, with whom he has two daughters. Since 2003, he and Thorpe have resided in Brooksville, Maine . [27]
WebPage index: 00193
TPB AFK
TPB AFK: The Pirate Bay Away From Keyboard is a documentary film released on 8 February 2013, directed by Simon Klose , based on the lives of the three founders of The Pirate Bay : Peter Sunde , Fredrik Neij and Gottfrid Svartholm . [1] Filming began in Summer 2008, and concluded on 25 February 2012. [2]

Production
The film's website was launched on 28 August 2010, along with a Kickstarter campaign to raise US$ 25,000 to hire an editor after the Court of Appeal trial . The campaign was fully funded within three days and raised $51,424 in total. [3] [4] [5] In February 2011, the Swedish government's Arts Grants Committee Konstnärsnämnden [6] granted the project an additional 200,000 SEK (≈ $30,000). [7] The film was pitched at Sheffield Doc/Fest 's 2009 MeetMarket.

Release
The full film was released under a Creative Commons [8] license (BY-NC-ND) onto The Pirate Bay and other BitTorrent sites. Also, a four-minute shorter version was released at the same time for those who wish to remix or re-edit their own version of the film, featuring an edit with certain copyright restricted content removed, under a different Creative Commons BY-NC-SA license.
For those who wish to support the creators, apart from online donations, they can buy the DVD version and digital download . The pre-order price of the DVD is $23 and a digital download is $10, which comes with deleted scenes and bonus material. Pre-orders can be made via the official movie website. TPB AFK's premiered at the 63rd Berlin International Film Festival on 8 February 2013, [9] opening the festival's documentary section, and was released online for worldwide free download (or purchase) at exactly the same time on YouTube and on The Pirate Bay.
On 19 February 2013, the film was broadcast on BBC Four in the UK as part of the BBC 's Storyville documentary series strand.

Reception
Peter Sunde , one of the main characters in the film, wrote on his blog, that he has "mixed feelings about the movie and the release of it". While he likes the technical side, he has serious issues with some scenes and general attitude of the film. This includes too much focus put on the trial, too dark depiction of it and portraying himself beyond self recognition. Despite having such different views on the subject, he regards the director as a friend. [10]

Censorship by Hollywood
On May 2013, Hollywood studios such as Viacom , Paramount , Fox and Lionsgate started to censor Google Search links pointing to the documentary, [11] [12] an action criticized by the director of the film Simon Klose . [13] On June, after the initial controversy, HBO and Lions Gate sent additional bogus DMCA takedown notices to Google requesting the removal of links related with the TPB AFK. [14] [15] In response, Simon Klose contacted Chilling Effects which recommended him to file a DMCA counter-notice where he explained that the purpose is "to share the film as much as possible". [16] Two months later, the censored links were reinstated only after public complaints made by the film director. [17]
WebPage index: 00194
Least-concern species
A least concern ( LC ) species is one which has been categorized by the International Union for Conservation of Nature as evaluated but not qualified for any other category. As such they do not qualify as threatened , near threatened , or (before 2001) conservation dependent .
Species cannot be assigned the Least Concern category unless they have had their population status evaluated. That is, adequate information is needed to make a direct, or indirect, assessment of its risk of extinction based on its distribution or population status.
Since 2001 the category has had the abbreviation "LC", following the IUCN 2001 Categories & Criteria (version 3.1). [1] However, around 20% of least concern taxa (3261 of 15636) in the IUCN database use the code "LR/lc", which indicates they have not been re-evaluated since 2000. Prior to 2001 "least concern" was a subcategory of the "Lower Risk" category and assigned the code "LR/lc" or (lc).
While "least concern" is not considered a red listed category by the IUCN, the 2006 Red List still assigns the category to 15636 taxa. The number of animal species listed in this category totals 14033 (which includes several undescribed species such as a frog from the genus Philautus [2] ). There are also 101 animal subspecies listed and 1500 plant taxa (1410 species, 55 subspecies, and 35 varieties). There are also two animal subpopulations listed: the Australasian and Southern African subpopulations of spiny dogfish . No fungi or protista have the classification, though only four species in those kingdoms have been evaluated by the IUCN. Humans qualify for this category, and in 2008 were formally assessed [3] as such by the IUCN.

See also

Notes and references

External links
WebPage index: 00195
Animal
Animals are multicellular , eukaryotic organisms of the kingdom Animalia (also called Metazoa ). The animal kingdom emerged as a clade within Apoikozoa as the sister group to the choanoflagellates . Animals are motile , meaning they can move spontaneously and independently at some point in their lives. Their body plan eventually becomes fixed as they develop , although some undergo a process of metamorphosis later in their lives. All animals are heterotrophs : they must ingest other organisms or their products for sustenance .
Most known animal phyla appeared in the fossil record as marine species during the Cambrian explosion , about 542 million years ago. Animals can be divided broadly into vertebrates and invertebrates . Vertebrates have a backbone or spine ( vertebral column ), and amount to less than five percent of all described animal species . They include fish , amphibians , reptiles , birds and mammals . The remaining animals are the invertebrates, which lack a backbone. These include molluscs ( clams , oysters , octopuses , squid , snails ); arthropods ( millipedes , centipedes , insects , spiders , scorpions , crabs , lobsters , shrimp ); annelids ( earthworms , leeches ), nematodes ( filarial worms , hookworms ), flatworms ( tapeworms , liver flukes ), cnidarians ( jellyfish , sea anemones , corals ), ctenophores (comb jellies), and sponges . The study of animals is called zoology .

Etymology
The word "animal" comes from the Latin animalis , meaning having breath , having soul or living being . [3] In everyday non-scientific usage the word excludes humans – that is, "animal" is often used to refer only to non-human members of the kingdom Animalia; often, only closer relatives of humans such as mammals and other vertebrates, are meant. [4] The biological definition of the word refers to all members of the kingdom Animalia, encompassing creatures as diverse as sponges , jellyfish , insects , and humans . [5]

History of classification
Aristotle divided the living world between animals and plants , and this was followed by Carl Linnaeus , in the first hierarchical classification. [7] In Linnaeus's original scheme, the animals were one of three kingdoms, divided into the classes of Vermes , Insecta , Pisces , Amphibia , Aves , and Mammalia . Since then the last four have all been subsumed into a single phylum, the Chordata , whereas the various other forms have been separated out.
In 1874, Ernst Haeckel divided the animal kingdom into two subkingdoms: Metazoa (multicellular animals) and Protozoa (single-celled animals). [8] The protozoa were later moved to the kingdom Protista , leaving only the metazoa. Thus Metazoa is now considered a synonym of Animalia. [9]

Characteristics
Animals have several characteristics that set them apart from other living things. Animals are eukaryotic and multicellular , [10] which separates them from bacteria and most protists . They are heterotrophic , [11] generally digesting food in an internal chamber, which separates them from plants and algae . [12] They are also distinguished from plants, algae, and fungi by lacking rigid cell walls . [13] All animals are motile , [14] if only at certain life stages. In most animals, embryos pass through a blastula stage , [15] which is a characteristic exclusive to animals.

Structure
With a few exceptions, most notably the sponges (Phylum Porifera) and Placozoa , animals have bodies differentiated into separate tissues . These include muscles , which are able to contract and control locomotion, and nerve tissues , which send and process signals. Typically, there is also an internal digestive chamber, with one or two openings. [16] Animals with this sort of organization are called metazoans, or eumetazoans when the former is used for animals in general. [17]
All animals have eukaryotic cells, surrounded by a characteristic extracellular matrix composed of collagen and elastic glycoproteins . [18] This may be calcified to form structures like shells , bones , and spicules . [19] During development, it forms a relatively flexible framework [20] upon which cells can move about and be reorganized, making complex structures possible. In contrast, other multicellular organisms , like plants and fungi, have cells held in place by cell walls, and so develop by progressive growth. [16] Also, unique to animal cells are the following intercellular junctions: tight junctions , gap junctions , and desmosomes . [21]

Reproduction and development
Nearly all animals undergo some form of sexual reproduction . [23] They produce haploid gametes by meiosis (see Origin and function of meiosis ). The smaller, motile gametes are spermatozoa and the larger, non-motile gametes are ova . [24] These fuse to form zygotes , which develop into new individuals [25] (see Allogamy ).
Many animals are also capable of asexual reproduction . [26] This may take place through parthenogenesis , where fertile eggs are produced without mating, budding, or fragmentation . [27]
A zygote initially develops into a hollow sphere, called a blastula , [28] which undergoes rearrangement and differentiation. In sponges, blastula larvae swim to a new location and develop into a new sponge. [29] In most other groups, the blastula undergoes more complicated rearrangement. [30] It first invaginates to form a gastrula with a digestive chamber, and two separate germ layers —an external ectoderm and an internal endoderm . [31] In most cases, a mesoderm also develops between them. [32] These germ layers then differentiate to form tissues and organs. [33]

Inbreeding avoidance
During sexual reproduction , mating with a close relative ( inbreeding ) generally leads to inbreeding depression . For instance, inbreeding was found to increase juvenile mortality in 11 small animal species. [34] Inbreeding depression is considered to be largely due to expression of deleterious recessive mutations . [35] Mating with unrelated or distantly related members of the same species is generally thought to provide the advantage of masking deleterious recessive mutations in progeny. [36] (see Heterosis ). Animals have evolved numerous diverse mechanisms for avoiding close inbreeding and promoting outcrossing [37] (see Inbreeding avoidance ).
As indicated in the image of chimpanzees, they have adopted dispersal as a way to separate close relatives and prevent inbreeding. [37] Their dispersal route is known as natal dispersal, whereby individuals move away from the area of birth.
In various species, such as the splendid fairywren , females benefit by mating with multiple males, thus producing more offspring of higher genetic quality. Females that are pair bonded to a male of poor genetic quality, as is the case in inbreeding, are more likely to engage in extra-pair copulations in order to improve their reproductive success and the survivability of their offspring. [38]

Food and energy sourcing
All animals are heterotrophs , meaning that they feed directly or indirectly on other living things. [39] They are often further subdivided into groups such as carnivores , herbivores , omnivores , and parasites . [40]
Predation is a biological interaction where a predator (a heterotroph that is hunting) feeds on its prey (the organism that is attacked). [41] Predators may or may not kill their prey prior to feeding on them, but the act of predation almost always results in the death of the prey. [42] The other main category of consumption is detritivory , the consumption of dead organic matter . [43] It can at times be difficult to separate the two feeding behaviours , for example, where parasitic species prey on a host organism and then lay their eggs on it for their offspring to feed on its decaying corpse. Selective pressures imposed on one another has led to an evolutionary arms race between prey and predator, resulting in various antipredator adaptations . [44]
Most animals indirectly use the energy of sunlight by eating plants or plant-eating animals. Most plants use light to convert inorganic molecules in their environment into carbohydrates , fats , proteins and other biomolecules, characteristically containing reduced carbon in the form of carbon-hydrogen bonds. Starting with carbon dioxide (CO 2 ) and water (H 2 O), photosynthesis converts the energy of sunlight into chemical energy in the form of simple sugars (e.g., glucose ), with the release of molecular oxygen . These sugars are then used as the building blocks for plant growth, including the production of other biomolecules. [16] When an animal eats plants (or eats other animals which have eaten plants), the reduced carbon compounds in the food become a source of energy and building materials for the animal. [45] They are either used directly to help the animal grow, or broken down, releasing stored solar energy, and giving the animal the energy required for motion. [46] [47]
Animals living close to hydrothermal vents and cold seeps on the ocean floor are not dependent on the energy of sunlight. [48] Instead chemosynthetic archaea and bacteria form the base of the food chain . [49]

Origin and fossil record
Animals are generally considered to have emerged within flagellated eukaryota. [51] Their closest known living relatives are the choanoflagellates , collared flagellates that have a morphology similar to the choanocytes of certain sponges. [52] Molecular studies place animals in a supergroup called the opisthokonts , which also include the choanoflagellates, fungi and a few small parasitic protists . [53] The name comes from the posterior location of the flagellum in motile cells, such as most animal spermatozoa, whereas other eukaryotes tend to have anterior flagella. [54]
The first fossils that might represent animals appear in the Trezona Formation at Trezona Bore, West Central Flinders, South Australia . [55] These fossils are interpreted as being early sponges. They were found in 665-million-year-old rock. [55]
The next oldest possible animal fossils are found towards the end of the Precambrian , around 610 million years ago, and are known as the Ediacaran or Vendian biota . [56] These are difficult to relate to later fossils, however. Some may represent precursors of modern phyla, but they may be separate groups, and it is possible they are not really animals at all. [57]
Aside from them, most known animal phyla make a more or less simultaneous appearance during the Cambrian period, about 542 million years ago. [58] It is still disputed whether this event, called the Cambrian explosion , is due to a rapid divergence between different groups or due to a change in conditions that made fossilization possible.
Some palaeontologists suggest that animals appeared much earlier than the Cambrian explosion, possibly as early as 1 billion years ago. [59] Trace fossils such as tracks and burrows found in the Tonian period indicate the presence of triploblastic worms, like metazoans, roughly as large (about 5 mm wide) and complex as earthworms . [60] During the beginning of the Tonian period around 1 billion years ago, there was a decrease in Stromatolite diversity, which may indicate the appearance of grazing animals, since stromatolite diversity increased when grazing animals became extinct at the End Permian and End Ordovician extinction events, and decreased shortly after the grazer populations recovered. However the discovery that tracks very similar to these early trace fossils are produced today by the giant single-celled protist Gromia sphaerica casts doubt on their interpretation as evidence of early animal evolution. [61] [62]

Groups of animals
Traditional morphological and modern molecular phylogenetic analysis have both recognized a major evolutionary transition from "non-bilaterian" animals, which are those lacking a bilaterally symmetric body plan ( Porifera , Ctenophora , Cnidaria and Placozoa ), to "bilaterian" animals ( Bilateria ) whose body plans display bilateral symmetry. The latter are further classified based on a major division between Deuterostomes and Protostomes . The relationships among non-bilaterian animals are disputed, but all bilaterian animals are thought to form a monophyletic group. Current understanding of the relationships among the major groups of animals is summarized by the following cladogram: [63]

Non-bilaterian animals: Porifera, Placozoa, Ctenophora, Cnidaria
Several animal phyla are recognized for their lack of bilateral symmetry , and are thought to have diverged from other animals early in evolution. Among these, the sponges ( Porifera ) were long thought to have diverged first, representing the oldest animal phylum. [64] They lack the complex organization found in most other phyla. [65] Their cells are differentiated, but in most cases not organized into distinct tissues. [66] Sponges typically feed by drawing in water through pores. [67] However, a series of phylogenomic studies from 2008-2015 have found support for Ctenophora , or comb jellies, as the basal lineage of animals. [68] [69] [70] [71] This result has been controversial, since it would imply that sponges may not be so primitive, but may instead be secondarily simplified. [68] Other researchers have argued that the placement of Ctenophora as the earliest-diverging animal phylum is a statistical anomaly caused by the high rate of evolution in ctenophore genomes. [72] [73] [74] [75]
Among the other phyla, the Ctenophora and the Cnidaria , which includes sea anemones , corals , and jellyfish , are radially symmetric and have digestive chambers with a single opening, which serves as both the mouth and the anus. [76] Both have distinct tissues, but they are not organized into organs . [77] There are only two main germ layers, the ectoderm and endoderm, with only scattered cells between them. As such, these animals are sometimes called diploblastic . [78] The tiny placozoans are similar, but they do not have a permanent digestive chamber.
The Myxozoa , microscopic parasites that were originally considered Protozoa, are now believed to have evolved within Cnidaria. [79]

Bilaterian animals
The remaining animals form a monophyletic group called the Bilateria . For the most part, they are bilaterally symmetric , and often have a specialized head with feeding and sensory organs. The body is triploblastic , i.e. all three germ layers are well-developed, and tissues form distinct organs. The digestive chamber has two openings, a mouth and an anus, and there is also an internal body cavity called a coelom or pseudocoelom. There are exceptions to each of these characteristics, however—for instance adult echinoderms are radially symmetric, and certain parasitic worms have extremely simplified body structures.
Genetic studies have considerably changed our understanding of the relationships within the Bilateria. Most appear to belong to two major lineages: the deuterostomes and the protostomes , the latter of which includes the Ecdysozoa , and Lophotrochozoa . The Chaetognatha or arrow worms have been traditionally classified as deuterostomes, though recent molecular studies have identified this group as a basal protostome lineage. [80]
In addition, there are a few small groups of bilaterians with relatively cryptic morphology whose relationships with other animals are not well-established. For example, recent molecular studies have identified Acoelomorpha and Xenoturbella as comprising a monophyletic group, [81] [82] [83] but studies disagree as to whether this group evolved from within deuterostomes, [82] or whether it represents the sister group to all other bilaterian animals ( Nephrozoa ). [84] [85] Other groups of uncertain affinity include the Rhombozoa and Orthonectida . One phyla, the Monoblastozoa , was described by a scientist in 1892, but so far there have been no evidence of its existence. [86]

Deuterostomes and protostomes
Deuterostomes differ from protostomes in several ways. Animals from both groups possess a complete digestive tract. However, in protostomes, the first opening of the gut to appear in embryological development (the archenteron ) develops into the mouth, with the anus forming secondarily. In deuterostomes the anus forms first, with the mouth developing secondarily. [87] In most protostomes, cells simply fill in the interior of the gastrula to form the mesoderm, called schizocoelous development, but in deuterostomes, it forms through invagination of the endoderm, called enterocoelic pouching. [88] Deuterostome embryos undergo radial cleavage during cell division, while protostomes undergo spiral cleavage. [89]
All this suggests the deuterostomes and protostomes are separate, monophyletic lineages. The main phyla of deuterostomes are the Echinodermata and Chordata . [90] The former are radially symmetric and exclusively marine, such as starfish , sea urchins , and sea cucumbers . [91] The latter are dominated by the vertebrates, animals with backbones. [92] These include fish, amphibians, reptiles, birds, and mammals. [93]
In addition to these, the deuterostomes also include the Hemichordata , or acorn worms, which are thought to be closely related to Echinodermata forming a group known as Ambulacraria . [94] [95] Although they are not especially prominent today, the important fossil graptolites may belong to this group. [96]

Ecdysozoa
The Ecdysozoa are protostomes, named after the common trait of growth by moulting or ecdysis . [97] The largest animal phylum belongs here, the Arthropoda , including insects, spiders, crabs, and their kin. All these organisms have a body divided into repeating segments, typically with paired appendages. Two smaller phyla, the Onychophora and Tardigrada , are close relatives of the arthropods and share these traits. The ecdysozoans also include the Nematoda or roundworms, perhaps the second largest animal phylum. Roundworms are typically microscopic, and occur in nearly every environment where there is water. [98] A number are important parasites. [99] Smaller phyla related to them are the Nematomorpha or horsehair worms, and the Kinorhyncha , Priapulida , and Loricifera . These groups have a reduced coelom, called a pseudocoelom.

Lophotrochozoa
The Lophotrochozoa , evolved within Protostomia, include two of the most successful animal phyla, the Mollusca and Annelida . [100] [101] The former, which is the second-largest animal phylum by number of described species, includes animals such as snails , clams , and squids , and the latter comprises the segmented worms, such as earthworms and leeches . These two groups have long been considered close relatives because of the common presence of trochophore larvae, but the annelids were considered closer to the arthropods because they are both segmented. [102] Now, this is generally considered convergent evolution , owing to many morphological and genetic differences between the two phyla. [103] Lophotrochozoa also includes the Nemertea or ribbon worms, the Sipuncula , and several phyla that have a ring of ciliated tentacles around the mouth, called a lophophore . [104] These were traditionally grouped together as the lophophorates. [105] but it now appears that the lophophorate group may be paraphyletic , [106] with some closer to the nemerteans and some to the molluscs and annelids. [107] [108] They include the Brachiopoda or lamp shells, which are prominent in the fossil record, the Entoprocta , the Phoronida , and possibly the Bryozoa or moss animals. [109]
The Platyzoa include the phylum Platyhelminthes , the flatworms. [110] These were originally considered some of the most primitive Bilateria, but it now appears they developed from more complex ancestors. [111] A number of parasites are included in this group, such as the flukes and tapeworms . [110] Flatworms are acoelomates , lacking a body cavity, as are their closest relatives, the microscopic Gastrotricha . [112] The other platyzoan phyla are mostly microscopic and pseudocoelomate . The most prominent are the Rotifera or rotifers, which are common in aqueous environments. They also include the Acanthocephala or spiny-headed worms, the Gnathostomulida , Micrognathozoa , and possibly the Cycliophora . [113] These groups share the presence of complex jaws, from which they are called the Gnathifera .
A relationship between the Brachiopoda and Nemertea has been suggested by molecular data. [114] A second study has also suggested this relationship. [115] This latter study also suggested that Annelida and Mollusca may be sister clades. Another study has suggested that Annelida and Mollusca are sister clades. [116] This clade has been termed the Neotrochozoa .

Number of extant species
Animals can be divided into two broad groups: vertebrates (animals with a backbone ) and invertebrates (animals without a backbone). Half of all described vertebrate species are fishes and three-quarters of all described invertebrate species are insects. The following table lists the number of described extant species for each major animal subgroup as estimated for the IUCN Red List of Threatened Species , 2014.3. [117]
Over 95% of the described animal species in the world are invertebrates.

Model organisms
Because of the great diversity found in animals, it is more economical for scientists to study a small number of chosen species so that connections can be drawn from their work and conclusions extrapolated about how animals function in general. Because they are easy to keep and breed, the fruit fly Drosophila melanogaster and the nematode Caenorhabditis elegans have long been the most intensively studied metazoan model organisms , and were among the first life-forms to be genetically sequenced. This was facilitated by the severely reduced state of their genomes , but as many genes , introns , and linkages lost, these ecdysozoans can teach us little about the origins of animals in general. The extent of this type of evolution within the superphylum will be revealed by the crustacean, annelid, and molluscan genome projects currently in progress. Analysis of the starlet sea anemone genome has emphasized the importance of sponges, placozoans, and choanoflagellates , also being sequenced, in explaining the arrival of 1500 ancestral genes unique to the Eumetazoa. [118]
An analysis of the homoscleromorph sponge Oscarella carmela also suggests that the last common ancestor of sponges and the eumetazoan animals was more complex than previously assumed. [119]
Other model organisms belonging to the animal kingdom include the house mouse ( Mus musculus ), laboratory rat ( Rattus norvegicus ) and zebrafish ( Danio rerio ).

See also
